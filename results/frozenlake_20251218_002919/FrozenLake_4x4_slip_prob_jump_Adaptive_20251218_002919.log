wandb: Currently logged in as: hungtrab (hungtrab-hanoi-university-of-science-and-technology) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: setting up run npesjsqb
wandb: Tracking run with wandb version 0.23.1
wandb: Run data is saved locally in logs/FrozenLake_4x4_slip_prob_jump_Adaptive_20251218_002919/wandb/run-20251218_003042-npesjsqb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run FrozenLake_4x4_slip_prob_jump_Adaptive_20251218_002919
wandb: â­ï¸ View project at https://wandb.ai/hungtrab-hanoi-university-of-science-and-technology/FrozenLake_Drift_Research
wandb: ðŸš€ View run at https://wandb.ai/hungtrab-hanoi-university-of-science-and-technology/FrozenLake_Drift_Research/runs/npesjsqb
/home/hungchan/miniconda3/envs/rl_hf_course/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run TRPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.
  warnings.warn(
--- Training Start: FrozenLake_4x4_slip_prob_jump_Adaptive_20251218_002919 ---
>>> [Wrapper] Initialized Non-Stationary FrozenLake
    - slip_prob: jump (base=0.67)
>>> Initializing TRPO with kwargs: ['policy', 'env', 'learning_rate', 'gamma', 'verbose', 'tensorboard_log', 'n_steps', 'batch_size']
Using cuda device
Wrapping the env in a DummyVecEnv.
Logging to logs/FrozenLake_4x4_slip_prob_jump_Adaptive_20251218_002919_0
>>> [DriftAdaptiveCallback] Training Started
    Algorithm: TRPO
    Target Param: slip_prob (base=9.8)
    Scale Factor: 0.2
    
    Adaptive Hyperparameters:
      - Learning Rate: 0.001000
      - Target KL: 0.0100 (adapt=True)
-----------------------------------
| adaptive/            |          |
|    adaptation_factor | 1        |
|    algorithm         | TRPO     |
|    base_lr           | 0.001    |
|    base_target_kl    | 0.01     |
|    drift_magnitude   | 0        |
|    learning_rate     | 0.001    |
|    target_kl         | 0.01     |
| env/                 |          |
|    base_value        | 9.8      |
|    slip_prob         | 9.8      |
| rollout/             |          |
|    ep_len_mean       | 5.68     |
|    ep_rew_mean       | 0        |
| time/                |          |
|    fps               | 398      |
|    iterations        | 1        |
|    time_elapsed      | 0        |
|    total_timesteps   | 128      |
-----------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.17     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 458      |
|    iterations             | 2        |
|    time_elapsed           | 0        |
|    total_timesteps        | 256      |
| train/                    |          |
|    explained_variance     | -143     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00496  |
|    learning_rate          | 0.001    |
|    n_updates              | 1        |
|    policy_objective       | 0.0269   |
|    value_loss             | 0.0022   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.38     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 524      |
|    iterations             | 3        |
|    time_elapsed           | 0        |
|    total_timesteps        | 384      |
| train/                    |          |
|    explained_variance     | -20.7    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00193  |
|    learning_rate          | 0.001    |
|    n_updates              | 2        |
|    policy_objective       | 0.0651   |
|    value_loss             | 0.000106 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.01     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 569      |
|    iterations             | 4        |
|    time_elapsed           | 0        |
|    total_timesteps        | 512      |
| train/                    |          |
|    explained_variance     | -50.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00506  |
|    learning_rate          | 0.001    |
|    n_updates              | 3        |
|    policy_objective       | 0.0437   |
|    value_loss             | 3.07e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.29     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 600      |
|    iterations             | 5        |
|    time_elapsed           | 1        |
|    total_timesteps        | 640      |
| train/                    |          |
|    explained_variance     | -15.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00263  |
|    learning_rate          | 0.001    |
|    n_updates              | 4        |
|    policy_objective       | 0.0503   |
|    value_loss             | 0.000505 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.5      |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 623      |
|    iterations             | 6        |
|    time_elapsed           | 1        |
|    total_timesteps        | 768      |
| train/                    |          |
|    explained_variance     | -10      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00296  |
|    learning_rate          | 0.001    |
|    n_updates              | 5        |
|    policy_objective       | 0.0521   |
|    value_loss             | 1.52e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.94     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 638      |
|    iterations             | 7        |
|    time_elapsed           | 1        |
|    total_timesteps        | 896      |
| train/                    |          |
|    explained_variance     | 0.0282   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00192  |
|    learning_rate          | 0.001    |
|    n_updates              | 6        |
|    policy_objective       | 0.0424   |
|    value_loss             | 0.0237   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.48     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 646      |
|    iterations             | 8        |
|    time_elapsed           | 1        |
|    total_timesteps        | 1024     |
| train/                    |          |
|    explained_variance     | -1.57    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0015   |
|    learning_rate          | 0.001    |
|    n_updates              | 7        |
|    policy_objective       | 0.0506   |
|    value_loss             | 0.0017   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.61     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 653      |
|    iterations             | 9        |
|    time_elapsed           | 1        |
|    total_timesteps        | 1152     |
| train/                    |          |
|    explained_variance     | -78.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00118  |
|    learning_rate          | 0.001    |
|    n_updates              | 8        |
|    policy_objective       | 0.0493   |
|    value_loss             | 0.00226  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.19     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 666      |
|    iterations             | 10       |
|    time_elapsed           | 1        |
|    total_timesteps        | 1280     |
| train/                    |          |
|    explained_variance     | -0.122   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00427  |
|    learning_rate          | 0.001    |
|    n_updates              | 9        |
|    policy_objective       | 0.0524   |
|    value_loss             | 0.0441   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.79     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 673      |
|    iterations             | 11       |
|    time_elapsed           | 2        |
|    total_timesteps        | 1408     |
| train/                    |          |
|    explained_variance     | -9.33    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00229  |
|    learning_rate          | 0.001    |
|    n_updates              | 10       |
|    policy_objective       | 0.0523   |
|    value_loss             | 0.00132  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.82     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 678      |
|    iterations             | 12       |
|    time_elapsed           | 2        |
|    total_timesteps        | 1536     |
| train/                    |          |
|    explained_variance     | -5.22    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00472  |
|    learning_rate          | 0.001    |
|    n_updates              | 11       |
|    policy_objective       | 0.052    |
|    value_loss             | 9.68e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.74     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 682      |
|    iterations             | 13       |
|    time_elapsed           | 2        |
|    total_timesteps        | 1664     |
| train/                    |          |
|    explained_variance     | -48.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.000984 |
|    learning_rate          | 0.001    |
|    n_updates              | 12       |
|    policy_objective       | 0.0669   |
|    value_loss             | 5.5e-06  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.98     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 687      |
|    iterations             | 14       |
|    time_elapsed           | 2        |
|    total_timesteps        | 1792     |
| train/                    |          |
|    explained_variance     | -33.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00578  |
|    learning_rate          | 0.001    |
|    n_updates              | 13       |
|    policy_objective       | 0.0583   |
|    value_loss             | 1.76e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.97     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 691      |
|    iterations             | 15       |
|    time_elapsed           | 2        |
|    total_timesteps        | 1920     |
| train/                    |          |
|    explained_variance     | -90.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.000997 |
|    learning_rate          | 0.001    |
|    n_updates              | 14       |
|    policy_objective       | 0.0508   |
|    value_loss             | 3.19e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.31     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 692      |
|    iterations             | 16       |
|    time_elapsed           | 2        |
|    total_timesteps        | 2048     |
| train/                    |          |
|    explained_variance     | -11.7    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00468  |
|    learning_rate          | 0.001    |
|    n_updates              | 15       |
|    policy_objective       | 0.0411   |
|    value_loss             | 4.82e-09 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.25     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 693      |
|    iterations             | 17       |
|    time_elapsed           | 3        |
|    total_timesteps        | 2176     |
| train/                    |          |
|    explained_variance     | 0.0222   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00568  |
|    learning_rate          | 0.001    |
|    n_updates              | 16       |
|    policy_objective       | 0.0629   |
|    value_loss             | 0.0344   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.23     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 696      |
|    iterations             | 18       |
|    time_elapsed           | 3        |
|    total_timesteps        | 2304     |
| train/                    |          |
|    explained_variance     | -12.6    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00253  |
|    learning_rate          | 0.001    |
|    n_updates              | 17       |
|    policy_objective       | 0.0582   |
|    value_loss             | 0.000349 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.61     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 699      |
|    iterations             | 19       |
|    time_elapsed           | 3        |
|    total_timesteps        | 2432     |
| train/                    |          |
|    explained_variance     | 0.081    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00507  |
|    learning_rate          | 0.001    |
|    n_updates              | 18       |
|    policy_objective       | 0.0495   |
|    value_loss             | 0.0433   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.68     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 701      |
|    iterations             | 20       |
|    time_elapsed           | 3        |
|    total_timesteps        | 2560     |
| train/                    |          |
|    explained_variance     | -0.0162  |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00366  |
|    learning_rate          | 0.001    |
|    n_updates              | 19       |
|    policy_objective       | 0.0647   |
|    value_loss             | 0.055    |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.66     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 703      |
|    iterations             | 21       |
|    time_elapsed           | 3        |
|    total_timesteps        | 2688     |
| train/                    |          |
|    explained_variance     | -16.7    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0056   |
|    learning_rate          | 0.001    |
|    n_updates              | 20       |
|    policy_objective       | 0.056    |
|    value_loss             | 0.0018   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.15     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 22       |
|    time_elapsed           | 3        |
|    total_timesteps        | 2816     |
| train/                    |          |
|    explained_variance     | -46.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00148  |
|    learning_rate          | 0.001    |
|    n_updates              | 21       |
|    policy_objective       | 0.054    |
|    value_loss             | 0.000273 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.21     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 706      |
|    iterations             | 23       |
|    time_elapsed           | 4        |
|    total_timesteps        | 2944     |
| train/                    |          |
|    explained_variance     | -81.7    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00154  |
|    learning_rate          | 0.001    |
|    n_updates              | 22       |
|    policy_objective       | 0.0711   |
|    value_loss             | 2.7e-05  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.25     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 705      |
|    iterations             | 24       |
|    time_elapsed           | 4        |
|    total_timesteps        | 3072     |
| train/                    |          |
|    explained_variance     | 0.108    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00357  |
|    learning_rate          | 0.001    |
|    n_updates              | 23       |
|    policy_objective       | 0.0578   |
|    value_loss             | 0.0369   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.03     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 705      |
|    iterations             | 25       |
|    time_elapsed           | 4        |
|    total_timesteps        | 3200     |
| train/                    |          |
|    explained_variance     | -9.21    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00242  |
|    learning_rate          | 0.001    |
|    n_updates              | 24       |
|    policy_objective       | 0.0628   |
|    value_loss             | 0.00418  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7        |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 26       |
|    time_elapsed           | 4        |
|    total_timesteps        | 3328     |
| train/                    |          |
|    explained_variance     | 0.21     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00512  |
|    learning_rate          | 0.001    |
|    n_updates              | 25       |
|    policy_objective       | 0.0682   |
|    value_loss             | 0.0399   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.97     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 706      |
|    iterations             | 27       |
|    time_elapsed           | 4        |
|    total_timesteps        | 3456     |
| train/                    |          |
|    explained_variance     | -27.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0022   |
|    learning_rate          | 0.001    |
|    n_updates              | 26       |
|    policy_objective       | 0.0773   |
|    value_loss             | 0.00373  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.72     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 706      |
|    iterations             | 28       |
|    time_elapsed           | 5        |
|    total_timesteps        | 3584     |
| train/                    |          |
|    explained_variance     | -28      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00613  |
|    learning_rate          | 0.001    |
|    n_updates              | 27       |
|    policy_objective       | 0.0527   |
|    value_loss             | 2.49e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.52     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 707      |
|    iterations             | 29       |
|    time_elapsed           | 5        |
|    total_timesteps        | 3712     |
| train/                    |          |
|    explained_variance     | -26.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00335  |
|    learning_rate          | 0.001    |
|    n_updates              | 28       |
|    policy_objective       | 0.0572   |
|    value_loss             | 6.68e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.39     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 708      |
|    iterations             | 30       |
|    time_elapsed           | 5        |
|    total_timesteps        | 3840     |
| train/                    |          |
|    explained_variance     | -36.6    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00385  |
|    learning_rate          | 0.001    |
|    n_updates              | 29       |
|    policy_objective       | 0.0344   |
|    value_loss             | 9.87e-09 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.81     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 709      |
|    iterations             | 31       |
|    time_elapsed           | 5        |
|    total_timesteps        | 3968     |
| train/                    |          |
|    explained_variance     | -81.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00239  |
|    learning_rate          | 0.001    |
|    n_updates              | 30       |
|    policy_objective       | 0.0376   |
|    value_loss             | 1.36e-08 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.69     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 709      |
|    iterations             | 32       |
|    time_elapsed           | 5        |
|    total_timesteps        | 4096     |
| train/                    |          |
|    explained_variance     | -52.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00135  |
|    learning_rate          | 0.001    |
|    n_updates              | 31       |
|    policy_objective       | 0.0985   |
|    value_loss             | 1.19e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.06     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 709      |
|    iterations             | 33       |
|    time_elapsed           | 5        |
|    total_timesteps        | 4224     |
| train/                    |          |
|    explained_variance     | -41.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00233  |
|    learning_rate          | 0.001    |
|    n_updates              | 32       |
|    policy_objective       | 0.0669   |
|    value_loss             | 0.00371  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.18     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 709      |
|    iterations             | 34       |
|    time_elapsed           | 6        |
|    total_timesteps        | 4352     |
| train/                    |          |
|    explained_variance     | 0.0886   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00411  |
|    learning_rate          | 0.001    |
|    n_updates              | 33       |
|    policy_objective       | 0.0544   |
|    value_loss             | 0.0219   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.63     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 709      |
|    iterations             | 35       |
|    time_elapsed           | 6        |
|    total_timesteps        | 4480     |
| train/                    |          |
|    explained_variance     | -71.6    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00159  |
|    learning_rate          | 0.001    |
|    n_updates              | 34       |
|    policy_objective       | 0.0553   |
|    value_loss             | 0.00414  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.24     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 708      |
|    iterations             | 36       |
|    time_elapsed           | 6        |
|    total_timesteps        | 4608     |
| train/                    |          |
|    explained_variance     | -6.1     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00449  |
|    learning_rate          | 0.001    |
|    n_updates              | 35       |
|    policy_objective       | 0.0587   |
|    value_loss             | 7.28e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.6      |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 706      |
|    iterations             | 37       |
|    time_elapsed           | 6        |
|    total_timesteps        | 4736     |
| train/                    |          |
|    explained_variance     | -13.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.004    |
|    learning_rate          | 0.001    |
|    n_updates              | 36       |
|    policy_objective       | 0.0463   |
|    value_loss             | 3.08e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.82     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 705      |
|    iterations             | 38       |
|    time_elapsed           | 6        |
|    total_timesteps        | 4864     |
| train/                    |          |
|    explained_variance     | -65.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00278  |
|    learning_rate          | 0.001    |
|    n_updates              | 37       |
|    policy_objective       | 0.0322   |
|    value_loss             | 0.00123  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.79     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 39       |
|    time_elapsed           | 7        |
|    total_timesteps        | 4992     |
| train/                    |          |
|    explained_variance     | 0.0763   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00646  |
|    learning_rate          | 0.001    |
|    n_updates              | 38       |
|    policy_objective       | 0.119    |
|    value_loss             | 0.034    |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.89     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 702      |
|    iterations             | 40       |
|    time_elapsed           | 7        |
|    total_timesteps        | 5120     |
| train/                    |          |
|    explained_variance     | 0.311    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00627  |
|    learning_rate          | 0.001    |
|    n_updates              | 39       |
|    policy_objective       | 0.0306   |
|    value_loss             | 0.0359   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.73     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 701      |
|    iterations             | 41       |
|    time_elapsed           | 7        |
|    total_timesteps        | 5248     |
| train/                    |          |
|    explained_variance     | 0.113    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00721  |
|    learning_rate          | 0.001    |
|    n_updates              | 40       |
|    policy_objective       | 0.0781   |
|    value_loss             | 0.0474   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.95     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 701      |
|    iterations             | 42       |
|    time_elapsed           | 7        |
|    total_timesteps        | 5376     |
| train/                    |          |
|    explained_variance     | 0.14     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00541  |
|    learning_rate          | 0.001    |
|    n_updates              | 41       |
|    policy_objective       | 0.055    |
|    value_loss             | 0.0398   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.01     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 701      |
|    iterations             | 43       |
|    time_elapsed           | 7        |
|    total_timesteps        | 5504     |
| train/                    |          |
|    explained_variance     | -9.96    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00299  |
|    learning_rate          | 0.001    |
|    n_updates              | 42       |
|    policy_objective       | 0.0435   |
|    value_loss             | 0.0114   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.53     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 700      |
|    iterations             | 44       |
|    time_elapsed           | 8        |
|    total_timesteps        | 5632     |
| train/                    |          |
|    explained_variance     | -10.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00352  |
|    learning_rate          | 0.001    |
|    n_updates              | 43       |
|    policy_objective       | 0.0326   |
|    value_loss             | 0.00158  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.68     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 700      |
|    iterations             | 45       |
|    time_elapsed           | 8        |
|    total_timesteps        | 5760     |
| train/                    |          |
|    explained_variance     | -171     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00204  |
|    learning_rate          | 0.001    |
|    n_updates              | 44       |
|    policy_objective       | 0.0694   |
|    value_loss             | 0.00269  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.61     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 701      |
|    iterations             | 46       |
|    time_elapsed           | 8        |
|    total_timesteps        | 5888     |
| train/                    |          |
|    explained_variance     | 0.017    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00597  |
|    learning_rate          | 0.001    |
|    n_updates              | 45       |
|    policy_objective       | 0.0938   |
|    value_loss             | 0.0334   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.39     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 701      |
|    iterations             | 47       |
|    time_elapsed           | 8        |
|    total_timesteps        | 6016     |
| train/                    |          |
|    explained_variance     | -14.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00421  |
|    learning_rate          | 0.001    |
|    n_updates              | 46       |
|    policy_objective       | 0.0459   |
|    value_loss             | 0.00639  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.61     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 701      |
|    iterations             | 48       |
|    time_elapsed           | 8        |
|    total_timesteps        | 6144     |
| train/                    |          |
|    explained_variance     | -9.01    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00629  |
|    learning_rate          | 0.001    |
|    n_updates              | 47       |
|    policy_objective       | 0.0409   |
|    value_loss             | 0.000258 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.97     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 701      |
|    iterations             | 49       |
|    time_elapsed           | 8        |
|    total_timesteps        | 6272     |
| train/                    |          |
|    explained_variance     | -7.1     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00432  |
|    learning_rate          | 0.001    |
|    n_updates              | 48       |
|    policy_objective       | 0.0448   |
|    value_loss             | 1.1e-05  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.01     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 700      |
|    iterations             | 50       |
|    time_elapsed           | 9        |
|    total_timesteps        | 6400     |
| train/                    |          |
|    explained_variance     | -1.32    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00643  |
|    learning_rate          | 0.001    |
|    n_updates              | 49       |
|    policy_objective       | 0.0481   |
|    value_loss             | 6.48e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.16     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 700      |
|    iterations             | 51       |
|    time_elapsed           | 9        |
|    total_timesteps        | 6528     |
| train/                    |          |
|    explained_variance     | 0.00159  |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00692  |
|    learning_rate          | 0.001    |
|    n_updates              | 50       |
|    policy_objective       | 0.0396   |
|    value_loss             | 0.0533   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.73     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 702      |
|    iterations             | 52       |
|    time_elapsed           | 9        |
|    total_timesteps        | 6656     |
| train/                    |          |
|    explained_variance     | -29.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00524  |
|    learning_rate          | 0.001    |
|    n_updates              | 51       |
|    policy_objective       | 0.0423   |
|    value_loss             | 0.00307  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.63     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 702      |
|    iterations             | 53       |
|    time_elapsed           | 9        |
|    total_timesteps        | 6784     |
| train/                    |          |
|    explained_variance     | 0.228    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00646  |
|    learning_rate          | 0.001    |
|    n_updates              | 52       |
|    policy_objective       | 0.109    |
|    value_loss             | 0.0311   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.32     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 702      |
|    iterations             | 54       |
|    time_elapsed           | 9        |
|    total_timesteps        | 6912     |
| train/                    |          |
|    explained_variance     | -7.66    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0031   |
|    learning_rate          | 0.001    |
|    n_updates              | 53       |
|    policy_objective       | 0.0641   |
|    value_loss             | 0.0012   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.13     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 701      |
|    iterations             | 55       |
|    time_elapsed           | 10       |
|    total_timesteps        | 7040     |
| train/                    |          |
|    explained_variance     | -8.76    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00359  |
|    learning_rate          | 0.001    |
|    n_updates              | 54       |
|    policy_objective       | 0.0318   |
|    value_loss             | 6.14e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.57     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 701      |
|    iterations             | 56       |
|    time_elapsed           | 10       |
|    total_timesteps        | 7168     |
| train/                    |          |
|    explained_variance     | -9.7     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00668  |
|    learning_rate          | 0.001    |
|    n_updates              | 55       |
|    policy_objective       | 0.0737   |
|    value_loss             | 1.79e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.47     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 701      |
|    iterations             | 57       |
|    time_elapsed           | 10       |
|    total_timesteps        | 7296     |
| train/                    |          |
|    explained_variance     | 0.117    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00466  |
|    learning_rate          | 0.001    |
|    n_updates              | 56       |
|    policy_objective       | 0.0599   |
|    value_loss             | 0.0457   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.83     |
|    ep_rew_mean            | 0.05     |
| time/                     |          |
|    fps                    | 702      |
|    iterations             | 58       |
|    time_elapsed           | 10       |
|    total_timesteps        | 7424     |
| train/                    |          |
|    explained_variance     | 0.202    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00509  |
|    learning_rate          | 0.001    |
|    n_updates              | 57       |
|    policy_objective       | 0.0586   |
|    value_loss             | 0.0596   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.78     |
|    ep_rew_mean            | 0.05     |
| time/                     |          |
|    fps                    | 703      |
|    iterations             | 59       |
|    time_elapsed           | 10       |
|    total_timesteps        | 7552     |
| train/                    |          |
|    explained_variance     | 0.257    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00632  |
|    learning_rate          | 0.001    |
|    n_updates              | 58       |
|    policy_objective       | 0.0368   |
|    value_loss             | 0.0639   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.8      |
|    ep_rew_mean            | 0.05     |
| time/                     |          |
|    fps                    | 703      |
|    iterations             | 60       |
|    time_elapsed           | 10       |
|    total_timesteps        | 7680     |
| train/                    |          |
|    explained_variance     | -15.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00481  |
|    learning_rate          | 0.001    |
|    n_updates              | 59       |
|    policy_objective       | 0.0598   |
|    value_loss             | 0.00816  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.96     |
|    ep_rew_mean            | 0.05     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 61       |
|    time_elapsed           | 11       |
|    total_timesteps        | 7808     |
| train/                    |          |
|    explained_variance     | -6.55    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0074   |
|    learning_rate          | 0.001    |
|    n_updates              | 60       |
|    policy_objective       | 0.0414   |
|    value_loss             | 0.000235 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.19     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 705      |
|    iterations             | 62       |
|    time_elapsed           | 11       |
|    total_timesteps        | 7936     |
| train/                    |          |
|    explained_variance     | -0.0169  |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00751  |
|    learning_rate          | 0.001    |
|    n_updates              | 61       |
|    policy_objective       | 0.0422   |
|    value_loss             | 0.047    |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.66     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 706      |
|    iterations             | 63       |
|    time_elapsed           | 11       |
|    total_timesteps        | 8064     |
| train/                    |          |
|    explained_variance     | -4.27    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00472  |
|    learning_rate          | 0.001    |
|    n_updates              | 62       |
|    policy_objective       | 0.0687   |
|    value_loss             | 0.00079  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.76     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 707      |
|    iterations             | 64       |
|    time_elapsed           | 11       |
|    total_timesteps        | 8192     |
| train/                    |          |
|    explained_variance     | -11      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00302  |
|    learning_rate          | 0.001    |
|    n_updates              | 63       |
|    policy_objective       | 0.0809   |
|    value_loss             | 8.13e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.43     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 707      |
|    iterations             | 65       |
|    time_elapsed           | 11       |
|    total_timesteps        | 8320     |
| train/                    |          |
|    explained_variance     | -29.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00308  |
|    learning_rate          | 0.001    |
|    n_updates              | 64       |
|    policy_objective       | 0.055    |
|    value_loss             | 0.000195 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.37     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 708      |
|    iterations             | 66       |
|    time_elapsed           | 11       |
|    total_timesteps        | 8448     |
| train/                    |          |
|    explained_variance     | -7.44    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00544  |
|    learning_rate          | 0.001    |
|    n_updates              | 65       |
|    policy_objective       | 0.0797   |
|    value_loss             | 8.99e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.48     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 708      |
|    iterations             | 67       |
|    time_elapsed           | 12       |
|    total_timesteps        | 8576     |
| train/                    |          |
|    explained_variance     | 0.0969   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00564  |
|    learning_rate          | 0.001    |
|    n_updates              | 66       |
|    policy_objective       | 0.0479   |
|    value_loss             | 0.0402   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.69     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 709      |
|    iterations             | 68       |
|    time_elapsed           | 12       |
|    total_timesteps        | 8704     |
| train/                    |          |
|    explained_variance     | -5.13    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00578  |
|    learning_rate          | 0.001    |
|    n_updates              | 67       |
|    policy_objective       | 0.0416   |
|    value_loss             | 0.000514 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.97     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 709      |
|    iterations             | 69       |
|    time_elapsed           | 12       |
|    total_timesteps        | 8832     |
| train/                    |          |
|    explained_variance     | 0.287    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00747  |
|    learning_rate          | 0.001    |
|    n_updates              | 68       |
|    policy_objective       | 0.0352   |
|    value_loss             | 0.0339   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.02     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 710      |
|    iterations             | 70       |
|    time_elapsed           | 12       |
|    total_timesteps        | 8960     |
| train/                    |          |
|    explained_variance     | -20.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0065   |
|    learning_rate          | 0.001    |
|    n_updates              | 69       |
|    policy_objective       | 0.0476   |
|    value_loss             | 0.00117  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.52     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 710      |
|    iterations             | 71       |
|    time_elapsed           | 12       |
|    total_timesteps        | 9088     |
| train/                    |          |
|    explained_variance     | -5.45    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00441  |
|    learning_rate          | 0.001    |
|    n_updates              | 70       |
|    policy_objective       | 0.0523   |
|    value_loss             | 3.44e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.53     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 711      |
|    iterations             | 72       |
|    time_elapsed           | 12       |
|    total_timesteps        | 9216     |
| train/                    |          |
|    explained_variance     | -45.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00405  |
|    learning_rate          | 0.001    |
|    n_updates              | 71       |
|    policy_objective       | 0.021    |
|    value_loss             | 0.000159 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.76     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 712      |
|    iterations             | 73       |
|    time_elapsed           | 13       |
|    total_timesteps        | 9344     |
| train/                    |          |
|    explained_variance     | -73.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0024   |
|    learning_rate          | 0.001    |
|    n_updates              | 72       |
|    policy_objective       | 0.0307   |
|    value_loss             | 0.00364  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.39     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 712      |
|    iterations             | 74       |
|    time_elapsed           | 13       |
|    total_timesteps        | 9472     |
| train/                    |          |
|    explained_variance     | -18.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00496  |
|    learning_rate          | 0.001    |
|    n_updates              | 73       |
|    policy_objective       | 0.0675   |
|    value_loss             | 6.16e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.39     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 75       |
|    time_elapsed           | 13       |
|    total_timesteps        | 9600     |
| train/                    |          |
|    explained_variance     | -8.75    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00288  |
|    learning_rate          | 0.001    |
|    n_updates              | 74       |
|    policy_objective       | 0.044    |
|    value_loss             | 0.000949 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.95     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 76       |
|    time_elapsed           | 13       |
|    total_timesteps        | 9728     |
| train/                    |          |
|    explained_variance     | 0.406    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0058   |
|    learning_rate          | 0.001    |
|    n_updates              | 75       |
|    policy_objective       | 0.0505   |
|    value_loss             | 3.34e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.55     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 714      |
|    iterations             | 77       |
|    time_elapsed           | 13       |
|    total_timesteps        | 9856     |
| train/                    |          |
|    explained_variance     | -13.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00602  |
|    learning_rate          | 0.001    |
|    n_updates              | 76       |
|    policy_objective       | 0.051    |
|    value_loss             | 2.21e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.72     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 714      |
|    iterations             | 78       |
|    time_elapsed           | 13       |
|    total_timesteps        | 9984     |
| train/                    |          |
|    explained_variance     | 0.0311   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.005    |
|    learning_rate          | 0.001    |
|    n_updates              | 77       |
|    policy_objective       | 0.0535   |
|    value_loss             | 0.0417   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.31     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 714      |
|    iterations             | 79       |
|    time_elapsed           | 14       |
|    total_timesteps        | 10112    |
| train/                    |          |
|    explained_variance     | -11.7    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00614  |
|    learning_rate          | 0.001    |
|    n_updates              | 78       |
|    policy_objective       | 0.0413   |
|    value_loss             | 0.00135  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.09     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 714      |
|    iterations             | 80       |
|    time_elapsed           | 14       |
|    total_timesteps        | 10240    |
| train/                    |          |
|    explained_variance     | -14.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00242  |
|    learning_rate          | 0.001    |
|    n_updates              | 79       |
|    policy_objective       | 0.0635   |
|    value_loss             | 0.000172 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.39     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 714      |
|    iterations             | 81       |
|    time_elapsed           | 14       |
|    total_timesteps        | 10368    |
| train/                    |          |
|    explained_variance     | 0.25     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0054   |
|    learning_rate          | 0.001    |
|    n_updates              | 80       |
|    policy_objective       | 0.0516   |
|    value_loss             | 0.0393   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.54     |
|    ep_rew_mean            | 0.05     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 82       |
|    time_elapsed           | 14       |
|    total_timesteps        | 10496    |
| train/                    |          |
|    explained_variance     | 0.0692   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00597  |
|    learning_rate          | 0.001    |
|    n_updates              | 81       |
|    policy_objective       | 0.0512   |
|    value_loss             | 0.0382   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.64     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 83       |
|    time_elapsed           | 14       |
|    total_timesteps        | 10624    |
| train/                    |          |
|    explained_variance     | 0.284    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00469  |
|    learning_rate          | 0.001    |
|    n_updates              | 82       |
|    policy_objective       | 0.0563   |
|    value_loss             | 0.0601   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.87     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 84       |
|    time_elapsed           | 15       |
|    total_timesteps        | 10752    |
| train/                    |          |
|    explained_variance     | -7.03    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00395  |
|    learning_rate          | 0.001    |
|    n_updates              | 83       |
|    policy_objective       | 0.0509   |
|    value_loss             | 0.00358  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.92     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 85       |
|    time_elapsed           | 15       |
|    total_timesteps        | 10880    |
| train/                    |          |
|    explained_variance     | -5.81    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00462  |
|    learning_rate          | 0.001    |
|    n_updates              | 84       |
|    policy_objective       | 0.046    |
|    value_loss             | 0.00971  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.91     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 86       |
|    time_elapsed           | 15       |
|    total_timesteps        | 11008    |
| train/                    |          |
|    explained_variance     | -11.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00531  |
|    learning_rate          | 0.001    |
|    n_updates              | 85       |
|    policy_objective       | 0.164    |
|    value_loss             | 0.000161 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.33     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 87       |
|    time_elapsed           | 15       |
|    total_timesteps        | 11136    |
| train/                    |          |
|    explained_variance     | -35.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00232  |
|    learning_rate          | 0.001    |
|    n_updates              | 86       |
|    policy_objective       | 0.0946   |
|    value_loss             | 5.64e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.78     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 712      |
|    iterations             | 88       |
|    time_elapsed           | 15       |
|    total_timesteps        | 11264    |
| train/                    |          |
|    explained_variance     | -51.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0019   |
|    learning_rate          | 0.001    |
|    n_updates              | 87       |
|    policy_objective       | 0.0459   |
|    value_loss             | 1.81e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.63     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 712      |
|    iterations             | 89       |
|    time_elapsed           | 15       |
|    total_timesteps        | 11392    |
| train/                    |          |
|    explained_variance     | -166     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00197  |
|    learning_rate          | 0.001    |
|    n_updates              | 88       |
|    policy_objective       | 0.0368   |
|    value_loss             | 2.72e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.26     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 712      |
|    iterations             | 90       |
|    time_elapsed           | 16       |
|    total_timesteps        | 11520    |
| train/                    |          |
|    explained_variance     | -73.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00133  |
|    learning_rate          | 0.001    |
|    n_updates              | 89       |
|    policy_objective       | 0.0581   |
|    value_loss             | 8.21e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.96     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 711      |
|    iterations             | 91       |
|    time_elapsed           | 16       |
|    total_timesteps        | 11648    |
| train/                    |          |
|    explained_variance     | -22.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00286  |
|    learning_rate          | 0.001    |
|    n_updates              | 90       |
|    policy_objective       | 0.0672   |
|    value_loss             | 0.000203 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.71     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 711      |
|    iterations             | 92       |
|    time_elapsed           | 16       |
|    total_timesteps        | 11776    |
| train/                    |          |
|    explained_variance     | -15.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00459  |
|    learning_rate          | 0.001    |
|    n_updates              | 91       |
|    policy_objective       | 0.0614   |
|    value_loss             | 0.00011  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.44     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 710      |
|    iterations             | 93       |
|    time_elapsed           | 16       |
|    total_timesteps        | 11904    |
| train/                    |          |
|    explained_variance     | 0.00742  |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00276  |
|    learning_rate          | 0.001    |
|    n_updates              | 92       |
|    policy_objective       | 0.0599   |
|    value_loss             | 0.0367   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.2      |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 710      |
|    iterations             | 94       |
|    time_elapsed           | 16       |
|    total_timesteps        | 12032    |
| train/                    |          |
|    explained_variance     | -28.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00239  |
|    learning_rate          | 0.001    |
|    n_updates              | 93       |
|    policy_objective       | 0.0615   |
|    value_loss             | 0.00392  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.32     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 709      |
|    iterations             | 95       |
|    time_elapsed           | 17       |
|    total_timesteps        | 12160    |
| train/                    |          |
|    explained_variance     | -2.8     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00339  |
|    learning_rate          | 0.001    |
|    n_updates              | 94       |
|    policy_objective       | 0.0464   |
|    value_loss             | 0.00121  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.63     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 709      |
|    iterations             | 96       |
|    time_elapsed           | 17       |
|    total_timesteps        | 12288    |
| train/                    |          |
|    explained_variance     | -10.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00575  |
|    learning_rate          | 0.001    |
|    n_updates              | 95       |
|    policy_objective       | 0.0697   |
|    value_loss             | 0.00208  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.61     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 709      |
|    iterations             | 97       |
|    time_elapsed           | 17       |
|    total_timesteps        | 12416    |
| train/                    |          |
|    explained_variance     | -14      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00343  |
|    learning_rate          | 0.001    |
|    n_updates              | 96       |
|    policy_objective       | 0.0523   |
|    value_loss             | 5.05e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.03     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 708      |
|    iterations             | 98       |
|    time_elapsed           | 17       |
|    total_timesteps        | 12544    |
| train/                    |          |
|    explained_variance     | -91.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00637  |
|    learning_rate          | 0.001    |
|    n_updates              | 97       |
|    policy_objective       | 0.0547   |
|    value_loss             | 3.41e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.58     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 708      |
|    iterations             | 99       |
|    time_elapsed           | 17       |
|    total_timesteps        | 12672    |
| train/                    |          |
|    explained_variance     | -73.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00187  |
|    learning_rate          | 0.001    |
|    n_updates              | 98       |
|    policy_objective       | 0.071    |
|    value_loss             | 3.33e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.59     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 708      |
|    iterations             | 100      |
|    time_elapsed           | 18       |
|    total_timesteps        | 12800    |
| train/                    |          |
|    explained_variance     | -76.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00251  |
|    learning_rate          | 0.001    |
|    n_updates              | 99       |
|    policy_objective       | 0.0823   |
|    value_loss             | 1.91e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.3      |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 707      |
|    iterations             | 101      |
|    time_elapsed           | 18       |
|    total_timesteps        | 12928    |
| train/                    |          |
|    explained_variance     | -34.6    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00267  |
|    learning_rate          | 0.001    |
|    n_updates              | 100      |
|    policy_objective       | 0.0348   |
|    value_loss             | 9.65e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.35     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 707      |
|    iterations             | 102      |
|    time_elapsed           | 18       |
|    total_timesteps        | 13056    |
| train/                    |          |
|    explained_variance     | -5.34    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00172  |
|    learning_rate          | 0.001    |
|    n_updates              | 101      |
|    policy_objective       | 0.0515   |
|    value_loss             | 6.5e-06  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.25     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 707      |
|    iterations             | 103      |
|    time_elapsed           | 18       |
|    total_timesteps        | 13184    |
| train/                    |          |
|    explained_variance     | -15.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00273  |
|    learning_rate          | 0.001    |
|    n_updates              | 102      |
|    policy_objective       | 0.0585   |
|    value_loss             | 1.04e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.1      |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 707      |
|    iterations             | 104      |
|    time_elapsed           | 18       |
|    total_timesteps        | 13312    |
| train/                    |          |
|    explained_variance     | -64      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00733  |
|    learning_rate          | 0.001    |
|    n_updates              | 103      |
|    policy_objective       | 0.105    |
|    value_loss             | 4.26e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.41     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 707      |
|    iterations             | 105      |
|    time_elapsed           | 18       |
|    total_timesteps        | 13440    |
| train/                    |          |
|    explained_variance     | -20.6    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00262  |
|    learning_rate          | 0.001    |
|    n_updates              | 104      |
|    policy_objective       | 0.0523   |
|    value_loss             | 1.59e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.65     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 707      |
|    iterations             | 106      |
|    time_elapsed           | 19       |
|    total_timesteps        | 13568    |
| train/                    |          |
|    explained_variance     | -43.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00804  |
|    learning_rate          | 0.001    |
|    n_updates              | 105      |
|    policy_objective       | 0.0658   |
|    value_loss             | 7.01e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.85     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 707      |
|    iterations             | 107      |
|    time_elapsed           | 19       |
|    total_timesteps        | 13696    |
| train/                    |          |
|    explained_variance     | -20.6    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00435  |
|    learning_rate          | 0.001    |
|    n_updates              | 106      |
|    policy_objective       | 0.0413   |
|    value_loss             | 3.19e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.46     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 707      |
|    iterations             | 108      |
|    time_elapsed           | 19       |
|    total_timesteps        | 13824    |
| train/                    |          |
|    explained_variance     | -18.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00437  |
|    learning_rate          | 0.001    |
|    n_updates              | 107      |
|    policy_objective       | 0.0548   |
|    value_loss             | 2.8e-08  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.91     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 707      |
|    iterations             | 109      |
|    time_elapsed           | 19       |
|    total_timesteps        | 13952    |
| train/                    |          |
|    explained_variance     | -37.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00332  |
|    learning_rate          | 0.001    |
|    n_updates              | 108      |
|    policy_objective       | 0.0338   |
|    value_loss             | 2.51e-09 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.46     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 707      |
|    iterations             | 110      |
|    time_elapsed           | 19       |
|    total_timesteps        | 14080    |
| train/                    |          |
|    explained_variance     | -10.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00498  |
|    learning_rate          | 0.001    |
|    n_updates              | 109      |
|    policy_objective       | 0.0598   |
|    value_loss             | 3.63e-10 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.62     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 707      |
|    iterations             | 111      |
|    time_elapsed           | 20       |
|    total_timesteps        | 14208    |
| train/                    |          |
|    explained_variance     | -44      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00114  |
|    learning_rate          | 0.001    |
|    n_updates              | 110      |
|    policy_objective       | 0.0619   |
|    value_loss             | 3.73e-10 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.32     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 707      |
|    iterations             | 112      |
|    time_elapsed           | 20       |
|    total_timesteps        | 14336    |
| train/                    |          |
|    explained_variance     | -76.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00216  |
|    learning_rate          | 0.001    |
|    n_updates              | 111      |
|    policy_objective       | 0.0313   |
|    value_loss             | 1.66e-10 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.4      |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 707      |
|    iterations             | 113      |
|    time_elapsed           | 20       |
|    total_timesteps        | 14464    |
| train/                    |          |
|    explained_variance     | -30.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00195  |
|    learning_rate          | 0.001    |
|    n_updates              | 112      |
|    policy_objective       | 0.0392   |
|    value_loss             | 6.97e-12 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.85     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 707      |
|    iterations             | 114      |
|    time_elapsed           | 20       |
|    total_timesteps        | 14592    |
| train/                    |          |
|    explained_variance     | -45.6    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00376  |
|    learning_rate          | 0.001    |
|    n_updates              | 113      |
|    policy_objective       | 0.0321   |
|    value_loss             | 5.42e-13 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.17     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 707      |
|    iterations             | 115      |
|    time_elapsed           | 20       |
|    total_timesteps        | 14720    |
| train/                    |          |
|    explained_variance     | -59.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00164  |
|    learning_rate          | 0.001    |
|    n_updates              | 114      |
|    policy_objective       | 0.0587   |
|    value_loss             | 7.13e-11 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.66     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 707      |
|    iterations             | 116      |
|    time_elapsed           | 20       |
|    total_timesteps        | 14848    |
| train/                    |          |
|    explained_variance     | 0.000257 |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00456  |
|    learning_rate          | 0.001    |
|    n_updates              | 115      |
|    policy_objective       | 0.0682   |
|    value_loss             | 0.0436   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.35     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 707      |
|    iterations             | 117      |
|    time_elapsed           | 21       |
|    total_timesteps        | 14976    |
| train/                    |          |
|    explained_variance     | -0.398   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00427  |
|    learning_rate          | 0.001    |
|    n_updates              | 116      |
|    policy_objective       | 0.0385   |
|    value_loss             | 0.00397  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.47     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 707      |
|    iterations             | 118      |
|    time_elapsed           | 21       |
|    total_timesteps        | 15104    |
| train/                    |          |
|    explained_variance     | -53.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00215  |
|    learning_rate          | 0.001    |
|    n_updates              | 117      |
|    policy_objective       | 0.0494   |
|    value_loss             | 0.0015   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.67     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 706      |
|    iterations             | 119      |
|    time_elapsed           | 21       |
|    total_timesteps        | 15232    |
| train/                    |          |
|    explained_variance     | -53.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0021   |
|    learning_rate          | 0.001    |
|    n_updates              | 118      |
|    policy_objective       | 0.0246   |
|    value_loss             | 0.000413 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.88     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 706      |
|    iterations             | 120      |
|    time_elapsed           | 21       |
|    total_timesteps        | 15360    |
| train/                    |          |
|    explained_variance     | 0.292    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00574  |
|    learning_rate          | 0.001    |
|    n_updates              | 119      |
|    policy_objective       | 0.0807   |
|    value_loss             | 0.0213   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.31     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 706      |
|    iterations             | 121      |
|    time_elapsed           | 21       |
|    total_timesteps        | 15488    |
| train/                    |          |
|    explained_variance     | -5.28    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00464  |
|    learning_rate          | 0.001    |
|    n_updates              | 120      |
|    policy_objective       | 0.0362   |
|    value_loss             | 0.0133   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.37     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 707      |
|    iterations             | 122      |
|    time_elapsed           | 22       |
|    total_timesteps        | 15616    |
| train/                    |          |
|    explained_variance     | 0.0485   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00717  |
|    learning_rate          | 0.001    |
|    n_updates              | 121      |
|    policy_objective       | 0.0798   |
|    value_loss             | 0.0439   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.41     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 707      |
|    iterations             | 123      |
|    time_elapsed           | 22       |
|    total_timesteps        | 15744    |
| train/                    |          |
|    explained_variance     | -23.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00556  |
|    learning_rate          | 0.001    |
|    n_updates              | 122      |
|    policy_objective       | 0.0445   |
|    value_loss             | 0.00409  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.39     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 707      |
|    iterations             | 124      |
|    time_elapsed           | 22       |
|    total_timesteps        | 15872    |
| train/                    |          |
|    explained_variance     | 0.0518   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00556  |
|    learning_rate          | 0.001    |
|    n_updates              | 123      |
|    policy_objective       | 0.0351   |
|    value_loss             | 0.0381   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.7      |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 707      |
|    iterations             | 125      |
|    time_elapsed           | 22       |
|    total_timesteps        | 16000    |
| train/                    |          |
|    explained_variance     | -22.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00812  |
|    learning_rate          | 0.001    |
|    n_updates              | 124      |
|    policy_objective       | 0.0693   |
|    value_loss             | 0.00158  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.66     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 707      |
|    iterations             | 126      |
|    time_elapsed           | 22       |
|    total_timesteps        | 16128    |
| train/                    |          |
|    explained_variance     | -23.7    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00601  |
|    learning_rate          | 0.001    |
|    n_updates              | 125      |
|    policy_objective       | 0.0641   |
|    value_loss             | 0.0028   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.76     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 707      |
|    iterations             | 127      |
|    time_elapsed           | 22       |
|    total_timesteps        | 16256    |
| train/                    |          |
|    explained_variance     | 0.0818   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00523  |
|    learning_rate          | 0.001    |
|    n_updates              | 126      |
|    policy_objective       | 0.0754   |
|    value_loss             | 0.0659   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.78     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 707      |
|    iterations             | 128      |
|    time_elapsed           | 23       |
|    total_timesteps        | 16384    |
| train/                    |          |
|    explained_variance     | -52.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00427  |
|    learning_rate          | 0.001    |
|    n_updates              | 127      |
|    policy_objective       | 0.0313   |
|    value_loss             | 0.00722  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.92     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 707      |
|    iterations             | 129      |
|    time_elapsed           | 23       |
|    total_timesteps        | 16512    |
| train/                    |          |
|    explained_variance     | -15.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00353  |
|    learning_rate          | 0.001    |
|    n_updates              | 128      |
|    policy_objective       | 0.0545   |
|    value_loss             | 0.00396  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.62     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 707      |
|    iterations             | 130      |
|    time_elapsed           | 23       |
|    total_timesteps        | 16640    |
| train/                    |          |
|    explained_variance     | -3.86    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00544  |
|    learning_rate          | 0.001    |
|    n_updates              | 129      |
|    policy_objective       | 0.035    |
|    value_loss             | 3.78e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.85     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 708      |
|    iterations             | 131      |
|    time_elapsed           | 23       |
|    total_timesteps        | 16768    |
| train/                    |          |
|    explained_variance     | 0.0109   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00489  |
|    learning_rate          | 0.001    |
|    n_updates              | 130      |
|    policy_objective       | 0.0464   |
|    value_loss             | 0.0328   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.17     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 707      |
|    iterations             | 132      |
|    time_elapsed           | 23       |
|    total_timesteps        | 16896    |
| train/                    |          |
|    explained_variance     | 0.094    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00485  |
|    learning_rate          | 0.001    |
|    n_updates              | 131      |
|    policy_objective       | 0.0393   |
|    value_loss             | 0.0523   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.58     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 707      |
|    iterations             | 133      |
|    time_elapsed           | 24       |
|    total_timesteps        | 17024    |
| train/                    |          |
|    explained_variance     | -5.17    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00564  |
|    learning_rate          | 0.001    |
|    n_updates              | 132      |
|    policy_objective       | 0.0297   |
|    value_loss             | 0.00431  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.68     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 707      |
|    iterations             | 134      |
|    time_elapsed           | 24       |
|    total_timesteps        | 17152    |
| train/                    |          |
|    explained_variance     | -2.12    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00589  |
|    learning_rate          | 0.001    |
|    n_updates              | 133      |
|    policy_objective       | 0.0466   |
|    value_loss             | 0.000238 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.59     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 707      |
|    iterations             | 135      |
|    time_elapsed           | 24       |
|    total_timesteps        | 17280    |
| train/                    |          |
|    explained_variance     | -14.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00597  |
|    learning_rate          | 0.001    |
|    n_updates              | 134      |
|    policy_objective       | 0.0611   |
|    value_loss             | 3.17e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.93     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 707      |
|    iterations             | 136      |
|    time_elapsed           | 24       |
|    total_timesteps        | 17408    |
| train/                    |          |
|    explained_variance     | -36.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00404  |
|    learning_rate          | 0.001    |
|    n_updates              | 135      |
|    policy_objective       | 0.049    |
|    value_loss             | 2.02e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.67     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 707      |
|    iterations             | 137      |
|    time_elapsed           | 24       |
|    total_timesteps        | 17536    |
| train/                    |          |
|    explained_variance     | -29.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.005    |
|    learning_rate          | 0.001    |
|    n_updates              | 136      |
|    policy_objective       | 0.0448   |
|    value_loss             | 0.00177  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.76     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 707      |
|    iterations             | 138      |
|    time_elapsed           | 24       |
|    total_timesteps        | 17664    |
| train/                    |          |
|    explained_variance     | -25.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00376  |
|    learning_rate          | 0.001    |
|    n_updates              | 137      |
|    policy_objective       | 0.0497   |
|    value_loss             | 7.94e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.32     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 707      |
|    iterations             | 139      |
|    time_elapsed           | 25       |
|    total_timesteps        | 17792    |
| train/                    |          |
|    explained_variance     | -28.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00406  |
|    learning_rate          | 0.001    |
|    n_updates              | 138      |
|    policy_objective       | 0.0378   |
|    value_loss             | 6.1e-07  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.91     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 707      |
|    iterations             | 140      |
|    time_elapsed           | 25       |
|    total_timesteps        | 17920    |
| train/                    |          |
|    explained_variance     | -90.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00304  |
|    learning_rate          | 0.001    |
|    n_updates              | 139      |
|    policy_objective       | 0.146    |
|    value_loss             | 5e-08    |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.21     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 707      |
|    iterations             | 141      |
|    time_elapsed           | 25       |
|    total_timesteps        | 18048    |
| train/                    |          |
|    explained_variance     | -33.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00286  |
|    learning_rate          | 0.001    |
|    n_updates              | 140      |
|    policy_objective       | 0.0476   |
|    value_loss             | 1.05e-09 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.34     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 707      |
|    iterations             | 142      |
|    time_elapsed           | 25       |
|    total_timesteps        | 18176    |
| train/                    |          |
|    explained_variance     | -29.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00157  |
|    learning_rate          | 0.001    |
|    n_updates              | 141      |
|    policy_objective       | 0.0512   |
|    value_loss             | 0.000422 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.24     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 707      |
|    iterations             | 143      |
|    time_elapsed           | 25       |
|    total_timesteps        | 18304    |
| train/                    |          |
|    explained_variance     | -29.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00544  |
|    learning_rate          | 0.001    |
|    n_updates              | 142      |
|    policy_objective       | 0.0353   |
|    value_loss             | 7.72e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.65     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 706      |
|    iterations             | 144      |
|    time_elapsed           | 26       |
|    total_timesteps        | 18432    |
| train/                    |          |
|    explained_variance     | -124     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00316  |
|    learning_rate          | 0.001    |
|    n_updates              | 143      |
|    policy_objective       | 0.014    |
|    value_loss             | 7.93e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.71     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 706      |
|    iterations             | 145      |
|    time_elapsed           | 26       |
|    total_timesteps        | 18560    |
| train/                    |          |
|    explained_variance     | -37.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00199  |
|    learning_rate          | 0.001    |
|    n_updates              | 144      |
|    policy_objective       | 0.0363   |
|    value_loss             | 2.21e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.16     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 706      |
|    iterations             | 146      |
|    time_elapsed           | 26       |
|    total_timesteps        | 18688    |
| train/                    |          |
|    explained_variance     | 0.0277   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00433  |
|    learning_rate          | 0.001    |
|    n_updates              | 145      |
|    policy_objective       | 0.102    |
|    value_loss             | 0.0397   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.03     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 706      |
|    iterations             | 147      |
|    time_elapsed           | 26       |
|    total_timesteps        | 18816    |
| train/                    |          |
|    explained_variance     | -11.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0034   |
|    learning_rate          | 0.001    |
|    n_updates              | 146      |
|    policy_objective       | 0.0394   |
|    value_loss             | 0.00517  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.89     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 705      |
|    iterations             | 148      |
|    time_elapsed           | 26       |
|    total_timesteps        | 18944    |
| train/                    |          |
|    explained_variance     | -3.05    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00313  |
|    learning_rate          | 0.001    |
|    n_updates              | 147      |
|    policy_objective       | 0.0538   |
|    value_loss             | 0.001    |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.03     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 705      |
|    iterations             | 149      |
|    time_elapsed           | 27       |
|    total_timesteps        | 19072    |
| train/                    |          |
|    explained_variance     | -22.6    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00209  |
|    learning_rate          | 0.001    |
|    n_updates              | 148      |
|    policy_objective       | 0.0454   |
|    value_loss             | 0.000144 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.99     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 706      |
|    iterations             | 150      |
|    time_elapsed           | 27       |
|    total_timesteps        | 19200    |
| train/                    |          |
|    explained_variance     | 0.263    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00658  |
|    learning_rate          | 0.001    |
|    n_updates              | 149      |
|    policy_objective       | 0.0349   |
|    value_loss             | 0.0378   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.62     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 706      |
|    iterations             | 151      |
|    time_elapsed           | 27       |
|    total_timesteps        | 19328    |
| train/                    |          |
|    explained_variance     | -14.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00609  |
|    learning_rate          | 0.001    |
|    n_updates              | 150      |
|    policy_objective       | 0.0375   |
|    value_loss             | 0.00243  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.59     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 706      |
|    iterations             | 152      |
|    time_elapsed           | 27       |
|    total_timesteps        | 19456    |
| train/                    |          |
|    explained_variance     | 0.447    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00352  |
|    learning_rate          | 0.001    |
|    n_updates              | 151      |
|    policy_objective       | 0.0747   |
|    value_loss             | 0.0259   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.26     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 706      |
|    iterations             | 153      |
|    time_elapsed           | 27       |
|    total_timesteps        | 19584    |
| train/                    |          |
|    explained_variance     | -0.119   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00623  |
|    learning_rate          | 0.001    |
|    n_updates              | 152      |
|    policy_objective       | 0.034    |
|    value_loss             | 0.0541   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.97     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 706      |
|    iterations             | 154      |
|    time_elapsed           | 27       |
|    total_timesteps        | 19712    |
| train/                    |          |
|    explained_variance     | -3.86    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00628  |
|    learning_rate          | 0.001    |
|    n_updates              | 153      |
|    policy_objective       | 0.0305   |
|    value_loss             | 0.00398  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.95     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 706      |
|    iterations             | 155      |
|    time_elapsed           | 28       |
|    total_timesteps        | 19840    |
| train/                    |          |
|    explained_variance     | -4.06    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00466  |
|    learning_rate          | 0.001    |
|    n_updates              | 154      |
|    policy_objective       | 0.0307   |
|    value_loss             | 0.000253 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.1      |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 706      |
|    iterations             | 156      |
|    time_elapsed           | 28       |
|    total_timesteps        | 19968    |
| train/                    |          |
|    explained_variance     | -23.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00403  |
|    learning_rate          | 0.001    |
|    n_updates              | 155      |
|    policy_objective       | 0.0636   |
|    value_loss             | 0.000251 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.07     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 705      |
|    iterations             | 157      |
|    time_elapsed           | 28       |
|    total_timesteps        | 20096    |
| train/                    |          |
|    explained_variance     | -7.26    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00334  |
|    learning_rate          | 0.001    |
|    n_updates              | 156      |
|    policy_objective       | 0.0513   |
|    value_loss             | 3.73e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.19     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 705      |
|    iterations             | 158      |
|    time_elapsed           | 28       |
|    total_timesteps        | 20224    |
| train/                    |          |
|    explained_variance     | -33.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00378  |
|    learning_rate          | 0.001    |
|    n_updates              | 157      |
|    policy_objective       | 0.119    |
|    value_loss             | 1.44e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.18     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 705      |
|    iterations             | 159      |
|    time_elapsed           | 28       |
|    total_timesteps        | 20352    |
| train/                    |          |
|    explained_variance     | -9.42    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00591  |
|    learning_rate          | 0.001    |
|    n_updates              | 158      |
|    policy_objective       | 0.0364   |
|    value_loss             | 1.91e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.47     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 705      |
|    iterations             | 160      |
|    time_elapsed           | 29       |
|    total_timesteps        | 20480    |
| train/                    |          |
|    explained_variance     | -261     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00291  |
|    learning_rate          | 0.001    |
|    n_updates              | 159      |
|    policy_objective       | 0.0502   |
|    value_loss             | 4.36e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.12     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 161      |
|    time_elapsed           | 29       |
|    total_timesteps        | 20608    |
| train/                    |          |
|    explained_variance     | -75.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00403  |
|    learning_rate          | 0.001    |
|    n_updates              | 160      |
|    policy_objective       | 0.0327   |
|    value_loss             | 5.5e-08  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.62     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 705      |
|    iterations             | 162      |
|    time_elapsed           | 29       |
|    total_timesteps        | 20736    |
| train/                    |          |
|    explained_variance     | -18.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00387  |
|    learning_rate          | 0.001    |
|    n_updates              | 161      |
|    policy_objective       | 0.0301   |
|    value_loss             | 3.39e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.48     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 705      |
|    iterations             | 163      |
|    time_elapsed           | 29       |
|    total_timesteps        | 20864    |
| train/                    |          |
|    explained_variance     | -2.96    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00569  |
|    learning_rate          | 0.001    |
|    n_updates              | 162      |
|    policy_objective       | 0.0395   |
|    value_loss             | 9.89e-08 |
----------------------------------------
-----------------------------------------
| adaptive/                 |           |
|    adaptation_factor      | 1         |
|    algorithm              | TRPO      |
|    base_lr                | 0.001     |
|    base_target_kl         | 0.01      |
|    drift_magnitude        | 0         |
|    learning_rate          | 0.001     |
|    target_kl              | 0.01      |
| env/                      |           |
|    base_value             | 9.8       |
|    slip_prob              | 9.8       |
| rollout/                  |           |
|    ep_len_mean            | 8.58      |
|    ep_rew_mean            | 0.01      |
| time/                     |           |
|    fps                    | 705       |
|    iterations             | 164       |
|    time_elapsed           | 29        |
|    total_timesteps        | 20992     |
| train/                    |           |
|    explained_variance     | -0.000251 |
|    is_line_search_success | 1         |
|    kl_divergence_loss     | 0.00664   |
|    learning_rate          | 0.001     |
|    n_updates              | 163       |
|    policy_objective       | 0.0698    |
|    value_loss             | 0.0275    |
-----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.82     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 705      |
|    iterations             | 165      |
|    time_elapsed           | 29       |
|    total_timesteps        | 21120    |
| train/                    |          |
|    explained_variance     | -35.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00405  |
|    learning_rate          | 0.001    |
|    n_updates              | 164      |
|    policy_objective       | 0.0461   |
|    value_loss             | 0.00505  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.31     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 705      |
|    iterations             | 166      |
|    time_elapsed           | 30       |
|    total_timesteps        | 21248    |
| train/                    |          |
|    explained_variance     | -0.366   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00524  |
|    learning_rate          | 0.001    |
|    n_updates              | 165      |
|    policy_objective       | 0.037    |
|    value_loss             | 0.0192   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.99     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 167      |
|    time_elapsed           | 30       |
|    total_timesteps        | 21376    |
| train/                    |          |
|    explained_variance     | 0.19     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00639  |
|    learning_rate          | 0.001    |
|    n_updates              | 166      |
|    policy_objective       | 0.0314   |
|    value_loss             | 0.00471  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.95     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 703      |
|    iterations             | 168      |
|    time_elapsed           | 30       |
|    total_timesteps        | 21504    |
| train/                    |          |
|    explained_variance     | -51.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0016   |
|    learning_rate          | 0.001    |
|    n_updates              | 167      |
|    policy_objective       | 0.0518   |
|    value_loss             | 0.000526 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.44     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 703      |
|    iterations             | 169      |
|    time_elapsed           | 30       |
|    total_timesteps        | 21632    |
| train/                    |          |
|    explained_variance     | -7.88    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0043   |
|    learning_rate          | 0.001    |
|    n_updates              | 168      |
|    policy_objective       | 0.156    |
|    value_loss             | 1.28e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.85     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 703      |
|    iterations             | 170      |
|    time_elapsed           | 30       |
|    total_timesteps        | 21760    |
| train/                    |          |
|    explained_variance     | 0.265    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00491  |
|    learning_rate          | 0.001    |
|    n_updates              | 169      |
|    policy_objective       | 0.0907   |
|    value_loss             | 0.0274   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.63     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 703      |
|    iterations             | 171      |
|    time_elapsed           | 31       |
|    total_timesteps        | 21888    |
| train/                    |          |
|    explained_variance     | -48.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0052   |
|    learning_rate          | 0.001    |
|    n_updates              | 170      |
|    policy_objective       | 0.0675   |
|    value_loss             | 0.00118  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.31     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 703      |
|    iterations             | 172      |
|    time_elapsed           | 31       |
|    total_timesteps        | 22016    |
| train/                    |          |
|    explained_variance     | -69      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00548  |
|    learning_rate          | 0.001    |
|    n_updates              | 171      |
|    policy_objective       | 0.0578   |
|    value_loss             | 1.62e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.64     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 703      |
|    iterations             | 173      |
|    time_elapsed           | 31       |
|    total_timesteps        | 22144    |
| train/                    |          |
|    explained_variance     | -10.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00663  |
|    learning_rate          | 0.001    |
|    n_updates              | 172      |
|    policy_objective       | 0.0203   |
|    value_loss             | 1.2e-07  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.21     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 703      |
|    iterations             | 174      |
|    time_elapsed           | 31       |
|    total_timesteps        | 22272    |
| train/                    |          |
|    explained_variance     | 0.0187   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00647  |
|    learning_rate          | 0.001    |
|    n_updates              | 173      |
|    policy_objective       | 0.0453   |
|    value_loss             | 0.0412   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.84     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 703      |
|    iterations             | 175      |
|    time_elapsed           | 31       |
|    total_timesteps        | 22400    |
| train/                    |          |
|    explained_variance     | -11.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0065   |
|    learning_rate          | 0.001    |
|    n_updates              | 174      |
|    policy_objective       | 0.0692   |
|    value_loss             | 0.00123  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.15     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 703      |
|    iterations             | 176      |
|    time_elapsed           | 32       |
|    total_timesteps        | 22528    |
| train/                    |          |
|    explained_variance     | -59.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0034   |
|    learning_rate          | 0.001    |
|    n_updates              | 175      |
|    policy_objective       | 0.0582   |
|    value_loss             | 0.00171  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.72     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 703      |
|    iterations             | 177      |
|    time_elapsed           | 32       |
|    total_timesteps        | 22656    |
| train/                    |          |
|    explained_variance     | 0.111    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00462  |
|    learning_rate          | 0.001    |
|    n_updates              | 176      |
|    policy_objective       | 0.05     |
|    value_loss             | 0.0427   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.25     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 178      |
|    time_elapsed           | 32       |
|    total_timesteps        | 22784    |
| train/                    |          |
|    explained_variance     | 0.204    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0041   |
|    learning_rate          | 0.001    |
|    n_updates              | 177      |
|    policy_objective       | 0.096    |
|    value_loss             | 0.0374   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.22     |
|    ep_rew_mean            | 0.05     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 179      |
|    time_elapsed           | 32       |
|    total_timesteps        | 22912    |
| train/                    |          |
|    explained_variance     | 0.131    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0052   |
|    learning_rate          | 0.001    |
|    n_updates              | 178      |
|    policy_objective       | 0.0766   |
|    value_loss             | 0.0382   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.47     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 180      |
|    time_elapsed           | 32       |
|    total_timesteps        | 23040    |
| train/                    |          |
|    explained_variance     | 0.273    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00661  |
|    learning_rate          | 0.001    |
|    n_updates              | 179      |
|    policy_objective       | 0.0447   |
|    value_loss             | 0.0418   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.69     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 181      |
|    time_elapsed           | 32       |
|    total_timesteps        | 23168    |
| train/                    |          |
|    explained_variance     | -20.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00505  |
|    learning_rate          | 0.001    |
|    n_updates              | 180      |
|    policy_objective       | 0.0358   |
|    value_loss             | 0.00384  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.58     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 182      |
|    time_elapsed           | 33       |
|    total_timesteps        | 23296    |
| train/                    |          |
|    explained_variance     | -35.7    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00346  |
|    learning_rate          | 0.001    |
|    n_updates              | 181      |
|    policy_objective       | 0.0394   |
|    value_loss             | 8.88e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.46     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 703      |
|    iterations             | 183      |
|    time_elapsed           | 33       |
|    total_timesteps        | 23424    |
| train/                    |          |
|    explained_variance     | -22.6    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00366  |
|    learning_rate          | 0.001    |
|    n_updates              | 182      |
|    policy_objective       | 0.0471   |
|    value_loss             | 0.00338  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.52     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 703      |
|    iterations             | 184      |
|    time_elapsed           | 33       |
|    total_timesteps        | 23552    |
| train/                    |          |
|    explained_variance     | -55.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00267  |
|    learning_rate          | 0.001    |
|    n_updates              | 183      |
|    policy_objective       | 0.065    |
|    value_loss             | 0.000309 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.45     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 703      |
|    iterations             | 185      |
|    time_elapsed           | 33       |
|    total_timesteps        | 23680    |
| train/                    |          |
|    explained_variance     | -44.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00204  |
|    learning_rate          | 0.001    |
|    n_updates              | 184      |
|    policy_objective       | 0.0527   |
|    value_loss             | 8.99e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.69     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 703      |
|    iterations             | 186      |
|    time_elapsed           | 33       |
|    total_timesteps        | 23808    |
| train/                    |          |
|    explained_variance     | 0.0499   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00548  |
|    learning_rate          | 0.001    |
|    n_updates              | 185      |
|    policy_objective       | 0.0543   |
|    value_loss             | 0.0221   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.1      |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 703      |
|    iterations             | 187      |
|    time_elapsed           | 34       |
|    total_timesteps        | 23936    |
| train/                    |          |
|    explained_variance     | 0.284    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00793  |
|    learning_rate          | 0.001    |
|    n_updates              | 186      |
|    policy_objective       | 0.0371   |
|    value_loss             | 0.0249   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.86     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 703      |
|    iterations             | 188      |
|    time_elapsed           | 34       |
|    total_timesteps        | 24064    |
| train/                    |          |
|    explained_variance     | -28.6    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0019   |
|    learning_rate          | 0.001    |
|    n_updates              | 187      |
|    policy_objective       | 0.0777   |
|    value_loss             | 0.00297  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.02     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 703      |
|    iterations             | 189      |
|    time_elapsed           | 34       |
|    total_timesteps        | 24192    |
| train/                    |          |
|    explained_variance     | -35.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00331  |
|    learning_rate          | 0.001    |
|    n_updates              | 188      |
|    policy_objective       | 0.0608   |
|    value_loss             | 0.00419  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.81     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 703      |
|    iterations             | 190      |
|    time_elapsed           | 34       |
|    total_timesteps        | 24320    |
| train/                    |          |
|    explained_variance     | 0.104    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00533  |
|    learning_rate          | 0.001    |
|    n_updates              | 189      |
|    policy_objective       | 0.0487   |
|    value_loss             | 0.0387   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.74     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 703      |
|    iterations             | 191      |
|    time_elapsed           | 34       |
|    total_timesteps        | 24448    |
| train/                    |          |
|    explained_variance     | -8.13    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00499  |
|    learning_rate          | 0.001    |
|    n_updates              | 190      |
|    policy_objective       | 0.0803   |
|    value_loss             | 0.00698  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.23     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 703      |
|    iterations             | 192      |
|    time_elapsed           | 34       |
|    total_timesteps        | 24576    |
| train/                    |          |
|    explained_variance     | -6.2     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00443  |
|    learning_rate          | 0.001    |
|    n_updates              | 191      |
|    policy_objective       | 0.036    |
|    value_loss             | 0.000276 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.47     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 703      |
|    iterations             | 193      |
|    time_elapsed           | 35       |
|    total_timesteps        | 24704    |
| train/                    |          |
|    explained_variance     | -24.6    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00416  |
|    learning_rate          | 0.001    |
|    n_updates              | 192      |
|    policy_objective       | 0.0538   |
|    value_loss             | 0.000108 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.97     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 702      |
|    iterations             | 194      |
|    time_elapsed           | 35       |
|    total_timesteps        | 24832    |
| train/                    |          |
|    explained_variance     | 0.132    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00573  |
|    learning_rate          | 0.001    |
|    n_updates              | 193      |
|    policy_objective       | 0.0348   |
|    value_loss             | 0.0455   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.56     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 702      |
|    iterations             | 195      |
|    time_elapsed           | 35       |
|    total_timesteps        | 24960    |
| train/                    |          |
|    explained_variance     | -20.7    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00647  |
|    learning_rate          | 0.001    |
|    n_updates              | 194      |
|    policy_objective       | 0.0314   |
|    value_loss             | 0.00788  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.54     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 702      |
|    iterations             | 196      |
|    time_elapsed           | 35       |
|    total_timesteps        | 25088    |
| train/                    |          |
|    explained_variance     | -0.102   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00367  |
|    learning_rate          | 0.001    |
|    n_updates              | 195      |
|    policy_objective       | 0.086    |
|    value_loss             | 0.000385 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.72     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 702      |
|    iterations             | 197      |
|    time_elapsed           | 35       |
|    total_timesteps        | 25216    |
| train/                    |          |
|    explained_variance     | -17.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0025   |
|    learning_rate          | 0.001    |
|    n_updates              | 196      |
|    policy_objective       | 0.0524   |
|    value_loss             | 0.0001   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.81     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 702      |
|    iterations             | 198      |
|    time_elapsed           | 36       |
|    total_timesteps        | 25344    |
| train/                    |          |
|    explained_variance     | -19.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00626  |
|    learning_rate          | 0.001    |
|    n_updates              | 197      |
|    policy_objective       | 0.0733   |
|    value_loss             | 0.000143 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.71     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 702      |
|    iterations             | 199      |
|    time_elapsed           | 36       |
|    total_timesteps        | 25472    |
| train/                    |          |
|    explained_variance     | -14.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00576  |
|    learning_rate          | 0.001    |
|    n_updates              | 198      |
|    policy_objective       | 0.0188   |
|    value_loss             | 5.84e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.58     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 702      |
|    iterations             | 200      |
|    time_elapsed           | 36       |
|    total_timesteps        | 25600    |
| train/                    |          |
|    explained_variance     | 0.00797  |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00372  |
|    learning_rate          | 0.001    |
|    n_updates              | 199      |
|    policy_objective       | 0.0799   |
|    value_loss             | 0.0418   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.79     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 701      |
|    iterations             | 201      |
|    time_elapsed           | 36       |
|    total_timesteps        | 25728    |
| train/                    |          |
|    explained_variance     | 0.285    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0061   |
|    learning_rate          | 0.001    |
|    n_updates              | 200      |
|    policy_objective       | 0.0564   |
|    value_loss             | 0.0257   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.46     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 701      |
|    iterations             | 202      |
|    time_elapsed           | 36       |
|    total_timesteps        | 25856    |
| train/                    |          |
|    explained_variance     | -41      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00273  |
|    learning_rate          | 0.001    |
|    n_updates              | 201      |
|    policy_objective       | 0.0349   |
|    value_loss             | 0.0022   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.25     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 701      |
|    iterations             | 203      |
|    time_elapsed           | 37       |
|    total_timesteps        | 25984    |
| train/                    |          |
|    explained_variance     | 0.485    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00461  |
|    learning_rate          | 0.001    |
|    n_updates              | 202      |
|    policy_objective       | 0.0345   |
|    value_loss             | 0.022    |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.87     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 702      |
|    iterations             | 204      |
|    time_elapsed           | 37       |
|    total_timesteps        | 26112    |
| train/                    |          |
|    explained_variance     | -48.6    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00257  |
|    learning_rate          | 0.001    |
|    n_updates              | 203      |
|    policy_objective       | 0.0706   |
|    value_loss             | 0.000581 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.9      |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 702      |
|    iterations             | 205      |
|    time_elapsed           | 37       |
|    total_timesteps        | 26240    |
| train/                    |          |
|    explained_variance     | 0.0935   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0038   |
|    learning_rate          | 0.001    |
|    n_updates              | 204      |
|    policy_objective       | 0.0314   |
|    value_loss             | 0.0355   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.25     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 702      |
|    iterations             | 206      |
|    time_elapsed           | 37       |
|    total_timesteps        | 26368    |
| train/                    |          |
|    explained_variance     | -13.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00488  |
|    learning_rate          | 0.001    |
|    n_updates              | 205      |
|    policy_objective       | 0.0413   |
|    value_loss             | 0.00531  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.56     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 702      |
|    iterations             | 207      |
|    time_elapsed           | 37       |
|    total_timesteps        | 26496    |
| train/                    |          |
|    explained_variance     | 0.164    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00497  |
|    learning_rate          | 0.001    |
|    n_updates              | 206      |
|    policy_objective       | 0.0672   |
|    value_loss             | 0.0422   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.67     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 702      |
|    iterations             | 208      |
|    time_elapsed           | 37       |
|    total_timesteps        | 26624    |
| train/                    |          |
|    explained_variance     | -16.6    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00468  |
|    learning_rate          | 0.001    |
|    n_updates              | 207      |
|    policy_objective       | 0.0414   |
|    value_loss             | 0.00726  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.02     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 702      |
|    iterations             | 209      |
|    time_elapsed           | 38       |
|    total_timesteps        | 26752    |
| train/                    |          |
|    explained_variance     | -20.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00604  |
|    learning_rate          | 0.001    |
|    n_updates              | 208      |
|    policy_objective       | 0.0321   |
|    value_loss             | 0.00266  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.06     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 702      |
|    iterations             | 210      |
|    time_elapsed           | 38       |
|    total_timesteps        | 26880    |
| train/                    |          |
|    explained_variance     | -11.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00327  |
|    learning_rate          | 0.001    |
|    n_updates              | 209      |
|    policy_objective       | 0.0417   |
|    value_loss             | 6.67e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.59     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 702      |
|    iterations             | 211      |
|    time_elapsed           | 38       |
|    total_timesteps        | 27008    |
| train/                    |          |
|    explained_variance     | -19.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00366  |
|    learning_rate          | 0.001    |
|    n_updates              | 210      |
|    policy_objective       | 0.0529   |
|    value_loss             | 1.5e-05  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.38     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 702      |
|    iterations             | 212      |
|    time_elapsed           | 38       |
|    total_timesteps        | 27136    |
| train/                    |          |
|    explained_variance     | -0.0339  |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00583  |
|    learning_rate          | 0.001    |
|    n_updates              | 211      |
|    policy_objective       | 0.0425   |
|    value_loss             | 0.036    |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.53     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 702      |
|    iterations             | 213      |
|    time_elapsed           | 38       |
|    total_timesteps        | 27264    |
| train/                    |          |
|    explained_variance     | -0.0079  |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00366  |
|    learning_rate          | 0.001    |
|    n_updates              | 212      |
|    policy_objective       | 0.0327   |
|    value_loss             | 0.00143  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.27     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 702      |
|    iterations             | 214      |
|    time_elapsed           | 38       |
|    total_timesteps        | 27392    |
| train/                    |          |
|    explained_variance     | 0.445    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0056   |
|    learning_rate          | 0.001    |
|    n_updates              | 213      |
|    policy_objective       | 0.0564   |
|    value_loss             | 0.0284   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.57     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 702      |
|    iterations             | 215      |
|    time_elapsed           | 39       |
|    total_timesteps        | 27520    |
| train/                    |          |
|    explained_variance     | -32.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0052   |
|    learning_rate          | 0.001    |
|    n_updates              | 214      |
|    policy_objective       | 0.049    |
|    value_loss             | 0.00388  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.93     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 703      |
|    iterations             | 216      |
|    time_elapsed           | 39       |
|    total_timesteps        | 27648    |
| train/                    |          |
|    explained_variance     | -11.7    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00299  |
|    learning_rate          | 0.001    |
|    n_updates              | 215      |
|    policy_objective       | 0.0568   |
|    value_loss             | 0.000891 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.02     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 703      |
|    iterations             | 217      |
|    time_elapsed           | 39       |
|    total_timesteps        | 27776    |
| train/                    |          |
|    explained_variance     | -6.82    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00478  |
|    learning_rate          | 0.001    |
|    n_updates              | 216      |
|    policy_objective       | 0.0494   |
|    value_loss             | 1.85e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.9      |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 703      |
|    iterations             | 218      |
|    time_elapsed           | 39       |
|    total_timesteps        | 27904    |
| train/                    |          |
|    explained_variance     | 0.279    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00551  |
|    learning_rate          | 0.001    |
|    n_updates              | 217      |
|    policy_objective       | 0.258    |
|    value_loss             | 0.0306   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8        |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 703      |
|    iterations             | 219      |
|    time_elapsed           | 39       |
|    total_timesteps        | 28032    |
| train/                    |          |
|    explained_variance     | -30.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00425  |
|    learning_rate          | 0.001    |
|    n_updates              | 218      |
|    policy_objective       | 0.0537   |
|    value_loss             | 0.00243  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.04     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 703      |
|    iterations             | 220      |
|    time_elapsed           | 40       |
|    total_timesteps        | 28160    |
| train/                    |          |
|    explained_variance     | 0.243    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00878  |
|    learning_rate          | 0.001    |
|    n_updates              | 219      |
|    policy_objective       | 0.059    |
|    value_loss             | 0.0427   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.4      |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 703      |
|    iterations             | 221      |
|    time_elapsed           | 40       |
|    total_timesteps        | 28288    |
| train/                    |          |
|    explained_variance     | -28.6    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00256  |
|    learning_rate          | 0.001    |
|    n_updates              | 220      |
|    policy_objective       | 0.0614   |
|    value_loss             | 0.00288  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.58     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 703      |
|    iterations             | 222      |
|    time_elapsed           | 40       |
|    total_timesteps        | 28416    |
| train/                    |          |
|    explained_variance     | -14.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00215  |
|    learning_rate          | 0.001    |
|    n_updates              | 221      |
|    policy_objective       | 0.075    |
|    value_loss             | 6.74e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.28     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 703      |
|    iterations             | 223      |
|    time_elapsed           | 40       |
|    total_timesteps        | 28544    |
| train/                    |          |
|    explained_variance     | -38.6    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00293  |
|    learning_rate          | 0.001    |
|    n_updates              | 222      |
|    policy_objective       | 0.0453   |
|    value_loss             | 0.000475 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.56     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 703      |
|    iterations             | 224      |
|    time_elapsed           | 40       |
|    total_timesteps        | 28672    |
| train/                    |          |
|    explained_variance     | -33.7    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00396  |
|    learning_rate          | 0.001    |
|    n_updates              | 223      |
|    policy_objective       | 0.0974   |
|    value_loss             | 4.06e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.89     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 703      |
|    iterations             | 225      |
|    time_elapsed           | 40       |
|    total_timesteps        | 28800    |
| train/                    |          |
|    explained_variance     | -38.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00181  |
|    learning_rate          | 0.001    |
|    n_updates              | 224      |
|    policy_objective       | 0.0623   |
|    value_loss             | 0.00265  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.53     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 703      |
|    iterations             | 226      |
|    time_elapsed           | 41       |
|    total_timesteps        | 28928    |
| train/                    |          |
|    explained_variance     | 0.22     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00406  |
|    learning_rate          | 0.001    |
|    n_updates              | 225      |
|    policy_objective       | 0.0497   |
|    value_loss             | 0.0366   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.19     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 703      |
|    iterations             | 227      |
|    time_elapsed           | 41       |
|    total_timesteps        | 29056    |
| train/                    |          |
|    explained_variance     | -0.0635  |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00599  |
|    learning_rate          | 0.001    |
|    n_updates              | 226      |
|    policy_objective       | 0.0754   |
|    value_loss             | 0.054    |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.84     |
|    ep_rew_mean            | 0.05     |
| time/                     |          |
|    fps                    | 703      |
|    iterations             | 228      |
|    time_elapsed           | 41       |
|    total_timesteps        | 29184    |
| train/                    |          |
|    explained_variance     | 0.17     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00634  |
|    learning_rate          | 0.001    |
|    n_updates              | 227      |
|    policy_objective       | 0.0601   |
|    value_loss             | 0.0371   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.64     |
|    ep_rew_mean            | 0.05     |
| time/                     |          |
|    fps                    | 703      |
|    iterations             | 229      |
|    time_elapsed           | 41       |
|    total_timesteps        | 29312    |
| train/                    |          |
|    explained_variance     | 0.257    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00632  |
|    learning_rate          | 0.001    |
|    n_updates              | 228      |
|    policy_objective       | 0.0201   |
|    value_loss             | 0.0641   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.21     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 230      |
|    time_elapsed           | 41       |
|    total_timesteps        | 29440    |
| train/                    |          |
|    explained_variance     | -8.3     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00349  |
|    learning_rate          | 0.001    |
|    n_updates              | 229      |
|    policy_objective       | 0.0337   |
|    value_loss             | 0.0137   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.83     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 231      |
|    time_elapsed           | 41       |
|    total_timesteps        | 29568    |
| train/                    |          |
|    explained_variance     | -8.6     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00382  |
|    learning_rate          | 0.001    |
|    n_updates              | 230      |
|    policy_objective       | 0.0275   |
|    value_loss             | 0.000657 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.9      |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 232      |
|    time_elapsed           | 42       |
|    total_timesteps        | 29696    |
| train/                    |          |
|    explained_variance     | 0.0876   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00397  |
|    learning_rate          | 0.001    |
|    n_updates              | 231      |
|    policy_objective       | 0.121    |
|    value_loss             | 7.4e-05  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.2      |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 233      |
|    time_elapsed           | 42       |
|    total_timesteps        | 29824    |
| train/                    |          |
|    explained_variance     | -38.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00458  |
|    learning_rate          | 0.001    |
|    n_updates              | 232      |
|    policy_objective       | 0.0557   |
|    value_loss             | 6.35e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.42     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 234      |
|    time_elapsed           | 42       |
|    total_timesteps        | 29952    |
| train/                    |          |
|    explained_variance     | 0.0252   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00702  |
|    learning_rate          | 0.001    |
|    n_updates              | 233      |
|    policy_objective       | 0.0609   |
|    value_loss             | 0.0364   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.58     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 235      |
|    time_elapsed           | 42       |
|    total_timesteps        | 30080    |
| train/                    |          |
|    explained_variance     | 0.417    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00589  |
|    learning_rate          | 0.001    |
|    n_updates              | 234      |
|    policy_objective       | 0.0371   |
|    value_loss             | 0.0254   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.53     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 236      |
|    time_elapsed           | 42       |
|    total_timesteps        | 30208    |
| train/                    |          |
|    explained_variance     | 0.484    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00353  |
|    learning_rate          | 0.001    |
|    n_updates              | 235      |
|    policy_objective       | 0.0354   |
|    value_loss             | 0.0374   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.17     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 237      |
|    time_elapsed           | 43       |
|    total_timesteps        | 30336    |
| train/                    |          |
|    explained_variance     | 0.291    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00606  |
|    learning_rate          | 0.001    |
|    n_updates              | 236      |
|    policy_objective       | 0.0327   |
|    value_loss             | 0.0332   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.07     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 238      |
|    time_elapsed           | 43       |
|    total_timesteps        | 30464    |
| train/                    |          |
|    explained_variance     | -0.00941 |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00391  |
|    learning_rate          | 0.001    |
|    n_updates              | 237      |
|    policy_objective       | 0.0391   |
|    value_loss             | 0.0511   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.56     |
|    ep_rew_mean            | 0.06     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 239      |
|    time_elapsed           | 43       |
|    total_timesteps        | 30592    |
| train/                    |          |
|    explained_variance     | -6.18    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00684  |
|    learning_rate          | 0.001    |
|    n_updates              | 238      |
|    policy_objective       | 0.0417   |
|    value_loss             | 0.00728  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.98     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 703      |
|    iterations             | 240      |
|    time_elapsed           | 43       |
|    total_timesteps        | 30720    |
| train/                    |          |
|    explained_variance     | 0.0435   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0059   |
|    learning_rate          | 0.001    |
|    n_updates              | 239      |
|    policy_objective       | 0.037    |
|    value_loss             | 0.0485   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.17     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 241      |
|    time_elapsed           | 43       |
|    total_timesteps        | 30848    |
| train/                    |          |
|    explained_variance     | -7.74    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00496  |
|    learning_rate          | 0.001    |
|    n_updates              | 240      |
|    policy_objective       | 0.0393   |
|    value_loss             | 0.0104   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.11     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 242      |
|    time_elapsed           | 43       |
|    total_timesteps        | 30976    |
| train/                    |          |
|    explained_variance     | -4.66    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00571  |
|    learning_rate          | 0.001    |
|    n_updates              | 241      |
|    policy_objective       | 0.0314   |
|    value_loss             | 0.00096  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.7      |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 243      |
|    time_elapsed           | 44       |
|    total_timesteps        | 31104    |
| train/                    |          |
|    explained_variance     | -40.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00357  |
|    learning_rate          | 0.001    |
|    n_updates              | 242      |
|    policy_objective       | 0.023    |
|    value_loss             | 0.000386 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.29     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 244      |
|    time_elapsed           | 44       |
|    total_timesteps        | 31232    |
| train/                    |          |
|    explained_variance     | -0.00504 |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00588  |
|    learning_rate          | 0.001    |
|    n_updates              | 243      |
|    policy_objective       | 0.0273   |
|    value_loss             | 0.0304   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.29     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 245      |
|    time_elapsed           | 44       |
|    total_timesteps        | 31360    |
| train/                    |          |
|    explained_variance     | -20.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00238  |
|    learning_rate          | 0.001    |
|    n_updates              | 244      |
|    policy_objective       | 0.0378   |
|    value_loss             | 0.00747  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.38     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 246      |
|    time_elapsed           | 44       |
|    total_timesteps        | 31488    |
| train/                    |          |
|    explained_variance     | -34.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00288  |
|    learning_rate          | 0.001    |
|    n_updates              | 245      |
|    policy_objective       | 0.0315   |
|    value_loss             | 0.00152  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.32     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 703      |
|    iterations             | 247      |
|    time_elapsed           | 44       |
|    total_timesteps        | 31616    |
| train/                    |          |
|    explained_variance     | 0.141    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0051   |
|    learning_rate          | 0.001    |
|    n_updates              | 246      |
|    policy_objective       | 0.0477   |
|    value_loss             | 0.0406   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.44     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 703      |
|    iterations             | 248      |
|    time_elapsed           | 45       |
|    total_timesteps        | 31744    |
| train/                    |          |
|    explained_variance     | -8.91    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00759  |
|    learning_rate          | 0.001    |
|    n_updates              | 247      |
|    policy_objective       | 0.0524   |
|    value_loss             | 0.00173  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.7      |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 703      |
|    iterations             | 249      |
|    time_elapsed           | 45       |
|    total_timesteps        | 31872    |
| train/                    |          |
|    explained_variance     | 0.0881   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00625  |
|    learning_rate          | 0.001    |
|    n_updates              | 248      |
|    policy_objective       | 0.0578   |
|    value_loss             | 0.0482   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.21     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 703      |
|    iterations             | 250      |
|    time_elapsed           | 45       |
|    total_timesteps        | 32000    |
| train/                    |          |
|    explained_variance     | -30.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00263  |
|    learning_rate          | 0.001    |
|    n_updates              | 249      |
|    policy_objective       | 0.0395   |
|    value_loss             | 0.00633  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.44     |
|    ep_rew_mean            | 0.05     |
| time/                     |          |
|    fps                    | 703      |
|    iterations             | 251      |
|    time_elapsed           | 45       |
|    total_timesteps        | 32128    |
| train/                    |          |
|    explained_variance     | 0.127    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00626  |
|    learning_rate          | 0.001    |
|    n_updates              | 250      |
|    policy_objective       | 0.0208   |
|    value_loss             | 0.0664   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.61     |
|    ep_rew_mean            | 0.06     |
| time/                     |          |
|    fps                    | 703      |
|    iterations             | 252      |
|    time_elapsed           | 45       |
|    total_timesteps        | 32256    |
| train/                    |          |
|    explained_variance     | 0.232    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00892  |
|    learning_rate          | 0.001    |
|    n_updates              | 251      |
|    policy_objective       | 0.0581   |
|    value_loss             | 0.0309   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.85     |
|    ep_rew_mean            | 0.05     |
| time/                     |          |
|    fps                    | 703      |
|    iterations             | 253      |
|    time_elapsed           | 46       |
|    total_timesteps        | 32384    |
| train/                    |          |
|    explained_variance     | 0.535    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00419  |
|    learning_rate          | 0.001    |
|    n_updates              | 252      |
|    policy_objective       | 0.0231   |
|    value_loss             | 0.0342   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.68     |
|    ep_rew_mean            | 0.07     |
| time/                     |          |
|    fps                    | 703      |
|    iterations             | 254      |
|    time_elapsed           | 46       |
|    total_timesteps        | 32512    |
| train/                    |          |
|    explained_variance     | -3.85    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00623  |
|    learning_rate          | 0.001    |
|    n_updates              | 253      |
|    policy_objective       | 0.032    |
|    value_loss             | 0.0041   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.21     |
|    ep_rew_mean            | 0.06     |
| time/                     |          |
|    fps                    | 703      |
|    iterations             | 255      |
|    time_elapsed           | 46       |
|    total_timesteps        | 32640    |
| train/                    |          |
|    explained_variance     | 0.397    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00322  |
|    learning_rate          | 0.001    |
|    n_updates              | 254      |
|    policy_objective       | 0.0288   |
|    value_loss             | 0.0546   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.62     |
|    ep_rew_mean            | 0.05     |
| time/                     |          |
|    fps                    | 703      |
|    iterations             | 256      |
|    time_elapsed           | 46       |
|    total_timesteps        | 32768    |
| train/                    |          |
|    explained_variance     | -3.7     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00727  |
|    learning_rate          | 0.001    |
|    n_updates              | 255      |
|    policy_objective       | 0.0202   |
|    value_loss             | 0.0154   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.95     |
|    ep_rew_mean            | 0.05     |
| time/                     |          |
|    fps                    | 703      |
|    iterations             | 257      |
|    time_elapsed           | 46       |
|    total_timesteps        | 32896    |
| train/                    |          |
|    explained_variance     | 0.103    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00439  |
|    learning_rate          | 0.001    |
|    n_updates              | 256      |
|    policy_objective       | 0.151    |
|    value_loss             | 0.0414   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.77     |
|    ep_rew_mean            | 0.05     |
| time/                     |          |
|    fps                    | 703      |
|    iterations             | 258      |
|    time_elapsed           | 46       |
|    total_timesteps        | 33024    |
| train/                    |          |
|    explained_variance     | 0.219    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00321  |
|    learning_rate          | 0.001    |
|    n_updates              | 257      |
|    policy_objective       | 0.0317   |
|    value_loss             | 0.0146   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.25     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 703      |
|    iterations             | 259      |
|    time_elapsed           | 47       |
|    total_timesteps        | 33152    |
| train/                    |          |
|    explained_variance     | -31.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00583  |
|    learning_rate          | 0.001    |
|    n_updates              | 258      |
|    policy_objective       | 0.053    |
|    value_loss             | 0.00272  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.21     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 703      |
|    iterations             | 260      |
|    time_elapsed           | 47       |
|    total_timesteps        | 33280    |
| train/                    |          |
|    explained_variance     | -41.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00304  |
|    learning_rate          | 0.001    |
|    n_updates              | 259      |
|    policy_objective       | 0.0176   |
|    value_loss             | 0.00105  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.58     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 703      |
|    iterations             | 261      |
|    time_elapsed           | 47       |
|    total_timesteps        | 33408    |
| train/                    |          |
|    explained_variance     | 0.16     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0057   |
|    learning_rate          | 0.001    |
|    n_updates              | 260      |
|    policy_objective       | 0.155    |
|    value_loss             | 0.0454   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.22     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 703      |
|    iterations             | 262      |
|    time_elapsed           | 47       |
|    total_timesteps        | 33536    |
| train/                    |          |
|    explained_variance     | -10.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00519  |
|    learning_rate          | 0.001    |
|    n_updates              | 261      |
|    policy_objective       | 0.0348   |
|    value_loss             | 0.00246  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.16     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 703      |
|    iterations             | 263      |
|    time_elapsed           | 47       |
|    total_timesteps        | 33664    |
| train/                    |          |
|    explained_variance     | -25.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0049   |
|    learning_rate          | 0.001    |
|    n_updates              | 262      |
|    policy_objective       | 0.0324   |
|    value_loss             | 0.00464  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.52     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 264      |
|    time_elapsed           | 47       |
|    total_timesteps        | 33792    |
| train/                    |          |
|    explained_variance     | -24.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00409  |
|    learning_rate          | 0.001    |
|    n_updates              | 263      |
|    policy_objective       | 0.0282   |
|    value_loss             | 0.0013   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.24     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 265      |
|    time_elapsed           | 48       |
|    total_timesteps        | 33920    |
| train/                    |          |
|    explained_variance     | -1.55    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00487  |
|    learning_rate          | 0.001    |
|    n_updates              | 264      |
|    policy_objective       | 0.0547   |
|    value_loss             | 0.00126  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.53     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 266      |
|    time_elapsed           | 48       |
|    total_timesteps        | 34048    |
| train/                    |          |
|    explained_variance     | 0.184    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0044   |
|    learning_rate          | 0.001    |
|    n_updates              | 265      |
|    policy_objective       | 0.178    |
|    value_loss             | 0.0178   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.41     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 267      |
|    time_elapsed           | 48       |
|    total_timesteps        | 34176    |
| train/                    |          |
|    explained_variance     | -34.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00204  |
|    learning_rate          | 0.001    |
|    n_updates              | 266      |
|    policy_objective       | 0.057    |
|    value_loss             | 0.00163  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.21     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 268      |
|    time_elapsed           | 48       |
|    total_timesteps        | 34304    |
| train/                    |          |
|    explained_variance     | -64.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00881  |
|    learning_rate          | 0.001    |
|    n_updates              | 267      |
|    policy_objective       | 0.0422   |
|    value_loss             | 0.000321 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.69     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 269      |
|    time_elapsed           | 48       |
|    total_timesteps        | 34432    |
| train/                    |          |
|    explained_variance     | -87.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00373  |
|    learning_rate          | 0.001    |
|    n_updates              | 268      |
|    policy_objective       | 0.0353   |
|    value_loss             | 0.000693 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.8      |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 270      |
|    time_elapsed           | 49       |
|    total_timesteps        | 34560    |
| train/                    |          |
|    explained_variance     | -10.7    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00642  |
|    learning_rate          | 0.001    |
|    n_updates              | 269      |
|    policy_objective       | 0.0531   |
|    value_loss             | 0.00257  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.09     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 703      |
|    iterations             | 271      |
|    time_elapsed           | 49       |
|    total_timesteps        | 34688    |
| train/                    |          |
|    explained_variance     | 0.101    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00578  |
|    learning_rate          | 0.001    |
|    n_updates              | 270      |
|    policy_objective       | 0.119    |
|    value_loss             | 0.0305   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.08     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 272      |
|    time_elapsed           | 49       |
|    total_timesteps        | 34816    |
| train/                    |          |
|    explained_variance     | -16.6    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00462  |
|    learning_rate          | 0.001    |
|    n_updates              | 271      |
|    policy_objective       | 0.0631   |
|    value_loss             | 0.00122  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.13     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 273      |
|    time_elapsed           | 49       |
|    total_timesteps        | 34944    |
| train/                    |          |
|    explained_variance     | -38.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00283  |
|    learning_rate          | 0.001    |
|    n_updates              | 272      |
|    policy_objective       | 0.0497   |
|    value_loss             | 7.77e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.57     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 274      |
|    time_elapsed           | 49       |
|    total_timesteps        | 35072    |
| train/                    |          |
|    explained_variance     | -32.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00152  |
|    learning_rate          | 0.001    |
|    n_updates              | 273      |
|    policy_objective       | 0.0288   |
|    value_loss             | 0.000111 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.07     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 275      |
|    time_elapsed           | 49       |
|    total_timesteps        | 35200    |
| train/                    |          |
|    explained_variance     | 0.119    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00582  |
|    learning_rate          | 0.001    |
|    n_updates              | 274      |
|    policy_objective       | 0.0376   |
|    value_loss             | 0.0324   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.17     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 703      |
|    iterations             | 276      |
|    time_elapsed           | 50       |
|    total_timesteps        | 35328    |
| train/                    |          |
|    explained_variance     | -17.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00403  |
|    learning_rate          | 0.001    |
|    n_updates              | 275      |
|    policy_objective       | 0.0346   |
|    value_loss             | 0.00285  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.2      |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 703      |
|    iterations             | 277      |
|    time_elapsed           | 50       |
|    total_timesteps        | 35456    |
| train/                    |          |
|    explained_variance     | 0.0314   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00516  |
|    learning_rate          | 0.001    |
|    n_updates              | 276      |
|    policy_objective       | 0.0402   |
|    value_loss             | 0.042    |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.44     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 703      |
|    iterations             | 278      |
|    time_elapsed           | 50       |
|    total_timesteps        | 35584    |
| train/                    |          |
|    explained_variance     | 0.151    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00621  |
|    learning_rate          | 0.001    |
|    n_updates              | 277      |
|    policy_objective       | 0.0376   |
|    value_loss             | 0.0434   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.62     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 703      |
|    iterations             | 279      |
|    time_elapsed           | 50       |
|    total_timesteps        | 35712    |
| train/                    |          |
|    explained_variance     | 0.37     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0043   |
|    learning_rate          | 0.001    |
|    n_updates              | 278      |
|    policy_objective       | 0.1      |
|    value_loss             | 0.023    |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.2      |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 703      |
|    iterations             | 280      |
|    time_elapsed           | 50       |
|    total_timesteps        | 35840    |
| train/                    |          |
|    explained_variance     | -18.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00628  |
|    learning_rate          | 0.001    |
|    n_updates              | 279      |
|    policy_objective       | 0.0466   |
|    value_loss             | 0.0126   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.98     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 703      |
|    iterations             | 281      |
|    time_elapsed           | 51       |
|    total_timesteps        | 35968    |
| train/                    |          |
|    explained_variance     | -13.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00563  |
|    learning_rate          | 0.001    |
|    n_updates              | 280      |
|    policy_objective       | 0.049    |
|    value_loss             | 0.000407 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.76     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 703      |
|    iterations             | 282      |
|    time_elapsed           | 51       |
|    total_timesteps        | 36096    |
| train/                    |          |
|    explained_variance     | 0.0576   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00449  |
|    learning_rate          | 0.001    |
|    n_updates              | 281      |
|    policy_objective       | 0.0435   |
|    value_loss             | 0.0468   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.65     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 283      |
|    time_elapsed           | 51       |
|    total_timesteps        | 36224    |
| train/                    |          |
|    explained_variance     | -28.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00435  |
|    learning_rate          | 0.001    |
|    n_updates              | 282      |
|    policy_objective       | 0.0544   |
|    value_loss             | 0.00431  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.28     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 284      |
|    time_elapsed           | 51       |
|    total_timesteps        | 36352    |
| train/                    |          |
|    explained_variance     | -32.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00469  |
|    learning_rate          | 0.001    |
|    n_updates              | 283      |
|    policy_objective       | 0.063    |
|    value_loss             | 0.000741 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.34     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 285      |
|    time_elapsed           | 51       |
|    total_timesteps        | 36480    |
| train/                    |          |
|    explained_variance     | 0.164    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00673  |
|    learning_rate          | 0.001    |
|    n_updates              | 284      |
|    policy_objective       | 0.0979   |
|    value_loss             | 0.0334   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.55     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 286      |
|    time_elapsed           | 51       |
|    total_timesteps        | 36608    |
| train/                    |          |
|    explained_variance     | -7.76    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00547  |
|    learning_rate          | 0.001    |
|    n_updates              | 285      |
|    policy_objective       | 0.0537   |
|    value_loss             | 0.00203  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.02     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 287      |
|    time_elapsed           | 52       |
|    total_timesteps        | 36736    |
| train/                    |          |
|    explained_variance     | -40.7    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00146  |
|    learning_rate          | 0.001    |
|    n_updates              | 286      |
|    policy_objective       | 0.0694   |
|    value_loss             | 0.00344  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.34     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 288      |
|    time_elapsed           | 52       |
|    total_timesteps        | 36864    |
| train/                    |          |
|    explained_variance     | 0.462    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00595  |
|    learning_rate          | 0.001    |
|    n_updates              | 287      |
|    policy_objective       | 0.0346   |
|    value_loss             | 0.0283   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9        |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 289      |
|    time_elapsed           | 52       |
|    total_timesteps        | 36992    |
| train/                    |          |
|    explained_variance     | 0.524    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00683  |
|    learning_rate          | 0.001    |
|    n_updates              | 288      |
|    policy_objective       | 0.0641   |
|    value_loss             | 0.0326   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.05     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 290      |
|    time_elapsed           | 52       |
|    total_timesteps        | 37120    |
| train/                    |          |
|    explained_variance     | -26.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00472  |
|    learning_rate          | 0.001    |
|    n_updates              | 289      |
|    policy_objective       | 0.072    |
|    value_loss             | 0.00161  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.87     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 291      |
|    time_elapsed           | 52       |
|    total_timesteps        | 37248    |
| train/                    |          |
|    explained_variance     | -12.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0035   |
|    learning_rate          | 0.001    |
|    n_updates              | 290      |
|    policy_objective       | 0.0325   |
|    value_loss             | 0.00833  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.69     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 292      |
|    time_elapsed           | 53       |
|    total_timesteps        | 37376    |
| train/                    |          |
|    explained_variance     | -12.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0044   |
|    learning_rate          | 0.001    |
|    n_updates              | 291      |
|    policy_objective       | 0.0466   |
|    value_loss             | 0.000221 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.77     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 293      |
|    time_elapsed           | 53       |
|    total_timesteps        | 37504    |
| train/                    |          |
|    explained_variance     | -46.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00473  |
|    learning_rate          | 0.001    |
|    n_updates              | 292      |
|    policy_objective       | 0.0347   |
|    value_loss             | 0.000175 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.25     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 294      |
|    time_elapsed           | 53       |
|    total_timesteps        | 37632    |
| train/                    |          |
|    explained_variance     | -21.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00897  |
|    learning_rate          | 0.001    |
|    n_updates              | 293      |
|    policy_objective       | 0.0378   |
|    value_loss             | 1.29e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.6      |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 295      |
|    time_elapsed           | 53       |
|    total_timesteps        | 37760    |
| train/                    |          |
|    explained_variance     | -28.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00466  |
|    learning_rate          | 0.001    |
|    n_updates              | 294      |
|    policy_objective       | 0.0551   |
|    value_loss             | 9.31e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.32     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 296      |
|    time_elapsed           | 53       |
|    total_timesteps        | 37888    |
| train/                    |          |
|    explained_variance     | -124     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00483  |
|    learning_rate          | 0.001    |
|    n_updates              | 295      |
|    policy_objective       | 0.0781   |
|    value_loss             | 1.89e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.62     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 297      |
|    time_elapsed           | 53       |
|    total_timesteps        | 38016    |
| train/                    |          |
|    explained_variance     | -0.00461 |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00419  |
|    learning_rate          | 0.001    |
|    n_updates              | 296      |
|    policy_objective       | 0.0478   |
|    value_loss             | 0.0384   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.19     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 298      |
|    time_elapsed           | 54       |
|    total_timesteps        | 38144    |
| train/                    |          |
|    explained_variance     | -2.49    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00677  |
|    learning_rate          | 0.001    |
|    n_updates              | 297      |
|    policy_objective       | 0.058    |
|    value_loss             | 0.00187  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.94     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 705      |
|    iterations             | 299      |
|    time_elapsed           | 54       |
|    total_timesteps        | 38272    |
| train/                    |          |
|    explained_variance     | -17.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00402  |
|    learning_rate          | 0.001    |
|    n_updates              | 298      |
|    policy_objective       | 0.0655   |
|    value_loss             | 0.00182  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.82     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 705      |
|    iterations             | 300      |
|    time_elapsed           | 54       |
|    total_timesteps        | 38400    |
| train/                    |          |
|    explained_variance     | -33.6    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00445  |
|    learning_rate          | 0.001    |
|    n_updates              | 299      |
|    policy_objective       | 0.027    |
|    value_loss             | 0.000265 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.45     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 705      |
|    iterations             | 301      |
|    time_elapsed           | 54       |
|    total_timesteps        | 38528    |
| train/                    |          |
|    explained_variance     | 0.0647   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00545  |
|    learning_rate          | 0.001    |
|    n_updates              | 300      |
|    policy_objective       | 0.0414   |
|    value_loss             | 0.0392   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.31     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 705      |
|    iterations             | 302      |
|    time_elapsed           | 54       |
|    total_timesteps        | 38656    |
| train/                    |          |
|    explained_variance     | 0.116    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0047   |
|    learning_rate          | 0.001    |
|    n_updates              | 301      |
|    policy_objective       | 0.0305   |
|    value_loss             | 0.0278   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.6      |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 705      |
|    iterations             | 303      |
|    time_elapsed           | 55       |
|    total_timesteps        | 38784    |
| train/                    |          |
|    explained_variance     | 0.393    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00645  |
|    learning_rate          | 0.001    |
|    n_updates              | 302      |
|    policy_objective       | 0.0444   |
|    value_loss             | 0.0301   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.52     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 705      |
|    iterations             | 304      |
|    time_elapsed           | 55       |
|    total_timesteps        | 38912    |
| train/                    |          |
|    explained_variance     | -7.11    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00509  |
|    learning_rate          | 0.001    |
|    n_updates              | 303      |
|    policy_objective       | 0.0409   |
|    value_loss             | 0.0119   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.53     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 305      |
|    time_elapsed           | 55       |
|    total_timesteps        | 39040    |
| train/                    |          |
|    explained_variance     | -8.24    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00682  |
|    learning_rate          | 0.001    |
|    n_updates              | 304      |
|    policy_objective       | 0.0492   |
|    value_loss             | 0.000401 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.37     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 705      |
|    iterations             | 306      |
|    time_elapsed           | 55       |
|    total_timesteps        | 39168    |
| train/                    |          |
|    explained_variance     | 0.0773   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0068   |
|    learning_rate          | 0.001    |
|    n_updates              | 305      |
|    policy_objective       | 0.111    |
|    value_loss             | 0.0346   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.01     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 705      |
|    iterations             | 307      |
|    time_elapsed           | 55       |
|    total_timesteps        | 39296    |
| train/                    |          |
|    explained_variance     | -0.0699  |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00416  |
|    learning_rate          | 0.001    |
|    n_updates              | 306      |
|    policy_objective       | 0.0546   |
|    value_loss             | 0.0012   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.57     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 705      |
|    iterations             | 308      |
|    time_elapsed           | 55       |
|    total_timesteps        | 39424    |
| train/                    |          |
|    explained_variance     | 0.332    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00234  |
|    learning_rate          | 0.001    |
|    n_updates              | 307      |
|    policy_objective       | 0.0779   |
|    value_loss             | 0.00886  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.22     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 705      |
|    iterations             | 309      |
|    time_elapsed           | 56       |
|    total_timesteps        | 39552    |
| train/                    |          |
|    explained_variance     | 0.179    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0042   |
|    learning_rate          | 0.001    |
|    n_updates              | 308      |
|    policy_objective       | 0.199    |
|    value_loss             | 0.033    |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.88     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 705      |
|    iterations             | 310      |
|    time_elapsed           | 56       |
|    total_timesteps        | 39680    |
| train/                    |          |
|    explained_variance     | 0.393    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00765  |
|    learning_rate          | 0.001    |
|    n_updates              | 309      |
|    policy_objective       | 0.0365   |
|    value_loss             | 0.0262   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.33     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 705      |
|    iterations             | 311      |
|    time_elapsed           | 56       |
|    total_timesteps        | 39808    |
| train/                    |          |
|    explained_variance     | -65.7    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00442  |
|    learning_rate          | 0.001    |
|    n_updates              | 310      |
|    policy_objective       | 0.0245   |
|    value_loss             | 0.00333  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.93     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 705      |
|    iterations             | 312      |
|    time_elapsed           | 56       |
|    total_timesteps        | 39936    |
| train/                    |          |
|    explained_variance     | -10.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00299  |
|    learning_rate          | 0.001    |
|    n_updates              | 311      |
|    policy_objective       | 0.0561   |
|    value_loss             | 0.00234  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.04     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 705      |
|    iterations             | 313      |
|    time_elapsed           | 56       |
|    total_timesteps        | 40064    |
| train/                    |          |
|    explained_variance     | 0.472    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00671  |
|    learning_rate          | 0.001    |
|    n_updates              | 312      |
|    policy_objective       | 0.0508   |
|    value_loss             | 0.031    |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.28     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 705      |
|    iterations             | 314      |
|    time_elapsed           | 56       |
|    total_timesteps        | 40192    |
| train/                    |          |
|    explained_variance     | -21.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00398  |
|    learning_rate          | 0.001    |
|    n_updates              | 313      |
|    policy_objective       | 0.0477   |
|    value_loss             | 0.00477  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.07     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 705      |
|    iterations             | 315      |
|    time_elapsed           | 57       |
|    total_timesteps        | 40320    |
| train/                    |          |
|    explained_variance     | -22.6    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00408  |
|    learning_rate          | 0.001    |
|    n_updates              | 314      |
|    policy_objective       | 0.0381   |
|    value_loss             | 0.00279  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.73     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 705      |
|    iterations             | 316      |
|    time_elapsed           | 57       |
|    total_timesteps        | 40448    |
| train/                    |          |
|    explained_variance     | 0.191    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00621  |
|    learning_rate          | 0.001    |
|    n_updates              | 315      |
|    policy_objective       | 0.0499   |
|    value_loss             | 0.042    |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.44     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 705      |
|    iterations             | 317      |
|    time_elapsed           | 57       |
|    total_timesteps        | 40576    |
| train/                    |          |
|    explained_variance     | -18.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00644  |
|    learning_rate          | 0.001    |
|    n_updates              | 316      |
|    policy_objective       | 0.0367   |
|    value_loss             | 0.000812 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.7      |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 705      |
|    iterations             | 318      |
|    time_elapsed           | 57       |
|    total_timesteps        | 40704    |
| train/                    |          |
|    explained_variance     | 0.244    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00835  |
|    learning_rate          | 0.001    |
|    n_updates              | 317      |
|    policy_objective       | 0.0242   |
|    value_loss             | 0.032    |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.67     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 706      |
|    iterations             | 319      |
|    time_elapsed           | 57       |
|    total_timesteps        | 40832    |
| train/                    |          |
|    explained_variance     | 0.546    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00627  |
|    learning_rate          | 0.001    |
|    n_updates              | 318      |
|    policy_objective       | 0.0756   |
|    value_loss             | 0.0286   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.64     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 706      |
|    iterations             | 320      |
|    time_elapsed           | 58       |
|    total_timesteps        | 40960    |
| train/                    |          |
|    explained_variance     | -32.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00653  |
|    learning_rate          | 0.001    |
|    n_updates              | 319      |
|    policy_objective       | 0.0405   |
|    value_loss             | 0.000502 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.05     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 706      |
|    iterations             | 321      |
|    time_elapsed           | 58       |
|    total_timesteps        | 41088    |
| train/                    |          |
|    explained_variance     | -9.96    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00492  |
|    learning_rate          | 0.001    |
|    n_updates              | 320      |
|    policy_objective       | 0.0412   |
|    value_loss             | 0.0118   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.22     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 706      |
|    iterations             | 322      |
|    time_elapsed           | 58       |
|    total_timesteps        | 41216    |
| train/                    |          |
|    explained_variance     | -6.9     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00404  |
|    learning_rate          | 0.001    |
|    n_updates              | 321      |
|    policy_objective       | 0.0387   |
|    value_loss             | 0.000661 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.45     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 706      |
|    iterations             | 323      |
|    time_elapsed           | 58       |
|    total_timesteps        | 41344    |
| train/                    |          |
|    explained_variance     | 0.0313   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00346  |
|    learning_rate          | 0.001    |
|    n_updates              | 322      |
|    policy_objective       | 0.0395   |
|    value_loss             | 0.0021   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.98     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 705      |
|    iterations             | 324      |
|    time_elapsed           | 58       |
|    total_timesteps        | 41472    |
| train/                    |          |
|    explained_variance     | -49      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00221  |
|    learning_rate          | 0.001    |
|    n_updates              | 323      |
|    policy_objective       | 0.0551   |
|    value_loss             | 0.000588 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.25     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 706      |
|    iterations             | 325      |
|    time_elapsed           | 58       |
|    total_timesteps        | 41600    |
| train/                    |          |
|    explained_variance     | -2.73    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00588  |
|    learning_rate          | 0.001    |
|    n_updates              | 324      |
|    policy_objective       | 0.0476   |
|    value_loss             | 1.2e-05  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.29     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 706      |
|    iterations             | 326      |
|    time_elapsed           | 59       |
|    total_timesteps        | 41728    |
| train/                    |          |
|    explained_variance     | 0.0331   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00679  |
|    learning_rate          | 0.001    |
|    n_updates              | 325      |
|    policy_objective       | 0.0297   |
|    value_loss             | 0.0301   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.29     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 706      |
|    iterations             | 327      |
|    time_elapsed           | 59       |
|    total_timesteps        | 41856    |
| train/                    |          |
|    explained_variance     | -11      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00532  |
|    learning_rate          | 0.001    |
|    n_updates              | 326      |
|    policy_objective       | 0.0222   |
|    value_loss             | 0.00123  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.17     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 705      |
|    iterations             | 328      |
|    time_elapsed           | 59       |
|    total_timesteps        | 41984    |
| train/                    |          |
|    explained_variance     | -17.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00598  |
|    learning_rate          | 0.001    |
|    n_updates              | 327      |
|    policy_objective       | 0.0266   |
|    value_loss             | 0.00541  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.06     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 705      |
|    iterations             | 329      |
|    time_elapsed           | 59       |
|    total_timesteps        | 42112    |
| train/                    |          |
|    explained_variance     | -1.68    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00647  |
|    learning_rate          | 0.001    |
|    n_updates              | 328      |
|    policy_objective       | 0.0489   |
|    value_loss             | 0.000136 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.22     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 705      |
|    iterations             | 330      |
|    time_elapsed           | 59       |
|    total_timesteps        | 42240    |
| train/                    |          |
|    explained_variance     | 0.033    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00783  |
|    learning_rate          | 0.001    |
|    n_updates              | 329      |
|    policy_objective       | 0.0789   |
|    value_loss             | 0.00179  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.78     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 705      |
|    iterations             | 331      |
|    time_elapsed           | 60       |
|    total_timesteps        | 42368    |
| train/                    |          |
|    explained_variance     | 0.394    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00111  |
|    learning_rate          | 0.001    |
|    n_updates              | 330      |
|    policy_objective       | 0.0146   |
|    value_loss             | 0.00405  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.65     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 705      |
|    iterations             | 332      |
|    time_elapsed           | 60       |
|    total_timesteps        | 42496    |
| train/                    |          |
|    explained_variance     | 0.0838   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00799  |
|    learning_rate          | 0.001    |
|    n_updates              | 331      |
|    policy_objective       | 0.0256   |
|    value_loss             | 0.0474   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.55     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 705      |
|    iterations             | 333      |
|    time_elapsed           | 60       |
|    total_timesteps        | 42624    |
| train/                    |          |
|    explained_variance     | -1.35    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00758  |
|    learning_rate          | 0.001    |
|    n_updates              | 332      |
|    policy_objective       | 0.0378   |
|    value_loss             | 0.000873 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.14     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 705      |
|    iterations             | 334      |
|    time_elapsed           | 60       |
|    total_timesteps        | 42752    |
| train/                    |          |
|    explained_variance     | -19      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00496  |
|    learning_rate          | 0.001    |
|    n_updates              | 333      |
|    policy_objective       | 0.0362   |
|    value_loss             | 0.000598 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.04     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 705      |
|    iterations             | 335      |
|    time_elapsed           | 60       |
|    total_timesteps        | 42880    |
| train/                    |          |
|    explained_variance     | -13.7    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00491  |
|    learning_rate          | 0.001    |
|    n_updates              | 334      |
|    policy_objective       | 0.059    |
|    value_loss             | 0.00014  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.12     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 705      |
|    iterations             | 336      |
|    time_elapsed           | 60       |
|    total_timesteps        | 43008    |
| train/                    |          |
|    explained_variance     | -25.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00576  |
|    learning_rate          | 0.001    |
|    n_updates              | 335      |
|    policy_objective       | 0.0571   |
|    value_loss             | 8.75e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.85     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 705      |
|    iterations             | 337      |
|    time_elapsed           | 61       |
|    total_timesteps        | 43136    |
| train/                    |          |
|    explained_variance     | 0.107    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0065   |
|    learning_rate          | 0.001    |
|    n_updates              | 336      |
|    policy_objective       | 0.0659   |
|    value_loss             | 0.0348   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8        |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 338      |
|    time_elapsed           | 61       |
|    total_timesteps        | 43264    |
| train/                    |          |
|    explained_variance     | -14      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00545  |
|    learning_rate          | 0.001    |
|    n_updates              | 337      |
|    policy_objective       | 0.0482   |
|    value_loss             | 0.00137  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.75     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 339      |
|    time_elapsed           | 61       |
|    total_timesteps        | 43392    |
| train/                    |          |
|    explained_variance     | -30.7    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00357  |
|    learning_rate          | 0.001    |
|    n_updates              | 338      |
|    policy_objective       | 0.0365   |
|    value_loss             | 0.00089  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.95     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 705      |
|    iterations             | 340      |
|    time_elapsed           | 61       |
|    total_timesteps        | 43520    |
| train/                    |          |
|    explained_variance     | 0.239    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00522  |
|    learning_rate          | 0.001    |
|    n_updates              | 339      |
|    policy_objective       | 0.0427   |
|    value_loss             | 0.0256   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.15     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 341      |
|    time_elapsed           | 61       |
|    total_timesteps        | 43648    |
| train/                    |          |
|    explained_variance     | -8.5     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0027   |
|    learning_rate          | 0.001    |
|    n_updates              | 340      |
|    policy_objective       | 0.0571   |
|    value_loss             | 0.00242  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.52     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 342      |
|    time_elapsed           | 62       |
|    total_timesteps        | 43776    |
| train/                    |          |
|    explained_variance     | -6.21    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00735  |
|    learning_rate          | 0.001    |
|    n_updates              | 341      |
|    policy_objective       | 0.0219   |
|    value_loss             | 0.0068   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.13     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 343      |
|    time_elapsed           | 62       |
|    total_timesteps        | 43904    |
| train/                    |          |
|    explained_variance     | -17      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00304  |
|    learning_rate          | 0.001    |
|    n_updates              | 342      |
|    policy_objective       | 0.0942   |
|    value_loss             | 0.0004   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.9      |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 344      |
|    time_elapsed           | 62       |
|    total_timesteps        | 44032    |
| train/                    |          |
|    explained_variance     | -11.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00563  |
|    learning_rate          | 0.001    |
|    n_updates              | 343      |
|    policy_objective       | 0.0261   |
|    value_loss             | 0.000714 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.51     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 345      |
|    time_elapsed           | 62       |
|    total_timesteps        | 44160    |
| train/                    |          |
|    explained_variance     | -8.64    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00903  |
|    learning_rate          | 0.001    |
|    n_updates              | 344      |
|    policy_objective       | 0.0649   |
|    value_loss             | 1.94e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.21     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 346      |
|    time_elapsed           | 62       |
|    total_timesteps        | 44288    |
| train/                    |          |
|    explained_variance     | -12.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00445  |
|    learning_rate          | 0.001    |
|    n_updates              | 345      |
|    policy_objective       | 0.0399   |
|    value_loss             | 1.01e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.94     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 347      |
|    time_elapsed           | 63       |
|    total_timesteps        | 44416    |
| train/                    |          |
|    explained_variance     | -33.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0047   |
|    learning_rate          | 0.001    |
|    n_updates              | 346      |
|    policy_objective       | 0.0215   |
|    value_loss             | 2.87e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.42     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 348      |
|    time_elapsed           | 63       |
|    total_timesteps        | 44544    |
| train/                    |          |
|    explained_variance     | -9.25    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00185  |
|    learning_rate          | 0.001    |
|    n_updates              | 347      |
|    policy_objective       | 0.0687   |
|    value_loss             | 7.84e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.05     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 349      |
|    time_elapsed           | 63       |
|    total_timesteps        | 44672    |
| train/                    |          |
|    explained_variance     | -15.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00495  |
|    learning_rate          | 0.001    |
|    n_updates              | 348      |
|    policy_objective       | 0.178    |
|    value_loss             | 1.05e-08 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.53     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 350      |
|    time_elapsed           | 63       |
|    total_timesteps        | 44800    |
| train/                    |          |
|    explained_variance     | -51.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00423  |
|    learning_rate          | 0.001    |
|    n_updates              | 349      |
|    policy_objective       | 0.117    |
|    value_loss             | 5.23e-10 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.94     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 351      |
|    time_elapsed           | 63       |
|    total_timesteps        | 44928    |
| train/                    |          |
|    explained_variance     | -6.89    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00392  |
|    learning_rate          | 0.001    |
|    n_updates              | 350      |
|    policy_objective       | 0.0416   |
|    value_loss             | 2.3e-10  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.06     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 352      |
|    time_elapsed           | 63       |
|    total_timesteps        | 45056    |
| train/                    |          |
|    explained_variance     | -603     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00279  |
|    learning_rate          | 0.001    |
|    n_updates              | 351      |
|    policy_objective       | 0.0496   |
|    value_loss             | 9.28e-08 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.45     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 353      |
|    time_elapsed           | 64       |
|    total_timesteps        | 45184    |
| train/                    |          |
|    explained_variance     | -211     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00679  |
|    learning_rate          | 0.001    |
|    n_updates              | 352      |
|    policy_objective       | 0.0503   |
|    value_loss             | 3.19e-08 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.11     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 354      |
|    time_elapsed           | 64       |
|    total_timesteps        | 45312    |
| train/                    |          |
|    explained_variance     | -44.7    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00253  |
|    learning_rate          | 0.001    |
|    n_updates              | 353      |
|    policy_objective       | 0.0306   |
|    value_loss             | 1.36e-11 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.54     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 355      |
|    time_elapsed           | 64       |
|    total_timesteps        | 45440    |
| train/                    |          |
|    explained_variance     | 4.56e-05 |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0076   |
|    learning_rate          | 0.001    |
|    n_updates              | 354      |
|    policy_objective       | 0.0398   |
|    value_loss             | 0.0434   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.89     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 356      |
|    time_elapsed           | 64       |
|    total_timesteps        | 45568    |
| train/                    |          |
|    explained_variance     | 0.0984   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00845  |
|    learning_rate          | 0.001    |
|    n_updates              | 355      |
|    policy_objective       | 0.048    |
|    value_loss             | 0.0581   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.86     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 357      |
|    time_elapsed           | 64       |
|    total_timesteps        | 45696    |
| train/                    |          |
|    explained_variance     | -8.44    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00427  |
|    learning_rate          | 0.001    |
|    n_updates              | 356      |
|    policy_objective       | 0.054    |
|    value_loss             | 0.00816  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.11     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 358      |
|    time_elapsed           | 65       |
|    total_timesteps        | 45824    |
| train/                    |          |
|    explained_variance     | -0.0134  |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0088   |
|    learning_rate          | 0.001    |
|    n_updates              | 357      |
|    policy_objective       | 0.0427   |
|    value_loss             | 0.0469   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.34     |
|    ep_rew_mean            | 0.05     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 359      |
|    time_elapsed           | 65       |
|    total_timesteps        | 45952    |
| train/                    |          |
|    explained_variance     | -6.86    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00658  |
|    learning_rate          | 0.001    |
|    n_updates              | 358      |
|    policy_objective       | 0.0276   |
|    value_loss             | 0.00157  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.37     |
|    ep_rew_mean            | 0.07     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 360      |
|    time_elapsed           | 65       |
|    total_timesteps        | 46080    |
| train/                    |          |
|    explained_variance     | 0.0511   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0026   |
|    learning_rate          | 0.001    |
|    n_updates              | 359      |
|    policy_objective       | 0.233    |
|    value_loss             | 0.0336   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.11     |
|    ep_rew_mean            | 0.07     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 361      |
|    time_elapsed           | 65       |
|    total_timesteps        | 46208    |
| train/                    |          |
|    explained_variance     | 0.233    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00611  |
|    learning_rate          | 0.001    |
|    n_updates              | 360      |
|    policy_objective       | 0.0364   |
|    value_loss             | 0.063    |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.54     |
|    ep_rew_mean            | 0.07     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 362      |
|    time_elapsed           | 65       |
|    total_timesteps        | 46336    |
| train/                    |          |
|    explained_variance     | 0.303    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00761  |
|    learning_rate          | 0.001    |
|    n_updates              | 361      |
|    policy_objective       | 0.0338   |
|    value_loss             | 0.0371   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.41     |
|    ep_rew_mean            | 0.06     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 363      |
|    time_elapsed           | 65       |
|    total_timesteps        | 46464    |
| train/                    |          |
|    explained_variance     | 0.256    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00584  |
|    learning_rate          | 0.001    |
|    n_updates              | 362      |
|    policy_objective       | 0.149    |
|    value_loss             | 0.0733   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.08     |
|    ep_rew_mean            | 0.06     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 364      |
|    time_elapsed           | 66       |
|    total_timesteps        | 46592    |
| train/                    |          |
|    explained_variance     | -4.4     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00673  |
|    learning_rate          | 0.001    |
|    n_updates              | 363      |
|    policy_objective       | 0.0519   |
|    value_loss             | 0.017    |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.87     |
|    ep_rew_mean            | 0.06     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 365      |
|    time_elapsed           | 66       |
|    total_timesteps        | 46720    |
| train/                    |          |
|    explained_variance     | -7.45    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00253  |
|    learning_rate          | 0.001    |
|    n_updates              | 364      |
|    policy_objective       | 0.0444   |
|    value_loss             | 0.000794 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.42     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 366      |
|    time_elapsed           | 66       |
|    total_timesteps        | 46848    |
| train/                    |          |
|    explained_variance     | 0.0322   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00594  |
|    learning_rate          | 0.001    |
|    n_updates              | 365      |
|    policy_objective       | 0.0913   |
|    value_loss             | 0.0301   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.59     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 367      |
|    time_elapsed           | 66       |
|    total_timesteps        | 46976    |
| train/                    |          |
|    explained_variance     | -13.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00571  |
|    learning_rate          | 0.001    |
|    n_updates              | 366      |
|    policy_objective       | 0.071    |
|    value_loss             | 0.00344  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.75     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 368      |
|    time_elapsed           | 66       |
|    total_timesteps        | 47104    |
| train/                    |          |
|    explained_variance     | 0.0949   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0064   |
|    learning_rate          | 0.001    |
|    n_updates              | 367      |
|    policy_objective       | 0.0506   |
|    value_loss             | 0.0436   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.98     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 369      |
|    time_elapsed           | 67       |
|    total_timesteps        | 47232    |
| train/                    |          |
|    explained_variance     | -7.73    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00399  |
|    learning_rate          | 0.001    |
|    n_updates              | 368      |
|    policy_objective       | 0.0433   |
|    value_loss             | 0.00353  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.84     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 370      |
|    time_elapsed           | 67       |
|    total_timesteps        | 47360    |
| train/                    |          |
|    explained_variance     | 0.222    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00489  |
|    learning_rate          | 0.001    |
|    n_updates              | 369      |
|    policy_objective       | 0.0226   |
|    value_loss             | 0.0337   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.96     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 371      |
|    time_elapsed           | 67       |
|    total_timesteps        | 47488    |
| train/                    |          |
|    explained_variance     | -19.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00588  |
|    learning_rate          | 0.001    |
|    n_updates              | 370      |
|    policy_objective       | 0.0295   |
|    value_loss             | 0.00528  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.47     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 372      |
|    time_elapsed           | 67       |
|    total_timesteps        | 47616    |
| train/                    |          |
|    explained_variance     | -0.628   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00252  |
|    learning_rate          | 0.001    |
|    n_updates              | 371      |
|    policy_objective       | 0.031    |
|    value_loss             | 0.000355 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.47     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 373      |
|    time_elapsed           | 67       |
|    total_timesteps        | 47744    |
| train/                    |          |
|    explained_variance     | -43.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00601  |
|    learning_rate          | 0.001    |
|    n_updates              | 372      |
|    policy_objective       | 0.0274   |
|    value_loss             | 0.00097  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.99     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 705      |
|    iterations             | 374      |
|    time_elapsed           | 67       |
|    total_timesteps        | 47872    |
| train/                    |          |
|    explained_variance     | 0.173    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00629  |
|    learning_rate          | 0.001    |
|    n_updates              | 373      |
|    policy_objective       | 0.0403   |
|    value_loss             | 0.0511   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.76     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 375      |
|    time_elapsed           | 68       |
|    total_timesteps        | 48000    |
| train/                    |          |
|    explained_variance     | -30.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0088   |
|    learning_rate          | 0.001    |
|    n_updates              | 374      |
|    policy_objective       | 0.0613   |
|    value_loss             | 0.00599  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.59     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 376      |
|    time_elapsed           | 68       |
|    total_timesteps        | 48128    |
| train/                    |          |
|    explained_variance     | -55      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0043   |
|    learning_rate          | 0.001    |
|    n_updates              | 375      |
|    policy_objective       | 0.0252   |
|    value_loss             | 0.000943 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.34     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 377      |
|    time_elapsed           | 68       |
|    total_timesteps        | 48256    |
| train/                    |          |
|    explained_variance     | 0.105    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00603  |
|    learning_rate          | 0.001    |
|    n_updates              | 376      |
|    policy_objective       | 0.058    |
|    value_loss             | 0.0417   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.78     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 378      |
|    time_elapsed           | 68       |
|    total_timesteps        | 48384    |
| train/                    |          |
|    explained_variance     | -11.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0025   |
|    learning_rate          | 0.001    |
|    n_updates              | 377      |
|    policy_objective       | 0.0331   |
|    value_loss             | 0.00349  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.5      |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 379      |
|    time_elapsed           | 68       |
|    total_timesteps        | 48512    |
| train/                    |          |
|    explained_variance     | -10.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00231  |
|    learning_rate          | 0.001    |
|    n_updates              | 378      |
|    policy_objective       | 0.0586   |
|    value_loss             | 7.57e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.48     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 380      |
|    time_elapsed           | 68       |
|    total_timesteps        | 48640    |
| train/                    |          |
|    explained_variance     | -13.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00449  |
|    learning_rate          | 0.001    |
|    n_updates              | 379      |
|    policy_objective       | 0.0407   |
|    value_loss             | 0.000206 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.87     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 705      |
|    iterations             | 381      |
|    time_elapsed           | 69       |
|    total_timesteps        | 48768    |
| train/                    |          |
|    explained_variance     | -15.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00306  |
|    learning_rate          | 0.001    |
|    n_updates              | 380      |
|    policy_objective       | 0.0786   |
|    value_loss             | 0.000267 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.23     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 705      |
|    iterations             | 382      |
|    time_elapsed           | 69       |
|    total_timesteps        | 48896    |
| train/                    |          |
|    explained_variance     | 0.0386   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00941  |
|    learning_rate          | 0.001    |
|    n_updates              | 381      |
|    policy_objective       | 0.18     |
|    value_loss             | 0.0445   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.31     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 705      |
|    iterations             | 383      |
|    time_elapsed           | 69       |
|    total_timesteps        | 49024    |
| train/                    |          |
|    explained_variance     | 0.0291   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00532  |
|    learning_rate          | 0.001    |
|    n_updates              | 382      |
|    policy_objective       | 0.0281   |
|    value_loss             | 0.0405   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.55     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 705      |
|    iterations             | 384      |
|    time_elapsed           | 69       |
|    total_timesteps        | 49152    |
| train/                    |          |
|    explained_variance     | -12.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00629  |
|    learning_rate          | 0.001    |
|    n_updates              | 383      |
|    policy_objective       | 0.0456   |
|    value_loss             | 0.00147  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.86     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 705      |
|    iterations             | 385      |
|    time_elapsed           | 69       |
|    total_timesteps        | 49280    |
| train/                    |          |
|    explained_variance     | -16.7    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00322  |
|    learning_rate          | 0.001    |
|    n_updates              | 384      |
|    policy_objective       | 0.0462   |
|    value_loss             | 0.00219  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.08     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 705      |
|    iterations             | 386      |
|    time_elapsed           | 70       |
|    total_timesteps        | 49408    |
| train/                    |          |
|    explained_variance     | 0.101    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0058   |
|    learning_rate          | 0.001    |
|    n_updates              | 385      |
|    policy_objective       | 0.0463   |
|    value_loss             | 0.0376   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.56     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 705      |
|    iterations             | 387      |
|    time_elapsed           | 70       |
|    total_timesteps        | 49536    |
| train/                    |          |
|    explained_variance     | 0.218    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00509  |
|    learning_rate          | 0.001    |
|    n_updates              | 386      |
|    policy_objective       | 0.0495   |
|    value_loss             | 0.0381   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.78     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 705      |
|    iterations             | 388      |
|    time_elapsed           | 70       |
|    total_timesteps        | 49664    |
| train/                    |          |
|    explained_variance     | -14.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00723  |
|    learning_rate          | 0.001    |
|    n_updates              | 387      |
|    policy_objective       | 0.0338   |
|    value_loss             | 0.0176   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.62     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 389      |
|    time_elapsed           | 70       |
|    total_timesteps        | 49792    |
| train/                    |          |
|    explained_variance     | -18      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00263  |
|    learning_rate          | 0.001    |
|    n_updates              | 388      |
|    policy_objective       | 0.0482   |
|    value_loss             | 0.000619 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.5      |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 390      |
|    time_elapsed           | 70       |
|    total_timesteps        | 49920    |
| train/                    |          |
|    explained_variance     | -4.31    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00314  |
|    learning_rate          | 0.001    |
|    n_updates              | 389      |
|    policy_objective       | 0.0365   |
|    value_loss             | 3.96e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.73     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 391      |
|    time_elapsed           | 70       |
|    total_timesteps        | 50048    |
| train/                    |          |
|    explained_variance     | -0.0326  |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00767  |
|    learning_rate          | 0.001    |
|    n_updates              | 390      |
|    policy_objective       | 0.0832   |
|    value_loss             | 0.0348   |
----------------------------------------
wandb: WARNING Symlinked 1 file into the W&B run directory; call wandb.save again to sync new files.
wandb: updating run metadata
wandb: uploading model.zip; uploading output.log; uploading wandb-summary.json
wandb: uploading model.zip; uploading output.log; uploading logs/FrozenLake_4x4_slip_prob_jump_Adaptive_20251218_002919_0/events.out.tfevents.1765992644.hungchan-Precision-7560.435689.0
wandb: uploading output.log; uploading logs/FrozenLake_4x4_slip_prob_jump_Adaptive_20251218_002919_0/events.out.tfevents.1765992644.hungchan-Precision-7560.435689.0
wandb: uploading history steps 5145-6640, summary, console lines 9491-11351
wandb: 
wandb: Run history:
wandb: adaptive/adaptation_factor â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:           adaptive/base_lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    adaptive/base_target_kl â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:   adaptive/drift_magnitude â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:     adaptive/learning_rate â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         adaptive/target_kl â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:             env/base_value â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:              env/slip_prob â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                global_step â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:        rollout/ep_len_mean â–â–‚â–†â–„â–„â–„â–ƒâ–ƒâ–â–ƒâ–„â–ƒâ–ˆâ–†â–…â–†â–†â–ƒâ–„â–ƒâ–ƒâ–…â–…â–ƒâ–…â–‡â–…â–…â–‡â–ƒâ–‡â–…â–„â–„â–‚â–ˆâ–„â–†â–†â–…
wandb:                         +8 ...
wandb: 
wandb: Run summary:
wandb: adaptive/adaptation_factor 1
wandb:           adaptive/base_lr 0.001
wandb:    adaptive/base_target_kl 0.01
wandb:   adaptive/drift_magnitude 0
wandb:     adaptive/learning_rate 0.001
wandb:         adaptive/target_kl 0.01
wandb:             env/base_value 9.8
wandb:              env/slip_prob 9.8
wandb:                global_step 50048
wandb:        rollout/ep_len_mean 7.73
wandb:                         +8 ...
wandb: 
wandb: ðŸš€ View run FrozenLake_4x4_slip_prob_jump_Adaptive_20251218_002919 at: https://wandb.ai/hungtrab-hanoi-university-of-science-and-technology/FrozenLake_Drift_Research/runs/npesjsqb
wandb: â­ï¸ View project at: https://wandb.ai/hungtrab-hanoi-university-of-science-and-technology/FrozenLake_Drift_Research
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)
wandb: Find logs at: logs/FrozenLake_4x4_slip_prob_jump_Adaptive_20251218_002919/wandb/run-20251218_003042-npesjsqb/logs
>>> [DriftAdaptiveCallback] Training Ended
    Final LR: 0.001000
    Last Drift Magnitude: 0.0000
    Final Target KL: 0.0100
Model saved locally to: models/FrozenLake_4x4_slip_prob_jump_Adaptive_20251218_002919.zip
/home/hungchan/miniconda3/envs/rl_hf_course/lib/python3.10/site-packages/gymnasium/wrappers/rendering.py:293: UserWarning: [33mWARN: Overwriting existing videos at /home/hungchan/Work/Deep-RL/videos/FrozenLake_4x4_slip_prob_jump_Adaptive_20251218_002919 folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)[0m
  logger.warn(
/home/hungchan/miniconda3/envs/rl_hf_course/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run TRPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.
  warnings.warn(
>>> [Wrapper] Initialized Non-Stationary FrozenLake
    - slip_prob: jump (base=0.67)
Loading TRPO model from: models/FrozenLake_4x4_slip_prob_jump_Adaptive_20251218_002919.zip

Recording Episode 1/1...
Traceback (most recent call last):
  File "/home/hungchan/Work/Deep-RL/scripts/render.py", line 179, in <module>
    main()
  File "/home/hungchan/Work/Deep-RL/scripts/render.py", line 168, in main
    record_video(
  File "/home/hungchan/Work/Deep-RL/scripts/render.py", line 137, in record_video
    obs, reward, done, truncated, info = env.step(action)
  File "/home/hungchan/miniconda3/envs/rl_hf_course/lib/python3.10/site-packages/gymnasium/wrappers/rendering.py", line 363, in step
    obs, rew, terminated, truncated, info = self.env.step(action)
  File "/home/hungchan/Work/Deep-RL/scripts/../src/envs/multi_env_wrappers.py", line 378, in step
    obs, reward, terminated, truncated, info = self.env.step(action)
  File "/home/hungchan/miniconda3/envs/rl_hf_course/lib/python3.10/site-packages/gymnasium/wrappers/common.py", line 125, in step
    observation, reward, terminated, truncated, info = self.env.step(action)
  File "/home/hungchan/miniconda3/envs/rl_hf_course/lib/python3.10/site-packages/gymnasium/wrappers/common.py", line 393, in step
    return super().step(action)
  File "/home/hungchan/miniconda3/envs/rl_hf_course/lib/python3.10/site-packages/gymnasium/core.py", line 327, in step
    return self.env.step(action)
  File "/home/hungchan/miniconda3/envs/rl_hf_course/lib/python3.10/site-packages/gymnasium/wrappers/common.py", line 285, in step
    return self.env.step(action)
  File "/home/hungchan/miniconda3/envs/rl_hf_course/lib/python3.10/site-packages/gymnasium/envs/toy_text/frozen_lake.py", line 325, in step
    transitions = self.P[self.s][a]
TypeError: unhashable type: 'numpy.ndarray'
/home/hungchan/miniconda3/envs/rl_hf_course/lib/python3.10/site-packages/gymnasium/wrappers/rendering.py:434: UserWarning: [33mWARN: Unable to save last video! Did you call close()?[0m
  logger.warn("Unable to save last video! Did you call close()?")
