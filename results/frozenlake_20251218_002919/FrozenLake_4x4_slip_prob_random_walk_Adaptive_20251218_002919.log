wandb: Currently logged in as: hungtrab (hungtrab-hanoi-university-of-science-and-technology) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: setting up run xxgbye3u
wandb: Tracking run with wandb version 0.23.1
wandb: Run data is saved locally in logs/FrozenLake_4x4_slip_prob_random_walk_Adaptive_20251218_002919/wandb/run-20251218_003847-xxgbye3u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run FrozenLake_4x4_slip_prob_random_walk_Adaptive_20251218_002919
wandb: â­ï¸ View project at https://wandb.ai/hungtrab-hanoi-university-of-science-and-technology/FrozenLake_Drift_Research
wandb: ðŸš€ View run at https://wandb.ai/hungtrab-hanoi-university-of-science-and-technology/FrozenLake_Drift_Research/runs/xxgbye3u
/home/hungchan/miniconda3/envs/rl_hf_course/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run TRPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.
  warnings.warn(
--- Training Start: FrozenLake_4x4_slip_prob_random_walk_Adaptive_20251218_002919 ---
>>> [Wrapper] Initialized Non-Stationary FrozenLake
    - slip_prob: random_walk (base=0.67)
>>> Initializing TRPO with kwargs: ['policy', 'env', 'learning_rate', 'gamma', 'verbose', 'tensorboard_log', 'n_steps', 'batch_size']
Using cuda device
Wrapping the env in a DummyVecEnv.
Logging to logs/FrozenLake_4x4_slip_prob_random_walk_Adaptive_20251218_002919_0
>>> [DriftAdaptiveCallback] Training Started
    Algorithm: TRPO
    Target Param: slip_prob (base=9.8)
    Scale Factor: 0.2
    
    Adaptive Hyperparameters:
      - Learning Rate: 0.001000
      - Target KL: 0.0100 (adapt=True)
-----------------------------------
| adaptive/            |          |
|    adaptation_factor | 1        |
|    algorithm         | TRPO     |
|    base_lr           | 0.001    |
|    base_target_kl    | 0.01     |
|    drift_magnitude   | 0        |
|    learning_rate     | 0.001    |
|    target_kl         | 0.01     |
| env/                 |          |
|    base_value        | 9.8      |
|    slip_prob         | 9.8      |
| rollout/             |          |
|    ep_len_mean       | 6.89     |
|    ep_rew_mean       | 0        |
| time/                |          |
|    fps               | 430      |
|    iterations        | 1        |
|    time_elapsed      | 0        |
|    total_timesteps   | 128      |
-----------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.41     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 480      |
|    iterations             | 2        |
|    time_elapsed           | 0        |
|    total_timesteps        | 256      |
| train/                    |          |
|    explained_variance     | -16.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00215  |
|    learning_rate          | 0.001    |
|    n_updates              | 1        |
|    policy_objective       | 0.044    |
|    value_loss             | 0.00528  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.96     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 524      |
|    iterations             | 3        |
|    time_elapsed           | 0        |
|    total_timesteps        | 384      |
| train/                    |          |
|    explained_variance     | -9.97    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00327  |
|    learning_rate          | 0.001    |
|    n_updates              | 2        |
|    policy_objective       | 0.0437   |
|    value_loss             | 0.000122 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.2      |
|    ep_rew_mean            | 0.0141   |
| time/                     |          |
|    fps                    | 567      |
|    iterations             | 4        |
|    time_elapsed           | 0        |
|    total_timesteps        | 512      |
| train/                    |          |
|    explained_variance     | -30      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00197  |
|    learning_rate          | 0.001    |
|    n_updates              | 3        |
|    policy_objective       | 0.042    |
|    value_loss             | 4.87e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.31     |
|    ep_rew_mean            | 0.0115   |
| time/                     |          |
|    fps                    | 596      |
|    iterations             | 5        |
|    time_elapsed           | 1        |
|    total_timesteps        | 640      |
| train/                    |          |
|    explained_variance     | -0.159   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00363  |
|    learning_rate          | 0.001    |
|    n_updates              | 4        |
|    policy_objective       | 0.045    |
|    value_loss             | 0.0306   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.62     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 617      |
|    iterations             | 6        |
|    time_elapsed           | 1        |
|    total_timesteps        | 768      |
| train/                    |          |
|    explained_variance     | -10.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00543  |
|    learning_rate          | 0.001    |
|    n_updates              | 5        |
|    policy_objective       | 0.036    |
|    value_loss             | 0.00477  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.53     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 635      |
|    iterations             | 7        |
|    time_elapsed           | 1        |
|    total_timesteps        | 896      |
| train/                    |          |
|    explained_variance     | -17.6    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00134  |
|    learning_rate          | 0.001    |
|    n_updates              | 6        |
|    policy_objective       | 0.0556   |
|    value_loss             | 0.00283  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.77     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 644      |
|    iterations             | 8        |
|    time_elapsed           | 1        |
|    total_timesteps        | 1024     |
| train/                    |          |
|    explained_variance     | 0.0838   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0041   |
|    learning_rate          | 0.001    |
|    n_updates              | 7        |
|    policy_objective       | 0.0574   |
|    value_loss             | 0.0767   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.61     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 653      |
|    iterations             | 9        |
|    time_elapsed           | 1        |
|    total_timesteps        | 1152     |
| train/                    |          |
|    explained_variance     | 0.221    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00544  |
|    learning_rate          | 0.001    |
|    n_updates              | 8        |
|    policy_objective       | 0.0696   |
|    value_loss             | 0.0364   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.92     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 664      |
|    iterations             | 10       |
|    time_elapsed           | 1        |
|    total_timesteps        | 1280     |
| train/                    |          |
|    explained_variance     | -33.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00189  |
|    learning_rate          | 0.001    |
|    n_updates              | 9        |
|    policy_objective       | 0.0554   |
|    value_loss             | 0.00754  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.25     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 669      |
|    iterations             | 11       |
|    time_elapsed           | 2        |
|    total_timesteps        | 1408     |
| train/                    |          |
|    explained_variance     | -39.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00248  |
|    learning_rate          | 0.001    |
|    n_updates              | 10       |
|    policy_objective       | 0.0556   |
|    value_loss             | 0.000261 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.43     |
|    ep_rew_mean            | 0.05     |
| time/                     |          |
|    fps                    | 678      |
|    iterations             | 12       |
|    time_elapsed           | 2        |
|    total_timesteps        | 1536     |
| train/                    |          |
|    explained_variance     | -19.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00538  |
|    learning_rate          | 0.001    |
|    n_updates              | 11       |
|    policy_objective       | 0.0438   |
|    value_loss             | 2.94e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.18     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 677      |
|    iterations             | 13       |
|    time_elapsed           | 2        |
|    total_timesteps        | 1664     |
| train/                    |          |
|    explained_variance     | 0.145    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00407  |
|    learning_rate          | 0.001    |
|    n_updates              | 12       |
|    policy_objective       | 0.066    |
|    value_loss             | 0.049    |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.16     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 681      |
|    iterations             | 14       |
|    time_elapsed           | 2        |
|    total_timesteps        | 1792     |
| train/                    |          |
|    explained_variance     | -2.78    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00491  |
|    learning_rate          | 0.001    |
|    n_updates              | 13       |
|    policy_objective       | 0.0451   |
|    value_loss             | 0.0215   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.96     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 684      |
|    iterations             | 15       |
|    time_elapsed           | 2        |
|    total_timesteps        | 1920     |
| train/                    |          |
|    explained_variance     | -11.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00297  |
|    learning_rate          | 0.001    |
|    n_updates              | 14       |
|    policy_objective       | 0.0473   |
|    value_loss             | 0.00202  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.39     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 683      |
|    iterations             | 16       |
|    time_elapsed           | 2        |
|    total_timesteps        | 2048     |
| train/                    |          |
|    explained_variance     | -0.919   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00413  |
|    learning_rate          | 0.001    |
|    n_updates              | 15       |
|    policy_objective       | 0.0407   |
|    value_loss             | 5.35e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.09     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 684      |
|    iterations             | 17       |
|    time_elapsed           | 3        |
|    total_timesteps        | 2176     |
| train/                    |          |
|    explained_variance     | 0.042    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00302  |
|    learning_rate          | 0.001    |
|    n_updates              | 16       |
|    policy_objective       | 0.058    |
|    value_loss             | 0.0308   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.73     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 686      |
|    iterations             | 18       |
|    time_elapsed           | 3        |
|    total_timesteps        | 2304     |
| train/                    |          |
|    explained_variance     | -9.98    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00542  |
|    learning_rate          | 0.001    |
|    n_updates              | 17       |
|    policy_objective       | 0.0727   |
|    value_loss             | 0.0154   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.47     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 687      |
|    iterations             | 19       |
|    time_elapsed           | 3        |
|    total_timesteps        | 2432     |
| train/                    |          |
|    explained_variance     | -12.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00362  |
|    learning_rate          | 0.001    |
|    n_updates              | 18       |
|    policy_objective       | 0.0816   |
|    value_loss             | 0.000788 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.5      |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 20       |
|    time_elapsed           | 3        |
|    total_timesteps        | 2560     |
| train/                    |          |
|    explained_variance     | -18.7    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00476  |
|    learning_rate          | 0.001    |
|    n_updates              | 19       |
|    policy_objective       | 0.0495   |
|    value_loss             | 2e-05    |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.86     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 691      |
|    iterations             | 21       |
|    time_elapsed           | 3        |
|    total_timesteps        | 2688     |
| train/                    |          |
|    explained_variance     | -35.7    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00363  |
|    learning_rate          | 0.001    |
|    n_updates              | 20       |
|    policy_objective       | 0.0527   |
|    value_loss             | 1.21e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.03     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 695      |
|    iterations             | 22       |
|    time_elapsed           | 4        |
|    total_timesteps        | 2816     |
| train/                    |          |
|    explained_variance     | -28.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00302  |
|    learning_rate          | 0.001    |
|    n_updates              | 21       |
|    policy_objective       | 0.0623   |
|    value_loss             | 3.92e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.83     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 697      |
|    iterations             | 23       |
|    time_elapsed           | 4        |
|    total_timesteps        | 2944     |
| train/                    |          |
|    explained_variance     | -14      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00126  |
|    learning_rate          | 0.001    |
|    n_updates              | 22       |
|    policy_objective       | 0.0548   |
|    value_loss             | 2.04e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.93     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 698      |
|    iterations             | 24       |
|    time_elapsed           | 4        |
|    total_timesteps        | 3072     |
| train/                    |          |
|    explained_variance     | 0.00669  |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00232  |
|    learning_rate          | 0.001    |
|    n_updates              | 23       |
|    policy_objective       | 0.0871   |
|    value_loss             | 0.0276   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.4      |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 700      |
|    iterations             | 25       |
|    time_elapsed           | 4        |
|    total_timesteps        | 3200     |
| train/                    |          |
|    explained_variance     | 0.0832   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00453  |
|    learning_rate          | 0.001    |
|    n_updates              | 24       |
|    policy_objective       | 0.047    |
|    value_loss             | 0.039    |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.1      |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 700      |
|    iterations             | 26       |
|    time_elapsed           | 4        |
|    total_timesteps        | 3328     |
| train/                    |          |
|    explained_variance     | -9.86    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00384  |
|    learning_rate          | 0.001    |
|    n_updates              | 25       |
|    policy_objective       | 0.0414   |
|    value_loss             | 0.011    |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.27     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 702      |
|    iterations             | 27       |
|    time_elapsed           | 4        |
|    total_timesteps        | 3456     |
| train/                    |          |
|    explained_variance     | -12.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00342  |
|    learning_rate          | 0.001    |
|    n_updates              | 26       |
|    policy_objective       | 0.0445   |
|    value_loss             | 0.00016  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.81     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 703      |
|    iterations             | 28       |
|    time_elapsed           | 5        |
|    total_timesteps        | 3584     |
| train/                    |          |
|    explained_variance     | 0.163    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00684  |
|    learning_rate          | 0.001    |
|    n_updates              | 27       |
|    policy_objective       | 0.0776   |
|    value_loss             | 0.0433   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.23     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 705      |
|    iterations             | 29       |
|    time_elapsed           | 5        |
|    total_timesteps        | 3712     |
| train/                    |          |
|    explained_variance     | -22.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00237  |
|    learning_rate          | 0.001    |
|    n_updates              | 28       |
|    policy_objective       | 0.0343   |
|    value_loss             | 0.00204  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.63     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 706      |
|    iterations             | 30       |
|    time_elapsed           | 5        |
|    total_timesteps        | 3840     |
| train/                    |          |
|    explained_variance     | -14.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00305  |
|    learning_rate          | 0.001    |
|    n_updates              | 29       |
|    policy_objective       | 0.0549   |
|    value_loss             | 5.97e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.83     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 31       |
|    time_elapsed           | 5        |
|    total_timesteps        | 3968     |
| train/                    |          |
|    explained_variance     | -12.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00199  |
|    learning_rate          | 0.001    |
|    n_updates              | 30       |
|    policy_objective       | 0.0577   |
|    value_loss             | 8.82e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.86     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 32       |
|    time_elapsed           | 5        |
|    total_timesteps        | 4096     |
| train/                    |          |
|    explained_variance     | -9.08    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00301  |
|    learning_rate          | 0.001    |
|    n_updates              | 31       |
|    policy_objective       | 0.0699   |
|    value_loss             | 0.00765  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.99     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 705      |
|    iterations             | 33       |
|    time_elapsed           | 5        |
|    total_timesteps        | 4224     |
| train/                    |          |
|    explained_variance     | -8.59    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00465  |
|    learning_rate          | 0.001    |
|    n_updates              | 32       |
|    policy_objective       | 0.0442   |
|    value_loss             | 0.000356 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.61     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 706      |
|    iterations             | 34       |
|    time_elapsed           | 6        |
|    total_timesteps        | 4352     |
| train/                    |          |
|    explained_variance     | -15.6    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00286  |
|    learning_rate          | 0.001    |
|    n_updates              | 33       |
|    policy_objective       | 0.046    |
|    value_loss             | 1.96e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.69     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 707      |
|    iterations             | 35       |
|    time_elapsed           | 6        |
|    total_timesteps        | 4480     |
| train/                    |          |
|    explained_variance     | -29.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00244  |
|    learning_rate          | 0.001    |
|    n_updates              | 34       |
|    policy_objective       | 0.0433   |
|    value_loss             | 3.61e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.26     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 707      |
|    iterations             | 36       |
|    time_elapsed           | 6        |
|    total_timesteps        | 4608     |
| train/                    |          |
|    explained_variance     | 0.0228   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00602  |
|    learning_rate          | 0.001    |
|    n_updates              | 35       |
|    policy_objective       | 0.0407   |
|    value_loss             | 0.034    |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.11     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 707      |
|    iterations             | 37       |
|    time_elapsed           | 6        |
|    total_timesteps        | 4736     |
| train/                    |          |
|    explained_variance     | -9.9     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00677  |
|    learning_rate          | 0.001    |
|    n_updates              | 36       |
|    policy_objective       | 0.0492   |
|    value_loss             | 0.00255  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.59     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 707      |
|    iterations             | 38       |
|    time_elapsed           | 6        |
|    total_timesteps        | 4864     |
| train/                    |          |
|    explained_variance     | -10.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00382  |
|    learning_rate          | 0.001    |
|    n_updates              | 37       |
|    policy_objective       | 0.0629   |
|    value_loss             | 6.59e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.09     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 707      |
|    iterations             | 39       |
|    time_elapsed           | 7        |
|    total_timesteps        | 4992     |
| train/                    |          |
|    explained_variance     | 0.0352   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00275  |
|    learning_rate          | 0.001    |
|    n_updates              | 38       |
|    policy_objective       | 0.0793   |
|    value_loss             | 0.0368   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.68     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 707      |
|    iterations             | 40       |
|    time_elapsed           | 7        |
|    total_timesteps        | 5120     |
| train/                    |          |
|    explained_variance     | -9       |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00437  |
|    learning_rate          | 0.001    |
|    n_updates              | 39       |
|    policy_objective       | 0.0407   |
|    value_loss             | 0.00286  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.22     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 707      |
|    iterations             | 41       |
|    time_elapsed           | 7        |
|    total_timesteps        | 5248     |
| train/                    |          |
|    explained_variance     | 0.0336   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00499  |
|    learning_rate          | 0.001    |
|    n_updates              | 40       |
|    policy_objective       | 0.053    |
|    value_loss             | 0.0872   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.17     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 708      |
|    iterations             | 42       |
|    time_elapsed           | 7        |
|    total_timesteps        | 5376     |
| train/                    |          |
|    explained_variance     | -3.79    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00463  |
|    learning_rate          | 0.001    |
|    n_updates              | 41       |
|    policy_objective       | 0.0444   |
|    value_loss             | 0.00454  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.33     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 708      |
|    iterations             | 43       |
|    time_elapsed           | 7        |
|    total_timesteps        | 5504     |
| train/                    |          |
|    explained_variance     | -27.6    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00175  |
|    learning_rate          | 0.001    |
|    n_updates              | 42       |
|    policy_objective       | 0.0863   |
|    value_loss             | 0.00107  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.42     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 710      |
|    iterations             | 44       |
|    time_elapsed           | 7        |
|    total_timesteps        | 5632     |
| train/                    |          |
|    explained_variance     | -38.6    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00195  |
|    learning_rate          | 0.001    |
|    n_updates              | 43       |
|    policy_objective       | 0.05     |
|    value_loss             | 8.94e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.78     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 710      |
|    iterations             | 45       |
|    time_elapsed           | 8        |
|    total_timesteps        | 5760     |
| train/                    |          |
|    explained_variance     | 0.0633   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00585  |
|    learning_rate          | 0.001    |
|    n_updates              | 44       |
|    policy_objective       | 0.0703   |
|    value_loss             | 0.0453   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.54     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 711      |
|    iterations             | 46       |
|    time_elapsed           | 8        |
|    total_timesteps        | 5888     |
| train/                    |          |
|    explained_variance     | -11.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00461  |
|    learning_rate          | 0.001    |
|    n_updates              | 45       |
|    policy_objective       | 0.0719   |
|    value_loss             | 0.0019   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.99     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 711      |
|    iterations             | 47       |
|    time_elapsed           | 8        |
|    total_timesteps        | 6016     |
| train/                    |          |
|    explained_variance     | -18.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00442  |
|    learning_rate          | 0.001    |
|    n_updates              | 46       |
|    policy_objective       | 0.0273   |
|    value_loss             | 0.00156  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.86     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 712      |
|    iterations             | 48       |
|    time_elapsed           | 8        |
|    total_timesteps        | 6144     |
| train/                    |          |
|    explained_variance     | -57.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00265  |
|    learning_rate          | 0.001    |
|    n_updates              | 47       |
|    policy_objective       | 0.0323   |
|    value_loss             | 0.000364 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.03     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 712      |
|    iterations             | 49       |
|    time_elapsed           | 8        |
|    total_timesteps        | 6272     |
| train/                    |          |
|    explained_variance     | -45.6    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0011   |
|    learning_rate          | 0.001    |
|    n_updates              | 48       |
|    policy_objective       | 0.0546   |
|    value_loss             | 7.66e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.81     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 710      |
|    iterations             | 50       |
|    time_elapsed           | 9        |
|    total_timesteps        | 6400     |
| train/                    |          |
|    explained_variance     | -60      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00103  |
|    learning_rate          | 0.001    |
|    n_updates              | 49       |
|    policy_objective       | 0.045    |
|    value_loss             | 4.45e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.23     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 710      |
|    iterations             | 51       |
|    time_elapsed           | 9        |
|    total_timesteps        | 6528     |
| train/                    |          |
|    explained_variance     | -68.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00184  |
|    learning_rate          | 0.001    |
|    n_updates              | 50       |
|    policy_objective       | 0.0786   |
|    value_loss             | 5.37e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.98     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 710      |
|    iterations             | 52       |
|    time_elapsed           | 9        |
|    total_timesteps        | 6656     |
| train/                    |          |
|    explained_variance     | 0.0467   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.004    |
|    learning_rate          | 0.001    |
|    n_updates              | 51       |
|    policy_objective       | 0.0582   |
|    value_loss             | 0.044    |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.87     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 709      |
|    iterations             | 53       |
|    time_elapsed           | 9        |
|    total_timesteps        | 6784     |
| train/                    |          |
|    explained_variance     | -11.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00351  |
|    learning_rate          | 0.001    |
|    n_updates              | 52       |
|    policy_objective       | 0.05     |
|    value_loss             | 0.00443  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.61     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 709      |
|    iterations             | 54       |
|    time_elapsed           | 9        |
|    total_timesteps        | 6912     |
| train/                    |          |
|    explained_variance     | 0.0556   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00625  |
|    learning_rate          | 0.001    |
|    n_updates              | 53       |
|    policy_objective       | 0.052    |
|    value_loss             | 0.0409   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.32     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 709      |
|    iterations             | 55       |
|    time_elapsed           | 9        |
|    total_timesteps        | 7040     |
| train/                    |          |
|    explained_variance     | 0.158    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00616  |
|    learning_rate          | 0.001    |
|    n_updates              | 54       |
|    policy_objective       | 0.0505   |
|    value_loss             | 0.0614   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.84     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 708      |
|    iterations             | 56       |
|    time_elapsed           | 10       |
|    total_timesteps        | 7168     |
| train/                    |          |
|    explained_variance     | -8.22    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00377  |
|    learning_rate          | 0.001    |
|    n_updates              | 55       |
|    policy_objective       | 0.0411   |
|    value_loss             | 0.00838  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.44     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 708      |
|    iterations             | 57       |
|    time_elapsed           | 10       |
|    total_timesteps        | 7296     |
| train/                    |          |
|    explained_variance     | -19.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00432  |
|    learning_rate          | 0.001    |
|    n_updates              | 56       |
|    policy_objective       | 0.0387   |
|    value_loss             | 0.0104   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.19     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 709      |
|    iterations             | 58       |
|    time_elapsed           | 10       |
|    total_timesteps        | 7424     |
| train/                    |          |
|    explained_variance     | -6.73    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00444  |
|    learning_rate          | 0.001    |
|    n_updates              | 57       |
|    policy_objective       | 0.0588   |
|    value_loss             | 0.000326 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.18     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 709      |
|    iterations             | 59       |
|    time_elapsed           | 10       |
|    total_timesteps        | 7552     |
| train/                    |          |
|    explained_variance     | 0.00642  |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00453  |
|    learning_rate          | 0.001    |
|    n_updates              | 58       |
|    policy_objective       | 0.0498   |
|    value_loss             | 0.0577   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.37     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 709      |
|    iterations             | 60       |
|    time_elapsed           | 10       |
|    total_timesteps        | 7680     |
| train/                    |          |
|    explained_variance     | -21.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00231  |
|    learning_rate          | 0.001    |
|    n_updates              | 59       |
|    policy_objective       | 0.0369   |
|    value_loss             | 0.00767  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.05     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 710      |
|    iterations             | 61       |
|    time_elapsed           | 10       |
|    total_timesteps        | 7808     |
| train/                    |          |
|    explained_variance     | -20.7    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00475  |
|    learning_rate          | 0.001    |
|    n_updates              | 60       |
|    policy_objective       | 0.0526   |
|    value_loss             | 0.00142  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.01     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 710      |
|    iterations             | 62       |
|    time_elapsed           | 11       |
|    total_timesteps        | 7936     |
| train/                    |          |
|    explained_variance     | -13      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00437  |
|    learning_rate          | 0.001    |
|    n_updates              | 61       |
|    policy_objective       | 0.0408   |
|    value_loss             | 9.4e-06  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.33     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 708      |
|    iterations             | 63       |
|    time_elapsed           | 11       |
|    total_timesteps        | 8064     |
| train/                    |          |
|    explained_variance     | -18.6    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00597  |
|    learning_rate          | 0.001    |
|    n_updates              | 62       |
|    policy_objective       | 0.0302   |
|    value_loss             | 0.0012   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.38     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 708      |
|    iterations             | 64       |
|    time_elapsed           | 11       |
|    total_timesteps        | 8192     |
| train/                    |          |
|    explained_variance     | -34.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00452  |
|    learning_rate          | 0.001    |
|    n_updates              | 63       |
|    policy_objective       | 0.0435   |
|    value_loss             | 0.000123 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.28     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 707      |
|    iterations             | 65       |
|    time_elapsed           | 11       |
|    total_timesteps        | 8320     |
| train/                    |          |
|    explained_variance     | -116     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00542  |
|    learning_rate          | 0.001    |
|    n_updates              | 64       |
|    policy_objective       | 0.0487   |
|    value_loss             | 5.48e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.56     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 707      |
|    iterations             | 66       |
|    time_elapsed           | 11       |
|    total_timesteps        | 8448     |
| train/                    |          |
|    explained_variance     | 0.0232   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00631  |
|    learning_rate          | 0.001    |
|    n_updates              | 65       |
|    policy_objective       | 0.0365   |
|    value_loss             | 0.0483   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.93     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 707      |
|    iterations             | 67       |
|    time_elapsed           | 12       |
|    total_timesteps        | 8576     |
| train/                    |          |
|    explained_variance     | -20.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00736  |
|    learning_rate          | 0.001    |
|    n_updates              | 66       |
|    policy_objective       | 0.0302   |
|    value_loss             | 0.00491  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.79     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 708      |
|    iterations             | 68       |
|    time_elapsed           | 12       |
|    total_timesteps        | 8704     |
| train/                    |          |
|    explained_variance     | -13.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00437  |
|    learning_rate          | 0.001    |
|    n_updates              | 67       |
|    policy_objective       | 0.066    |
|    value_loss             | 0.00449  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.41     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 708      |
|    iterations             | 69       |
|    time_elapsed           | 12       |
|    total_timesteps        | 8832     |
| train/                    |          |
|    explained_variance     | -23.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00425  |
|    learning_rate          | 0.001    |
|    n_updates              | 68       |
|    policy_objective       | 0.0413   |
|    value_loss             | 0.00462  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.43     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 708      |
|    iterations             | 70       |
|    time_elapsed           | 12       |
|    total_timesteps        | 8960     |
| train/                    |          |
|    explained_variance     | -24.7    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0033   |
|    learning_rate          | 0.001    |
|    n_updates              | 69       |
|    policy_objective       | 0.0786   |
|    value_loss             | 1.76e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.47     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 708      |
|    iterations             | 71       |
|    time_elapsed           | 12       |
|    total_timesteps        | 9088     |
| train/                    |          |
|    explained_variance     | -58.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0039   |
|    learning_rate          | 0.001    |
|    n_updates              | 70       |
|    policy_objective       | 0.0408   |
|    value_loss             | 0.000186 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.69     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 709      |
|    iterations             | 72       |
|    time_elapsed           | 12       |
|    total_timesteps        | 9216     |
| train/                    |          |
|    explained_variance     | -80.6    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00286  |
|    learning_rate          | 0.001    |
|    n_updates              | 71       |
|    policy_objective       | 0.0557   |
|    value_loss             | 5.11e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.07     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 709      |
|    iterations             | 73       |
|    time_elapsed           | 13       |
|    total_timesteps        | 9344     |
| train/                    |          |
|    explained_variance     | 0.0209   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00443  |
|    learning_rate          | 0.001    |
|    n_updates              | 72       |
|    policy_objective       | 0.0544   |
|    value_loss             | 0.0343   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.96     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 709      |
|    iterations             | 74       |
|    time_elapsed           | 13       |
|    total_timesteps        | 9472     |
| train/                    |          |
|    explained_variance     | 0.297    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00517  |
|    learning_rate          | 0.001    |
|    n_updates              | 73       |
|    policy_objective       | 0.0547   |
|    value_loss             | 0.027    |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.87     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 709      |
|    iterations             | 75       |
|    time_elapsed           | 13       |
|    total_timesteps        | 9600     |
| train/                    |          |
|    explained_variance     | -0.741   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00535  |
|    learning_rate          | 0.001    |
|    n_updates              | 74       |
|    policy_objective       | 0.0617   |
|    value_loss             | 0.0308   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.25     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 710      |
|    iterations             | 76       |
|    time_elapsed           | 13       |
|    total_timesteps        | 9728     |
| train/                    |          |
|    explained_variance     | -0.0364  |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00216  |
|    learning_rate          | 0.001    |
|    n_updates              | 75       |
|    policy_objective       | 0.23     |
|    value_loss             | 0.00651  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.54     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 710      |
|    iterations             | 77       |
|    time_elapsed           | 13       |
|    total_timesteps        | 9856     |
| train/                    |          |
|    explained_variance     | -4.57    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00456  |
|    learning_rate          | 0.001    |
|    n_updates              | 76       |
|    policy_objective       | 0.0526   |
|    value_loss             | 0.000104 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.29     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 710      |
|    iterations             | 78       |
|    time_elapsed           | 14       |
|    total_timesteps        | 9984     |
| train/                    |          |
|    explained_variance     | 0.0766   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00568  |
|    learning_rate          | 0.001    |
|    n_updates              | 77       |
|    policy_objective       | 0.0646   |
|    value_loss             | 0.0369   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.78     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 710      |
|    iterations             | 79       |
|    time_elapsed           | 14       |
|    total_timesteps        | 10112    |
| train/                    |          |
|    explained_variance     | -15.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00507  |
|    learning_rate          | 0.001    |
|    n_updates              | 78       |
|    policy_objective       | 0.046    |
|    value_loss             | 0.00517  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.79     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 711      |
|    iterations             | 80       |
|    time_elapsed           | 14       |
|    total_timesteps        | 10240    |
| train/                    |          |
|    explained_variance     | -44.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00228  |
|    learning_rate          | 0.001    |
|    n_updates              | 79       |
|    policy_objective       | 0.0521   |
|    value_loss             | 0.00251  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.97     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 711      |
|    iterations             | 81       |
|    time_elapsed           | 14       |
|    total_timesteps        | 10368    |
| train/                    |          |
|    explained_variance     | 0.0798   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0061   |
|    learning_rate          | 0.001    |
|    n_updates              | 80       |
|    policy_objective       | 0.0602   |
|    value_loss             | 0.0476   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.08     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 711      |
|    iterations             | 82       |
|    time_elapsed           | 14       |
|    total_timesteps        | 10496    |
| train/                    |          |
|    explained_variance     | -0.347   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0061   |
|    learning_rate          | 0.001    |
|    n_updates              | 81       |
|    policy_objective       | 0.04     |
|    value_loss             | 0.0229   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.46     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 712      |
|    iterations             | 83       |
|    time_elapsed           | 14       |
|    total_timesteps        | 10624    |
| train/                    |          |
|    explained_variance     | -20.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0051   |
|    learning_rate          | 0.001    |
|    n_updates              | 82       |
|    policy_objective       | 0.0604   |
|    value_loss             | 0.00223  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.79     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 711      |
|    iterations             | 84       |
|    time_elapsed           | 15       |
|    total_timesteps        | 10752    |
| train/                    |          |
|    explained_variance     | -3.39    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00202  |
|    learning_rate          | 0.001    |
|    n_updates              | 83       |
|    policy_objective       | 0.0655   |
|    value_loss             | 6.96e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.72     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 712      |
|    iterations             | 85       |
|    time_elapsed           | 15       |
|    total_timesteps        | 10880    |
| train/                    |          |
|    explained_variance     | -30.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00438  |
|    learning_rate          | 0.001    |
|    n_updates              | 84       |
|    policy_objective       | 0.0342   |
|    value_loss             | 9.25e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.24     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 711      |
|    iterations             | 86       |
|    time_elapsed           | 15       |
|    total_timesteps        | 11008    |
| train/                    |          |
|    explained_variance     | -22.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00237  |
|    learning_rate          | 0.001    |
|    n_updates              | 85       |
|    policy_objective       | 0.0708   |
|    value_loss             | 8.34e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.16     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 711      |
|    iterations             | 87       |
|    time_elapsed           | 15       |
|    total_timesteps        | 11136    |
| train/                    |          |
|    explained_variance     | 0.208    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00407  |
|    learning_rate          | 0.001    |
|    n_updates              | 86       |
|    policy_objective       | 0.0477   |
|    value_loss             | 0.0392   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.99     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 711      |
|    iterations             | 88       |
|    time_elapsed           | 15       |
|    total_timesteps        | 11264    |
| train/                    |          |
|    explained_variance     | -6.17    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00183  |
|    learning_rate          | 0.001    |
|    n_updates              | 87       |
|    policy_objective       | 0.0687   |
|    value_loss             | 0.00593  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.31     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 711      |
|    iterations             | 89       |
|    time_elapsed           | 16       |
|    total_timesteps        | 11392    |
| train/                    |          |
|    explained_variance     | -7.66    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00579  |
|    learning_rate          | 0.001    |
|    n_updates              | 88       |
|    policy_objective       | 0.0632   |
|    value_loss             | 8.5e-05  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.29     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 711      |
|    iterations             | 90       |
|    time_elapsed           | 16       |
|    total_timesteps        | 11520    |
| train/                    |          |
|    explained_variance     | -6.84    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00395  |
|    learning_rate          | 0.001    |
|    n_updates              | 89       |
|    policy_objective       | 0.0471   |
|    value_loss             | 0.0029   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.87     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 711      |
|    iterations             | 91       |
|    time_elapsed           | 16       |
|    total_timesteps        | 11648    |
| train/                    |          |
|    explained_variance     | -29.7    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00476  |
|    learning_rate          | 0.001    |
|    n_updates              | 90       |
|    policy_objective       | 0.0597   |
|    value_loss             | 0.000163 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.13     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 712      |
|    iterations             | 92       |
|    time_elapsed           | 16       |
|    total_timesteps        | 11776    |
| train/                    |          |
|    explained_variance     | -42.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00292  |
|    learning_rate          | 0.001    |
|    n_updates              | 91       |
|    policy_objective       | 0.0381   |
|    value_loss             | 6.04e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.51     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 712      |
|    iterations             | 93       |
|    time_elapsed           | 16       |
|    total_timesteps        | 11904    |
| train/                    |          |
|    explained_variance     | -10.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00391  |
|    learning_rate          | 0.001    |
|    n_updates              | 92       |
|    policy_objective       | 0.072    |
|    value_loss             | 0.00147  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.46     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 712      |
|    iterations             | 94       |
|    time_elapsed           | 16       |
|    total_timesteps        | 12032    |
| train/                    |          |
|    explained_variance     | 0.152    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00568  |
|    learning_rate          | 0.001    |
|    n_updates              | 93       |
|    policy_objective       | 0.0442   |
|    value_loss             | 0.0592   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.36     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 712      |
|    iterations             | 95       |
|    time_elapsed           | 17       |
|    total_timesteps        | 12160    |
| train/                    |          |
|    explained_variance     | -14.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.004    |
|    learning_rate          | 0.001    |
|    n_updates              | 94       |
|    policy_objective       | 0.0577   |
|    value_loss             | 0.00887  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.81     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 712      |
|    iterations             | 96       |
|    time_elapsed           | 17       |
|    total_timesteps        | 12288    |
| train/                    |          |
|    explained_variance     | -8.46    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00852  |
|    learning_rate          | 0.001    |
|    n_updates              | 95       |
|    policy_objective       | 0.0397   |
|    value_loss             | 0.000237 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.95     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 712      |
|    iterations             | 97       |
|    time_elapsed           | 17       |
|    total_timesteps        | 12416    |
| train/                    |          |
|    explained_variance     | -34.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00208  |
|    learning_rate          | 0.001    |
|    n_updates              | 96       |
|    policy_objective       | 0.0606   |
|    value_loss             | 0.00183  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.68     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 712      |
|    iterations             | 98       |
|    time_elapsed           | 17       |
|    total_timesteps        | 12544    |
| train/                    |          |
|    explained_variance     | -16      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00518  |
|    learning_rate          | 0.001    |
|    n_updates              | 97       |
|    policy_objective       | 0.0513   |
|    value_loss             | 0.000637 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.86     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 712      |
|    iterations             | 99       |
|    time_elapsed           | 17       |
|    total_timesteps        | 12672    |
| train/                    |          |
|    explained_variance     | -55.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00642  |
|    learning_rate          | 0.001    |
|    n_updates              | 98       |
|    policy_objective       | 0.111    |
|    value_loss             | 1.34e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.94     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 712      |
|    iterations             | 100      |
|    time_elapsed           | 17       |
|    total_timesteps        | 12800    |
| train/                    |          |
|    explained_variance     | -64.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00205  |
|    learning_rate          | 0.001    |
|    n_updates              | 99       |
|    policy_objective       | 0.0537   |
|    value_loss             | 3.77e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.44     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 712      |
|    iterations             | 101      |
|    time_elapsed           | 18       |
|    total_timesteps        | 12928    |
| train/                    |          |
|    explained_variance     | 0.0253   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00422  |
|    learning_rate          | 0.001    |
|    n_updates              | 100      |
|    policy_objective       | 0.0641   |
|    value_loss             | 0.0428   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.92     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 712      |
|    iterations             | 102      |
|    time_elapsed           | 18       |
|    total_timesteps        | 13056    |
| train/                    |          |
|    explained_variance     | 0.042    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00487  |
|    learning_rate          | 0.001    |
|    n_updates              | 101      |
|    policy_objective       | 0.0565   |
|    value_loss             | 0.0515   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.41     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 712      |
|    iterations             | 103      |
|    time_elapsed           | 18       |
|    total_timesteps        | 13184    |
| train/                    |          |
|    explained_variance     | 0.305    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00533  |
|    learning_rate          | 0.001    |
|    n_updates              | 102      |
|    policy_objective       | 0.141    |
|    value_loss             | 0.0279   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.38     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 711      |
|    iterations             | 104      |
|    time_elapsed           | 18       |
|    total_timesteps        | 13312    |
| train/                    |          |
|    explained_variance     | -0.36    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.007    |
|    learning_rate          | 0.001    |
|    n_updates              | 103      |
|    policy_objective       | 0.0931   |
|    value_loss             | 0.0479   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.61     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 712      |
|    iterations             | 105      |
|    time_elapsed           | 18       |
|    total_timesteps        | 13440    |
| train/                    |          |
|    explained_variance     | -21.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00246  |
|    learning_rate          | 0.001    |
|    n_updates              | 104      |
|    policy_objective       | 0.0572   |
|    value_loss             | 0.00121  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.77     |
|    ep_rew_mean            | 0.05     |
| time/                     |          |
|    fps                    | 712      |
|    iterations             | 106      |
|    time_elapsed           | 19       |
|    total_timesteps        | 13568    |
| train/                    |          |
|    explained_variance     | -13.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0013   |
|    learning_rate          | 0.001    |
|    n_updates              | 105      |
|    policy_objective       | 0.0569   |
|    value_loss             | 0.00113  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.11     |
|    ep_rew_mean            | 0.05     |
| time/                     |          |
|    fps                    | 712      |
|    iterations             | 107      |
|    time_elapsed           | 19       |
|    total_timesteps        | 13696    |
| train/                    |          |
|    explained_variance     | 0.107    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00686  |
|    learning_rate          | 0.001    |
|    n_updates              | 106      |
|    policy_objective       | 0.0496   |
|    value_loss             | 0.0472   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.42     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 712      |
|    iterations             | 108      |
|    time_elapsed           | 19       |
|    total_timesteps        | 13824    |
| train/                    |          |
|    explained_variance     | -0.0387  |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00586  |
|    learning_rate          | 0.001    |
|    n_updates              | 107      |
|    policy_objective       | 0.0455   |
|    value_loss             | 0.0543   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.4      |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 712      |
|    iterations             | 109      |
|    time_elapsed           | 19       |
|    total_timesteps        | 13952    |
| train/                    |          |
|    explained_variance     | -2.23    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0051   |
|    learning_rate          | 0.001    |
|    n_updates              | 108      |
|    policy_objective       | 0.0575   |
|    value_loss             | 0.00127  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.04     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 712      |
|    iterations             | 110      |
|    time_elapsed           | 19       |
|    total_timesteps        | 14080    |
| train/                    |          |
|    explained_variance     | -65.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00708  |
|    learning_rate          | 0.001    |
|    n_updates              | 109      |
|    policy_objective       | 0.026    |
|    value_loss             | 0.00146  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.42     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 712      |
|    iterations             | 111      |
|    time_elapsed           | 19       |
|    total_timesteps        | 14208    |
| train/                    |          |
|    explained_variance     | -14.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00427  |
|    learning_rate          | 0.001    |
|    n_updates              | 110      |
|    policy_objective       | 0.0577   |
|    value_loss             | 0.00252  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.94     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 712      |
|    iterations             | 112      |
|    time_elapsed           | 20       |
|    total_timesteps        | 14336    |
| train/                    |          |
|    explained_variance     | 0.0699   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00572  |
|    learning_rate          | 0.001    |
|    n_updates              | 111      |
|    policy_objective       | 0.041    |
|    value_loss             | 0.0525   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.21     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 712      |
|    iterations             | 113      |
|    time_elapsed           | 20       |
|    total_timesteps        | 14464    |
| train/                    |          |
|    explained_variance     | -10.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00372  |
|    learning_rate          | 0.001    |
|    n_updates              | 112      |
|    policy_objective       | 0.0553   |
|    value_loss             | 0.00291  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.83     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 712      |
|    iterations             | 114      |
|    time_elapsed           | 20       |
|    total_timesteps        | 14592    |
| train/                    |          |
|    explained_variance     | -17.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00618  |
|    learning_rate          | 0.001    |
|    n_updates              | 113      |
|    policy_objective       | 0.0327   |
|    value_loss             | 0.000338 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.32     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 712      |
|    iterations             | 115      |
|    time_elapsed           | 20       |
|    total_timesteps        | 14720    |
| train/                    |          |
|    explained_variance     | 0.0491   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00558  |
|    learning_rate          | 0.001    |
|    n_updates              | 114      |
|    policy_objective       | 0.0451   |
|    value_loss             | 0.0409   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.72     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 116      |
|    time_elapsed           | 20       |
|    total_timesteps        | 14848    |
| train/                    |          |
|    explained_variance     | 0.182    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0058   |
|    learning_rate          | 0.001    |
|    n_updates              | 115      |
|    policy_objective       | 0.0298   |
|    value_loss             | 0.0397   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.49     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 117      |
|    time_elapsed           | 20       |
|    total_timesteps        | 14976    |
| train/                    |          |
|    explained_variance     | -9.52    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00598  |
|    learning_rate          | 0.001    |
|    n_updates              | 116      |
|    policy_objective       | 0.0402   |
|    value_loss             | 0.00146  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.75     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 118      |
|    time_elapsed           | 21       |
|    total_timesteps        | 15104    |
| train/                    |          |
|    explained_variance     | -0.706   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00284  |
|    learning_rate          | 0.001    |
|    n_updates              | 117      |
|    policy_objective       | 0.0627   |
|    value_loss             | 0.00458  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.67     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 119      |
|    time_elapsed           | 21       |
|    total_timesteps        | 15232    |
| train/                    |          |
|    explained_variance     | -19.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00107  |
|    learning_rate          | 0.001    |
|    n_updates              | 118      |
|    policy_objective       | 0.0686   |
|    value_loss             | 0.00165  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.89     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 120      |
|    time_elapsed           | 21       |
|    total_timesteps        | 15360    |
| train/                    |          |
|    explained_variance     | 0.262    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00614  |
|    learning_rate          | 0.001    |
|    n_updates              | 119      |
|    policy_objective       | 0.0554   |
|    value_loss             | 0.0388   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.27     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 121      |
|    time_elapsed           | 21       |
|    total_timesteps        | 15488    |
| train/                    |          |
|    explained_variance     | -10.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00321  |
|    learning_rate          | 0.001    |
|    n_updates              | 120      |
|    policy_objective       | 0.0452   |
|    value_loss             | 0.00111  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.96     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 122      |
|    time_elapsed           | 21       |
|    total_timesteps        | 15616    |
| train/                    |          |
|    explained_variance     | -9.44    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00403  |
|    learning_rate          | 0.001    |
|    n_updates              | 121      |
|    policy_objective       | 0.0317   |
|    value_loss             | 0.0118   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.01     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 123      |
|    time_elapsed           | 22       |
|    total_timesteps        | 15744    |
| train/                    |          |
|    explained_variance     | -2.85    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00664  |
|    learning_rate          | 0.001    |
|    n_updates              | 122      |
|    policy_objective       | 0.0324   |
|    value_loss             | 0.00182  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.85     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 124      |
|    time_elapsed           | 22       |
|    total_timesteps        | 15872    |
| train/                    |          |
|    explained_variance     | -23.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00554  |
|    learning_rate          | 0.001    |
|    n_updates              | 123      |
|    policy_objective       | 0.0367   |
|    value_loss             | 0.000156 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.66     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 125      |
|    time_elapsed           | 22       |
|    total_timesteps        | 16000    |
| train/                    |          |
|    explained_variance     | -28.7    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00509  |
|    learning_rate          | 0.001    |
|    n_updates              | 124      |
|    policy_objective       | 0.0398   |
|    value_loss             | 9.25e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.04     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 126      |
|    time_elapsed           | 22       |
|    total_timesteps        | 16128    |
| train/                    |          |
|    explained_variance     | -33.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00306  |
|    learning_rate          | 0.001    |
|    n_updates              | 125      |
|    policy_objective       | 0.0396   |
|    value_loss             | 3.16e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.13     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 127      |
|    time_elapsed           | 22       |
|    total_timesteps        | 16256    |
| train/                    |          |
|    explained_variance     | -9.71    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00704  |
|    learning_rate          | 0.001    |
|    n_updates              | 126      |
|    policy_objective       | 0.0342   |
|    value_loss             | 4.68e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.11     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 712      |
|    iterations             | 128      |
|    time_elapsed           | 22       |
|    total_timesteps        | 16384    |
| train/                    |          |
|    explained_variance     | -12.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00419  |
|    learning_rate          | 0.001    |
|    n_updates              | 127      |
|    policy_objective       | 0.0867   |
|    value_loss             | 2.05e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.46     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 129      |
|    time_elapsed           | 23       |
|    total_timesteps        | 16512    |
| train/                    |          |
|    explained_variance     | -0.6     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00619  |
|    learning_rate          | 0.001    |
|    n_updates              | 128      |
|    policy_objective       | 0.0414   |
|    value_loss             | 1.07e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.56     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 130      |
|    time_elapsed           | 23       |
|    total_timesteps        | 16640    |
| train/                    |          |
|    explained_variance     | 0.0146   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00266  |
|    learning_rate          | 0.001    |
|    n_updates              | 129      |
|    policy_objective       | 0.0446   |
|    value_loss             | 0.0169   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.76     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 131      |
|    time_elapsed           | 23       |
|    total_timesteps        | 16768    |
| train/                    |          |
|    explained_variance     | 0.141    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00711  |
|    learning_rate          | 0.001    |
|    n_updates              | 130      |
|    policy_objective       | 0.0501   |
|    value_loss             | 0.0462   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.61     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 132      |
|    time_elapsed           | 23       |
|    total_timesteps        | 16896    |
| train/                    |          |
|    explained_variance     | -6.91    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00635  |
|    learning_rate          | 0.001    |
|    n_updates              | 131      |
|    policy_objective       | 0.0386   |
|    value_loss             | 0.00111  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.95     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 133      |
|    time_elapsed           | 23       |
|    total_timesteps        | 17024    |
| train/                    |          |
|    explained_variance     | -6.37    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00471  |
|    learning_rate          | 0.001    |
|    n_updates              | 132      |
|    policy_objective       | 0.0674   |
|    value_loss             | 5.63e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.25     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 134      |
|    time_elapsed           | 24       |
|    total_timesteps        | 17152    |
| train/                    |          |
|    explained_variance     | -23.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00523  |
|    learning_rate          | 0.001    |
|    n_updates              | 133      |
|    policy_objective       | 0.0443   |
|    value_loss             | 0.00385  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.92     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 135      |
|    time_elapsed           | 24       |
|    total_timesteps        | 17280    |
| train/                    |          |
|    explained_variance     | -21.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00415  |
|    learning_rate          | 0.001    |
|    n_updates              | 134      |
|    policy_objective       | 0.0333   |
|    value_loss             | 0.000197 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.06     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 136      |
|    time_elapsed           | 24       |
|    total_timesteps        | 17408    |
| train/                    |          |
|    explained_variance     | -3.04    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00654  |
|    learning_rate          | 0.001    |
|    n_updates              | 135      |
|    policy_objective       | 0.0722   |
|    value_loss             | 2.96e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.16     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 137      |
|    time_elapsed           | 24       |
|    total_timesteps        | 17536    |
| train/                    |          |
|    explained_variance     | -18.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.003    |
|    learning_rate          | 0.001    |
|    n_updates              | 136      |
|    policy_objective       | 0.0269   |
|    value_loss             | 0.00114  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.63     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 138      |
|    time_elapsed           | 24       |
|    total_timesteps        | 17664    |
| train/                    |          |
|    explained_variance     | -15.6    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00467  |
|    learning_rate          | 0.001    |
|    n_updates              | 137      |
|    policy_objective       | 0.0507   |
|    value_loss             | 0.000418 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.61     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 139      |
|    time_elapsed           | 24       |
|    total_timesteps        | 17792    |
| train/                    |          |
|    explained_variance     | 0.0288   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00582  |
|    learning_rate          | 0.001    |
|    n_updates              | 138      |
|    policy_objective       | 0.0482   |
|    value_loss             | 0.0472   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.83     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 140      |
|    time_elapsed           | 25       |
|    total_timesteps        | 17920    |
| train/                    |          |
|    explained_variance     | 0.261    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00717  |
|    learning_rate          | 0.001    |
|    n_updates              | 139      |
|    policy_objective       | 0.0402   |
|    value_loss             | 0.0522   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.05     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 141      |
|    time_elapsed           | 25       |
|    total_timesteps        | 18048    |
| train/                    |          |
|    explained_variance     | -0.158   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00775  |
|    learning_rate          | 0.001    |
|    n_updates              | 140      |
|    policy_objective       | 0.0653   |
|    value_loss             | 0.0454   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.05     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 142      |
|    time_elapsed           | 25       |
|    total_timesteps        | 18176    |
| train/                    |          |
|    explained_variance     | -14.7    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00296  |
|    learning_rate          | 0.001    |
|    n_updates              | 141      |
|    policy_objective       | 0.0367   |
|    value_loss             | 0.00632  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.16     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 143      |
|    time_elapsed           | 25       |
|    total_timesteps        | 18304    |
| train/                    |          |
|    explained_variance     | -0.888   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0083   |
|    learning_rate          | 0.001    |
|    n_updates              | 142      |
|    policy_objective       | 0.0363   |
|    value_loss             | 0.000275 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.49     |
|    ep_rew_mean            | 0.05     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 144      |
|    time_elapsed           | 25       |
|    total_timesteps        | 18432    |
| train/                    |          |
|    explained_variance     | -52.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00393  |
|    learning_rate          | 0.001    |
|    n_updates              | 143      |
|    policy_objective       | 0.0604   |
|    value_loss             | 0.00189  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.09     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 145      |
|    time_elapsed           | 25       |
|    total_timesteps        | 18560    |
| train/                    |          |
|    explained_variance     | 0.0251   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0029   |
|    learning_rate          | 0.001    |
|    n_updates              | 144      |
|    policy_objective       | 0.115    |
|    value_loss             | 0.0382   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.82     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 146      |
|    time_elapsed           | 26       |
|    total_timesteps        | 18688    |
| train/                    |          |
|    explained_variance     | -18.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00193  |
|    learning_rate          | 0.001    |
|    n_updates              | 145      |
|    policy_objective       | 0.0455   |
|    value_loss             | 0.00653  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.77     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 714      |
|    iterations             | 147      |
|    time_elapsed           | 26       |
|    total_timesteps        | 18816    |
| train/                    |          |
|    explained_variance     | -48.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00285  |
|    learning_rate          | 0.001    |
|    n_updates              | 146      |
|    policy_objective       | 0.0545   |
|    value_loss             | 0.000692 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.28     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 714      |
|    iterations             | 148      |
|    time_elapsed           | 26       |
|    total_timesteps        | 18944    |
| train/                    |          |
|    explained_variance     | -20.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00156  |
|    learning_rate          | 0.001    |
|    n_updates              | 147      |
|    policy_objective       | 0.0448   |
|    value_loss             | 4.18e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.11     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 714      |
|    iterations             | 149      |
|    time_elapsed           | 26       |
|    total_timesteps        | 19072    |
| train/                    |          |
|    explained_variance     | -15.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00462  |
|    learning_rate          | 0.001    |
|    n_updates              | 148      |
|    policy_objective       | 0.031    |
|    value_loss             | 2.68e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.24     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 714      |
|    iterations             | 150      |
|    time_elapsed           | 26       |
|    total_timesteps        | 19200    |
| train/                    |          |
|    explained_variance     | 0.0182   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00583  |
|    learning_rate          | 0.001    |
|    n_updates              | 149      |
|    policy_objective       | 0.0461   |
|    value_loss             | 0.0398   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.87     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 714      |
|    iterations             | 151      |
|    time_elapsed           | 27       |
|    total_timesteps        | 19328    |
| train/                    |          |
|    explained_variance     | -9.28    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0047   |
|    learning_rate          | 0.001    |
|    n_updates              | 150      |
|    policy_objective       | 0.0628   |
|    value_loss             | 0.00306  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.99     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 714      |
|    iterations             | 152      |
|    time_elapsed           | 27       |
|    total_timesteps        | 19456    |
| train/                    |          |
|    explained_variance     | 0.113    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00607  |
|    learning_rate          | 0.001    |
|    n_updates              | 151      |
|    policy_objective       | 0.0435   |
|    value_loss             | 0.0383   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.72     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 714      |
|    iterations             | 153      |
|    time_elapsed           | 27       |
|    total_timesteps        | 19584    |
| train/                    |          |
|    explained_variance     | -2.76    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00705  |
|    learning_rate          | 0.001    |
|    n_updates              | 152      |
|    policy_objective       | 0.0316   |
|    value_loss             | 0.000426 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.79     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 714      |
|    iterations             | 154      |
|    time_elapsed           | 27       |
|    total_timesteps        | 19712    |
| train/                    |          |
|    explained_variance     | -18.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00325  |
|    learning_rate          | 0.001    |
|    n_updates              | 153      |
|    policy_objective       | 0.0376   |
|    value_loss             | 0.00127  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.74     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 714      |
|    iterations             | 155      |
|    time_elapsed           | 27       |
|    total_timesteps        | 19840    |
| train/                    |          |
|    explained_variance     | 0.132    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00734  |
|    learning_rate          | 0.001    |
|    n_updates              | 154      |
|    policy_objective       | 0.0244   |
|    value_loss             | 0.0307   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.25     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 714      |
|    iterations             | 156      |
|    time_elapsed           | 27       |
|    total_timesteps        | 19968    |
| train/                    |          |
|    explained_variance     | 0.321    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00777  |
|    learning_rate          | 0.001    |
|    n_updates              | 155      |
|    policy_objective       | 0.0734   |
|    value_loss             | 0.028    |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.11     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 714      |
|    iterations             | 157      |
|    time_elapsed           | 28       |
|    total_timesteps        | 20096    |
| train/                    |          |
|    explained_variance     | -11.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00328  |
|    learning_rate          | 0.001    |
|    n_updates              | 156      |
|    policy_objective       | 0.0335   |
|    value_loss             | 0.0109   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.14     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 714      |
|    iterations             | 158      |
|    time_elapsed           | 28       |
|    total_timesteps        | 20224    |
| train/                    |          |
|    explained_variance     | -9.22    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00533  |
|    learning_rate          | 0.001    |
|    n_updates              | 157      |
|    policy_objective       | 0.0221   |
|    value_loss             | 0.000463 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.28     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 714      |
|    iterations             | 159      |
|    time_elapsed           | 28       |
|    total_timesteps        | 20352    |
| train/                    |          |
|    explained_variance     | 0.0185   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00821  |
|    learning_rate          | 0.001    |
|    n_updates              | 158      |
|    policy_objective       | 0.0316   |
|    value_loss             | 0.0439   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.09     |
|    ep_rew_mean            | 0.05     |
| time/                     |          |
|    fps                    | 714      |
|    iterations             | 160      |
|    time_elapsed           | 28       |
|    total_timesteps        | 20480    |
| train/                    |          |
|    explained_variance     | 0.158    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0082   |
|    learning_rate          | 0.001    |
|    n_updates              | 159      |
|    policy_objective       | 0.0511   |
|    value_loss             | 0.0296   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.17     |
|    ep_rew_mean            | 0.06     |
| time/                     |          |
|    fps                    | 714      |
|    iterations             | 161      |
|    time_elapsed           | 28       |
|    total_timesteps        | 20608    |
| train/                    |          |
|    explained_variance     | -0.19    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00512  |
|    learning_rate          | 0.001    |
|    n_updates              | 160      |
|    policy_objective       | 0.0353   |
|    value_loss             | 0.0762   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.64     |
|    ep_rew_mean            | 0.07     |
| time/                     |          |
|    fps                    | 714      |
|    iterations             | 162      |
|    time_elapsed           | 29       |
|    total_timesteps        | 20736    |
| train/                    |          |
|    explained_variance     | 0.334    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00704  |
|    learning_rate          | 0.001    |
|    n_updates              | 161      |
|    policy_objective       | 0.0501   |
|    value_loss             | 0.0352   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.93     |
|    ep_rew_mean            | 0.08     |
| time/                     |          |
|    fps                    | 714      |
|    iterations             | 163      |
|    time_elapsed           | 29       |
|    total_timesteps        | 20864    |
| train/                    |          |
|    explained_variance     | 0.0284   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00482  |
|    learning_rate          | 0.001    |
|    n_updates              | 162      |
|    policy_objective       | 0.0685   |
|    value_loss             | 0.0754   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.84     |
|    ep_rew_mean            | 0.08     |
| time/                     |          |
|    fps                    | 714      |
|    iterations             | 164      |
|    time_elapsed           | 29       |
|    total_timesteps        | 20992    |
| train/                    |          |
|    explained_variance     | 0.451    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00211  |
|    learning_rate          | 0.001    |
|    n_updates              | 163      |
|    policy_objective       | 0.0241   |
|    value_loss             | 0.0261   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.91     |
|    ep_rew_mean            | 0.07     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 165      |
|    time_elapsed           | 29       |
|    total_timesteps        | 21120    |
| train/                    |          |
|    explained_variance     | 0.223    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00717  |
|    learning_rate          | 0.001    |
|    n_updates              | 164      |
|    policy_objective       | 0.0466   |
|    value_loss             | 0.0495   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.02     |
|    ep_rew_mean            | 0.07     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 166      |
|    time_elapsed           | 29       |
|    total_timesteps        | 21248    |
| train/                    |          |
|    explained_variance     | -12.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0065   |
|    learning_rate          | 0.001    |
|    n_updates              | 165      |
|    policy_objective       | 0.0347   |
|    value_loss             | 0.00497  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.9      |
|    ep_rew_mean            | 0.06     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 167      |
|    time_elapsed           | 29       |
|    total_timesteps        | 21376    |
| train/                    |          |
|    explained_variance     | 0.181    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0089   |
|    learning_rate          | 0.001    |
|    n_updates              | 166      |
|    policy_objective       | 0.0628   |
|    value_loss             | 0.0586   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.82     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 168      |
|    time_elapsed           | 30       |
|    total_timesteps        | 21504    |
| train/                    |          |
|    explained_variance     | -3.88    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0076   |
|    learning_rate          | 0.001    |
|    n_updates              | 167      |
|    policy_objective       | 0.0614   |
|    value_loss             | 0.00275  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.96     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 169      |
|    time_elapsed           | 30       |
|    total_timesteps        | 21632    |
| train/                    |          |
|    explained_variance     | -27.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00483  |
|    learning_rate          | 0.001    |
|    n_updates              | 168      |
|    policy_objective       | 0.0284   |
|    value_loss             | 0.00728  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.3      |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 714      |
|    iterations             | 170      |
|    time_elapsed           | 30       |
|    total_timesteps        | 21760    |
| train/                    |          |
|    explained_variance     | -3.13    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00471  |
|    learning_rate          | 0.001    |
|    n_updates              | 169      |
|    policy_objective       | 0.0509   |
|    value_loss             | 7.81e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.08     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 171      |
|    time_elapsed           | 30       |
|    total_timesteps        | 21888    |
| train/                    |          |
|    explained_variance     | -55.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00389  |
|    learning_rate          | 0.001    |
|    n_updates              | 170      |
|    policy_objective       | 0.0202   |
|    value_loss             | 0.000292 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.12     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 172      |
|    time_elapsed           | 30       |
|    total_timesteps        | 22016    |
| train/                    |          |
|    explained_variance     | 0.0674   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0074   |
|    learning_rate          | 0.001    |
|    n_updates              | 171      |
|    policy_objective       | 0.0451   |
|    value_loss             | 0.0415   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.2      |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 173      |
|    time_elapsed           | 31       |
|    total_timesteps        | 22144    |
| train/                    |          |
|    explained_variance     | -5.21    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00143  |
|    learning_rate          | 0.001    |
|    n_updates              | 172      |
|    policy_objective       | 0.0413   |
|    value_loss             | 0.00507  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.29     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 174      |
|    time_elapsed           | 31       |
|    total_timesteps        | 22272    |
| train/                    |          |
|    explained_variance     | -6.34    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00281  |
|    learning_rate          | 0.001    |
|    n_updates              | 173      |
|    policy_objective       | 0.0519   |
|    value_loss             | 0.000152 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.49     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 175      |
|    time_elapsed           | 31       |
|    total_timesteps        | 22400    |
| train/                    |          |
|    explained_variance     | -11.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00504  |
|    learning_rate          | 0.001    |
|    n_updates              | 174      |
|    policy_objective       | 0.0465   |
|    value_loss             | 0.00137  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.5      |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 176      |
|    time_elapsed           | 31       |
|    total_timesteps        | 22528    |
| train/                    |          |
|    explained_variance     | -18.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00593  |
|    learning_rate          | 0.001    |
|    n_updates              | 175      |
|    policy_objective       | 0.0569   |
|    value_loss             | 3.76e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.57     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 177      |
|    time_elapsed           | 31       |
|    total_timesteps        | 22656    |
| train/                    |          |
|    explained_variance     | -67.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00772  |
|    learning_rate          | 0.001    |
|    n_updates              | 176      |
|    policy_objective       | 0.0548   |
|    value_loss             | 8.07e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.24     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 178      |
|    time_elapsed           | 31       |
|    total_timesteps        | 22784    |
| train/                    |          |
|    explained_variance     | -24.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00386  |
|    learning_rate          | 0.001    |
|    n_updates              | 177      |
|    policy_objective       | 0.0331   |
|    value_loss             | 6.93e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.79     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 179      |
|    time_elapsed           | 32       |
|    total_timesteps        | 22912    |
| train/                    |          |
|    explained_variance     | -46.6    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00336  |
|    learning_rate          | 0.001    |
|    n_updates              | 178      |
|    policy_objective       | 0.0162   |
|    value_loss             | 0.000366 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.8      |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 180      |
|    time_elapsed           | 32       |
|    total_timesteps        | 23040    |
| train/                    |          |
|    explained_variance     | 0.0437   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00583  |
|    learning_rate          | 0.001    |
|    n_updates              | 179      |
|    policy_objective       | 0.0934   |
|    value_loss             | 0.0392   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.74     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 181      |
|    time_elapsed           | 32       |
|    total_timesteps        | 23168    |
| train/                    |          |
|    explained_variance     | -25.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00621  |
|    learning_rate          | 0.001    |
|    n_updates              | 180      |
|    policy_objective       | 0.0454   |
|    value_loss             | 0.00584  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.82     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 182      |
|    time_elapsed           | 32       |
|    total_timesteps        | 23296    |
| train/                    |          |
|    explained_variance     | -11.6    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00563  |
|    learning_rate          | 0.001    |
|    n_updates              | 181      |
|    policy_objective       | 0.0552   |
|    value_loss             | 0.000231 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.81     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 183      |
|    time_elapsed           | 32       |
|    total_timesteps        | 23424    |
| train/                    |          |
|    explained_variance     | 0.0787   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00676  |
|    learning_rate          | 0.001    |
|    n_updates              | 182      |
|    policy_objective       | 0.0395   |
|    value_loss             | 0.0441   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.79     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 184      |
|    time_elapsed           | 33       |
|    total_timesteps        | 23552    |
| train/                    |          |
|    explained_variance     | -8.3     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00318  |
|    learning_rate          | 0.001    |
|    n_updates              | 183      |
|    policy_objective       | 0.0602   |
|    value_loss             | 0.00167  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.81     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 185      |
|    time_elapsed           | 33       |
|    total_timesteps        | 23680    |
| train/                    |          |
|    explained_variance     | 0.221    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0076   |
|    learning_rate          | 0.001    |
|    n_updates              | 184      |
|    policy_objective       | 0.0401   |
|    value_loss             | 0.0442   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.95     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 186      |
|    time_elapsed           | 33       |
|    total_timesteps        | 23808    |
| train/                    |          |
|    explained_variance     | -13.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0015   |
|    learning_rate          | 0.001    |
|    n_updates              | 185      |
|    policy_objective       | 0.0329   |
|    value_loss             | 0.00183  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.83     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 187      |
|    time_elapsed           | 33       |
|    total_timesteps        | 23936    |
| train/                    |          |
|    explained_variance     | -31.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00285  |
|    learning_rate          | 0.001    |
|    n_updates              | 186      |
|    policy_objective       | 0.0449   |
|    value_loss             | 0.00688  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.89     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 188      |
|    time_elapsed           | 33       |
|    total_timesteps        | 24064    |
| train/                    |          |
|    explained_variance     | -14.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00415  |
|    learning_rate          | 0.001    |
|    n_updates              | 187      |
|    policy_objective       | 0.0371   |
|    value_loss             | 0.000121 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.99     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 714      |
|    iterations             | 189      |
|    time_elapsed           | 33       |
|    total_timesteps        | 24192    |
| train/                    |          |
|    explained_variance     | 0.133    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00542  |
|    learning_rate          | 0.001    |
|    n_updates              | 188      |
|    policy_objective       | 0.0779   |
|    value_loss             | 0.056    |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.35     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 714      |
|    iterations             | 190      |
|    time_elapsed           | 34       |
|    total_timesteps        | 24320    |
| train/                    |          |
|    explained_variance     | 0.274    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00821  |
|    learning_rate          | 0.001    |
|    n_updates              | 189      |
|    policy_objective       | 0.036    |
|    value_loss             | 0.0108   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.11     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 714      |
|    iterations             | 191      |
|    time_elapsed           | 34       |
|    total_timesteps        | 24448    |
| train/                    |          |
|    explained_variance     | -11      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00578  |
|    learning_rate          | 0.001    |
|    n_updates              | 190      |
|    policy_objective       | 0.0514   |
|    value_loss             | 0.00236  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.11     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 714      |
|    iterations             | 192      |
|    time_elapsed           | 34       |
|    total_timesteps        | 24576    |
| train/                    |          |
|    explained_variance     | -11.6    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00767  |
|    learning_rate          | 0.001    |
|    n_updates              | 191      |
|    policy_objective       | 0.022    |
|    value_loss             | 0.000121 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.02     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 714      |
|    iterations             | 193      |
|    time_elapsed           | 34       |
|    total_timesteps        | 24704    |
| train/                    |          |
|    explained_variance     | 0.102    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00922  |
|    learning_rate          | 0.001    |
|    n_updates              | 192      |
|    policy_objective       | 0.0358   |
|    value_loss             | 0.0406   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.08     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 714      |
|    iterations             | 194      |
|    time_elapsed           | 34       |
|    total_timesteps        | 24832    |
| train/                    |          |
|    explained_variance     | -15.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00757  |
|    learning_rate          | 0.001    |
|    n_updates              | 193      |
|    policy_objective       | 0.0378   |
|    value_loss             | 0.000355 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.14     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 714      |
|    iterations             | 195      |
|    time_elapsed           | 34       |
|    total_timesteps        | 24960    |
| train/                    |          |
|    explained_variance     | -47.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00284  |
|    learning_rate          | 0.001    |
|    n_updates              | 194      |
|    policy_objective       | 0.0374   |
|    value_loss             | 0.000636 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.09     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 714      |
|    iterations             | 196      |
|    time_elapsed           | 35       |
|    total_timesteps        | 25088    |
| train/                    |          |
|    explained_variance     | -62.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00213  |
|    learning_rate          | 0.001    |
|    n_updates              | 195      |
|    policy_objective       | 0.0344   |
|    value_loss             | 0.000284 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.13     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 714      |
|    iterations             | 197      |
|    time_elapsed           | 35       |
|    total_timesteps        | 25216    |
| train/                    |          |
|    explained_variance     | 0.152    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00711  |
|    learning_rate          | 0.001    |
|    n_updates              | 196      |
|    policy_objective       | 0.0393   |
|    value_loss             | 0.0347   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.43     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 714      |
|    iterations             | 198      |
|    time_elapsed           | 35       |
|    total_timesteps        | 25344    |
| train/                    |          |
|    explained_variance     | 0.324    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00411  |
|    learning_rate          | 0.001    |
|    n_updates              | 197      |
|    policy_objective       | 0.081    |
|    value_loss             | 0.0445   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.53     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 714      |
|    iterations             | 199      |
|    time_elapsed           | 35       |
|    total_timesteps        | 25472    |
| train/                    |          |
|    explained_variance     | -31.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00586  |
|    learning_rate          | 0.001    |
|    n_updates              | 198      |
|    policy_objective       | 0.0465   |
|    value_loss             | 0.0116   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.12     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 714      |
|    iterations             | 200      |
|    time_elapsed           | 35       |
|    total_timesteps        | 25600    |
| train/                    |          |
|    explained_variance     | -15.6    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.000817 |
|    learning_rate          | 0.001    |
|    n_updates              | 199      |
|    policy_objective       | 0.0428   |
|    value_loss             | 0.000748 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.8      |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 714      |
|    iterations             | 201      |
|    time_elapsed           | 36       |
|    total_timesteps        | 25728    |
| train/                    |          |
|    explained_variance     | -0.0648  |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0048   |
|    learning_rate          | 0.001    |
|    n_updates              | 200      |
|    policy_objective       | 0.0488   |
|    value_loss             | 0.0548   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.71     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 714      |
|    iterations             | 202      |
|    time_elapsed           | 36       |
|    total_timesteps        | 25856    |
| train/                    |          |
|    explained_variance     | -0.813   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00525  |
|    learning_rate          | 0.001    |
|    n_updates              | 201      |
|    policy_objective       | 0.0448   |
|    value_loss             | 0.00555  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.43     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 714      |
|    iterations             | 203      |
|    time_elapsed           | 36       |
|    total_timesteps        | 25984    |
| train/                    |          |
|    explained_variance     | -29.6    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00794  |
|    learning_rate          | 0.001    |
|    n_updates              | 202      |
|    policy_objective       | 0.0645   |
|    value_loss             | 0.000811 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.75     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 714      |
|    iterations             | 204      |
|    time_elapsed           | 36       |
|    total_timesteps        | 26112    |
| train/                    |          |
|    explained_variance     | 0.153    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00716  |
|    learning_rate          | 0.001    |
|    n_updates              | 203      |
|    policy_objective       | 0.0329   |
|    value_loss             | 0.0357   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.28     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 714      |
|    iterations             | 205      |
|    time_elapsed           | 36       |
|    total_timesteps        | 26240    |
| train/                    |          |
|    explained_variance     | -8.63    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00521  |
|    learning_rate          | 0.001    |
|    n_updates              | 204      |
|    policy_objective       | 0.0547   |
|    value_loss             | 0.00951  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.43     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 714      |
|    iterations             | 206      |
|    time_elapsed           | 36       |
|    total_timesteps        | 26368    |
| train/                    |          |
|    explained_variance     | -16.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00531  |
|    learning_rate          | 0.001    |
|    n_updates              | 205      |
|    policy_objective       | 0.0443   |
|    value_loss             | 0.00379  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.31     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 714      |
|    iterations             | 207      |
|    time_elapsed           | 37       |
|    total_timesteps        | 26496    |
| train/                    |          |
|    explained_variance     | 0.253    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00568  |
|    learning_rate          | 0.001    |
|    n_updates              | 206      |
|    policy_objective       | 0.0302   |
|    value_loss             | 0.0365   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.63     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 714      |
|    iterations             | 208      |
|    time_elapsed           | 37       |
|    total_timesteps        | 26624    |
| train/                    |          |
|    explained_variance     | -21.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00678  |
|    learning_rate          | 0.001    |
|    n_updates              | 207      |
|    policy_objective       | 0.0367   |
|    value_loss             | 0.00119  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.84     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 714      |
|    iterations             | 209      |
|    time_elapsed           | 37       |
|    total_timesteps        | 26752    |
| train/                    |          |
|    explained_variance     | -24.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00483  |
|    learning_rate          | 0.001    |
|    n_updates              | 208      |
|    policy_objective       | 0.0862   |
|    value_loss             | 8.96e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.08     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 714      |
|    iterations             | 210      |
|    time_elapsed           | 37       |
|    total_timesteps        | 26880    |
| train/                    |          |
|    explained_variance     | 0.055    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00658  |
|    learning_rate          | 0.001    |
|    n_updates              | 209      |
|    policy_objective       | 0.0507   |
|    value_loss             | 0.00102  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.18     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 714      |
|    iterations             | 211      |
|    time_elapsed           | 37       |
|    total_timesteps        | 27008    |
| train/                    |          |
|    explained_variance     | 0.509    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00536  |
|    learning_rate          | 0.001    |
|    n_updates              | 210      |
|    policy_objective       | 0.0201   |
|    value_loss             | 0.0238   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.09     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 714      |
|    iterations             | 212      |
|    time_elapsed           | 37       |
|    total_timesteps        | 27136    |
| train/                    |          |
|    explained_variance     | 0.327    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00814  |
|    learning_rate          | 0.001    |
|    n_updates              | 211      |
|    policy_objective       | 0.0405   |
|    value_loss             | 0.0462   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.44     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 714      |
|    iterations             | 213      |
|    time_elapsed           | 38       |
|    total_timesteps        | 27264    |
| train/                    |          |
|    explained_variance     | -27.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00659  |
|    learning_rate          | 0.001    |
|    n_updates              | 212      |
|    policy_objective       | 0.0255   |
|    value_loss             | 0.00723  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.95     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 714      |
|    iterations             | 214      |
|    time_elapsed           | 38       |
|    total_timesteps        | 27392    |
| train/                    |          |
|    explained_variance     | -50.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00241  |
|    learning_rate          | 0.001    |
|    n_updates              | 213      |
|    policy_objective       | 0.0253   |
|    value_loss             | 0.00118  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.03     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 714      |
|    iterations             | 215      |
|    time_elapsed           | 38       |
|    total_timesteps        | 27520    |
| train/                    |          |
|    explained_variance     | -25.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0063   |
|    learning_rate          | 0.001    |
|    n_updates              | 214      |
|    policy_objective       | 0.0376   |
|    value_loss             | 5.26e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.05     |
|    ep_rew_mean            | 0.05     |
| time/                     |          |
|    fps                    | 715      |
|    iterations             | 216      |
|    time_elapsed           | 38       |
|    total_timesteps        | 27648    |
| train/                    |          |
|    explained_variance     | 0.153    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00797  |
|    learning_rate          | 0.001    |
|    n_updates              | 215      |
|    policy_objective       | 0.0582   |
|    value_loss             | 0.0692   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.22     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 715      |
|    iterations             | 217      |
|    time_elapsed           | 38       |
|    total_timesteps        | 27776    |
| train/                    |          |
|    explained_variance     | 0.206    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00668  |
|    learning_rate          | 0.001    |
|    n_updates              | 216      |
|    policy_objective       | 0.0343   |
|    value_loss             | 0.0336   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.56     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 715      |
|    iterations             | 218      |
|    time_elapsed           | 39       |
|    total_timesteps        | 27904    |
| train/                    |          |
|    explained_variance     | -8.62    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00598  |
|    learning_rate          | 0.001    |
|    n_updates              | 217      |
|    policy_objective       | 0.0243   |
|    value_loss             | 0.00572  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.4      |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 715      |
|    iterations             | 219      |
|    time_elapsed           | 39       |
|    total_timesteps        | 28032    |
| train/                    |          |
|    explained_variance     | -42.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00448  |
|    learning_rate          | 0.001    |
|    n_updates              | 218      |
|    policy_objective       | 0.045    |
|    value_loss             | 0.00124  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.71     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 715      |
|    iterations             | 220      |
|    time_elapsed           | 39       |
|    total_timesteps        | 28160    |
| train/                    |          |
|    explained_variance     | -7.09    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00565  |
|    learning_rate          | 0.001    |
|    n_updates              | 219      |
|    policy_objective       | 0.045    |
|    value_loss             | 5.1e-06  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 10.1     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 715      |
|    iterations             | 221      |
|    time_elapsed           | 39       |
|    total_timesteps        | 28288    |
| train/                    |          |
|    explained_variance     | -37.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00649  |
|    learning_rate          | 0.001    |
|    n_updates              | 220      |
|    policy_objective       | 0.0103   |
|    value_loss             | 0.00322  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.71     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 715      |
|    iterations             | 222      |
|    time_elapsed           | 39       |
|    total_timesteps        | 28416    |
| train/                    |          |
|    explained_variance     | -33.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00606  |
|    learning_rate          | 0.001    |
|    n_updates              | 221      |
|    policy_objective       | 0.0365   |
|    value_loss             | 3.8e-05  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.03     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 715      |
|    iterations             | 223      |
|    time_elapsed           | 39       |
|    total_timesteps        | 28544    |
| train/                    |          |
|    explained_variance     | -27.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00517  |
|    learning_rate          | 0.001    |
|    n_updates              | 222      |
|    policy_objective       | 0.013    |
|    value_loss             | 0.00132  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.41     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 714      |
|    iterations             | 224      |
|    time_elapsed           | 40       |
|    total_timesteps        | 28672    |
| train/                    |          |
|    explained_variance     | 0.153    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00893  |
|    learning_rate          | 0.001    |
|    n_updates              | 223      |
|    policy_objective       | 0.108    |
|    value_loss             | 0.032    |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.89     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 714      |
|    iterations             | 225      |
|    time_elapsed           | 40       |
|    total_timesteps        | 28800    |
| train/                    |          |
|    explained_variance     | -33.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00465  |
|    learning_rate          | 0.001    |
|    n_updates              | 224      |
|    policy_objective       | 0.023    |
|    value_loss             | 0.00182  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.96     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 714      |
|    iterations             | 226      |
|    time_elapsed           | 40       |
|    total_timesteps        | 28928    |
| train/                    |          |
|    explained_variance     | -26.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00585  |
|    learning_rate          | 0.001    |
|    n_updates              | 225      |
|    policy_objective       | 0.124    |
|    value_loss             | 1.71e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.29     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 227      |
|    time_elapsed           | 40       |
|    total_timesteps        | 29056    |
| train/                    |          |
|    explained_variance     | 0.538    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00619  |
|    learning_rate          | 0.001    |
|    n_updates              | 226      |
|    policy_objective       | 0.0439   |
|    value_loss             | 0.0325   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.85     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 228      |
|    time_elapsed           | 40       |
|    total_timesteps        | 29184    |
| train/                    |          |
|    explained_variance     | -4.5     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00394  |
|    learning_rate          | 0.001    |
|    n_updates              | 227      |
|    policy_objective       | 0.0367   |
|    value_loss             | 0.0132   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.8      |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 229      |
|    time_elapsed           | 41       |
|    total_timesteps        | 29312    |
| train/                    |          |
|    explained_variance     | -2.48    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00558  |
|    learning_rate          | 0.001    |
|    n_updates              | 228      |
|    policy_objective       | 0.0552   |
|    value_loss             | 0.00074  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.85     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 230      |
|    time_elapsed           | 41       |
|    total_timesteps        | 29440    |
| train/                    |          |
|    explained_variance     | 0.135    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00544  |
|    learning_rate          | 0.001    |
|    n_updates              | 229      |
|    policy_objective       | 0.0929   |
|    value_loss             | 0.0312   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.62     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 231      |
|    time_elapsed           | 41       |
|    total_timesteps        | 29568    |
| train/                    |          |
|    explained_variance     | -0.0704  |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00407  |
|    learning_rate          | 0.001    |
|    n_updates              | 230      |
|    policy_objective       | 0.0448   |
|    value_loss             | 0.0598   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 10.4     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 232      |
|    time_elapsed           | 41       |
|    total_timesteps        | 29696    |
| train/                    |          |
|    explained_variance     | -0.308   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00511  |
|    learning_rate          | 0.001    |
|    n_updates              | 231      |
|    policy_objective       | 0.0301   |
|    value_loss             | 0.00226  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 10.5     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 233      |
|    time_elapsed           | 41       |
|    total_timesteps        | 29824    |
| train/                    |          |
|    explained_variance     | 0.225    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00607  |
|    learning_rate          | 0.001    |
|    n_updates              | 232      |
|    policy_objective       | 0.0665   |
|    value_loss             | 0.0393   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 11.1     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 234      |
|    time_elapsed           | 41       |
|    total_timesteps        | 29952    |
| train/                    |          |
|    explained_variance     | -7.86    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00683  |
|    learning_rate          | 0.001    |
|    n_updates              | 233      |
|    policy_objective       | 0.0388   |
|    value_loss             | 0.00593  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 11.2     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 235      |
|    time_elapsed           | 42       |
|    total_timesteps        | 30080    |
| train/                    |          |
|    explained_variance     | -22.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00302  |
|    learning_rate          | 0.001    |
|    n_updates              | 234      |
|    policy_objective       | 0.0568   |
|    value_loss             | 0.00759  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 11.5     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 236      |
|    time_elapsed           | 42       |
|    total_timesteps        | 30208    |
| train/                    |          |
|    explained_variance     | -17      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00142  |
|    learning_rate          | 0.001    |
|    n_updates              | 235      |
|    policy_objective       | 0.0596   |
|    value_loss             | 0.000371 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 11.2     |
|    ep_rew_mean            | 0.05     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 237      |
|    time_elapsed           | 42       |
|    total_timesteps        | 30336    |
| train/                    |          |
|    explained_variance     | 0.174    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00956  |
|    learning_rate          | 0.001    |
|    n_updates              | 236      |
|    policy_objective       | 0.123    |
|    value_loss             | 0.0269   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 11.2     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 238      |
|    time_elapsed           | 42       |
|    total_timesteps        | 30464    |
| train/                    |          |
|    explained_variance     | 0.426    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00603  |
|    learning_rate          | 0.001    |
|    n_updates              | 237      |
|    policy_objective       | 0.0386   |
|    value_loss             | 0.0342   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 10.4     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 239      |
|    time_elapsed           | 42       |
|    total_timesteps        | 30592    |
| train/                    |          |
|    explained_variance     | -0.0141  |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00701  |
|    learning_rate          | 0.001    |
|    n_updates              | 238      |
|    policy_objective       | 0.052    |
|    value_loss             | 0.0492   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.93     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 240      |
|    time_elapsed           | 43       |
|    total_timesteps        | 30720    |
| train/                    |          |
|    explained_variance     | -0.809   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00475  |
|    learning_rate          | 0.001    |
|    n_updates              | 239      |
|    policy_objective       | 0.0408   |
|    value_loss             | 0.00133  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.93     |
|    ep_rew_mean            | 0.05     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 241      |
|    time_elapsed           | 43       |
|    total_timesteps        | 30848    |
| train/                    |          |
|    explained_variance     | 0.361    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00706  |
|    learning_rate          | 0.001    |
|    n_updates              | 240      |
|    policy_objective       | 0.0194   |
|    value_loss             | 0.0288   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.61     |
|    ep_rew_mean            | 0.05     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 242      |
|    time_elapsed           | 43       |
|    total_timesteps        | 30976    |
| train/                    |          |
|    explained_variance     | 0.242    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00744  |
|    learning_rate          | 0.001    |
|    n_updates              | 241      |
|    policy_objective       | 0.0129   |
|    value_loss             | 0.0326   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.62     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 712      |
|    iterations             | 243      |
|    time_elapsed           | 43       |
|    total_timesteps        | 31104    |
| train/                    |          |
|    explained_variance     | -9.54    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00762  |
|    learning_rate          | 0.001    |
|    n_updates              | 242      |
|    policy_objective       | 0.0537   |
|    value_loss             | 0.00356  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.21     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 712      |
|    iterations             | 244      |
|    time_elapsed           | 43       |
|    total_timesteps        | 31232    |
| train/                    |          |
|    explained_variance     | -11.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00524  |
|    learning_rate          | 0.001    |
|    n_updates              | 243      |
|    policy_objective       | 0.0219   |
|    value_loss             | 0.0084   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.89     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 712      |
|    iterations             | 245      |
|    time_elapsed           | 44       |
|    total_timesteps        | 31360    |
| train/                    |          |
|    explained_variance     | -24.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00637  |
|    learning_rate          | 0.001    |
|    n_updates              | 244      |
|    policy_objective       | 0.0288   |
|    value_loss             | 0.000359 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.02     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 712      |
|    iterations             | 246      |
|    time_elapsed           | 44       |
|    total_timesteps        | 31488    |
| train/                    |          |
|    explained_variance     | -39.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00795  |
|    learning_rate          | 0.001    |
|    n_updates              | 245      |
|    policy_objective       | 0.0206   |
|    value_loss             | 0.000264 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.77     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 712      |
|    iterations             | 247      |
|    time_elapsed           | 44       |
|    total_timesteps        | 31616    |
| train/                    |          |
|    explained_variance     | -28.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00534  |
|    learning_rate          | 0.001    |
|    n_updates              | 246      |
|    policy_objective       | 0.0257   |
|    value_loss             | 4.54e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.52     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 712      |
|    iterations             | 248      |
|    time_elapsed           | 44       |
|    total_timesteps        | 31744    |
| train/                    |          |
|    explained_variance     | -89.7    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00732  |
|    learning_rate          | 0.001    |
|    n_updates              | 247      |
|    policy_objective       | 0.0277   |
|    value_loss             | 6.74e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.45     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 249      |
|    time_elapsed           | 44       |
|    total_timesteps        | 31872    |
| train/                    |          |
|    explained_variance     | -65.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00434  |
|    learning_rate          | 0.001    |
|    n_updates              | 248      |
|    policy_objective       | 0.0216   |
|    value_loss             | 3.62e-08 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.76     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 250      |
|    time_elapsed           | 44       |
|    total_timesteps        | 32000    |
| train/                    |          |
|    explained_variance     | -62.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00315  |
|    learning_rate          | 0.001    |
|    n_updates              | 249      |
|    policy_objective       | 0.0213   |
|    value_loss             | 5.2e-05  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.83     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 251      |
|    time_elapsed           | 45       |
|    total_timesteps        | 32128    |
| train/                    |          |
|    explained_variance     | -20.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00846  |
|    learning_rate          | 0.001    |
|    n_updates              | 250      |
|    policy_objective       | 0.0836   |
|    value_loss             | 3.13e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.29     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 252      |
|    time_elapsed           | 45       |
|    total_timesteps        | 32256    |
| train/                    |          |
|    explained_variance     | -69.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00379  |
|    learning_rate          | 0.001    |
|    n_updates              | 251      |
|    policy_objective       | 0.0511   |
|    value_loss             | 1.06e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.43     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 253      |
|    time_elapsed           | 45       |
|    total_timesteps        | 32384    |
| train/                    |          |
|    explained_variance     | -12.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00496  |
|    learning_rate          | 0.001    |
|    n_updates              | 252      |
|    policy_objective       | 0.0717   |
|    value_loss             | 9.91e-08 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.46     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 254      |
|    time_elapsed           | 45       |
|    total_timesteps        | 32512    |
| train/                    |          |
|    explained_variance     | -3.13    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00534  |
|    learning_rate          | 0.001    |
|    n_updates              | 253      |
|    policy_objective       | 0.0312   |
|    value_loss             | 6.8e-09  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.37     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 255      |
|    time_elapsed           | 45       |
|    total_timesteps        | 32640    |
| train/                    |          |
|    explained_variance     | -28.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00591  |
|    learning_rate          | 0.001    |
|    n_updates              | 254      |
|    policy_objective       | 0.0412   |
|    value_loss             | 5.74e-10 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.49     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 256      |
|    time_elapsed           | 45       |
|    total_timesteps        | 32768    |
| train/                    |          |
|    explained_variance     | -19.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00405  |
|    learning_rate          | 0.001    |
|    n_updates              | 255      |
|    policy_objective       | 0.0375   |
|    value_loss             | 5.47e-11 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.98     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 257      |
|    time_elapsed           | 46       |
|    total_timesteps        | 32896    |
| train/                    |          |
|    explained_variance     | -53.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00796  |
|    learning_rate          | 0.001    |
|    n_updates              | 256      |
|    policy_objective       | 0.0162   |
|    value_loss             | 1.76e-10 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.68     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 258      |
|    time_elapsed           | 46       |
|    total_timesteps        | 33024    |
| train/                    |          |
|    explained_variance     | -72.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00303  |
|    learning_rate          | 0.001    |
|    n_updates              | 257      |
|    policy_objective       | 0.0585   |
|    value_loss             | 1.95e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8        |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 714      |
|    iterations             | 259      |
|    time_elapsed           | 46       |
|    total_timesteps        | 33152    |
| train/                    |          |
|    explained_variance     | -101     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00192  |
|    learning_rate          | 0.001    |
|    n_updates              | 258      |
|    policy_objective       | 0.0573   |
|    value_loss             | 3.19e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.98     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 714      |
|    iterations             | 260      |
|    time_elapsed           | 46       |
|    total_timesteps        | 33280    |
| train/                    |          |
|    explained_variance     | -8.15    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00493  |
|    learning_rate          | 0.001    |
|    n_updates              | 259      |
|    policy_objective       | 0.0218   |
|    value_loss             | 2.28e-09 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.06     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 714      |
|    iterations             | 261      |
|    time_elapsed           | 46       |
|    total_timesteps        | 33408    |
| train/                    |          |
|    explained_variance     | -72.7    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00556  |
|    learning_rate          | 0.001    |
|    n_updates              | 260      |
|    policy_objective       | 0.00767  |
|    value_loss             | 3.04e-09 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.84     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 714      |
|    iterations             | 262      |
|    time_elapsed           | 46       |
|    total_timesteps        | 33536    |
| train/                    |          |
|    explained_variance     | -74.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00256  |
|    learning_rate          | 0.001    |
|    n_updates              | 261      |
|    policy_objective       | 0.0253   |
|    value_loss             | 2.07e-10 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.93     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 714      |
|    iterations             | 263      |
|    time_elapsed           | 47       |
|    total_timesteps        | 33664    |
| train/                    |          |
|    explained_variance     | -88.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00771  |
|    learning_rate          | 0.001    |
|    n_updates              | 262      |
|    policy_objective       | 0.00373  |
|    value_loss             | 9.07e-10 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.32     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 714      |
|    iterations             | 264      |
|    time_elapsed           | 47       |
|    total_timesteps        | 33792    |
| train/                    |          |
|    explained_variance     | 0.00198  |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0044   |
|    learning_rate          | 0.001    |
|    n_updates              | 263      |
|    policy_objective       | 0.017    |
|    value_loss             | 0.0383   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.67     |
|    ep_rew_mean            | 0.06     |
| time/                     |          |
|    fps                    | 714      |
|    iterations             | 265      |
|    time_elapsed           | 47       |
|    total_timesteps        | 33920    |
| train/                    |          |
|    explained_variance     | 0.194    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00455  |
|    learning_rate          | 0.001    |
|    n_updates              | 264      |
|    policy_objective       | 0.236    |
|    value_loss             | 0.0457   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.86     |
|    ep_rew_mean            | 0.08     |
| time/                     |          |
|    fps                    | 714      |
|    iterations             | 266      |
|    time_elapsed           | 47       |
|    total_timesteps        | 34048    |
| train/                    |          |
|    explained_variance     | 0.365    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00628  |
|    learning_rate          | 0.001    |
|    n_updates              | 265      |
|    policy_objective       | 0.0171   |
|    value_loss             | 0.0781   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.35     |
|    ep_rew_mean            | 0.1      |
| time/                     |          |
|    fps                    | 714      |
|    iterations             | 267      |
|    time_elapsed           | 47       |
|    total_timesteps        | 34176    |
| train/                    |          |
|    explained_variance     | 0.522    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00644  |
|    learning_rate          | 0.001    |
|    n_updates              | 266      |
|    policy_objective       | 0.0211   |
|    value_loss             | 0.0389   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.88     |
|    ep_rew_mean            | 0.1      |
| time/                     |          |
|    fps                    | 714      |
|    iterations             | 268      |
|    time_elapsed           | 47       |
|    total_timesteps        | 34304    |
| train/                    |          |
|    explained_variance     | 0.39     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00636  |
|    learning_rate          | 0.001    |
|    n_updates              | 267      |
|    policy_objective       | 0.0167   |
|    value_loss             | 0.0441   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 10.3     |
|    ep_rew_mean            | 0.11     |
| time/                     |          |
|    fps                    | 714      |
|    iterations             | 269      |
|    time_elapsed           | 48       |
|    total_timesteps        | 34432    |
| train/                    |          |
|    explained_variance     | -9.18    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0076   |
|    learning_rate          | 0.001    |
|    n_updates              | 268      |
|    policy_objective       | 0.0222   |
|    value_loss             | 0.0104   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 10.6     |
|    ep_rew_mean            | 0.12     |
| time/                     |          |
|    fps                    | 715      |
|    iterations             | 270      |
|    time_elapsed           | 48       |
|    total_timesteps        | 34560    |
| train/                    |          |
|    explained_variance     | -0.0473  |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00669  |
|    learning_rate          | 0.001    |
|    n_updates              | 269      |
|    policy_objective       | 0.011    |
|    value_loss             | 0.0534   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 10.9     |
|    ep_rew_mean            | 0.13     |
| time/                     |          |
|    fps                    | 715      |
|    iterations             | 271      |
|    time_elapsed           | 48       |
|    total_timesteps        | 34688    |
| train/                    |          |
|    explained_variance     | 0.134    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00441  |
|    learning_rate          | 0.001    |
|    n_updates              | 270      |
|    policy_objective       | 0.023    |
|    value_loss             | 0.0358   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 10.8     |
|    ep_rew_mean            | 0.12     |
| time/                     |          |
|    fps                    | 715      |
|    iterations             | 272      |
|    time_elapsed           | 48       |
|    total_timesteps        | 34816    |
| train/                    |          |
|    explained_variance     | 0.178    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0088   |
|    learning_rate          | 0.001    |
|    n_updates              | 271      |
|    policy_objective       | 0.0439   |
|    value_loss             | 0.0705   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 11.2     |
|    ep_rew_mean            | 0.11     |
| time/                     |          |
|    fps                    | 715      |
|    iterations             | 273      |
|    time_elapsed           | 48       |
|    total_timesteps        | 34944    |
| train/                    |          |
|    explained_variance     | -10.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00524  |
|    learning_rate          | 0.001    |
|    n_updates              | 272      |
|    policy_objective       | 0.0314   |
|    value_loss             | 0.00659  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 10.7     |
|    ep_rew_mean            | 0.08     |
| time/                     |          |
|    fps                    | 715      |
|    iterations             | 274      |
|    time_elapsed           | 49       |
|    total_timesteps        | 35072    |
| train/                    |          |
|    explained_variance     | -7.55    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00571  |
|    learning_rate          | 0.001    |
|    n_updates              | 273      |
|    policy_objective       | 0.0157   |
|    value_loss             | 0.00102  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 10.2     |
|    ep_rew_mean            | 0.06     |
| time/                     |          |
|    fps                    | 715      |
|    iterations             | 275      |
|    time_elapsed           | 49       |
|    total_timesteps        | 35200    |
| train/                    |          |
|    explained_variance     | 0.189    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00607  |
|    learning_rate          | 0.001    |
|    n_updates              | 274      |
|    policy_objective       | 0.23     |
|    value_loss             | 0.0626   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.5      |
|    ep_rew_mean            | 0.05     |
| time/                     |          |
|    fps                    | 715      |
|    iterations             | 276      |
|    time_elapsed           | 49       |
|    total_timesteps        | 35328    |
| train/                    |          |
|    explained_variance     | -8.74    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00276  |
|    learning_rate          | 0.001    |
|    n_updates              | 275      |
|    policy_objective       | 0.0261   |
|    value_loss             | 0.00238  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.81     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 715      |
|    iterations             | 277      |
|    time_elapsed           | 49       |
|    total_timesteps        | 35456    |
| train/                    |          |
|    explained_variance     | -30.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.000534 |
|    learning_rate          | 0.001    |
|    n_updates              | 276      |
|    policy_objective       | 0.0248   |
|    value_loss             | 0.0118   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.04     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 715      |
|    iterations             | 278      |
|    time_elapsed           | 49       |
|    total_timesteps        | 35584    |
| train/                    |          |
|    explained_variance     | -15.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00849  |
|    learning_rate          | 0.001    |
|    n_updates              | 277      |
|    policy_objective       | 0.0296   |
|    value_loss             | 0.001    |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.36     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 715      |
|    iterations             | 279      |
|    time_elapsed           | 49       |
|    total_timesteps        | 35712    |
| train/                    |          |
|    explained_variance     | 0.0171   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00479  |
|    learning_rate          | 0.001    |
|    n_updates              | 278      |
|    policy_objective       | 0.0108   |
|    value_loss             | 0.0388   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.88     |
|    ep_rew_mean            | 0.05     |
| time/                     |          |
|    fps                    | 715      |
|    iterations             | 280      |
|    time_elapsed           | 50       |
|    total_timesteps        | 35840    |
| train/                    |          |
|    explained_variance     | 0.139    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00532  |
|    learning_rate          | 0.001    |
|    n_updates              | 279      |
|    policy_objective       | 0.202    |
|    value_loss             | 0.0265   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.73     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 715      |
|    iterations             | 281      |
|    time_elapsed           | 50       |
|    total_timesteps        | 35968    |
| train/                    |          |
|    explained_variance     | 0.459    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00568  |
|    learning_rate          | 0.001    |
|    n_updates              | 280      |
|    policy_objective       | 0.0247   |
|    value_loss             | 0.0262   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.71     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 715      |
|    iterations             | 282      |
|    time_elapsed           | 50       |
|    total_timesteps        | 36096    |
| train/                    |          |
|    explained_variance     | 0.29     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00843  |
|    learning_rate          | 0.001    |
|    n_updates              | 281      |
|    policy_objective       | 0.0209   |
|    value_loss             | 0.0268   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.64     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 715      |
|    iterations             | 283      |
|    time_elapsed           | 50       |
|    total_timesteps        | 36224    |
| train/                    |          |
|    explained_variance     | -40.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00676  |
|    learning_rate          | 0.001    |
|    n_updates              | 282      |
|    policy_objective       | 0.0279   |
|    value_loss             | 0.00834  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.49     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 716      |
|    iterations             | 284      |
|    time_elapsed           | 50       |
|    total_timesteps        | 36352    |
| train/                    |          |
|    explained_variance     | -2.35    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00613  |
|    learning_rate          | 0.001    |
|    n_updates              | 283      |
|    policy_objective       | 0.0442   |
|    value_loss             | 0.00311  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.08     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 716      |
|    iterations             | 285      |
|    time_elapsed           | 50       |
|    total_timesteps        | 36480    |
| train/                    |          |
|    explained_variance     | -23      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00304  |
|    learning_rate          | 0.001    |
|    n_updates              | 284      |
|    policy_objective       | 0.0302   |
|    value_loss             | 0.0011   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.93     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 716      |
|    iterations             | 286      |
|    time_elapsed           | 51       |
|    total_timesteps        | 36608    |
| train/                    |          |
|    explained_variance     | -88.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00555  |
|    learning_rate          | 0.001    |
|    n_updates              | 285      |
|    policy_objective       | 0.0216   |
|    value_loss             | 0.000111 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.21     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 716      |
|    iterations             | 287      |
|    time_elapsed           | 51       |
|    total_timesteps        | 36736    |
| train/                    |          |
|    explained_variance     | -64.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00386  |
|    learning_rate          | 0.001    |
|    n_updates              | 286      |
|    policy_objective       | 0.0296   |
|    value_loss             | 7.4e-06  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.46     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 717      |
|    iterations             | 288      |
|    time_elapsed           | 51       |
|    total_timesteps        | 36864    |
| train/                    |          |
|    explained_variance     | 0.00155  |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00495  |
|    learning_rate          | 0.001    |
|    n_updates              | 287      |
|    policy_objective       | 0.0264   |
|    value_loss             | 0.0473   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.79     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 717      |
|    iterations             | 289      |
|    time_elapsed           | 51       |
|    total_timesteps        | 36992    |
| train/                    |          |
|    explained_variance     | -3.78    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0063   |
|    learning_rate          | 0.001    |
|    n_updates              | 288      |
|    policy_objective       | 0.0356   |
|    value_loss             | 0.00108  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.79     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 717      |
|    iterations             | 290      |
|    time_elapsed           | 51       |
|    total_timesteps        | 37120    |
| train/                    |          |
|    explained_variance     | 0.254    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00809  |
|    learning_rate          | 0.001    |
|    n_updates              | 289      |
|    policy_objective       | 0.0461   |
|    value_loss             | 0.0246   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.18     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 717      |
|    iterations             | 291      |
|    time_elapsed           | 51       |
|    total_timesteps        | 37248    |
| train/                    |          |
|    explained_variance     | -19.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00761  |
|    learning_rate          | 0.001    |
|    n_updates              | 290      |
|    policy_objective       | 0.0309   |
|    value_loss             | 0.000897 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.99     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 717      |
|    iterations             | 292      |
|    time_elapsed           | 52       |
|    total_timesteps        | 37376    |
| train/                    |          |
|    explained_variance     | 0.0711   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00546  |
|    learning_rate          | 0.001    |
|    n_updates              | 291      |
|    policy_objective       | 0.106    |
|    value_loss             | 0.0759   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.24     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 717      |
|    iterations             | 293      |
|    time_elapsed           | 52       |
|    total_timesteps        | 37504    |
| train/                    |          |
|    explained_variance     | -9.82    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00686  |
|    learning_rate          | 0.001    |
|    n_updates              | 292      |
|    policy_objective       | 0.034    |
|    value_loss             | 0.00513  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.03     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 717      |
|    iterations             | 294      |
|    time_elapsed           | 52       |
|    total_timesteps        | 37632    |
| train/                    |          |
|    explained_variance     | -25.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00501  |
|    learning_rate          | 0.001    |
|    n_updates              | 293      |
|    policy_objective       | 0.0379   |
|    value_loss             | 0.00576  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.74     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 717      |
|    iterations             | 295      |
|    time_elapsed           | 52       |
|    total_timesteps        | 37760    |
| train/                    |          |
|    explained_variance     | -4.11    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00245  |
|    learning_rate          | 0.001    |
|    n_updates              | 294      |
|    policy_objective       | 0.0556   |
|    value_loss             | 6.12e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.2      |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 718      |
|    iterations             | 296      |
|    time_elapsed           | 52       |
|    total_timesteps        | 37888    |
| train/                    |          |
|    explained_variance     | 0.0186   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0055   |
|    learning_rate          | 0.001    |
|    n_updates              | 295      |
|    policy_objective       | 0.0327   |
|    value_loss             | 0.0484   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.85     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 718      |
|    iterations             | 297      |
|    time_elapsed           | 52       |
|    total_timesteps        | 38016    |
| train/                    |          |
|    explained_variance     | -3.45    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00681  |
|    learning_rate          | 0.001    |
|    n_updates              | 296      |
|    policy_objective       | 0.0479   |
|    value_loss             | 0.000699 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.17     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 718      |
|    iterations             | 298      |
|    time_elapsed           | 53       |
|    total_timesteps        | 38144    |
| train/                    |          |
|    explained_variance     | -15.7    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00424  |
|    learning_rate          | 0.001    |
|    n_updates              | 297      |
|    policy_objective       | 0.0188   |
|    value_loss             | 0.000732 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.2      |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 718      |
|    iterations             | 299      |
|    time_elapsed           | 53       |
|    total_timesteps        | 38272    |
| train/                    |          |
|    explained_variance     | 0.138    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00888  |
|    learning_rate          | 0.001    |
|    n_updates              | 298      |
|    policy_objective       | 0.0532   |
|    value_loss             | 0.0588   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.5      |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 718      |
|    iterations             | 300      |
|    time_elapsed           | 53       |
|    total_timesteps        | 38400    |
| train/                    |          |
|    explained_variance     | -0.232   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00745  |
|    learning_rate          | 0.001    |
|    n_updates              | 299      |
|    policy_objective       | 0.0294   |
|    value_loss             | 0.0375   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.48     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 718      |
|    iterations             | 301      |
|    time_elapsed           | 53       |
|    total_timesteps        | 38528    |
| train/                    |          |
|    explained_variance     | -7.62    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00672  |
|    learning_rate          | 0.001    |
|    n_updates              | 300      |
|    policy_objective       | 0.0204   |
|    value_loss             | 0.0112   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.91     |
|    ep_rew_mean            | 0.05     |
| time/                     |          |
|    fps                    | 718      |
|    iterations             | 302      |
|    time_elapsed           | 53       |
|    total_timesteps        | 38656    |
| train/                    |          |
|    explained_variance     | 0.0904   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0059   |
|    learning_rate          | 0.001    |
|    n_updates              | 301      |
|    policy_objective       | 0.0317   |
|    value_loss             | 0.0432   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.02     |
|    ep_rew_mean            | 0.06     |
| time/                     |          |
|    fps                    | 718      |
|    iterations             | 303      |
|    time_elapsed           | 53       |
|    total_timesteps        | 38784    |
| train/                    |          |
|    explained_variance     | -0.0893  |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00717  |
|    learning_rate          | 0.001    |
|    n_updates              | 302      |
|    policy_objective       | 0.0337   |
|    value_loss             | 0.0447   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.52     |
|    ep_rew_mean            | 0.06     |
| time/                     |          |
|    fps                    | 719      |
|    iterations             | 304      |
|    time_elapsed           | 54       |
|    total_timesteps        | 38912    |
| train/                    |          |
|    explained_variance     | 0.131    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00285  |
|    learning_rate          | 0.001    |
|    n_updates              | 303      |
|    policy_objective       | 0.0195   |
|    value_loss             | 0.0398   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.21     |
|    ep_rew_mean            | 0.05     |
| time/                     |          |
|    fps                    | 719      |
|    iterations             | 305      |
|    time_elapsed           | 54       |
|    total_timesteps        | 39040    |
| train/                    |          |
|    explained_variance     | -5.67    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00125  |
|    learning_rate          | 0.001    |
|    n_updates              | 304      |
|    policy_objective       | 0.0381   |
|    value_loss             | 0.00273  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.21     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 719      |
|    iterations             | 306      |
|    time_elapsed           | 54       |
|    total_timesteps        | 39168    |
| train/                    |          |
|    explained_variance     | 0.21     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00623  |
|    learning_rate          | 0.001    |
|    n_updates              | 305      |
|    policy_objective       | 0.042    |
|    value_loss             | 0.0406   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.78     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 719      |
|    iterations             | 307      |
|    time_elapsed           | 54       |
|    total_timesteps        | 39296    |
| train/                    |          |
|    explained_variance     | -15.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00345  |
|    learning_rate          | 0.001    |
|    n_updates              | 306      |
|    policy_objective       | 0.0307   |
|    value_loss             | 0.00666  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.78     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 719      |
|    iterations             | 308      |
|    time_elapsed           | 54       |
|    total_timesteps        | 39424    |
| train/                    |          |
|    explained_variance     | -16.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00217  |
|    learning_rate          | 0.001    |
|    n_updates              | 307      |
|    policy_objective       | 0.0213   |
|    value_loss             | 0.000607 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.63     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 719      |
|    iterations             | 309      |
|    time_elapsed           | 54       |
|    total_timesteps        | 39552    |
| train/                    |          |
|    explained_variance     | -8.88    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00725  |
|    learning_rate          | 0.001    |
|    n_updates              | 308      |
|    policy_objective       | 0.0241   |
|    value_loss             | 0.00471  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.47     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 719      |
|    iterations             | 310      |
|    time_elapsed           | 55       |
|    total_timesteps        | 39680    |
| train/                    |          |
|    explained_variance     | -0.759   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00774  |
|    learning_rate          | 0.001    |
|    n_updates              | 309      |
|    policy_objective       | 0.0533   |
|    value_loss             | 0.00123  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.36     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 719      |
|    iterations             | 311      |
|    time_elapsed           | 55       |
|    total_timesteps        | 39808    |
| train/                    |          |
|    explained_variance     | -31.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00683  |
|    learning_rate          | 0.001    |
|    n_updates              | 310      |
|    policy_objective       | 0.00893  |
|    value_loss             | 0.000896 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.06     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 719      |
|    iterations             | 312      |
|    time_elapsed           | 55       |
|    total_timesteps        | 39936    |
| train/                    |          |
|    explained_variance     | 0.139    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00591  |
|    learning_rate          | 0.001    |
|    n_updates              | 311      |
|    policy_objective       | 0.072    |
|    value_loss             | 0.0363   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.17     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 719      |
|    iterations             | 313      |
|    time_elapsed           | 55       |
|    total_timesteps        | 40064    |
| train/                    |          |
|    explained_variance     | -30.7    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00417  |
|    learning_rate          | 0.001    |
|    n_updates              | 312      |
|    policy_objective       | 0.0566   |
|    value_loss             | 0.00611  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.34     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 719      |
|    iterations             | 314      |
|    time_elapsed           | 55       |
|    total_timesteps        | 40192    |
| train/                    |          |
|    explained_variance     | -53.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00847  |
|    learning_rate          | 0.001    |
|    n_updates              | 313      |
|    policy_objective       | 0.0429   |
|    value_loss             | 8.72e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.25     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 720      |
|    iterations             | 315      |
|    time_elapsed           | 55       |
|    total_timesteps        | 40320    |
| train/                    |          |
|    explained_variance     | -23.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00524  |
|    learning_rate          | 0.001    |
|    n_updates              | 314      |
|    policy_objective       | 0.0559   |
|    value_loss             | 0.00222  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.44     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 720      |
|    iterations             | 316      |
|    time_elapsed           | 56       |
|    total_timesteps        | 40448    |
| train/                    |          |
|    explained_variance     | -17.6    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00498  |
|    learning_rate          | 0.001    |
|    n_updates              | 315      |
|    policy_objective       | 0.0427   |
|    value_loss             | 0.000411 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.92     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 720      |
|    iterations             | 317      |
|    time_elapsed           | 56       |
|    total_timesteps        | 40576    |
| train/                    |          |
|    explained_variance     | -0.722   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00507  |
|    learning_rate          | 0.001    |
|    n_updates              | 316      |
|    policy_objective       | 0.039    |
|    value_loss             | 0.000278 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.94     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 720      |
|    iterations             | 318      |
|    time_elapsed           | 56       |
|    total_timesteps        | 40704    |
| train/                    |          |
|    explained_variance     | -12.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00235  |
|    learning_rate          | 0.001    |
|    n_updates              | 317      |
|    policy_objective       | 0.0509   |
|    value_loss             | 8.66e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.74     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 720      |
|    iterations             | 319      |
|    time_elapsed           | 56       |
|    total_timesteps        | 40832    |
| train/                    |          |
|    explained_variance     | -57.7    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00493  |
|    learning_rate          | 0.001    |
|    n_updates              | 318      |
|    policy_objective       | 0.0663   |
|    value_loss             | 4.69e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.13     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 720      |
|    iterations             | 320      |
|    time_elapsed           | 56       |
|    total_timesteps        | 40960    |
| train/                    |          |
|    explained_variance     | 0.0984   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00927  |
|    learning_rate          | 0.001    |
|    n_updates              | 319      |
|    policy_objective       | 0.0926   |
|    value_loss             | 0.033    |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.45     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 720      |
|    iterations             | 321      |
|    time_elapsed           | 57       |
|    total_timesteps        | 41088    |
| train/                    |          |
|    explained_variance     | -1.89    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00758  |
|    learning_rate          | 0.001    |
|    n_updates              | 320      |
|    policy_objective       | 0.0225   |
|    value_loss             | 0.002    |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.5      |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 720      |
|    iterations             | 322      |
|    time_elapsed           | 57       |
|    total_timesteps        | 41216    |
| train/                    |          |
|    explained_variance     | 0.0138   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00846  |
|    learning_rate          | 0.001    |
|    n_updates              | 321      |
|    policy_objective       | 0.0413   |
|    value_loss             | 0.0462   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.69     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 721      |
|    iterations             | 323      |
|    time_elapsed           | 57       |
|    total_timesteps        | 41344    |
| train/                    |          |
|    explained_variance     | -14.7    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00081  |
|    learning_rate          | 0.001    |
|    n_updates              | 322      |
|    policy_objective       | 0.0196   |
|    value_loss             | 0.00224  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.94     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 721      |
|    iterations             | 324      |
|    time_elapsed           | 57       |
|    total_timesteps        | 41472    |
| train/                    |          |
|    explained_variance     | 0.116    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00392  |
|    learning_rate          | 0.001    |
|    n_updates              | 323      |
|    policy_objective       | 0.0166   |
|    value_loss             | 0.0392   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.89     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 721      |
|    iterations             | 325      |
|    time_elapsed           | 57       |
|    total_timesteps        | 41600    |
| train/                    |          |
|    explained_variance     | -10.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00915  |
|    learning_rate          | 0.001    |
|    n_updates              | 324      |
|    policy_objective       | 0.0385   |
|    value_loss             | 0.0017   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.08     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 721      |
|    iterations             | 326      |
|    time_elapsed           | 57       |
|    total_timesteps        | 41728    |
| train/                    |          |
|    explained_variance     | -43.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00245  |
|    learning_rate          | 0.001    |
|    n_updates              | 325      |
|    policy_objective       | 0.0431   |
|    value_loss             | 0.00441  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.51     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 721      |
|    iterations             | 327      |
|    time_elapsed           | 58       |
|    total_timesteps        | 41856    |
| train/                    |          |
|    explained_variance     | 0.274    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00682  |
|    learning_rate          | 0.001    |
|    n_updates              | 326      |
|    policy_objective       | 0.0316   |
|    value_loss             | 0.0445   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.85     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 721      |
|    iterations             | 328      |
|    time_elapsed           | 58       |
|    total_timesteps        | 41984    |
| train/                    |          |
|    explained_variance     | 0.377    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00815  |
|    learning_rate          | 0.001    |
|    n_updates              | 327      |
|    policy_objective       | 0.0401   |
|    value_loss             | 0.0293   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.91     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 721      |
|    iterations             | 329      |
|    time_elapsed           | 58       |
|    total_timesteps        | 42112    |
| train/                    |          |
|    explained_variance     | -20.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00692  |
|    learning_rate          | 0.001    |
|    n_updates              | 328      |
|    policy_objective       | 0.0244   |
|    value_loss             | 0.00981  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.59     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 721      |
|    iterations             | 330      |
|    time_elapsed           | 58       |
|    total_timesteps        | 42240    |
| train/                    |          |
|    explained_variance     | -8.7     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00728  |
|    learning_rate          | 0.001    |
|    n_updates              | 329      |
|    policy_objective       | 0.028    |
|    value_loss             | 0.000141 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.95     |
|    ep_rew_mean            | 0.05     |
| time/                     |          |
|    fps                    | 721      |
|    iterations             | 331      |
|    time_elapsed           | 58       |
|    total_timesteps        | 42368    |
| train/                    |          |
|    explained_variance     | 0.156    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00925  |
|    learning_rate          | 0.001    |
|    n_updates              | 330      |
|    policy_objective       | 0.142    |
|    value_loss             | 0.0408   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.08     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 721      |
|    iterations             | 332      |
|    time_elapsed           | 58       |
|    total_timesteps        | 42496    |
| train/                    |          |
|    explained_variance     | 0.2      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00595  |
|    learning_rate          | 0.001    |
|    n_updates              | 331      |
|    policy_objective       | 0.0187   |
|    value_loss             | 0.0698   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.89     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 721      |
|    iterations             | 333      |
|    time_elapsed           | 59       |
|    total_timesteps        | 42624    |
| train/                    |          |
|    explained_variance     | -14.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00258  |
|    learning_rate          | 0.001    |
|    n_updates              | 332      |
|    policy_objective       | 0.0439   |
|    value_loss             | 0.0113   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.27     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 721      |
|    iterations             | 334      |
|    time_elapsed           | 59       |
|    total_timesteps        | 42752    |
| train/                    |          |
|    explained_variance     | -9.75    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00636  |
|    learning_rate          | 0.001    |
|    n_updates              | 333      |
|    policy_objective       | 0.0498   |
|    value_loss             | 0.000218 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.27     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 721      |
|    iterations             | 335      |
|    time_elapsed           | 59       |
|    total_timesteps        | 42880    |
| train/                    |          |
|    explained_variance     | -16.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00568  |
|    learning_rate          | 0.001    |
|    n_updates              | 334      |
|    policy_objective       | 0.0345   |
|    value_loss             | 0.00136  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.27     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 721      |
|    iterations             | 336      |
|    time_elapsed           | 59       |
|    total_timesteps        | 43008    |
| train/                    |          |
|    explained_variance     | -12.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00517  |
|    learning_rate          | 0.001    |
|    n_updates              | 335      |
|    policy_objective       | 0.0342   |
|    value_loss             | 8.71e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.56     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 721      |
|    iterations             | 337      |
|    time_elapsed           | 59       |
|    total_timesteps        | 43136    |
| train/                    |          |
|    explained_variance     | 0.103    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0028   |
|    learning_rate          | 0.001    |
|    n_updates              | 336      |
|    policy_objective       | 0.244    |
|    value_loss             | 0.037    |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.09     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 722      |
|    iterations             | 338      |
|    time_elapsed           | 59       |
|    total_timesteps        | 43264    |
| train/                    |          |
|    explained_variance     | 0.0735   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00357  |
|    learning_rate          | 0.001    |
|    n_updates              | 337      |
|    policy_objective       | 0.0312   |
|    value_loss             | 0.0373   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.14     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 722      |
|    iterations             | 339      |
|    time_elapsed           | 60       |
|    total_timesteps        | 43392    |
| train/                    |          |
|    explained_variance     | -0.374   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0031   |
|    learning_rate          | 0.001    |
|    n_updates              | 338      |
|    policy_objective       | 0.0376   |
|    value_loss             | 0.048    |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.44     |
|    ep_rew_mean            | 0.06     |
| time/                     |          |
|    fps                    | 722      |
|    iterations             | 340      |
|    time_elapsed           | 60       |
|    total_timesteps        | 43520    |
| train/                    |          |
|    explained_variance     | -0.0176  |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00701  |
|    learning_rate          | 0.001    |
|    n_updates              | 339      |
|    policy_objective       | 0.0166   |
|    value_loss             | 0.0446   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.35     |
|    ep_rew_mean            | 0.07     |
| time/                     |          |
|    fps                    | 722      |
|    iterations             | 341      |
|    time_elapsed           | 60       |
|    total_timesteps        | 43648    |
| train/                    |          |
|    explained_variance     | 0.217    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00525  |
|    learning_rate          | 0.001    |
|    n_updates              | 340      |
|    policy_objective       | 0.0204   |
|    value_loss             | 0.0513   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 10       |
|    ep_rew_mean            | 0.08     |
| time/                     |          |
|    fps                    | 722      |
|    iterations             | 342      |
|    time_elapsed           | 60       |
|    total_timesteps        | 43776    |
| train/                    |          |
|    explained_variance     | -0.153   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00515  |
|    learning_rate          | 0.001    |
|    n_updates              | 341      |
|    policy_objective       | 0.0159   |
|    value_loss             | 0.0744   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 10.6     |
|    ep_rew_mean            | 0.08     |
| time/                     |          |
|    fps                    | 722      |
|    iterations             | 343      |
|    time_elapsed           | 60       |
|    total_timesteps        | 43904    |
| train/                    |          |
|    explained_variance     | 0.252    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00716  |
|    learning_rate          | 0.001    |
|    n_updates              | 342      |
|    policy_objective       | 0.0108   |
|    value_loss             | 0.0288   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 10.7     |
|    ep_rew_mean            | 0.08     |
| time/                     |          |
|    fps                    | 723      |
|    iterations             | 344      |
|    time_elapsed           | 60       |
|    total_timesteps        | 44032    |
| train/                    |          |
|    explained_variance     | -6.68    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00644  |
|    learning_rate          | 0.001    |
|    n_updates              | 343      |
|    policy_objective       | 0.0102   |
|    value_loss             | 0.00532  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 11.6     |
|    ep_rew_mean            | 0.07     |
| time/                     |          |
|    fps                    | 723      |
|    iterations             | 345      |
|    time_elapsed           | 61       |
|    total_timesteps        | 44160    |
| train/                    |          |
|    explained_variance     | -6.05    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00675  |
|    learning_rate          | 0.001    |
|    n_updates              | 344      |
|    policy_objective       | 0.0249   |
|    value_loss             | 0.00402  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 10.6     |
|    ep_rew_mean            | 0.07     |
| time/                     |          |
|    fps                    | 723      |
|    iterations             | 346      |
|    time_elapsed           | 61       |
|    total_timesteps        | 44288    |
| train/                    |          |
|    explained_variance     | -12.6    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00909  |
|    learning_rate          | 0.001    |
|    n_updates              | 345      |
|    policy_objective       | 0.0424   |
|    value_loss             | 0.000446 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.79     |
|    ep_rew_mean            | 0.05     |
| time/                     |          |
|    fps                    | 723      |
|    iterations             | 347      |
|    time_elapsed           | 61       |
|    total_timesteps        | 44416    |
| train/                    |          |
|    explained_variance     | -0.00291 |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00401  |
|    learning_rate          | 0.001    |
|    n_updates              | 346      |
|    policy_objective       | 0.0172   |
|    value_loss             | 0.0377   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 10       |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 723      |
|    iterations             | 348      |
|    time_elapsed           | 61       |
|    total_timesteps        | 44544    |
| train/                    |          |
|    explained_variance     | 0.146    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00669  |
|    learning_rate          | 0.001    |
|    n_updates              | 347      |
|    policy_objective       | 0.0606   |
|    value_loss             | 0.0103   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.73     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 723      |
|    iterations             | 349      |
|    time_elapsed           | 61       |
|    total_timesteps        | 44672    |
| train/                    |          |
|    explained_variance     | -22.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00725  |
|    learning_rate          | 0.001    |
|    n_updates              | 348      |
|    policy_objective       | 0.0567   |
|    value_loss             | 0.00292  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.53     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 723      |
|    iterations             | 350      |
|    time_elapsed           | 61       |
|    total_timesteps        | 44800    |
| train/                    |          |
|    explained_variance     | -0.658   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0074   |
|    learning_rate          | 0.001    |
|    n_updates              | 349      |
|    policy_objective       | 0.0312   |
|    value_loss             | 0.00158  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.06     |
|    ep_rew_mean            | 0.06     |
| time/                     |          |
|    fps                    | 723      |
|    iterations             | 351      |
|    time_elapsed           | 62       |
|    total_timesteps        | 44928    |
| train/                    |          |
|    explained_variance     | 0.315    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0075   |
|    learning_rate          | 0.001    |
|    n_updates              | 350      |
|    policy_objective       | 0.0828   |
|    value_loss             | 0.0413   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.24     |
|    ep_rew_mean            | 0.07     |
| time/                     |          |
|    fps                    | 724      |
|    iterations             | 352      |
|    time_elapsed           | 62       |
|    total_timesteps        | 45056    |
| train/                    |          |
|    explained_variance     | 0.172    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00977  |
|    learning_rate          | 0.001    |
|    n_updates              | 351      |
|    policy_objective       | 0.0602   |
|    value_loss             | 0.095    |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.37     |
|    ep_rew_mean            | 0.07     |
| time/                     |          |
|    fps                    | 724      |
|    iterations             | 353      |
|    time_elapsed           | 62       |
|    total_timesteps        | 45184    |
| train/                    |          |
|    explained_variance     | 0.143    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00828  |
|    learning_rate          | 0.001    |
|    n_updates              | 352      |
|    policy_objective       | 0.0319   |
|    value_loss             | 0.0356   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.88     |
|    ep_rew_mean            | 0.08     |
| time/                     |          |
|    fps                    | 724      |
|    iterations             | 354      |
|    time_elapsed           | 62       |
|    total_timesteps        | 45312    |
| train/                    |          |
|    explained_variance     | 0.219    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00316  |
|    learning_rate          | 0.001    |
|    n_updates              | 353      |
|    policy_objective       | 0.0222   |
|    value_loss             | 0.0478   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 10.4     |
|    ep_rew_mean            | 0.09     |
| time/                     |          |
|    fps                    | 724      |
|    iterations             | 355      |
|    time_elapsed           | 62       |
|    total_timesteps        | 45440    |
| train/                    |          |
|    explained_variance     | 0.458    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00462  |
|    learning_rate          | 0.001    |
|    n_updates              | 354      |
|    policy_objective       | 0.0298   |
|    value_loss             | 0.0219   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.55     |
|    ep_rew_mean            | 0.09     |
| time/                     |          |
|    fps                    | 724      |
|    iterations             | 356      |
|    time_elapsed           | 62       |
|    total_timesteps        | 45568    |
| train/                    |          |
|    explained_variance     | -0.43    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00368  |
|    learning_rate          | 0.001    |
|    n_updates              | 355      |
|    policy_objective       | 0.0171   |
|    value_loss             | 0.0592   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.77     |
|    ep_rew_mean            | 0.09     |
| time/                     |          |
|    fps                    | 724      |
|    iterations             | 357      |
|    time_elapsed           | 63       |
|    total_timesteps        | 45696    |
| train/                    |          |
|    explained_variance     | -5.39    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.000628 |
|    learning_rate          | 0.001    |
|    n_updates              | 356      |
|    policy_objective       | 0.0419   |
|    value_loss             | 0.00213  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.34     |
|    ep_rew_mean            | 0.06     |
| time/                     |          |
|    fps                    | 725      |
|    iterations             | 358      |
|    time_elapsed           | 63       |
|    total_timesteps        | 45824    |
| train/                    |          |
|    explained_variance     | 0.172    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00586  |
|    learning_rate          | 0.001    |
|    n_updates              | 357      |
|    policy_objective       | 0.0135   |
|    value_loss             | 0.0427   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.22     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 725      |
|    iterations             | 359      |
|    time_elapsed           | 63       |
|    total_timesteps        | 45952    |
| train/                    |          |
|    explained_variance     | -11.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.000729 |
|    learning_rate          | 0.001    |
|    n_updates              | 358      |
|    policy_objective       | 0.023    |
|    value_loss             | 0.00439  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.29     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 725      |
|    iterations             | 360      |
|    time_elapsed           | 63       |
|    total_timesteps        | 46080    |
| train/                    |          |
|    explained_variance     | -8.16    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00762  |
|    learning_rate          | 0.001    |
|    n_updates              | 359      |
|    policy_objective       | 0.0249   |
|    value_loss             | 6.14e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.03     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 725      |
|    iterations             | 361      |
|    time_elapsed           | 63       |
|    total_timesteps        | 46208    |
| train/                    |          |
|    explained_variance     | -0.0124  |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00485  |
|    learning_rate          | 0.001    |
|    n_updates              | 360      |
|    policy_objective       | 0.00882  |
|    value_loss             | 0.0388   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.21     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 725      |
|    iterations             | 362      |
|    time_elapsed           | 63       |
|    total_timesteps        | 46336    |
| train/                    |          |
|    explained_variance     | -28.7    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00608  |
|    learning_rate          | 0.001    |
|    n_updates              | 361      |
|    policy_objective       | 0.0406   |
|    value_loss             | 0.000462 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.19     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 725      |
|    iterations             | 363      |
|    time_elapsed           | 64       |
|    total_timesteps        | 46464    |
| train/                    |          |
|    explained_variance     | -17.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00796  |
|    learning_rate          | 0.001    |
|    n_updates              | 362      |
|    policy_objective       | 0.012    |
|    value_loss             | 0.00227  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7        |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 725      |
|    iterations             | 364      |
|    time_elapsed           | 64       |
|    total_timesteps        | 46592    |
| train/                    |          |
|    explained_variance     | 0.266    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00437  |
|    learning_rate          | 0.001    |
|    n_updates              | 363      |
|    policy_objective       | 0.00433  |
|    value_loss             | 0.0361   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.29     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 726      |
|    iterations             | 365      |
|    time_elapsed           | 64       |
|    total_timesteps        | 46720    |
| train/                    |          |
|    explained_variance     | -29      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00976  |
|    learning_rate          | 0.001    |
|    n_updates              | 364      |
|    policy_objective       | 0.122    |
|    value_loss             | 0.00239  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.71     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 726      |
|    iterations             | 366      |
|    time_elapsed           | 64       |
|    total_timesteps        | 46848    |
| train/                    |          |
|    explained_variance     | -37.7    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00711  |
|    learning_rate          | 0.001    |
|    n_updates              | 365      |
|    policy_objective       | 0.022    |
|    value_loss             | 4.15e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.37     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 726      |
|    iterations             | 367      |
|    time_elapsed           | 64       |
|    total_timesteps        | 46976    |
| train/                    |          |
|    explained_variance     | -12.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00621  |
|    learning_rate          | 0.001    |
|    n_updates              | 366      |
|    policy_objective       | 0.021    |
|    value_loss             | 2.66e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.17     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 726      |
|    iterations             | 368      |
|    time_elapsed           | 64       |
|    total_timesteps        | 47104    |
| train/                    |          |
|    explained_variance     | -34.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00676  |
|    learning_rate          | 0.001    |
|    n_updates              | 367      |
|    policy_objective       | 0.0114   |
|    value_loss             | 1.76e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.77     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 726      |
|    iterations             | 369      |
|    time_elapsed           | 65       |
|    total_timesteps        | 47232    |
| train/                    |          |
|    explained_variance     | -31.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00646  |
|    learning_rate          | 0.001    |
|    n_updates              | 368      |
|    policy_objective       | 0.0161   |
|    value_loss             | 0.00493  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.16     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 726      |
|    iterations             | 370      |
|    time_elapsed           | 65       |
|    total_timesteps        | 47360    |
| train/                    |          |
|    explained_variance     | -71.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00124  |
|    learning_rate          | 0.001    |
|    n_updates              | 369      |
|    policy_objective       | 0.0168   |
|    value_loss             | 0.00042  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.36     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 726      |
|    iterations             | 371      |
|    time_elapsed           | 65       |
|    total_timesteps        | 47488    |
| train/                    |          |
|    explained_variance     | -57.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00881  |
|    learning_rate          | 0.001    |
|    n_updates              | 370      |
|    policy_objective       | 0.0147   |
|    value_loss             | 0.000245 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.65     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 726      |
|    iterations             | 372      |
|    time_elapsed           | 65       |
|    total_timesteps        | 47616    |
| train/                    |          |
|    explained_variance     | -71.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00725  |
|    learning_rate          | 0.001    |
|    n_updates              | 371      |
|    policy_objective       | 0.0275   |
|    value_loss             | 5.33e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.08     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 726      |
|    iterations             | 373      |
|    time_elapsed           | 65       |
|    total_timesteps        | 47744    |
| train/                    |          |
|    explained_variance     | 0.00121  |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00242  |
|    learning_rate          | 0.001    |
|    n_updates              | 372      |
|    policy_objective       | 0.0131   |
|    value_loss             | 0.0332   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8        |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 726      |
|    iterations             | 374      |
|    time_elapsed           | 65       |
|    total_timesteps        | 47872    |
| train/                    |          |
|    explained_variance     | -28      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00696  |
|    learning_rate          | 0.001    |
|    n_updates              | 373      |
|    policy_objective       | 0.0375   |
|    value_loss             | 0.0061   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.73     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 726      |
|    iterations             | 375      |
|    time_elapsed           | 66       |
|    total_timesteps        | 48000    |
| train/                    |          |
|    explained_variance     | -21.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00598  |
|    learning_rate          | 0.001    |
|    n_updates              | 374      |
|    policy_objective       | 0.0182   |
|    value_loss             | 8.86e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.28     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 726      |
|    iterations             | 376      |
|    time_elapsed           | 66       |
|    total_timesteps        | 48128    |
| train/                    |          |
|    explained_variance     | -59.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00566  |
|    learning_rate          | 0.001    |
|    n_updates              | 375      |
|    policy_objective       | 0.0115   |
|    value_loss             | 0.000254 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.46     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 726      |
|    iterations             | 377      |
|    time_elapsed           | 66       |
|    total_timesteps        | 48256    |
| train/                    |          |
|    explained_variance     | 0.191    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00966  |
|    learning_rate          | 0.001    |
|    n_updates              | 376      |
|    policy_objective       | 0.024    |
|    value_loss             | 0.0346   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.56     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 726      |
|    iterations             | 378      |
|    time_elapsed           | 66       |
|    total_timesteps        | 48384    |
| train/                    |          |
|    explained_variance     | -47.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00587  |
|    learning_rate          | 0.001    |
|    n_updates              | 377      |
|    policy_objective       | 0.0402   |
|    value_loss             | 0.000841 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.86     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 727      |
|    iterations             | 379      |
|    time_elapsed           | 66       |
|    total_timesteps        | 48512    |
| train/                    |          |
|    explained_variance     | -42.7    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0081   |
|    learning_rate          | 0.001    |
|    n_updates              | 378      |
|    policy_objective       | 0.0315   |
|    value_loss             | 0.000547 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.45     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 727      |
|    iterations             | 380      |
|    time_elapsed           | 66       |
|    total_timesteps        | 48640    |
| train/                    |          |
|    explained_variance     | 0.0806   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00881  |
|    learning_rate          | 0.001    |
|    n_updates              | 379      |
|    policy_objective       | 0.0223   |
|    value_loss             | 0.023    |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.04     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 727      |
|    iterations             | 381      |
|    time_elapsed           | 67       |
|    total_timesteps        | 48768    |
| train/                    |          |
|    explained_variance     | 0.227    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00818  |
|    learning_rate          | 0.001    |
|    n_updates              | 380      |
|    policy_objective       | 0.0173   |
|    value_loss             | 0.0494   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.57     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 727      |
|    iterations             | 382      |
|    time_elapsed           | 67       |
|    total_timesteps        | 48896    |
| train/                    |          |
|    explained_variance     | -6.1     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00783  |
|    learning_rate          | 0.001    |
|    n_updates              | 381      |
|    policy_objective       | 0.0244   |
|    value_loss             | 0.0024   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.85     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 727      |
|    iterations             | 383      |
|    time_elapsed           | 67       |
|    total_timesteps        | 49024    |
| train/                    |          |
|    explained_variance     | 0.108    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00829  |
|    learning_rate          | 0.001    |
|    n_updates              | 382      |
|    policy_objective       | 0.0142   |
|    value_loss             | 0.0418   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.53     |
|    ep_rew_mean            | 0.05     |
| time/                     |          |
|    fps                    | 727      |
|    iterations             | 384      |
|    time_elapsed           | 67       |
|    total_timesteps        | 49152    |
| train/                    |          |
|    explained_variance     | 0.223    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00594  |
|    learning_rate          | 0.001    |
|    n_updates              | 383      |
|    policy_objective       | 0.0226   |
|    value_loss             | 0.0391   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 10       |
|    ep_rew_mean            | 0.05     |
| time/                     |          |
|    fps                    | 727      |
|    iterations             | 385      |
|    time_elapsed           | 67       |
|    total_timesteps        | 49280    |
| train/                    |          |
|    explained_variance     | -0.258   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00362  |
|    learning_rate          | 0.001    |
|    n_updates              | 384      |
|    policy_objective       | 0.0177   |
|    value_loss             | 0.0333   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.61     |
|    ep_rew_mean            | 0.05     |
| time/                     |          |
|    fps                    | 727      |
|    iterations             | 386      |
|    time_elapsed           | 67       |
|    total_timesteps        | 49408    |
| train/                    |          |
|    explained_variance     | -18.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00352  |
|    learning_rate          | 0.001    |
|    n_updates              | 385      |
|    policy_objective       | 0.0204   |
|    value_loss             | 0.0038   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.49     |
|    ep_rew_mean            | 0.05     |
| time/                     |          |
|    fps                    | 728      |
|    iterations             | 387      |
|    time_elapsed           | 68       |
|    total_timesteps        | 49536    |
| train/                    |          |
|    explained_variance     | -26.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00723  |
|    learning_rate          | 0.001    |
|    n_updates              | 386      |
|    policy_objective       | 0.00671  |
|    value_loss             | 0.000494 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.43     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 728      |
|    iterations             | 388      |
|    time_elapsed           | 68       |
|    total_timesteps        | 49664    |
| train/                    |          |
|    explained_variance     | 0.144    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00229  |
|    learning_rate          | 0.001    |
|    n_updates              | 387      |
|    policy_objective       | 0.00869  |
|    value_loss             | 0.0331   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.66     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 728      |
|    iterations             | 389      |
|    time_elapsed           | 68       |
|    total_timesteps        | 49792    |
| train/                    |          |
|    explained_variance     | -14.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00878  |
|    learning_rate          | 0.001    |
|    n_updates              | 388      |
|    policy_objective       | 0.0127   |
|    value_loss             | 0.00524  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 10.6     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 728      |
|    iterations             | 390      |
|    time_elapsed           | 68       |
|    total_timesteps        | 49920    |
| train/                    |          |
|    explained_variance     | -14.6    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00627  |
|    learning_rate          | 0.001    |
|    n_updates              | 389      |
|    policy_objective       | 0.0197   |
|    value_loss             | 0.00779  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 10.9     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 728      |
|    iterations             | 391      |
|    time_elapsed           | 68       |
|    total_timesteps        | 50048    |
| train/                    |          |
|    explained_variance     | -0.06    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0064   |
|    learning_rate          | 0.001    |
|    n_updates              | 390      |
|    policy_objective       | 0.0254   |
|    value_loss             | 0.0429   |
----------------------------------------
wandb: WARNING Symlinked 1 file into the W&B run directory; call wandb.save again to sync new files.
wandb: updating run metadata
wandb: uploading model.zip; uploading output.log; uploading wandb-summary.json
wandb: uploading model.zip; uploading output.log; uploading wandb-summary.json; uploading config.yaml; uploading logs/FrozenLake_4x4_slip_prob_random_walk_Adaptive_20251218_002919_0/events.out.tfevents.1765993129.hungchan-Precision-7560.444237.0
wandb: uploading output.log; uploading logs/FrozenLake_4x4_slip_prob_random_walk_Adaptive_20251218_002919_0/events.out.tfevents.1765993129.hungchan-Precision-7560.444237.0
wandb: uploading history steps 5247-6640, summary, console lines 9665-11351
wandb: 
wandb: Run history:
wandb: adaptive/adaptation_factor â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:           adaptive/base_lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    adaptive/base_target_kl â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:   adaptive/drift_magnitude â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:     adaptive/learning_rate â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         adaptive/target_kl â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:             env/base_value â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:              env/slip_prob â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                global_step â–â–â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:        rollout/ep_len_mean â–ƒâ–„â–â–‚â–ƒâ–‚â–‚â–‚â–‚â–â–â–„â–ƒâ–…â–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–„â–…â–…â–†â–ˆâ–‡â–„â–„â–…â–‚â–ƒâ–‚â–…â–†â–†â–â–â–â–ƒ
wandb:                         +8 ...
wandb: 
wandb: Run summary:
wandb: adaptive/adaptation_factor 1
wandb:           adaptive/base_lr 0.001
wandb:    adaptive/base_target_kl 0.01
wandb:   adaptive/drift_magnitude 0
wandb:     adaptive/learning_rate 0.001
wandb:         adaptive/target_kl 0.01
wandb:             env/base_value 9.8
wandb:              env/slip_prob 9.8
wandb:                global_step 50048
wandb:        rollout/ep_len_mean 10.93
wandb:                         +8 ...
wandb: 
wandb: ðŸš€ View run FrozenLake_4x4_slip_prob_random_walk_Adaptive_20251218_002919 at: https://wandb.ai/hungtrab-hanoi-university-of-science-and-technology/FrozenLake_Drift_Research/runs/xxgbye3u
wandb: â­ï¸ View project at: https://wandb.ai/hungtrab-hanoi-university-of-science-and-technology/FrozenLake_Drift_Research
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)
wandb: Find logs at: logs/FrozenLake_4x4_slip_prob_random_walk_Adaptive_20251218_002919/wandb/run-20251218_003847-xxgbye3u/logs
>>> [DriftAdaptiveCallback] Training Ended
    Final LR: 0.001000
    Last Drift Magnitude: 0.0000
    Final Target KL: 0.0100
Model saved locally to: models/FrozenLake_4x4_slip_prob_random_walk_Adaptive_20251218_002919.zip
/home/hungchan/miniconda3/envs/rl_hf_course/lib/python3.10/site-packages/gymnasium/wrappers/rendering.py:293: UserWarning: [33mWARN: Overwriting existing videos at /home/hungchan/Work/Deep-RL/videos/FrozenLake_4x4_slip_prob_random_walk_Adaptive_20251218_002919 folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)[0m
  logger.warn(
/home/hungchan/miniconda3/envs/rl_hf_course/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run TRPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.
  warnings.warn(
>>> [Wrapper] Initialized Non-Stationary FrozenLake
    - slip_prob: random_walk (base=0.67)
Loading TRPO model from: models/FrozenLake_4x4_slip_prob_random_walk_Adaptive_20251218_002919.zip

Recording Episode 1/1...
Traceback (most recent call last):
  File "/home/hungchan/Work/Deep-RL/scripts/render.py", line 179, in <module>
    main()
  File "/home/hungchan/Work/Deep-RL/scripts/render.py", line 168, in main
    record_video(
  File "/home/hungchan/Work/Deep-RL/scripts/render.py", line 137, in record_video
    obs, reward, done, truncated, info = env.step(action)
  File "/home/hungchan/miniconda3/envs/rl_hf_course/lib/python3.10/site-packages/gymnasium/wrappers/rendering.py", line 363, in step
    obs, rew, terminated, truncated, info = self.env.step(action)
  File "/home/hungchan/Work/Deep-RL/scripts/../src/envs/multi_env_wrappers.py", line 378, in step
    obs, reward, terminated, truncated, info = self.env.step(action)
  File "/home/hungchan/miniconda3/envs/rl_hf_course/lib/python3.10/site-packages/gymnasium/wrappers/common.py", line 125, in step
    observation, reward, terminated, truncated, info = self.env.step(action)
  File "/home/hungchan/miniconda3/envs/rl_hf_course/lib/python3.10/site-packages/gymnasium/wrappers/common.py", line 393, in step
    return super().step(action)
  File "/home/hungchan/miniconda3/envs/rl_hf_course/lib/python3.10/site-packages/gymnasium/core.py", line 327, in step
    return self.env.step(action)
  File "/home/hungchan/miniconda3/envs/rl_hf_course/lib/python3.10/site-packages/gymnasium/wrappers/common.py", line 285, in step
    return self.env.step(action)
  File "/home/hungchan/miniconda3/envs/rl_hf_course/lib/python3.10/site-packages/gymnasium/envs/toy_text/frozen_lake.py", line 325, in step
    transitions = self.P[self.s][a]
TypeError: unhashable type: 'numpy.ndarray'
/home/hungchan/miniconda3/envs/rl_hf_course/lib/python3.10/site-packages/gymnasium/wrappers/rendering.py:434: UserWarning: [33mWARN: Unable to save last video! Did you call close()?[0m
  logger.warn("Unable to save last video! Did you call close()?")
