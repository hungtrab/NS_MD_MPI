wandb: Currently logged in as: hungtrab (hungtrab-hanoi-university-of-science-and-technology) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: setting up run 5r0kengu
wandb: Tracking run with wandb version 0.23.1
wandb: Run data is saved locally in logs/FrozenLake_8x8_slip_prob_sine_Adaptive_20251218_002919/wandb/run-20251218_004128-5r0kengu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run FrozenLake_8x8_slip_prob_sine_Adaptive_20251218_002919
wandb: â­ï¸ View project at https://wandb.ai/hungtrab-hanoi-university-of-science-and-technology/FrozenLake_Drift_Research
wandb: ðŸš€ View run at https://wandb.ai/hungtrab-hanoi-university-of-science-and-technology/FrozenLake_Drift_Research/runs/5r0kengu
/home/hungchan/miniconda3/envs/rl_hf_course/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run TRPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.
  warnings.warn(
--- Training Start: FrozenLake_8x8_slip_prob_sine_Adaptive_20251218_002919 ---
>>> [Wrapper] Initialized Non-Stationary FrozenLake
    - slip_prob: sine (base=0.67)
>>> Initializing TRPO with kwargs: ['policy', 'env', 'learning_rate', 'gamma', 'verbose', 'tensorboard_log', 'n_steps', 'batch_size']
Using cuda device
Wrapping the env in a DummyVecEnv.
Logging to logs/FrozenLake_8x8_slip_prob_sine_Adaptive_20251218_002919_0
>>> [DriftAdaptiveCallback] Training Started
    Algorithm: TRPO
    Target Param: slip_prob (base=9.8)
    Scale Factor: 0.2
    
    Adaptive Hyperparameters:
      - Learning Rate: 0.001000
      - Target KL: 0.0100 (adapt=True)
-----------------------------------
| adaptive/            |          |
|    adaptation_factor | 1        |
|    algorithm         | TRPO     |
|    base_lr           | 0.001    |
|    base_target_kl    | 0.01     |
|    drift_magnitude   | 0        |
|    learning_rate     | 0.001    |
|    target_kl         | 0.01     |
| env/                 |          |
|    base_value        | 9.8      |
|    slip_prob         | 9.8      |
| rollout/             |          |
|    ep_len_mean       | 61.5     |
|    ep_rew_mean       | 0        |
| time/                |          |
|    fps               | 374      |
|    iterations        | 1        |
|    time_elapsed      | 0        |
|    total_timesteps   | 128      |
-----------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 44.6     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 413      |
|    iterations             | 2        |
|    time_elapsed           | 0        |
|    total_timesteps        | 256      |
| train/                    |          |
|    explained_variance     | -16.6    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00364  |
|    learning_rate          | 0.001    |
|    n_updates              | 1        |
|    policy_objective       | 0.0554   |
|    value_loss             | 0.00866  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 36.7     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 483      |
|    iterations             | 3        |
|    time_elapsed           | 0        |
|    total_timesteps        | 384      |
| train/                    |          |
|    explained_variance     | -1.53    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00261  |
|    learning_rate          | 0.001    |
|    n_updates              | 2        |
|    policy_objective       | 0.0519   |
|    value_loss             | 0.0024   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 33.3     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 532      |
|    iterations             | 4        |
|    time_elapsed           | 0        |
|    total_timesteps        | 512      |
| train/                    |          |
|    explained_variance     | -23.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0019   |
|    learning_rate          | 0.001    |
|    n_updates              | 3        |
|    policy_objective       | 0.0652   |
|    value_loss             | 0.000428 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 29.1     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 564      |
|    iterations             | 5        |
|    time_elapsed           | 1        |
|    total_timesteps        | 640      |
| train/                    |          |
|    explained_variance     | -3.52    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00426  |
|    learning_rate          | 0.001    |
|    n_updates              | 4        |
|    policy_objective       | 0.0614   |
|    value_loss             | 8.19e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 31.3     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 585      |
|    iterations             | 6        |
|    time_elapsed           | 1        |
|    total_timesteps        | 768      |
| train/                    |          |
|    explained_variance     | -16.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00147  |
|    learning_rate          | 0.001    |
|    n_updates              | 5        |
|    policy_objective       | 0.0727   |
|    value_loss             | 0.000899 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 32       |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 603      |
|    iterations             | 7        |
|    time_elapsed           | 1        |
|    total_timesteps        | 896      |
| train/                    |          |
|    explained_variance     | -3.56    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00212  |
|    learning_rate          | 0.001    |
|    n_updates              | 6        |
|    policy_objective       | 0.0596   |
|    value_loss             | 1.92e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 35.2     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 614      |
|    iterations             | 8        |
|    time_elapsed           | 1        |
|    total_timesteps        | 1024     |
| train/                    |          |
|    explained_variance     | -15.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00201  |
|    learning_rate          | 0.001    |
|    n_updates              | 7        |
|    policy_objective       | 0.0657   |
|    value_loss             | 0.000568 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 32.9     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 625      |
|    iterations             | 9        |
|    time_elapsed           | 1        |
|    total_timesteps        | 1152     |
| train/                    |          |
|    explained_variance     | -4.56    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00297  |
|    learning_rate          | 0.001    |
|    n_updates              | 8        |
|    policy_objective       | 0.0611   |
|    value_loss             | 2.21e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 33.1     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 631      |
|    iterations             | 10       |
|    time_elapsed           | 2        |
|    total_timesteps        | 1280     |
| train/                    |          |
|    explained_variance     | -1.26    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00303  |
|    learning_rate          | 0.001    |
|    n_updates              | 9        |
|    policy_objective       | 0.0525   |
|    value_loss             | 5.73e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 33.5     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 637      |
|    iterations             | 11       |
|    time_elapsed           | 2        |
|    total_timesteps        | 1408     |
| train/                    |          |
|    explained_variance     | -1.87    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00378  |
|    learning_rate          | 0.001    |
|    n_updates              | 10       |
|    policy_objective       | 0.0659   |
|    value_loss             | 8.81e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 33.2     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 637      |
|    iterations             | 12       |
|    time_elapsed           | 2        |
|    total_timesteps        | 1536     |
| train/                    |          |
|    explained_variance     | -149     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0018   |
|    learning_rate          | 0.001    |
|    n_updates              | 11       |
|    policy_objective       | 0.0893   |
|    value_loss             | 0.00014  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 33.9     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 643      |
|    iterations             | 13       |
|    time_elapsed           | 2        |
|    total_timesteps        | 1664     |
| train/                    |          |
|    explained_variance     | -4.51    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0021   |
|    learning_rate          | 0.001    |
|    n_updates              | 12       |
|    policy_objective       | 0.0715   |
|    value_loss             | 0.00149  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 33.7     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 651      |
|    iterations             | 14       |
|    time_elapsed           | 2        |
|    total_timesteps        | 1792     |
| train/                    |          |
|    explained_variance     | -0.489   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00348  |
|    learning_rate          | 0.001    |
|    n_updates              | 13       |
|    policy_objective       | 0.0606   |
|    value_loss             | 0.000127 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 32.7     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 656      |
|    iterations             | 15       |
|    time_elapsed           | 2        |
|    total_timesteps        | 1920     |
| train/                    |          |
|    explained_variance     | -3.04    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00416  |
|    learning_rate          | 0.001    |
|    n_updates              | 14       |
|    policy_objective       | 0.0583   |
|    value_loss             | 9.91e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 33.9     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 658      |
|    iterations             | 16       |
|    time_elapsed           | 3        |
|    total_timesteps        | 2048     |
| train/                    |          |
|    explained_variance     | 0.146    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00366  |
|    learning_rate          | 0.001    |
|    n_updates              | 15       |
|    policy_objective       | 0.0606   |
|    value_loss             | 0.000117 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 33.6     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 661      |
|    iterations             | 17       |
|    time_elapsed           | 3        |
|    total_timesteps        | 2176     |
| train/                    |          |
|    explained_variance     | -5.02    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00416  |
|    learning_rate          | 0.001    |
|    n_updates              | 16       |
|    policy_objective       | 0.0734   |
|    value_loss             | 7.49e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 34.2     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 664      |
|    iterations             | 18       |
|    time_elapsed           | 3        |
|    total_timesteps        | 2304     |
| train/                    |          |
|    explained_variance     | -3.76    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00279  |
|    learning_rate          | 0.001    |
|    n_updates              | 17       |
|    policy_objective       | 0.0694   |
|    value_loss             | 2.36e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 34       |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 668      |
|    iterations             | 19       |
|    time_elapsed           | 3        |
|    total_timesteps        | 2432     |
| train/                    |          |
|    explained_variance     | -9.75    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00164  |
|    learning_rate          | 0.001    |
|    n_updates              | 18       |
|    policy_objective       | 0.0628   |
|    value_loss             | 3.76e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 35       |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 671      |
|    iterations             | 20       |
|    time_elapsed           | 3        |
|    total_timesteps        | 2560     |
| train/                    |          |
|    explained_variance     | -23.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0034   |
|    learning_rate          | 0.001    |
|    n_updates              | 19       |
|    policy_objective       | 0.0511   |
|    value_loss             | 7.4e-06  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 33.9     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 675      |
|    iterations             | 21       |
|    time_elapsed           | 3        |
|    total_timesteps        | 2688     |
| train/                    |          |
|    explained_variance     | -3.13    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00443  |
|    learning_rate          | 0.001    |
|    n_updates              | 20       |
|    policy_objective       | 0.0522   |
|    value_loss             | 5.67e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 32.4     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 678      |
|    iterations             | 22       |
|    time_elapsed           | 4        |
|    total_timesteps        | 2816     |
| train/                    |          |
|    explained_variance     | -8.68    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00281  |
|    learning_rate          | 0.001    |
|    n_updates              | 21       |
|    policy_objective       | 0.07     |
|    value_loss             | 4.65e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 33.4     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 676      |
|    iterations             | 23       |
|    time_elapsed           | 4        |
|    total_timesteps        | 2944     |
| train/                    |          |
|    explained_variance     | -8.3     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00202  |
|    learning_rate          | 0.001    |
|    n_updates              | 22       |
|    policy_objective       | 0.0551   |
|    value_loss             | 5.87e-08 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 32.9     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 672      |
|    iterations             | 24       |
|    time_elapsed           | 4        |
|    total_timesteps        | 3072     |
| train/                    |          |
|    explained_variance     | -1.33    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0057   |
|    learning_rate          | 0.001    |
|    n_updates              | 23       |
|    policy_objective       | 0.07     |
|    value_loss             | 2.65e-08 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 32.9     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 669      |
|    iterations             | 25       |
|    time_elapsed           | 4        |
|    total_timesteps        | 3200     |
| train/                    |          |
|    explained_variance     | -45.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00286  |
|    learning_rate          | 0.001    |
|    n_updates              | 24       |
|    policy_objective       | 0.0656   |
|    value_loss             | 2.7e-07  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 31.6     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 666      |
|    iterations             | 26       |
|    time_elapsed           | 4        |
|    total_timesteps        | 3328     |
| train/                    |          |
|    explained_variance     | -5.54    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00302  |
|    learning_rate          | 0.001    |
|    n_updates              | 25       |
|    policy_objective       | 0.0704   |
|    value_loss             | 7.22e-09 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 31.3     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 665      |
|    iterations             | 27       |
|    time_elapsed           | 5        |
|    total_timesteps        | 3456     |
| train/                    |          |
|    explained_variance     | -3.48    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00238  |
|    learning_rate          | 0.001    |
|    n_updates              | 26       |
|    policy_objective       | 0.105    |
|    value_loss             | 1.85e-09 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 31.6     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 665      |
|    iterations             | 28       |
|    time_elapsed           | 5        |
|    total_timesteps        | 3584     |
| train/                    |          |
|    explained_variance     | -59.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00215  |
|    learning_rate          | 0.001    |
|    n_updates              | 27       |
|    policy_objective       | 0.0891   |
|    value_loss             | 4.08e-08 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 32.2     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 662      |
|    iterations             | 29       |
|    time_elapsed           | 5        |
|    total_timesteps        | 3712     |
| train/                    |          |
|    explained_variance     | -6.33    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00515  |
|    learning_rate          | 0.001    |
|    n_updates              | 28       |
|    policy_objective       | 0.0591   |
|    value_loss             | 0.000148 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 33       |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 662      |
|    iterations             | 30       |
|    time_elapsed           | 5        |
|    total_timesteps        | 3840     |
| train/                    |          |
|    explained_variance     | -111     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0015   |
|    learning_rate          | 0.001    |
|    n_updates              | 29       |
|    policy_objective       | 0.065    |
|    value_loss             | 0.000644 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 33.4     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 664      |
|    iterations             | 31       |
|    time_elapsed           | 5        |
|    total_timesteps        | 3968     |
| train/                    |          |
|    explained_variance     | -7.08    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00547  |
|    learning_rate          | 0.001    |
|    n_updates              | 30       |
|    policy_objective       | 0.0596   |
|    value_loss             | 3.99e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 31.7     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 665      |
|    iterations             | 32       |
|    time_elapsed           | 6        |
|    total_timesteps        | 4096     |
| train/                    |          |
|    explained_variance     | -40.7    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00228  |
|    learning_rate          | 0.001    |
|    n_updates              | 31       |
|    policy_objective       | 0.0551   |
|    value_loss             | 7.93e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 31.4     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 667      |
|    iterations             | 33       |
|    time_elapsed           | 6        |
|    total_timesteps        | 4224     |
| train/                    |          |
|    explained_variance     | -0.22    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00551  |
|    learning_rate          | 0.001    |
|    n_updates              | 32       |
|    policy_objective       | 0.0862   |
|    value_loss             | 5.43e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 32.4     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 668      |
|    iterations             | 34       |
|    time_elapsed           | 6        |
|    total_timesteps        | 4352     |
| train/                    |          |
|    explained_variance     | -82.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00181  |
|    learning_rate          | 0.001    |
|    n_updates              | 33       |
|    policy_objective       | 0.0671   |
|    value_loss             | 0.000101 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 32.2     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 668      |
|    iterations             | 35       |
|    time_elapsed           | 6        |
|    total_timesteps        | 4480     |
| train/                    |          |
|    explained_variance     | -4.16    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00477  |
|    learning_rate          | 0.001    |
|    n_updates              | 34       |
|    policy_objective       | 0.0758   |
|    value_loss             | 1.18e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 31.9     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 667      |
|    iterations             | 36       |
|    time_elapsed           | 6        |
|    total_timesteps        | 4608     |
| train/                    |          |
|    explained_variance     | -11.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00183  |
|    learning_rate          | 0.001    |
|    n_updates              | 35       |
|    policy_objective       | 0.0667   |
|    value_loss             | 1.81e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 31.4     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 667      |
|    iterations             | 37       |
|    time_elapsed           | 7        |
|    total_timesteps        | 4736     |
| train/                    |          |
|    explained_variance     | -44.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00233  |
|    learning_rate          | 0.001    |
|    n_updates              | 36       |
|    policy_objective       | 0.0648   |
|    value_loss             | 8.5e-07  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 31.9     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 668      |
|    iterations             | 38       |
|    time_elapsed           | 7        |
|    total_timesteps        | 4864     |
| train/                    |          |
|    explained_variance     | -63.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00161  |
|    learning_rate          | 0.001    |
|    n_updates              | 37       |
|    policy_objective       | 0.11     |
|    value_loss             | 2.34e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 31.3     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 668      |
|    iterations             | 39       |
|    time_elapsed           | 7        |
|    total_timesteps        | 4992     |
| train/                    |          |
|    explained_variance     | -2.61    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00428  |
|    learning_rate          | 0.001    |
|    n_updates              | 38       |
|    policy_objective       | 0.0739   |
|    value_loss             | 4.51e-08 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 30.4     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 669      |
|    iterations             | 40       |
|    time_elapsed           | 7        |
|    total_timesteps        | 5120     |
| train/                    |          |
|    explained_variance     | -19.7    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00205  |
|    learning_rate          | 0.001    |
|    n_updates              | 39       |
|    policy_objective       | 0.0691   |
|    value_loss             | 3.33e-08 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 30.6     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 670      |
|    iterations             | 41       |
|    time_elapsed           | 7        |
|    total_timesteps        | 5248     |
| train/                    |          |
|    explained_variance     | -51.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00142  |
|    learning_rate          | 0.001    |
|    n_updates              | 40       |
|    policy_objective       | 0.0593   |
|    value_loss             | 1.03e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 30.1     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 671      |
|    iterations             | 42       |
|    time_elapsed           | 8        |
|    total_timesteps        | 5376     |
| train/                    |          |
|    explained_variance     | -8.72    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00473  |
|    learning_rate          | 0.001    |
|    n_updates              | 41       |
|    policy_objective       | 0.0752   |
|    value_loss             | 2.28e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 30.3     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 672      |
|    iterations             | 43       |
|    time_elapsed           | 8        |
|    total_timesteps        | 5504     |
| train/                    |          |
|    explained_variance     | -13.6    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00329  |
|    learning_rate          | 0.001    |
|    n_updates              | 42       |
|    policy_objective       | 0.0719   |
|    value_loss             | 2.64e-08 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 29.9     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 673      |
|    iterations             | 44       |
|    time_elapsed           | 8        |
|    total_timesteps        | 5632     |
| train/                    |          |
|    explained_variance     | -33      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00421  |
|    learning_rate          | 0.001    |
|    n_updates              | 43       |
|    policy_objective       | 0.0851   |
|    value_loss             | 2.92e-08 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 30.1     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 673      |
|    iterations             | 45       |
|    time_elapsed           | 8        |
|    total_timesteps        | 5760     |
| train/                    |          |
|    explained_variance     | -78.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00231  |
|    learning_rate          | 0.001    |
|    n_updates              | 44       |
|    policy_objective       | 0.0569   |
|    value_loss             | 7.79e-08 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 30.5     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 673      |
|    iterations             | 46       |
|    time_elapsed           | 8        |
|    total_timesteps        | 5888     |
| train/                    |          |
|    explained_variance     | -11.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0054   |
|    learning_rate          | 0.001    |
|    n_updates              | 45       |
|    policy_objective       | 0.0547   |
|    value_loss             | 1.36e-08 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 30.1     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 673      |
|    iterations             | 47       |
|    time_elapsed           | 8        |
|    total_timesteps        | 6016     |
| train/                    |          |
|    explained_variance     | -1.2     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00444  |
|    learning_rate          | 0.001    |
|    n_updates              | 46       |
|    policy_objective       | 0.0569   |
|    value_loss             | 2.96e-09 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 30.8     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 674      |
|    iterations             | 48       |
|    time_elapsed           | 9        |
|    total_timesteps        | 6144     |
| train/                    |          |
|    explained_variance     | -10.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00531  |
|    learning_rate          | 0.001    |
|    n_updates              | 47       |
|    policy_objective       | 0.0621   |
|    value_loss             | 3.79e-10 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 31.2     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 674      |
|    iterations             | 49       |
|    time_elapsed           | 9        |
|    total_timesteps        | 6272     |
| train/                    |          |
|    explained_variance     | -6.62    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00161  |
|    learning_rate          | 0.001    |
|    n_updates              | 48       |
|    policy_objective       | 0.0573   |
|    value_loss             | 2.83e-10 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 31.2     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 675      |
|    iterations             | 50       |
|    time_elapsed           | 9        |
|    total_timesteps        | 6400     |
| train/                    |          |
|    explained_variance     | -52.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00506  |
|    learning_rate          | 0.001    |
|    n_updates              | 49       |
|    policy_objective       | 0.1      |
|    value_loss             | 7.91e-08 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 31.9     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 675      |
|    iterations             | 51       |
|    time_elapsed           | 9        |
|    total_timesteps        | 6528     |
| train/                    |          |
|    explained_variance     | -5.78    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00381  |
|    learning_rate          | 0.001    |
|    n_updates              | 50       |
|    policy_objective       | 0.0652   |
|    value_loss             | 2.59e-09 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 31.8     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 676      |
|    iterations             | 52       |
|    time_elapsed           | 9        |
|    total_timesteps        | 6656     |
| train/                    |          |
|    explained_variance     | -22.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00378  |
|    learning_rate          | 0.001    |
|    n_updates              | 51       |
|    policy_objective       | 0.049    |
|    value_loss             | 6.52e-10 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 32.9     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 676      |
|    iterations             | 53       |
|    time_elapsed           | 10       |
|    total_timesteps        | 6784     |
| train/                    |          |
|    explained_variance     | -2.75    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.004    |
|    learning_rate          | 0.001    |
|    n_updates              | 52       |
|    policy_objective       | 0.0686   |
|    value_loss             | 7.09e-11 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 31.7     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 676      |
|    iterations             | 54       |
|    time_elapsed           | 10       |
|    total_timesteps        | 6912     |
| train/                    |          |
|    explained_variance     | -32.7    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00224  |
|    learning_rate          | 0.001    |
|    n_updates              | 53       |
|    policy_objective       | 0.0931   |
|    value_loss             | 1.35e-10 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 31.8     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 676      |
|    iterations             | 55       |
|    time_elapsed           | 10       |
|    total_timesteps        | 7040     |
| train/                    |          |
|    explained_variance     | -13.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.005    |
|    learning_rate          | 0.001    |
|    n_updates              | 54       |
|    policy_objective       | 0.0679   |
|    value_loss             | 1.21e-11 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 31.8     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 676      |
|    iterations             | 56       |
|    time_elapsed           | 10       |
|    total_timesteps        | 7168     |
| train/                    |          |
|    explained_variance     | -88.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00263  |
|    learning_rate          | 0.001    |
|    n_updates              | 55       |
|    policy_objective       | 0.0871   |
|    value_loss             | 1.13e-08 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 32.5     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 676      |
|    iterations             | 57       |
|    time_elapsed           | 10       |
|    total_timesteps        | 7296     |
| train/                    |          |
|    explained_variance     | -27.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00735  |
|    learning_rate          | 0.001    |
|    n_updates              | 56       |
|    policy_objective       | 0.0702   |
|    value_loss             | 2.91e-10 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 31.9     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 675      |
|    iterations             | 58       |
|    time_elapsed           | 10       |
|    total_timesteps        | 7424     |
| train/                    |          |
|    explained_variance     | -64.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00242  |
|    learning_rate          | 0.001    |
|    n_updates              | 57       |
|    policy_objective       | 0.0866   |
|    value_loss             | 2.72e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 31.8     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 676      |
|    iterations             | 59       |
|    time_elapsed           | 11       |
|    total_timesteps        | 7552     |
| train/                    |          |
|    explained_variance     | -30      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00281  |
|    learning_rate          | 0.001    |
|    n_updates              | 58       |
|    policy_objective       | 0.0766   |
|    value_loss             | 3.62e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 31.2     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 676      |
|    iterations             | 60       |
|    time_elapsed           | 11       |
|    total_timesteps        | 7680     |
| train/                    |          |
|    explained_variance     | -14.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00237  |
|    learning_rate          | 0.001    |
|    n_updates              | 59       |
|    policy_objective       | 0.0683   |
|    value_loss             | 6.26e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 31.6     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 675      |
|    iterations             | 61       |
|    time_elapsed           | 11       |
|    total_timesteps        | 7808     |
| train/                    |          |
|    explained_variance     | -6.67    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00558  |
|    learning_rate          | 0.001    |
|    n_updates              | 60       |
|    policy_objective       | 0.0648   |
|    value_loss             | 1.33e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 30.8     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 675      |
|    iterations             | 62       |
|    time_elapsed           | 11       |
|    total_timesteps        | 7936     |
| train/                    |          |
|    explained_variance     | -19.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00446  |
|    learning_rate          | 0.001    |
|    n_updates              | 61       |
|    policy_objective       | 0.0691   |
|    value_loss             | 1.02e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 31.4     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 675      |
|    iterations             | 63       |
|    time_elapsed           | 11       |
|    total_timesteps        | 8064     |
| train/                    |          |
|    explained_variance     | -19.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.000983 |
|    learning_rate          | 0.001    |
|    n_updates              | 62       |
|    policy_objective       | 0.068    |
|    value_loss             | 5.63e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 31.9     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 675      |
|    iterations             | 64       |
|    time_elapsed           | 12       |
|    total_timesteps        | 8192     |
| train/                    |          |
|    explained_variance     | -4.09    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00634  |
|    learning_rate          | 0.001    |
|    n_updates              | 63       |
|    policy_objective       | 0.0588   |
|    value_loss             | 1.7e-07  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 32.3     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 676      |
|    iterations             | 65       |
|    time_elapsed           | 12       |
|    total_timesteps        | 8320     |
| train/                    |          |
|    explained_variance     | -3.7     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00616  |
|    learning_rate          | 0.001    |
|    n_updates              | 64       |
|    policy_objective       | 0.0535   |
|    value_loss             | 2.32e-08 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 33.5     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 676      |
|    iterations             | 66       |
|    time_elapsed           | 12       |
|    total_timesteps        | 8448     |
| train/                    |          |
|    explained_variance     | -33.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00329  |
|    learning_rate          | 0.001    |
|    n_updates              | 65       |
|    policy_objective       | 0.0458   |
|    value_loss             | 2.18e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 33.7     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 676      |
|    iterations             | 67       |
|    time_elapsed           | 12       |
|    total_timesteps        | 8576     |
| train/                    |          |
|    explained_variance     | -19      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00312  |
|    learning_rate          | 0.001    |
|    n_updates              | 66       |
|    policy_objective       | 0.05     |
|    value_loss             | 7.67e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 33.7     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 676      |
|    iterations             | 68       |
|    time_elapsed           | 12       |
|    total_timesteps        | 8704     |
| train/                    |          |
|    explained_variance     | -14.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00452  |
|    learning_rate          | 0.001    |
|    n_updates              | 67       |
|    policy_objective       | 0.0698   |
|    value_loss             | 1.48e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 34       |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 676      |
|    iterations             | 69       |
|    time_elapsed           | 13       |
|    total_timesteps        | 8832     |
| train/                    |          |
|    explained_variance     | -17.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0056   |
|    learning_rate          | 0.001    |
|    n_updates              | 68       |
|    policy_objective       | 0.051    |
|    value_loss             | 3.4e-08  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 33.8     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 676      |
|    iterations             | 70       |
|    time_elapsed           | 13       |
|    total_timesteps        | 8960     |
| train/                    |          |
|    explained_variance     | -15.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0049   |
|    learning_rate          | 0.001    |
|    n_updates              | 69       |
|    policy_objective       | 0.0631   |
|    value_loss             | 7.11e-09 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 34.9     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 677      |
|    iterations             | 71       |
|    time_elapsed           | 13       |
|    total_timesteps        | 9088     |
| train/                    |          |
|    explained_variance     | -72.6    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00201  |
|    learning_rate          | 0.001    |
|    n_updates              | 70       |
|    policy_objective       | 0.0684   |
|    value_loss             | 2.3e-06  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 34.7     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 676      |
|    iterations             | 72       |
|    time_elapsed           | 13       |
|    total_timesteps        | 9216     |
| train/                    |          |
|    explained_variance     | -4.62    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0061   |
|    learning_rate          | 0.001    |
|    n_updates              | 71       |
|    policy_objective       | 0.0773   |
|    value_loss             | 8.41e-08 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 34.2     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 676      |
|    iterations             | 73       |
|    time_elapsed           | 13       |
|    total_timesteps        | 9344     |
| train/                    |          |
|    explained_variance     | -26      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00473  |
|    learning_rate          | 0.001    |
|    n_updates              | 72       |
|    policy_objective       | 0.0438   |
|    value_loss             | 3.34e-08 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 35.1     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 676      |
|    iterations             | 74       |
|    time_elapsed           | 13       |
|    total_timesteps        | 9472     |
| train/                    |          |
|    explained_variance     | -23.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00598  |
|    learning_rate          | 0.001    |
|    n_updates              | 73       |
|    policy_objective       | 0.0305   |
|    value_loss             | 3.34e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 35       |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 676      |
|    iterations             | 75       |
|    time_elapsed           | 14       |
|    total_timesteps        | 9600     |
| train/                    |          |
|    explained_variance     | -1.54    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00647  |
|    learning_rate          | 0.001    |
|    n_updates              | 74       |
|    policy_objective       | 0.0717   |
|    value_loss             | 3.51e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 36.3     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 676      |
|    iterations             | 76       |
|    time_elapsed           | 14       |
|    total_timesteps        | 9728     |
| train/                    |          |
|    explained_variance     | -15.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00203  |
|    learning_rate          | 0.001    |
|    n_updates              | 75       |
|    policy_objective       | 0.072    |
|    value_loss             | 1.19e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 36       |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 675      |
|    iterations             | 77       |
|    time_elapsed           | 14       |
|    total_timesteps        | 9856     |
| train/                    |          |
|    explained_variance     | -11.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0036   |
|    learning_rate          | 0.001    |
|    n_updates              | 76       |
|    policy_objective       | 0.0768   |
|    value_loss             | 5.13e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 36.6     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 676      |
|    iterations             | 78       |
|    time_elapsed           | 14       |
|    total_timesteps        | 9984     |
| train/                    |          |
|    explained_variance     | -8.12    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00463  |
|    learning_rate          | 0.001    |
|    n_updates              | 77       |
|    policy_objective       | 0.0702   |
|    value_loss             | 3.06e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 37.2     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 676      |
|    iterations             | 79       |
|    time_elapsed           | 14       |
|    total_timesteps        | 10112    |
| train/                    |          |
|    explained_variance     | -16.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00518  |
|    learning_rate          | 0.001    |
|    n_updates              | 78       |
|    policy_objective       | 0.0669   |
|    value_loss             | 3.31e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 36.7     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 676      |
|    iterations             | 80       |
|    time_elapsed           | 15       |
|    total_timesteps        | 10240    |
| train/                    |          |
|    explained_variance     | -9.95    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00423  |
|    learning_rate          | 0.001    |
|    n_updates              | 79       |
|    policy_objective       | 0.068    |
|    value_loss             | 9.13e-08 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 37       |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 676      |
|    iterations             | 81       |
|    time_elapsed           | 15       |
|    total_timesteps        | 10368    |
| train/                    |          |
|    explained_variance     | -4.82    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00478  |
|    learning_rate          | 0.001    |
|    n_updates              | 80       |
|    policy_objective       | 0.0635   |
|    value_loss             | 1.03e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 36.6     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 677      |
|    iterations             | 82       |
|    time_elapsed           | 15       |
|    total_timesteps        | 10496    |
| train/                    |          |
|    explained_variance     | -29.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00314  |
|    learning_rate          | 0.001    |
|    n_updates              | 81       |
|    policy_objective       | 0.0581   |
|    value_loss             | 1.76e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 37.6     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 677      |
|    iterations             | 83       |
|    time_elapsed           | 15       |
|    total_timesteps        | 10624    |
| train/                    |          |
|    explained_variance     | -9.52    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00604  |
|    learning_rate          | 0.001    |
|    n_updates              | 82       |
|    policy_objective       | 0.0408   |
|    value_loss             | 8.05e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 36.9     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 678      |
|    iterations             | 84       |
|    time_elapsed           | 15       |
|    total_timesteps        | 10752    |
| train/                    |          |
|    explained_variance     | -13.6    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0033   |
|    learning_rate          | 0.001    |
|    n_updates              | 83       |
|    policy_objective       | 0.0378   |
|    value_loss             | 4.14e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 36.8     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 678      |
|    iterations             | 85       |
|    time_elapsed           | 16       |
|    total_timesteps        | 10880    |
| train/                    |          |
|    explained_variance     | -12.6    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00671  |
|    learning_rate          | 0.001    |
|    n_updates              | 84       |
|    policy_objective       | 0.0639   |
|    value_loss             | 5.26e-08 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 36.6     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 678      |
|    iterations             | 86       |
|    time_elapsed           | 16       |
|    total_timesteps        | 11008    |
| train/                    |          |
|    explained_variance     | -59.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00384  |
|    learning_rate          | 0.001    |
|    n_updates              | 85       |
|    policy_objective       | 0.0802   |
|    value_loss             | 8.18e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 37.1     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 678      |
|    iterations             | 87       |
|    time_elapsed           | 16       |
|    total_timesteps        | 11136    |
| train/                    |          |
|    explained_variance     | -47.6    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00202  |
|    learning_rate          | 0.001    |
|    n_updates              | 86       |
|    policy_objective       | 0.0687   |
|    value_loss             | 2.12e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 38       |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 679      |
|    iterations             | 88       |
|    time_elapsed           | 16       |
|    total_timesteps        | 11264    |
| train/                    |          |
|    explained_variance     | -2.01    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00526  |
|    learning_rate          | 0.001    |
|    n_updates              | 87       |
|    policy_objective       | 0.0548   |
|    value_loss             | 3.75e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 38.1     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 679      |
|    iterations             | 89       |
|    time_elapsed           | 16       |
|    total_timesteps        | 11392    |
| train/                    |          |
|    explained_variance     | -7.74    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00679  |
|    learning_rate          | 0.001    |
|    n_updates              | 88       |
|    policy_objective       | 0.0708   |
|    value_loss             | 2.04e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 37.5     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 679      |
|    iterations             | 90       |
|    time_elapsed           | 16       |
|    total_timesteps        | 11520    |
| train/                    |          |
|    explained_variance     | -10.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00327  |
|    learning_rate          | 0.001    |
|    n_updates              | 89       |
|    policy_objective       | 0.0714   |
|    value_loss             | 3.31e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 37.9     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 679      |
|    iterations             | 91       |
|    time_elapsed           | 17       |
|    total_timesteps        | 11648    |
| train/                    |          |
|    explained_variance     | -8.62    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00555  |
|    learning_rate          | 0.001    |
|    n_updates              | 90       |
|    policy_objective       | 0.0323   |
|    value_loss             | 1.19e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 38.2     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 680      |
|    iterations             | 92       |
|    time_elapsed           | 17       |
|    total_timesteps        | 11776    |
| train/                    |          |
|    explained_variance     | -94.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00301  |
|    learning_rate          | 0.001    |
|    n_updates              | 91       |
|    policy_objective       | 0.0576   |
|    value_loss             | 8.37e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 37.6     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 680      |
|    iterations             | 93       |
|    time_elapsed           | 17       |
|    total_timesteps        | 11904    |
| train/                    |          |
|    explained_variance     | -1       |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00544  |
|    learning_rate          | 0.001    |
|    n_updates              | 92       |
|    policy_objective       | 0.0755   |
|    value_loss             | 8.63e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 37.6     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 680      |
|    iterations             | 94       |
|    time_elapsed           | 17       |
|    total_timesteps        | 12032    |
| train/                    |          |
|    explained_variance     | -67      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0056   |
|    learning_rate          | 0.001    |
|    n_updates              | 93       |
|    policy_objective       | 0.0742   |
|    value_loss             | 5.38e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 36.9     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 681      |
|    iterations             | 95       |
|    time_elapsed           | 17       |
|    total_timesteps        | 12160    |
| train/                    |          |
|    explained_variance     | -7.59    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00494  |
|    learning_rate          | 0.001    |
|    n_updates              | 94       |
|    policy_objective       | 0.0622   |
|    value_loss             | 9.5e-07  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 37.5     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 681      |
|    iterations             | 96       |
|    time_elapsed           | 18       |
|    total_timesteps        | 12288    |
| train/                    |          |
|    explained_variance     | -9.64    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00634  |
|    learning_rate          | 0.001    |
|    n_updates              | 95       |
|    policy_objective       | 0.0768   |
|    value_loss             | 3.71e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 37.9     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 681      |
|    iterations             | 97       |
|    time_elapsed           | 18       |
|    total_timesteps        | 12416    |
| train/                    |          |
|    explained_variance     | -0.235   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00704  |
|    learning_rate          | 0.001    |
|    n_updates              | 96       |
|    policy_objective       | 0.0712   |
|    value_loss             | 5.09e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 37.8     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 681      |
|    iterations             | 98       |
|    time_elapsed           | 18       |
|    total_timesteps        | 12544    |
| train/                    |          |
|    explained_variance     | -20      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00426  |
|    learning_rate          | 0.001    |
|    n_updates              | 97       |
|    policy_objective       | 0.052    |
|    value_loss             | 2.28e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 38.7     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 682      |
|    iterations             | 99       |
|    time_elapsed           | 18       |
|    total_timesteps        | 12672    |
| train/                    |          |
|    explained_variance     | -28.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00212  |
|    learning_rate          | 0.001    |
|    n_updates              | 98       |
|    policy_objective       | 0.0779   |
|    value_loss             | 0.000272 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 38.4     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 682      |
|    iterations             | 100      |
|    time_elapsed           | 18       |
|    total_timesteps        | 12800    |
| train/                    |          |
|    explained_variance     | -10.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00838  |
|    learning_rate          | 0.001    |
|    n_updates              | 99       |
|    policy_objective       | 0.047    |
|    value_loss             | 3.17e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 37.9     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 682      |
|    iterations             | 101      |
|    time_elapsed           | 18       |
|    total_timesteps        | 12928    |
| train/                    |          |
|    explained_variance     | -4.26    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00481  |
|    learning_rate          | 0.001    |
|    n_updates              | 100      |
|    policy_objective       | 0.0722   |
|    value_loss             | 1.61e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 38.5     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 681      |
|    iterations             | 102      |
|    time_elapsed           | 19       |
|    total_timesteps        | 13056    |
| train/                    |          |
|    explained_variance     | -16.7    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00476  |
|    learning_rate          | 0.001    |
|    n_updates              | 101      |
|    policy_objective       | 0.0406   |
|    value_loss             | 1.84e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 39.1     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 682      |
|    iterations             | 103      |
|    time_elapsed           | 19       |
|    total_timesteps        | 13184    |
| train/                    |          |
|    explained_variance     | -3.1     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00445  |
|    learning_rate          | 0.001    |
|    n_updates              | 102      |
|    policy_objective       | 0.0598   |
|    value_loss             | 5.97e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 40.2     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 682      |
|    iterations             | 104      |
|    time_elapsed           | 19       |
|    total_timesteps        | 13312    |
| train/                    |          |
|    explained_variance     | -22.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00311  |
|    learning_rate          | 0.001    |
|    n_updates              | 103      |
|    policy_objective       | 0.0616   |
|    value_loss             | 2.08e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 39.8     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 682      |
|    iterations             | 105      |
|    time_elapsed           | 19       |
|    total_timesteps        | 13440    |
| train/                    |          |
|    explained_variance     | -9.76    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00275  |
|    learning_rate          | 0.001    |
|    n_updates              | 104      |
|    policy_objective       | 0.0637   |
|    value_loss             | 1.69e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 38.9     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 682      |
|    iterations             | 106      |
|    time_elapsed           | 19       |
|    total_timesteps        | 13568    |
| train/                    |          |
|    explained_variance     | -54.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00522  |
|    learning_rate          | 0.001    |
|    n_updates              | 105      |
|    policy_objective       | 0.0182   |
|    value_loss             | 4.45e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 37       |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 682      |
|    iterations             | 107      |
|    time_elapsed           | 20       |
|    total_timesteps        | 13696    |
| train/                    |          |
|    explained_variance     | -15.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00515  |
|    learning_rate          | 0.001    |
|    n_updates              | 106      |
|    policy_objective       | 0.0968   |
|    value_loss             | 2.23e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 36.9     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 682      |
|    iterations             | 108      |
|    time_elapsed           | 20       |
|    total_timesteps        | 13824    |
| train/                    |          |
|    explained_variance     | -8.32    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00292  |
|    learning_rate          | 0.001    |
|    n_updates              | 107      |
|    policy_objective       | 0.0558   |
|    value_loss             | 1.35e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 37.8     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 682      |
|    iterations             | 109      |
|    time_elapsed           | 20       |
|    total_timesteps        | 13952    |
| train/                    |          |
|    explained_variance     | -6.25    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00471  |
|    learning_rate          | 0.001    |
|    n_updates              | 108      |
|    policy_objective       | 0.0718   |
|    value_loss             | 1.92e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 37.6     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 682      |
|    iterations             | 110      |
|    time_elapsed           | 20       |
|    total_timesteps        | 14080    |
| train/                    |          |
|    explained_variance     | -6.35    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00501  |
|    learning_rate          | 0.001    |
|    n_updates              | 109      |
|    policy_objective       | 0.0628   |
|    value_loss             | 7.8e-07  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 37.6     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 682      |
|    iterations             | 111      |
|    time_elapsed           | 20       |
|    total_timesteps        | 14208    |
| train/                    |          |
|    explained_variance     | -64.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00363  |
|    learning_rate          | 0.001    |
|    n_updates              | 110      |
|    policy_objective       | 0.0979   |
|    value_loss             | 1.21e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 36.7     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 682      |
|    iterations             | 112      |
|    time_elapsed           | 20       |
|    total_timesteps        | 14336    |
| train/                    |          |
|    explained_variance     | -22.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00608  |
|    learning_rate          | 0.001    |
|    n_updates              | 111      |
|    policy_objective       | 0.227    |
|    value_loss             | 3.49e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 36.9     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 683      |
|    iterations             | 113      |
|    time_elapsed           | 21       |
|    total_timesteps        | 14464    |
| train/                    |          |
|    explained_variance     | -24.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00578  |
|    learning_rate          | 0.001    |
|    n_updates              | 112      |
|    policy_objective       | 0.0589   |
|    value_loss             | 1.24e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 37       |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 683      |
|    iterations             | 114      |
|    time_elapsed           | 21       |
|    total_timesteps        | 14592    |
| train/                    |          |
|    explained_variance     | -38.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00491  |
|    learning_rate          | 0.001    |
|    n_updates              | 113      |
|    policy_objective       | 0.0515   |
|    value_loss             | 4.12e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 36.8     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 683      |
|    iterations             | 115      |
|    time_elapsed           | 21       |
|    total_timesteps        | 14720    |
| train/                    |          |
|    explained_variance     | -41.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00593  |
|    learning_rate          | 0.001    |
|    n_updates              | 114      |
|    policy_objective       | 0.052    |
|    value_loss             | 3.05e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 36.9     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 683      |
|    iterations             | 116      |
|    time_elapsed           | 21       |
|    total_timesteps        | 14848    |
| train/                    |          |
|    explained_variance     | -11.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00794  |
|    learning_rate          | 0.001    |
|    n_updates              | 115      |
|    policy_objective       | 0.0646   |
|    value_loss             | 3.31e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 36.6     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 683      |
|    iterations             | 117      |
|    time_elapsed           | 21       |
|    total_timesteps        | 14976    |
| train/                    |          |
|    explained_variance     | -7.14    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00736  |
|    learning_rate          | 0.001    |
|    n_updates              | 116      |
|    policy_objective       | 0.0803   |
|    value_loss             | 2.88e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 37.2     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 683      |
|    iterations             | 118      |
|    time_elapsed           | 22       |
|    total_timesteps        | 15104    |
| train/                    |          |
|    explained_variance     | -11      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00528  |
|    learning_rate          | 0.001    |
|    n_updates              | 117      |
|    policy_objective       | 0.0944   |
|    value_loss             | 6.36e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 37.4     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 683      |
|    iterations             | 119      |
|    time_elapsed           | 22       |
|    total_timesteps        | 15232    |
| train/                    |          |
|    explained_variance     | -14.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00598  |
|    learning_rate          | 0.001    |
|    n_updates              | 118      |
|    policy_objective       | 0.0694   |
|    value_loss             | 1.11e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 36.7     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 683      |
|    iterations             | 120      |
|    time_elapsed           | 22       |
|    total_timesteps        | 15360    |
| train/                    |          |
|    explained_variance     | -1.02    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00548  |
|    learning_rate          | 0.001    |
|    n_updates              | 119      |
|    policy_objective       | 0.0579   |
|    value_loss             | 1.57e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 36.3     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 683      |
|    iterations             | 121      |
|    time_elapsed           | 22       |
|    total_timesteps        | 15488    |
| train/                    |          |
|    explained_variance     | -26.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00367  |
|    learning_rate          | 0.001    |
|    n_updates              | 120      |
|    policy_objective       | 0.0666   |
|    value_loss             | 5.39e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 36       |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 683      |
|    iterations             | 122      |
|    time_elapsed           | 22       |
|    total_timesteps        | 15616    |
| train/                    |          |
|    explained_variance     | -97.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00469  |
|    learning_rate          | 0.001    |
|    n_updates              | 121      |
|    policy_objective       | 0.0424   |
|    value_loss             | 2.14e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 35.6     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 684      |
|    iterations             | 123      |
|    time_elapsed           | 23       |
|    total_timesteps        | 15744    |
| train/                    |          |
|    explained_variance     | -11.7    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00548  |
|    learning_rate          | 0.001    |
|    n_updates              | 122      |
|    policy_objective       | 0.0393   |
|    value_loss             | 9.61e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 34.9     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 684      |
|    iterations             | 124      |
|    time_elapsed           | 23       |
|    total_timesteps        | 15872    |
| train/                    |          |
|    explained_variance     | -20.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00657  |
|    learning_rate          | 0.001    |
|    n_updates              | 123      |
|    policy_objective       | 0.0627   |
|    value_loss             | 3.5e-07  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 34.3     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 684      |
|    iterations             | 125      |
|    time_elapsed           | 23       |
|    total_timesteps        | 16000    |
| train/                    |          |
|    explained_variance     | -22.7    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00412  |
|    learning_rate          | 0.001    |
|    n_updates              | 124      |
|    policy_objective       | 0.053    |
|    value_loss             | 5.56e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 34.2     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 684      |
|    iterations             | 126      |
|    time_elapsed           | 23       |
|    total_timesteps        | 16128    |
| train/                    |          |
|    explained_variance     | -17.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0062   |
|    learning_rate          | 0.001    |
|    n_updates              | 125      |
|    policy_objective       | 0.0343   |
|    value_loss             | 1.55e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 33.7     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 684      |
|    iterations             | 127      |
|    time_elapsed           | 23       |
|    total_timesteps        | 16256    |
| train/                    |          |
|    explained_variance     | -2.65    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00545  |
|    learning_rate          | 0.001    |
|    n_updates              | 126      |
|    policy_objective       | 0.1      |
|    value_loss             | 6.15e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 33       |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 684      |
|    iterations             | 128      |
|    time_elapsed           | 23       |
|    total_timesteps        | 16384    |
| train/                    |          |
|    explained_variance     | -21.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00478  |
|    learning_rate          | 0.001    |
|    n_updates              | 127      |
|    policy_objective       | 0.0461   |
|    value_loss             | 1.79e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 32.6     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 684      |
|    iterations             | 129      |
|    time_elapsed           | 24       |
|    total_timesteps        | 16512    |
| train/                    |          |
|    explained_variance     | -1.83    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00737  |
|    learning_rate          | 0.001    |
|    n_updates              | 128      |
|    policy_objective       | 0.0514   |
|    value_loss             | 1.95e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 33       |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 685      |
|    iterations             | 130      |
|    time_elapsed           | 24       |
|    total_timesteps        | 16640    |
| train/                    |          |
|    explained_variance     | -52.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00697  |
|    learning_rate          | 0.001    |
|    n_updates              | 129      |
|    policy_objective       | 0.04     |
|    value_loss             | 4.29e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 32.9     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 685      |
|    iterations             | 131      |
|    time_elapsed           | 24       |
|    total_timesteps        | 16768    |
| train/                    |          |
|    explained_variance     | -0.489   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00622  |
|    learning_rate          | 0.001    |
|    n_updates              | 130      |
|    policy_objective       | 0.0406   |
|    value_loss             | 8.09e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 33.1     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 684      |
|    iterations             | 132      |
|    time_elapsed           | 24       |
|    total_timesteps        | 16896    |
| train/                    |          |
|    explained_variance     | -23      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.000851 |
|    learning_rate          | 0.001    |
|    n_updates              | 131      |
|    policy_objective       | 0.0792   |
|    value_loss             | 1.43e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 33.3     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 684      |
|    iterations             | 133      |
|    time_elapsed           | 24       |
|    total_timesteps        | 17024    |
| train/                    |          |
|    explained_variance     | -9.7     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00524  |
|    learning_rate          | 0.001    |
|    n_updates              | 132      |
|    policy_objective       | 0.0869   |
|    value_loss             | 1.29e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 33.3     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 685      |
|    iterations             | 134      |
|    time_elapsed           | 25       |
|    total_timesteps        | 17152    |
| train/                    |          |
|    explained_variance     | -13.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00213  |
|    learning_rate          | 0.001    |
|    n_updates              | 133      |
|    policy_objective       | 0.0361   |
|    value_loss             | 5.88e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 31.4     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 685      |
|    iterations             | 135      |
|    time_elapsed           | 25       |
|    total_timesteps        | 17280    |
| train/                    |          |
|    explained_variance     | -43.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00755  |
|    learning_rate          | 0.001    |
|    n_updates              | 134      |
|    policy_objective       | 0.0611   |
|    value_loss             | 2.3e-05  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 32.4     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 685      |
|    iterations             | 136      |
|    time_elapsed           | 25       |
|    total_timesteps        | 17408    |
| train/                    |          |
|    explained_variance     | -32.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00745  |
|    learning_rate          | 0.001    |
|    n_updates              | 135      |
|    policy_objective       | 0.0639   |
|    value_loss             | 2.08e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 32.5     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 685      |
|    iterations             | 137      |
|    time_elapsed           | 25       |
|    total_timesteps        | 17536    |
| train/                    |          |
|    explained_variance     | -34.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00819  |
|    learning_rate          | 0.001    |
|    n_updates              | 136      |
|    policy_objective       | 0.045    |
|    value_loss             | 3.45e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 33.4     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 685      |
|    iterations             | 138      |
|    time_elapsed           | 25       |
|    total_timesteps        | 17664    |
| train/                    |          |
|    explained_variance     | -2.35    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0042   |
|    learning_rate          | 0.001    |
|    n_updates              | 137      |
|    policy_objective       | 0.068    |
|    value_loss             | 1.2e-05  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 32.3     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 685      |
|    iterations             | 139      |
|    time_elapsed           | 25       |
|    total_timesteps        | 17792    |
| train/                    |          |
|    explained_variance     | -30.6    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00686  |
|    learning_rate          | 0.001    |
|    n_updates              | 138      |
|    policy_objective       | 0.0459   |
|    value_loss             | 6.45e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 33       |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 684      |
|    iterations             | 140      |
|    time_elapsed           | 26       |
|    total_timesteps        | 17920    |
| train/                    |          |
|    explained_variance     | -9.7     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00679  |
|    learning_rate          | 0.001    |
|    n_updates              | 139      |
|    policy_objective       | 0.0572   |
|    value_loss             | 8.57e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 33.1     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 684      |
|    iterations             | 141      |
|    time_elapsed           | 26       |
|    total_timesteps        | 18048    |
| train/                    |          |
|    explained_variance     | -8.72    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0048   |
|    learning_rate          | 0.001    |
|    n_updates              | 140      |
|    policy_objective       | 0.113    |
|    value_loss             | 1.21e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 33.6     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 684      |
|    iterations             | 142      |
|    time_elapsed           | 26       |
|    total_timesteps        | 18176    |
| train/                    |          |
|    explained_variance     | -16.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00376  |
|    learning_rate          | 0.001    |
|    n_updates              | 141      |
|    policy_objective       | 0.0653   |
|    value_loss             | 1.13e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 32.7     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 684      |
|    iterations             | 143      |
|    time_elapsed           | 26       |
|    total_timesteps        | 18304    |
| train/                    |          |
|    explained_variance     | -74.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00677  |
|    learning_rate          | 0.001    |
|    n_updates              | 142      |
|    policy_objective       | 0.0539   |
|    value_loss             | 3.9e-08  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 33       |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 685      |
|    iterations             | 144      |
|    time_elapsed           | 26       |
|    total_timesteps        | 18432    |
| train/                    |          |
|    explained_variance     | -41.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00649  |
|    learning_rate          | 0.001    |
|    n_updates              | 143      |
|    policy_objective       | 0.069    |
|    value_loss             | 5.95e-09 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 33.5     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 685      |
|    iterations             | 145      |
|    time_elapsed           | 27       |
|    total_timesteps        | 18560    |
| train/                    |          |
|    explained_variance     | -64.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00395  |
|    learning_rate          | 0.001    |
|    n_updates              | 144      |
|    policy_objective       | 0.0494   |
|    value_loss             | 0.000124 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 34       |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 686      |
|    iterations             | 146      |
|    time_elapsed           | 27       |
|    total_timesteps        | 18688    |
| train/                    |          |
|    explained_variance     | -2.61    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00458  |
|    learning_rate          | 0.001    |
|    n_updates              | 145      |
|    policy_objective       | 0.0677   |
|    value_loss             | 9.46e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 34.7     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 686      |
|    iterations             | 147      |
|    time_elapsed           | 27       |
|    total_timesteps        | 18816    |
| train/                    |          |
|    explained_variance     | -38.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0033   |
|    learning_rate          | 0.001    |
|    n_updates              | 146      |
|    policy_objective       | 0.113    |
|    value_loss             | 1.98e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 34.9     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 686      |
|    iterations             | 148      |
|    time_elapsed           | 27       |
|    total_timesteps        | 18944    |
| train/                    |          |
|    explained_variance     | -3.79    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00655  |
|    learning_rate          | 0.001    |
|    n_updates              | 147      |
|    policy_objective       | 0.0564   |
|    value_loss             | 2.2e-06  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 35.5     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 687      |
|    iterations             | 149      |
|    time_elapsed           | 27       |
|    total_timesteps        | 19072    |
| train/                    |          |
|    explained_variance     | -8.03    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00477  |
|    learning_rate          | 0.001    |
|    n_updates              | 148      |
|    policy_objective       | 0.0842   |
|    value_loss             | 6.75e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 35.8     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 687      |
|    iterations             | 150      |
|    time_elapsed           | 27       |
|    total_timesteps        | 19200    |
| train/                    |          |
|    explained_variance     | -15.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00468  |
|    learning_rate          | 0.001    |
|    n_updates              | 149      |
|    policy_objective       | 0.0506   |
|    value_loss             | 2.97e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 35.4     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 687      |
|    iterations             | 151      |
|    time_elapsed           | 28       |
|    total_timesteps        | 19328    |
| train/                    |          |
|    explained_variance     | -72.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00415  |
|    learning_rate          | 0.001    |
|    n_updates              | 150      |
|    policy_objective       | 0.317    |
|    value_loss             | 3e-06    |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 35.7     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 687      |
|    iterations             | 152      |
|    time_elapsed           | 28       |
|    total_timesteps        | 19456    |
| train/                    |          |
|    explained_variance     | -34.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.007    |
|    learning_rate          | 0.001    |
|    n_updates              | 151      |
|    policy_objective       | 0.0901   |
|    value_loss             | 2.32e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 36       |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 688      |
|    iterations             | 153      |
|    time_elapsed           | 28       |
|    total_timesteps        | 19584    |
| train/                    |          |
|    explained_variance     | -5.25    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00499  |
|    learning_rate          | 0.001    |
|    n_updates              | 152      |
|    policy_objective       | 0.101    |
|    value_loss             | 1.77e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 35.9     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 688      |
|    iterations             | 154      |
|    time_elapsed           | 28       |
|    total_timesteps        | 19712    |
| train/                    |          |
|    explained_variance     | -4.61    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00671  |
|    learning_rate          | 0.001    |
|    n_updates              | 153      |
|    policy_objective       | 0.0795   |
|    value_loss             | 1.47e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 35.6     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 688      |
|    iterations             | 155      |
|    time_elapsed           | 28       |
|    total_timesteps        | 19840    |
| train/                    |          |
|    explained_variance     | -29.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0045   |
|    learning_rate          | 0.001    |
|    n_updates              | 154      |
|    policy_objective       | 0.0464   |
|    value_loss             | 4.49e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 35.7     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 156      |
|    time_elapsed           | 28       |
|    total_timesteps        | 19968    |
| train/                    |          |
|    explained_variance     | -20.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00622  |
|    learning_rate          | 0.001    |
|    n_updates              | 155      |
|    policy_objective       | 0.0707   |
|    value_loss             | 4.29e-08 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 34.9     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 157      |
|    time_elapsed           | 29       |
|    total_timesteps        | 20096    |
| train/                    |          |
|    explained_variance     | -16.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00602  |
|    learning_rate          | 0.001    |
|    n_updates              | 156      |
|    policy_objective       | 0.0432   |
|    value_loss             | 1.2e-08  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 34.3     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 158      |
|    time_elapsed           | 29       |
|    total_timesteps        | 20224    |
| train/                    |          |
|    explained_variance     | -271     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00259  |
|    learning_rate          | 0.001    |
|    n_updates              | 157      |
|    policy_objective       | 0.0578   |
|    value_loss             | 5.6e-07  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 34.4     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 690      |
|    iterations             | 159      |
|    time_elapsed           | 29       |
|    total_timesteps        | 20352    |
| train/                    |          |
|    explained_variance     | -2.47    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00367  |
|    learning_rate          | 0.001    |
|    n_updates              | 158      |
|    policy_objective       | 0.0603   |
|    value_loss             | 1.29e-08 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 34       |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 690      |
|    iterations             | 160      |
|    time_elapsed           | 29       |
|    total_timesteps        | 20480    |
| train/                    |          |
|    explained_variance     | -22.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00546  |
|    learning_rate          | 0.001    |
|    n_updates              | 159      |
|    policy_objective       | 0.0461   |
|    value_loss             | 1.46e-08 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 33.8     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 690      |
|    iterations             | 161      |
|    time_elapsed           | 29       |
|    total_timesteps        | 20608    |
| train/                    |          |
|    explained_variance     | -21      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00308  |
|    learning_rate          | 0.001    |
|    n_updates              | 160      |
|    policy_objective       | 0.0527   |
|    value_loss             | 6.1e-08  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 34.7     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 691      |
|    iterations             | 162      |
|    time_elapsed           | 29       |
|    total_timesteps        | 20736    |
| train/                    |          |
|    explained_variance     | -47.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00539  |
|    learning_rate          | 0.001    |
|    n_updates              | 161      |
|    policy_objective       | 0.116    |
|    value_loss             | 2.23e-08 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 33.8     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 691      |
|    iterations             | 163      |
|    time_elapsed           | 30       |
|    total_timesteps        | 20864    |
| train/                    |          |
|    explained_variance     | -18.6    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00524  |
|    learning_rate          | 0.001    |
|    n_updates              | 162      |
|    policy_objective       | 0.05     |
|    value_loss             | 7.09e-09 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 33.9     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 692      |
|    iterations             | 164      |
|    time_elapsed           | 30       |
|    total_timesteps        | 20992    |
| train/                    |          |
|    explained_variance     | -15.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00521  |
|    learning_rate          | 0.001    |
|    n_updates              | 163      |
|    policy_objective       | 0.0761   |
|    value_loss             | 2.65e-08 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 33.9     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 692      |
|    iterations             | 165      |
|    time_elapsed           | 30       |
|    total_timesteps        | 21120    |
| train/                    |          |
|    explained_variance     | -14.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00691  |
|    learning_rate          | 0.001    |
|    n_updates              | 164      |
|    policy_objective       | 0.0766   |
|    value_loss             | 5.64e-08 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 34.4     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 692      |
|    iterations             | 166      |
|    time_elapsed           | 30       |
|    total_timesteps        | 21248    |
| train/                    |          |
|    explained_variance     | -1.89    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00558  |
|    learning_rate          | 0.001    |
|    n_updates              | 165      |
|    policy_objective       | 0.069    |
|    value_loss             | 1.86e-08 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 34.6     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 692      |
|    iterations             | 167      |
|    time_elapsed           | 30       |
|    total_timesteps        | 21376    |
| train/                    |          |
|    explained_variance     | -8.73    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00661  |
|    learning_rate          | 0.001    |
|    n_updates              | 166      |
|    policy_objective       | 0.047    |
|    value_loss             | 1.63e-08 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 33.9     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 692      |
|    iterations             | 168      |
|    time_elapsed           | 31       |
|    total_timesteps        | 21504    |
| train/                    |          |
|    explained_variance     | -4.39    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00609  |
|    learning_rate          | 0.001    |
|    n_updates              | 167      |
|    policy_objective       | 0.063    |
|    value_loss             | 1.26e-08 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 34.1     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 693      |
|    iterations             | 169      |
|    time_elapsed           | 31       |
|    total_timesteps        | 21632    |
| train/                    |          |
|    explained_variance     | -0.458   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00573  |
|    learning_rate          | 0.001    |
|    n_updates              | 168      |
|    policy_objective       | 0.0655   |
|    value_loss             | 1.55e-08 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 34.5     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 693      |
|    iterations             | 170      |
|    time_elapsed           | 31       |
|    total_timesteps        | 21760    |
| train/                    |          |
|    explained_variance     | -9.53    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00543  |
|    learning_rate          | 0.001    |
|    n_updates              | 169      |
|    policy_objective       | 0.0509   |
|    value_loss             | 2.25e-09 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 34.2     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 693      |
|    iterations             | 171      |
|    time_elapsed           | 31       |
|    total_timesteps        | 21888    |
| train/                    |          |
|    explained_variance     | -2.84    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00585  |
|    learning_rate          | 0.001    |
|    n_updates              | 170      |
|    policy_objective       | 0.0536   |
|    value_loss             | 5.71e-10 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 33.4     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 693      |
|    iterations             | 172      |
|    time_elapsed           | 31       |
|    total_timesteps        | 22016    |
| train/                    |          |
|    explained_variance     | -40      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00137  |
|    learning_rate          | 0.001    |
|    n_updates              | 171      |
|    policy_objective       | 0.0755   |
|    value_loss             | 4.32e-09 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 32.1     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 694      |
|    iterations             | 173      |
|    time_elapsed           | 31       |
|    total_timesteps        | 22144    |
| train/                    |          |
|    explained_variance     | -30      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00503  |
|    learning_rate          | 0.001    |
|    n_updates              | 172      |
|    policy_objective       | 0.0338   |
|    value_loss             | 2.93e-09 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 32.8     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 694      |
|    iterations             | 174      |
|    time_elapsed           | 32       |
|    total_timesteps        | 22272    |
| train/                    |          |
|    explained_variance     | -15.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00695  |
|    learning_rate          | 0.001    |
|    n_updates              | 173      |
|    policy_objective       | 0.059    |
|    value_loss             | 1.96e-09 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 32.9     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 694      |
|    iterations             | 175      |
|    time_elapsed           | 32       |
|    total_timesteps        | 22400    |
| train/                    |          |
|    explained_variance     | -98.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00236  |
|    learning_rate          | 0.001    |
|    n_updates              | 174      |
|    policy_objective       | 0.0308   |
|    value_loss             | 5.36e-09 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 33.7     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 694      |
|    iterations             | 176      |
|    time_elapsed           | 32       |
|    total_timesteps        | 22528    |
| train/                    |          |
|    explained_variance     | -9.91    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00498  |
|    learning_rate          | 0.001    |
|    n_updates              | 175      |
|    policy_objective       | 0.0466   |
|    value_loss             | 1.71e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 33.9     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 695      |
|    iterations             | 177      |
|    time_elapsed           | 32       |
|    total_timesteps        | 22656    |
| train/                    |          |
|    explained_variance     | -10.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00733  |
|    learning_rate          | 0.001    |
|    n_updates              | 176      |
|    policy_objective       | 0.0753   |
|    value_loss             | 2.61e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 33.7     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 695      |
|    iterations             | 178      |
|    time_elapsed           | 32       |
|    total_timesteps        | 22784    |
| train/                    |          |
|    explained_variance     | -25.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0057   |
|    learning_rate          | 0.001    |
|    n_updates              | 177      |
|    policy_objective       | 0.0347   |
|    value_loss             | 7.3e-08  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 34.4     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 695      |
|    iterations             | 179      |
|    time_elapsed           | 32       |
|    total_timesteps        | 22912    |
| train/                    |          |
|    explained_variance     | -38.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00704  |
|    learning_rate          | 0.001    |
|    n_updates              | 178      |
|    policy_objective       | 0.0584   |
|    value_loss             | 2.34e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 34.5     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 695      |
|    iterations             | 180      |
|    time_elapsed           | 33       |
|    total_timesteps        | 23040    |
| train/                    |          |
|    explained_variance     | -12.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00471  |
|    learning_rate          | 0.001    |
|    n_updates              | 179      |
|    policy_objective       | 0.0857   |
|    value_loss             | 3.77e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 34.8     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 696      |
|    iterations             | 181      |
|    time_elapsed           | 33       |
|    total_timesteps        | 23168    |
| train/                    |          |
|    explained_variance     | -18.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00476  |
|    learning_rate          | 0.001    |
|    n_updates              | 180      |
|    policy_objective       | 0.0571   |
|    value_loss             | 2.16e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 35.3     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 696      |
|    iterations             | 182      |
|    time_elapsed           | 33       |
|    total_timesteps        | 23296    |
| train/                    |          |
|    explained_variance     | -19.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0074   |
|    learning_rate          | 0.001    |
|    n_updates              | 181      |
|    policy_objective       | 0.0686   |
|    value_loss             | 7.37e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 36       |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 696      |
|    iterations             | 183      |
|    time_elapsed           | 33       |
|    total_timesteps        | 23424    |
| train/                    |          |
|    explained_variance     | -5.88    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00931  |
|    learning_rate          | 0.001    |
|    n_updates              | 182      |
|    policy_objective       | 0.091    |
|    value_loss             | 6.31e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 35.8     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 696      |
|    iterations             | 184      |
|    time_elapsed           | 33       |
|    total_timesteps        | 23552    |
| train/                    |          |
|    explained_variance     | -2.61    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00678  |
|    learning_rate          | 0.001    |
|    n_updates              | 183      |
|    policy_objective       | 0.0452   |
|    value_loss             | 9.86e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 35.9     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 696      |
|    iterations             | 185      |
|    time_elapsed           | 33       |
|    total_timesteps        | 23680    |
| train/                    |          |
|    explained_variance     | -14.7    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00712  |
|    learning_rate          | 0.001    |
|    n_updates              | 184      |
|    policy_objective       | 0.0531   |
|    value_loss             | 2.17e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 35.9     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 697      |
|    iterations             | 186      |
|    time_elapsed           | 34       |
|    total_timesteps        | 23808    |
| train/                    |          |
|    explained_variance     | -21      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00578  |
|    learning_rate          | 0.001    |
|    n_updates              | 185      |
|    policy_objective       | 0.0617   |
|    value_loss             | 6.12e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 35.4     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 697      |
|    iterations             | 187      |
|    time_elapsed           | 34       |
|    total_timesteps        | 23936    |
| train/                    |          |
|    explained_variance     | -3.17    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00318  |
|    learning_rate          | 0.001    |
|    n_updates              | 186      |
|    policy_objective       | 0.0429   |
|    value_loss             | 7.76e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 36.5     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 697      |
|    iterations             | 188      |
|    time_elapsed           | 34       |
|    total_timesteps        | 24064    |
| train/                    |          |
|    explained_variance     | -21.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00828  |
|    learning_rate          | 0.001    |
|    n_updates              | 187      |
|    policy_objective       | 0.0501   |
|    value_loss             | 8e-07    |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 37       |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 697      |
|    iterations             | 189      |
|    time_elapsed           | 34       |
|    total_timesteps        | 24192    |
| train/                    |          |
|    explained_variance     | -2.68    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00956  |
|    learning_rate          | 0.001    |
|    n_updates              | 188      |
|    policy_objective       | 0.0775   |
|    value_loss             | 3.51e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 37.8     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 697      |
|    iterations             | 190      |
|    time_elapsed           | 34       |
|    total_timesteps        | 24320    |
| train/                    |          |
|    explained_variance     | -5.04    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00619  |
|    learning_rate          | 0.001    |
|    n_updates              | 189      |
|    policy_objective       | 0.0294   |
|    value_loss             | 1.21e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 37.4     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 697      |
|    iterations             | 191      |
|    time_elapsed           | 35       |
|    total_timesteps        | 24448    |
| train/                    |          |
|    explained_variance     | -16.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00676  |
|    learning_rate          | 0.001    |
|    n_updates              | 190      |
|    policy_objective       | 0.0494   |
|    value_loss             | 2.36e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 38.7     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 697      |
|    iterations             | 192      |
|    time_elapsed           | 35       |
|    total_timesteps        | 24576    |
| train/                    |          |
|    explained_variance     | -14.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00614  |
|    learning_rate          | 0.001    |
|    n_updates              | 191      |
|    policy_objective       | 0.0586   |
|    value_loss             | 3.37e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 39       |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 697      |
|    iterations             | 193      |
|    time_elapsed           | 35       |
|    total_timesteps        | 24704    |
| train/                    |          |
|    explained_variance     | -8.1     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0047   |
|    learning_rate          | 0.001    |
|    n_updates              | 192      |
|    policy_objective       | 0.0707   |
|    value_loss             | 1.54e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 39.1     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 697      |
|    iterations             | 194      |
|    time_elapsed           | 35       |
|    total_timesteps        | 24832    |
| train/                    |          |
|    explained_variance     | -26.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00645  |
|    learning_rate          | 0.001    |
|    n_updates              | 193      |
|    policy_objective       | 0.0538   |
|    value_loss             | 6.62e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 39.1     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 698      |
|    iterations             | 195      |
|    time_elapsed           | 35       |
|    total_timesteps        | 24960    |
| train/                    |          |
|    explained_variance     | -9.85    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00575  |
|    learning_rate          | 0.001    |
|    n_updates              | 194      |
|    policy_objective       | 0.041    |
|    value_loss             | 4.01e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 39.1     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 698      |
|    iterations             | 196      |
|    time_elapsed           | 35       |
|    total_timesteps        | 25088    |
| train/                    |          |
|    explained_variance     | -10.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00631  |
|    learning_rate          | 0.001    |
|    n_updates              | 195      |
|    policy_objective       | 0.0657   |
|    value_loss             | 8.4e-06  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 39.6     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 698      |
|    iterations             | 197      |
|    time_elapsed           | 36       |
|    total_timesteps        | 25216    |
| train/                    |          |
|    explained_variance     | -5.67    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00438  |
|    learning_rate          | 0.001    |
|    n_updates              | 196      |
|    policy_objective       | 0.053    |
|    value_loss             | 3.41e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 39.6     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 699      |
|    iterations             | 198      |
|    time_elapsed           | 36       |
|    total_timesteps        | 25344    |
| train/                    |          |
|    explained_variance     | -1.78    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00777  |
|    learning_rate          | 0.001    |
|    n_updates              | 197      |
|    policy_objective       | 0.039    |
|    value_loss             | 8.7e-07  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 40.1     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 699      |
|    iterations             | 199      |
|    time_elapsed           | 36       |
|    total_timesteps        | 25472    |
| train/                    |          |
|    explained_variance     | -13.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00284  |
|    learning_rate          | 0.001    |
|    n_updates              | 198      |
|    policy_objective       | 0.0419   |
|    value_loss             | 9.72e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 40.1     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 699      |
|    iterations             | 200      |
|    time_elapsed           | 36       |
|    total_timesteps        | 25600    |
| train/                    |          |
|    explained_variance     | -7.7     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00912  |
|    learning_rate          | 0.001    |
|    n_updates              | 199      |
|    policy_objective       | 0.0647   |
|    value_loss             | 2.55e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 40.5     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 698      |
|    iterations             | 201      |
|    time_elapsed           | 36       |
|    total_timesteps        | 25728    |
| train/                    |          |
|    explained_variance     | -56.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00724  |
|    learning_rate          | 0.001    |
|    n_updates              | 200      |
|    policy_objective       | 0.0754   |
|    value_loss             | 4.25e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 40.2     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 698      |
|    iterations             | 202      |
|    time_elapsed           | 37       |
|    total_timesteps        | 25856    |
| train/                    |          |
|    explained_variance     | -0.491   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00697  |
|    learning_rate          | 0.001    |
|    n_updates              | 201      |
|    policy_objective       | 0.0722   |
|    value_loss             | 1.55e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 41       |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 698      |
|    iterations             | 203      |
|    time_elapsed           | 37       |
|    total_timesteps        | 25984    |
| train/                    |          |
|    explained_variance     | -3.57    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0061   |
|    learning_rate          | 0.001    |
|    n_updates              | 202      |
|    policy_objective       | 0.0376   |
|    value_loss             | 9.19e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 41.3     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 698      |
|    iterations             | 204      |
|    time_elapsed           | 37       |
|    total_timesteps        | 26112    |
| train/                    |          |
|    explained_variance     | -44.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00426  |
|    learning_rate          | 0.001    |
|    n_updates              | 203      |
|    policy_objective       | 0.376    |
|    value_loss             | 5.07e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 41.5     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 698      |
|    iterations             | 205      |
|    time_elapsed           | 37       |
|    total_timesteps        | 26240    |
| train/                    |          |
|    explained_variance     | -16.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00166  |
|    learning_rate          | 0.001    |
|    n_updates              | 204      |
|    policy_objective       | 0.0887   |
|    value_loss             | 4.99e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 42.3     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 699      |
|    iterations             | 206      |
|    time_elapsed           | 37       |
|    total_timesteps        | 26368    |
| train/                    |          |
|    explained_variance     | -0.456   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00536  |
|    learning_rate          | 0.001    |
|    n_updates              | 205      |
|    policy_objective       | 0.123    |
|    value_loss             | 5.98e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 41.6     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 699      |
|    iterations             | 207      |
|    time_elapsed           | 37       |
|    total_timesteps        | 26496    |
| train/                    |          |
|    explained_variance     | -6.39    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00734  |
|    learning_rate          | 0.001    |
|    n_updates              | 206      |
|    policy_objective       | 0.0506   |
|    value_loss             | 4.92e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 42.3     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 699      |
|    iterations             | 208      |
|    time_elapsed           | 38       |
|    total_timesteps        | 26624    |
| train/                    |          |
|    explained_variance     | -6.84    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00621  |
|    learning_rate          | 0.001    |
|    n_updates              | 207      |
|    policy_objective       | 0.0378   |
|    value_loss             | 3.53e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 41.2     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 699      |
|    iterations             | 209      |
|    time_elapsed           | 38       |
|    total_timesteps        | 26752    |
| train/                    |          |
|    explained_variance     | -14.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00298  |
|    learning_rate          | 0.001    |
|    n_updates              | 208      |
|    policy_objective       | 0.052    |
|    value_loss             | 2.75e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 41       |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 699      |
|    iterations             | 210      |
|    time_elapsed           | 38       |
|    total_timesteps        | 26880    |
| train/                    |          |
|    explained_variance     | -21.6    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00694  |
|    learning_rate          | 0.001    |
|    n_updates              | 209      |
|    policy_objective       | 0.0494   |
|    value_loss             | 6.49e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 40.6     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 699      |
|    iterations             | 211      |
|    time_elapsed           | 38       |
|    total_timesteps        | 27008    |
| train/                    |          |
|    explained_variance     | -12.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00505  |
|    learning_rate          | 0.001    |
|    n_updates              | 210      |
|    policy_objective       | 0.137    |
|    value_loss             | 1.78e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 39.9     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 700      |
|    iterations             | 212      |
|    time_elapsed           | 38       |
|    total_timesteps        | 27136    |
| train/                    |          |
|    explained_variance     | -61.6    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00666  |
|    learning_rate          | 0.001    |
|    n_updates              | 211      |
|    policy_objective       | 0.0492   |
|    value_loss             | 4.2e-08  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 40.3     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 700      |
|    iterations             | 213      |
|    time_elapsed           | 38       |
|    total_timesteps        | 27264    |
| train/                    |          |
|    explained_variance     | -16.6    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00772  |
|    learning_rate          | 0.001    |
|    n_updates              | 212      |
|    policy_objective       | 0.0484   |
|    value_loss             | 1.26e-08 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 39.4     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 700      |
|    iterations             | 214      |
|    time_elapsed           | 39       |
|    total_timesteps        | 27392    |
| train/                    |          |
|    explained_variance     | -2.43    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00785  |
|    learning_rate          | 0.001    |
|    n_updates              | 213      |
|    policy_objective       | 0.0318   |
|    value_loss             | 2.42e-08 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 39.5     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 700      |
|    iterations             | 215      |
|    time_elapsed           | 39       |
|    total_timesteps        | 27520    |
| train/                    |          |
|    explained_variance     | -26.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0031   |
|    learning_rate          | 0.001    |
|    n_updates              | 214      |
|    policy_objective       | 0.0575   |
|    value_loss             | 6.65e-08 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 40       |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 700      |
|    iterations             | 216      |
|    time_elapsed           | 39       |
|    total_timesteps        | 27648    |
| train/                    |          |
|    explained_variance     | -14.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00286  |
|    learning_rate          | 0.001    |
|    n_updates              | 215      |
|    policy_objective       | 0.0813   |
|    value_loss             | 2.67e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 39.9     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 700      |
|    iterations             | 217      |
|    time_elapsed           | 39       |
|    total_timesteps        | 27776    |
| train/                    |          |
|    explained_variance     | -9.85    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00671  |
|    learning_rate          | 0.001    |
|    n_updates              | 216      |
|    policy_objective       | 0.0951   |
|    value_loss             | 4.05e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 40.5     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 700      |
|    iterations             | 218      |
|    time_elapsed           | 39       |
|    total_timesteps        | 27904    |
| train/                    |          |
|    explained_variance     | -4.18    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00601  |
|    learning_rate          | 0.001    |
|    n_updates              | 217      |
|    policy_objective       | 0.0575   |
|    value_loss             | 3.33e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 39.6     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 700      |
|    iterations             | 219      |
|    time_elapsed           | 39       |
|    total_timesteps        | 28032    |
| train/                    |          |
|    explained_variance     | 0.0131   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00556  |
|    learning_rate          | 0.001    |
|    n_updates              | 218      |
|    policy_objective       | 0.0747   |
|    value_loss             | 0.0175   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 39       |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 701      |
|    iterations             | 220      |
|    time_elapsed           | 40       |
|    total_timesteps        | 28160    |
| train/                    |          |
|    explained_variance     | -9.24    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00486  |
|    learning_rate          | 0.001    |
|    n_updates              | 219      |
|    policy_objective       | 0.0569   |
|    value_loss             | 0.00224  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 37.6     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 700      |
|    iterations             | 221      |
|    time_elapsed           | 40       |
|    total_timesteps        | 28288    |
| train/                    |          |
|    explained_variance     | -2.17    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00722  |
|    learning_rate          | 0.001    |
|    n_updates              | 220      |
|    policy_objective       | 0.0556   |
|    value_loss             | 0.000141 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 37.6     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 700      |
|    iterations             | 222      |
|    time_elapsed           | 40       |
|    total_timesteps        | 28416    |
| train/                    |          |
|    explained_variance     | -3.17    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00665  |
|    learning_rate          | 0.001    |
|    n_updates              | 221      |
|    policy_objective       | 0.0424   |
|    value_loss             | 0.000112 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 37.3     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 701      |
|    iterations             | 223      |
|    time_elapsed           | 40       |
|    total_timesteps        | 28544    |
| train/                    |          |
|    explained_variance     | -0.911   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00496  |
|    learning_rate          | 0.001    |
|    n_updates              | 222      |
|    policy_objective       | 0.0428   |
|    value_loss             | 4.02e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 38       |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 701      |
|    iterations             | 224      |
|    time_elapsed           | 40       |
|    total_timesteps        | 28672    |
| train/                    |          |
|    explained_variance     | -6.17    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00662  |
|    learning_rate          | 0.001    |
|    n_updates              | 223      |
|    policy_objective       | 0.0679   |
|    value_loss             | 2.35e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 38.3     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 701      |
|    iterations             | 225      |
|    time_elapsed           | 41       |
|    total_timesteps        | 28800    |
| train/                    |          |
|    explained_variance     | -0.641   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0025   |
|    learning_rate          | 0.001    |
|    n_updates              | 224      |
|    policy_objective       | 0.0749   |
|    value_loss             | 0.000578 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 38       |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 701      |
|    iterations             | 226      |
|    time_elapsed           | 41       |
|    total_timesteps        | 28928    |
| train/                    |          |
|    explained_variance     | -7.1     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00388  |
|    learning_rate          | 0.001    |
|    n_updates              | 225      |
|    policy_objective       | 0.0718   |
|    value_loss             | 5.83e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 38.3     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 701      |
|    iterations             | 227      |
|    time_elapsed           | 41       |
|    total_timesteps        | 29056    |
| train/                    |          |
|    explained_variance     | -0.613   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00262  |
|    learning_rate          | 0.001    |
|    n_updates              | 226      |
|    policy_objective       | 0.0803   |
|    value_loss             | 7.75e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 37.5     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 701      |
|    iterations             | 228      |
|    time_elapsed           | 41       |
|    total_timesteps        | 29184    |
| train/                    |          |
|    explained_variance     | 0.188    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00658  |
|    learning_rate          | 0.001    |
|    n_updates              | 227      |
|    policy_objective       | 0.0542   |
|    value_loss             | 6.61e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 37.4     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 701      |
|    iterations             | 229      |
|    time_elapsed           | 41       |
|    total_timesteps        | 29312    |
| train/                    |          |
|    explained_variance     | -5.51    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00701  |
|    learning_rate          | 0.001    |
|    n_updates              | 228      |
|    policy_objective       | 0.0509   |
|    value_loss             | 0.00388  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 36       |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 702      |
|    iterations             | 230      |
|    time_elapsed           | 41       |
|    total_timesteps        | 29440    |
| train/                    |          |
|    explained_variance     | -1.76    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00709  |
|    learning_rate          | 0.001    |
|    n_updates              | 229      |
|    policy_objective       | 0.0729   |
|    value_loss             | 0.00045  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 36.8     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 702      |
|    iterations             | 231      |
|    time_elapsed           | 42       |
|    total_timesteps        | 29568    |
| train/                    |          |
|    explained_variance     | -1.48    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0048   |
|    learning_rate          | 0.001    |
|    n_updates              | 230      |
|    policy_objective       | 0.0528   |
|    value_loss             | 0.000845 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 36       |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 702      |
|    iterations             | 232      |
|    time_elapsed           | 42       |
|    total_timesteps        | 29696    |
| train/                    |          |
|    explained_variance     | -0.715   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00637  |
|    learning_rate          | 0.001    |
|    n_updates              | 231      |
|    policy_objective       | 0.0557   |
|    value_loss             | 7.11e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 36.5     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 702      |
|    iterations             | 233      |
|    time_elapsed           | 42       |
|    total_timesteps        | 29824    |
| train/                    |          |
|    explained_variance     | -5.7     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00974  |
|    learning_rate          | 0.001    |
|    n_updates              | 232      |
|    policy_objective       | 0.321    |
|    value_loss             | 2.41e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 36       |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 702      |
|    iterations             | 234      |
|    time_elapsed           | 42       |
|    total_timesteps        | 29952    |
| train/                    |          |
|    explained_variance     | -3.45    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00783  |
|    learning_rate          | 0.001    |
|    n_updates              | 233      |
|    policy_objective       | 0.0718   |
|    value_loss             | 1.77e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 36.9     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 702      |
|    iterations             | 235      |
|    time_elapsed           | 42       |
|    total_timesteps        | 30080    |
| train/                    |          |
|    explained_variance     | -0.415   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00356  |
|    learning_rate          | 0.001    |
|    n_updates              | 234      |
|    policy_objective       | 0.0391   |
|    value_loss             | 4.6e-05  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 37.3     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 702      |
|    iterations             | 236      |
|    time_elapsed           | 43       |
|    total_timesteps        | 30208    |
| train/                    |          |
|    explained_variance     | -2.6     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00487  |
|    learning_rate          | 0.001    |
|    n_updates              | 235      |
|    policy_objective       | 0.0507   |
|    value_loss             | 1.29e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 37.2     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 702      |
|    iterations             | 237      |
|    time_elapsed           | 43       |
|    total_timesteps        | 30336    |
| train/                    |          |
|    explained_variance     | 0.19     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00797  |
|    learning_rate          | 0.001    |
|    n_updates              | 236      |
|    policy_objective       | 0.122    |
|    value_loss             | 3.65e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 37.2     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 702      |
|    iterations             | 238      |
|    time_elapsed           | 43       |
|    total_timesteps        | 30464    |
| train/                    |          |
|    explained_variance     | -23.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00131  |
|    learning_rate          | 0.001    |
|    n_updates              | 237      |
|    policy_objective       | 0.0676   |
|    value_loss             | 0.000576 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 38       |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 701      |
|    iterations             | 239      |
|    time_elapsed           | 43       |
|    total_timesteps        | 30592    |
| train/                    |          |
|    explained_variance     | -14.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00403  |
|    learning_rate          | 0.001    |
|    n_updates              | 238      |
|    policy_objective       | 0.0833   |
|    value_loss             | 2.56e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 36.8     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 701      |
|    iterations             | 240      |
|    time_elapsed           | 43       |
|    total_timesteps        | 30720    |
| train/                    |          |
|    explained_variance     | -0.223   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00611  |
|    learning_rate          | 0.001    |
|    n_updates              | 239      |
|    policy_objective       | 0.218    |
|    value_loss             | 0.000113 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 37       |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 701      |
|    iterations             | 241      |
|    time_elapsed           | 44       |
|    total_timesteps        | 30848    |
| train/                    |          |
|    explained_variance     | -5.46    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0059   |
|    learning_rate          | 0.001    |
|    n_updates              | 240      |
|    policy_objective       | 0.0564   |
|    value_loss             | 3.07e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 37.2     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 700      |
|    iterations             | 242      |
|    time_elapsed           | 44       |
|    total_timesteps        | 30976    |
| train/                    |          |
|    explained_variance     | -1.69    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00628  |
|    learning_rate          | 0.001    |
|    n_updates              | 241      |
|    policy_objective       | 0.0236   |
|    value_loss             | 1.39e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 37.4     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 700      |
|    iterations             | 243      |
|    time_elapsed           | 44       |
|    total_timesteps        | 31104    |
| train/                    |          |
|    explained_variance     | -20.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0066   |
|    learning_rate          | 0.001    |
|    n_updates              | 242      |
|    policy_objective       | 0.0443   |
|    value_loss             | 2.06e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 38.1     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 699      |
|    iterations             | 244      |
|    time_elapsed           | 44       |
|    total_timesteps        | 31232    |
| train/                    |          |
|    explained_variance     | -2.06    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00557  |
|    learning_rate          | 0.001    |
|    n_updates              | 243      |
|    policy_objective       | 0.052    |
|    value_loss             | 1.83e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 38.8     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 699      |
|    iterations             | 245      |
|    time_elapsed           | 44       |
|    total_timesteps        | 31360    |
| train/                    |          |
|    explained_variance     | -4.33    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00702  |
|    learning_rate          | 0.001    |
|    n_updates              | 244      |
|    policy_objective       | 0.0446   |
|    value_loss             | 1.26e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 38       |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 699      |
|    iterations             | 246      |
|    time_elapsed           | 45       |
|    total_timesteps        | 31488    |
| train/                    |          |
|    explained_variance     | -3.98    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00775  |
|    learning_rate          | 0.001    |
|    n_updates              | 245      |
|    policy_objective       | 0.0745   |
|    value_loss             | 3.76e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 37.8     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 699      |
|    iterations             | 247      |
|    time_elapsed           | 45       |
|    total_timesteps        | 31616    |
| train/                    |          |
|    explained_variance     | -3.34    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00391  |
|    learning_rate          | 0.001    |
|    n_updates              | 246      |
|    policy_objective       | 0.0333   |
|    value_loss             | 2.48e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 38.3     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 699      |
|    iterations             | 248      |
|    time_elapsed           | 45       |
|    total_timesteps        | 31744    |
| train/                    |          |
|    explained_variance     | -0.362   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00768  |
|    learning_rate          | 0.001    |
|    n_updates              | 247      |
|    policy_objective       | 0.0394   |
|    value_loss             | 3.16e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 38.9     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 699      |
|    iterations             | 249      |
|    time_elapsed           | 45       |
|    total_timesteps        | 31872    |
| train/                    |          |
|    explained_variance     | -4.9     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00299  |
|    learning_rate          | 0.001    |
|    n_updates              | 248      |
|    policy_objective       | 0.0608   |
|    value_loss             | 1.77e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 39.5     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 699      |
|    iterations             | 250      |
|    time_elapsed           | 45       |
|    total_timesteps        | 32000    |
| train/                    |          |
|    explained_variance     | -0.249   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00748  |
|    learning_rate          | 0.001    |
|    n_updates              | 249      |
|    policy_objective       | 0.0495   |
|    value_loss             | 2.3e-07  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 39.2     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 698      |
|    iterations             | 251      |
|    time_elapsed           | 45       |
|    total_timesteps        | 32128    |
| train/                    |          |
|    explained_variance     | -0.511   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00481  |
|    learning_rate          | 0.001    |
|    n_updates              | 250      |
|    policy_objective       | 0.07     |
|    value_loss             | 5.46e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 39.1     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 698      |
|    iterations             | 252      |
|    time_elapsed           | 46       |
|    total_timesteps        | 32256    |
| train/                    |          |
|    explained_variance     | -24.6    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00254  |
|    learning_rate          | 0.001    |
|    n_updates              | 251      |
|    policy_objective       | 0.0349   |
|    value_loss             | 6.9e-06  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 39.6     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 698      |
|    iterations             | 253      |
|    time_elapsed           | 46       |
|    total_timesteps        | 32384    |
| train/                    |          |
|    explained_variance     | -38.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00748  |
|    learning_rate          | 0.001    |
|    n_updates              | 252      |
|    policy_objective       | 0.051    |
|    value_loss             | 8.9e-08  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 39.7     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 698      |
|    iterations             | 254      |
|    time_elapsed           | 46       |
|    total_timesteps        | 32512    |
| train/                    |          |
|    explained_variance     | -8.82    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00577  |
|    learning_rate          | 0.001    |
|    n_updates              | 253      |
|    policy_objective       | 0.0431   |
|    value_loss             | 1.26e-08 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 38.3     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 698      |
|    iterations             | 255      |
|    time_elapsed           | 46       |
|    total_timesteps        | 32640    |
| train/                    |          |
|    explained_variance     | -75.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00384  |
|    learning_rate          | 0.001    |
|    n_updates              | 254      |
|    policy_objective       | 0.0651   |
|    value_loss             | 2.29e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 38       |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 698      |
|    iterations             | 256      |
|    time_elapsed           | 46       |
|    total_timesteps        | 32768    |
| train/                    |          |
|    explained_variance     | -3.64    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00617  |
|    learning_rate          | 0.001    |
|    n_updates              | 255      |
|    policy_objective       | 0.0673   |
|    value_loss             | 1.95e-09 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 37.7     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 698      |
|    iterations             | 257      |
|    time_elapsed           | 47       |
|    total_timesteps        | 32896    |
| train/                    |          |
|    explained_variance     | -151     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00286  |
|    learning_rate          | 0.001    |
|    n_updates              | 256      |
|    policy_objective       | 0.0583   |
|    value_loss             | 5.24e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 38.2     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 698      |
|    iterations             | 258      |
|    time_elapsed           | 47       |
|    total_timesteps        | 33024    |
| train/                    |          |
|    explained_variance     | -6.63    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00457  |
|    learning_rate          | 0.001    |
|    n_updates              | 257      |
|    policy_objective       | 0.0572   |
|    value_loss             | 1.01e-09 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 38.6     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 698      |
|    iterations             | 259      |
|    time_elapsed           | 47       |
|    total_timesteps        | 33152    |
| train/                    |          |
|    explained_variance     | -38.6    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00676  |
|    learning_rate          | 0.001    |
|    n_updates              | 258      |
|    policy_objective       | 0.0142   |
|    value_loss             | 2.74e-09 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 38.5     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 697      |
|    iterations             | 260      |
|    time_elapsed           | 47       |
|    total_timesteps        | 33280    |
| train/                    |          |
|    explained_variance     | -7.32    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00541  |
|    learning_rate          | 0.001    |
|    n_updates              | 259      |
|    policy_objective       | 0.0519   |
|    value_loss             | 9.75e-11 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 38.7     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 697      |
|    iterations             | 261      |
|    time_elapsed           | 47       |
|    total_timesteps        | 33408    |
| train/                    |          |
|    explained_variance     | -3.73    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00722  |
|    learning_rate          | 0.001    |
|    n_updates              | 260      |
|    policy_objective       | 0.0168   |
|    value_loss             | 3.64e-10 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 38.5     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 697      |
|    iterations             | 262      |
|    time_elapsed           | 48       |
|    total_timesteps        | 33536    |
| train/                    |          |
|    explained_variance     | -0.917   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00599  |
|    learning_rate          | 0.001    |
|    n_updates              | 261      |
|    policy_objective       | 0.052    |
|    value_loss             | 7.48e-11 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 38.1     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 697      |
|    iterations             | 263      |
|    time_elapsed           | 48       |
|    total_timesteps        | 33664    |
| train/                    |          |
|    explained_variance     | -33.7    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00181  |
|    learning_rate          | 0.001    |
|    n_updates              | 262      |
|    policy_objective       | 0.0771   |
|    value_loss             | 6.79e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 39       |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 697      |
|    iterations             | 264      |
|    time_elapsed           | 48       |
|    total_timesteps        | 33792    |
| train/                    |          |
|    explained_variance     | -7.03    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00499  |
|    learning_rate          | 0.001    |
|    n_updates              | 263      |
|    policy_objective       | 0.0768   |
|    value_loss             | 4.32e-08 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 37.8     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 697      |
|    iterations             | 265      |
|    time_elapsed           | 48       |
|    total_timesteps        | 33920    |
| train/                    |          |
|    explained_variance     | -1.41    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00554  |
|    learning_rate          | 0.001    |
|    n_updates              | 264      |
|    policy_objective       | 0.0575   |
|    value_loss             | 3.79e-08 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 36.1     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 697      |
|    iterations             | 266      |
|    time_elapsed           | 48       |
|    total_timesteps        | 34048    |
| train/                    |          |
|    explained_variance     | -4.19    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00513  |
|    learning_rate          | 0.001    |
|    n_updates              | 265      |
|    policy_objective       | 0.0529   |
|    value_loss             | 9.56e-09 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 36.2     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 697      |
|    iterations             | 267      |
|    time_elapsed           | 48       |
|    total_timesteps        | 34176    |
| train/                    |          |
|    explained_variance     | -6.4     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00687  |
|    learning_rate          | 0.001    |
|    n_updates              | 266      |
|    policy_objective       | 0.029    |
|    value_loss             | 7.32e-09 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 36.3     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 697      |
|    iterations             | 268      |
|    time_elapsed           | 49       |
|    total_timesteps        | 34304    |
| train/                    |          |
|    explained_variance     | -11.6    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00609  |
|    learning_rate          | 0.001    |
|    n_updates              | 267      |
|    policy_objective       | 0.028    |
|    value_loss             | 9.74e-08 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 36.2     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 697      |
|    iterations             | 269      |
|    time_elapsed           | 49       |
|    total_timesteps        | 34432    |
| train/                    |          |
|    explained_variance     | -5.4     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00578  |
|    learning_rate          | 0.001    |
|    n_updates              | 268      |
|    policy_objective       | 0.0666   |
|    value_loss             | 1.97e-08 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 35.6     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 697      |
|    iterations             | 270      |
|    time_elapsed           | 49       |
|    total_timesteps        | 34560    |
| train/                    |          |
|    explained_variance     | -0.937   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00787  |
|    learning_rate          | 0.001    |
|    n_updates              | 269      |
|    policy_objective       | 0.0449   |
|    value_loss             | 5.33e-09 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 35.1     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 697      |
|    iterations             | 271      |
|    time_elapsed           | 49       |
|    total_timesteps        | 34688    |
| train/                    |          |
|    explained_variance     | -1.85    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00589  |
|    learning_rate          | 0.001    |
|    n_updates              | 270      |
|    policy_objective       | 0.0499   |
|    value_loss             | 3.78e-09 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 35.1     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 697      |
|    iterations             | 272      |
|    time_elapsed           | 49       |
|    total_timesteps        | 34816    |
| train/                    |          |
|    explained_variance     | -5.32    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00111  |
|    learning_rate          | 0.001    |
|    n_updates              | 271      |
|    policy_objective       | 0.0557   |
|    value_loss             | 7.81e-10 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 35.1     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 697      |
|    iterations             | 273      |
|    time_elapsed           | 50       |
|    total_timesteps        | 34944    |
| train/                    |          |
|    explained_variance     | -0.759   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00689  |
|    learning_rate          | 0.001    |
|    n_updates              | 272      |
|    policy_objective       | 0.168    |
|    value_loss             | 1.98e-09 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 35.6     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 697      |
|    iterations             | 274      |
|    time_elapsed           | 50       |
|    total_timesteps        | 35072    |
| train/                    |          |
|    explained_variance     | -7.57    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00269  |
|    learning_rate          | 0.001    |
|    n_updates              | 273      |
|    policy_objective       | 0.0565   |
|    value_loss             | 7.64e-10 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 35.4     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 697      |
|    iterations             | 275      |
|    time_elapsed           | 50       |
|    total_timesteps        | 35200    |
| train/                    |          |
|    explained_variance     | -34.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00564  |
|    learning_rate          | 0.001    |
|    n_updates              | 274      |
|    policy_objective       | 0.0192   |
|    value_loss             | 1.49e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 34.7     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 697      |
|    iterations             | 276      |
|    time_elapsed           | 50       |
|    total_timesteps        | 35328    |
| train/                    |          |
|    explained_variance     | -13.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0054   |
|    learning_rate          | 0.001    |
|    n_updates              | 275      |
|    policy_objective       | 0.0661   |
|    value_loss             | 5.78e-09 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 33.6     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 697      |
|    iterations             | 277      |
|    time_elapsed           | 50       |
|    total_timesteps        | 35456    |
| train/                    |          |
|    explained_variance     | -39.7    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00516  |
|    learning_rate          | 0.001    |
|    n_updates              | 276      |
|    policy_objective       | 0.0415   |
|    value_loss             | 3.92e-09 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 34       |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 697      |
|    iterations             | 278      |
|    time_elapsed           | 50       |
|    total_timesteps        | 35584    |
| train/                    |          |
|    explained_variance     | -29.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00426  |
|    learning_rate          | 0.001    |
|    n_updates              | 277      |
|    policy_objective       | 0.019    |
|    value_loss             | 1.23e-09 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 34.2     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 697      |
|    iterations             | 279      |
|    time_elapsed           | 51       |
|    total_timesteps        | 35712    |
| train/                    |          |
|    explained_variance     | -3.04    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00546  |
|    learning_rate          | 0.001    |
|    n_updates              | 278      |
|    policy_objective       | 0.0373   |
|    value_loss             | 2.06e-11 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 34.9     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 697      |
|    iterations             | 280      |
|    time_elapsed           | 51       |
|    total_timesteps        | 35840    |
| train/                    |          |
|    explained_variance     | -43.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00551  |
|    learning_rate          | 0.001    |
|    n_updates              | 279      |
|    policy_objective       | 0.0773   |
|    value_loss             | 8.87e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 34.6     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 697      |
|    iterations             | 281      |
|    time_elapsed           | 51       |
|    total_timesteps        | 35968    |
| train/                    |          |
|    explained_variance     | -1.67    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00716  |
|    learning_rate          | 0.001    |
|    n_updates              | 280      |
|    policy_objective       | 0.0317   |
|    value_loss             | 6.4e-09  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 34.6     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 697      |
|    iterations             | 282      |
|    time_elapsed           | 51       |
|    total_timesteps        | 36096    |
| train/                    |          |
|    explained_variance     | -16.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00624  |
|    learning_rate          | 0.001    |
|    n_updates              | 281      |
|    policy_objective       | 0.0335   |
|    value_loss             | 4.29e-09 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 34.9     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 698      |
|    iterations             | 283      |
|    time_elapsed           | 51       |
|    total_timesteps        | 36224    |
| train/                    |          |
|    explained_variance     | -6.05    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00601  |
|    learning_rate          | 0.001    |
|    n_updates              | 282      |
|    policy_objective       | 0.0284   |
|    value_loss             | 2.95e-10 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 34.9     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 698      |
|    iterations             | 284      |
|    time_elapsed           | 52       |
|    total_timesteps        | 36352    |
| train/                    |          |
|    explained_variance     | -281     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.000949 |
|    learning_rate          | 0.001    |
|    n_updates              | 283      |
|    policy_objective       | 0.0526   |
|    value_loss             | 1.85e-08 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 34.6     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 698      |
|    iterations             | 285      |
|    time_elapsed           | 52       |
|    total_timesteps        | 36480    |
| train/                    |          |
|    explained_variance     | 0.12     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00678  |
|    learning_rate          | 0.001    |
|    n_updates              | 284      |
|    policy_objective       | 0.0411   |
|    value_loss             | 0.0212   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 34.7     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 697      |
|    iterations             | 286      |
|    time_elapsed           | 52       |
|    total_timesteps        | 36608    |
| train/                    |          |
|    explained_variance     | -5.44    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00764  |
|    learning_rate          | 0.001    |
|    n_updates              | 285      |
|    policy_objective       | 0.0298   |
|    value_loss             | 0.000897 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 33.1     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 697      |
|    iterations             | 287      |
|    time_elapsed           | 52       |
|    total_timesteps        | 36736    |
| train/                    |          |
|    explained_variance     | -5.23    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00704  |
|    learning_rate          | 0.001    |
|    n_updates              | 286      |
|    policy_objective       | 0.0396   |
|    value_loss             | 0.00992  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 34.1     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 697      |
|    iterations             | 288      |
|    time_elapsed           | 52       |
|    total_timesteps        | 36864    |
| train/                    |          |
|    explained_variance     | 0.524    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00367  |
|    learning_rate          | 0.001    |
|    n_updates              | 287      |
|    policy_objective       | 0.032    |
|    value_loss             | 0.0022   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 33.5     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 697      |
|    iterations             | 289      |
|    time_elapsed           | 53       |
|    total_timesteps        | 36992    |
| train/                    |          |
|    explained_variance     | 0.398    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.000966 |
|    learning_rate          | 0.001    |
|    n_updates              | 288      |
|    policy_objective       | 0.0357   |
|    value_loss             | 0.00143  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 33.4     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 697      |
|    iterations             | 290      |
|    time_elapsed           | 53       |
|    total_timesteps        | 37120    |
| train/                    |          |
|    explained_variance     | -1.99    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00861  |
|    learning_rate          | 0.001    |
|    n_updates              | 289      |
|    policy_objective       | 0.0375   |
|    value_loss             | 0.000303 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 33.2     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 697      |
|    iterations             | 291      |
|    time_elapsed           | 53       |
|    total_timesteps        | 37248    |
| train/                    |          |
|    explained_variance     | -10.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00344  |
|    learning_rate          | 0.001    |
|    n_updates              | 290      |
|    policy_objective       | 0.0352   |
|    value_loss             | 0.000294 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 33.5     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 697      |
|    iterations             | 292      |
|    time_elapsed           | 53       |
|    total_timesteps        | 37376    |
| train/                    |          |
|    explained_variance     | -2.16    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00898  |
|    learning_rate          | 0.001    |
|    n_updates              | 291      |
|    policy_objective       | 0.0501   |
|    value_loss             | 5.14e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 33.9     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 697      |
|    iterations             | 293      |
|    time_elapsed           | 53       |
|    total_timesteps        | 37504    |
| train/                    |          |
|    explained_variance     | -28      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0085   |
|    learning_rate          | 0.001    |
|    n_updates              | 292      |
|    policy_objective       | 0.0184   |
|    value_loss             | 2.03e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 33.2     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 697      |
|    iterations             | 294      |
|    time_elapsed           | 53       |
|    total_timesteps        | 37632    |
| train/                    |          |
|    explained_variance     | -24.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00499  |
|    learning_rate          | 0.001    |
|    n_updates              | 293      |
|    policy_objective       | 0.0364   |
|    value_loss             | 0.000346 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 32.9     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 697      |
|    iterations             | 295      |
|    time_elapsed           | 54       |
|    total_timesteps        | 37760    |
| train/                    |          |
|    explained_variance     | -5.19    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00551  |
|    learning_rate          | 0.001    |
|    n_updates              | 294      |
|    policy_objective       | 0.0683   |
|    value_loss             | 3.3e-05  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 33.3     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 697      |
|    iterations             | 296      |
|    time_elapsed           | 54       |
|    total_timesteps        | 37888    |
| train/                    |          |
|    explained_variance     | -3.39    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00798  |
|    learning_rate          | 0.001    |
|    n_updates              | 295      |
|    policy_objective       | 0.0451   |
|    value_loss             | 1.11e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 32.6     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 696      |
|    iterations             | 297      |
|    time_elapsed           | 54       |
|    total_timesteps        | 38016    |
| train/                    |          |
|    explained_variance     | -6.68    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00233  |
|    learning_rate          | 0.001    |
|    n_updates              | 296      |
|    policy_objective       | 0.0652   |
|    value_loss             | 0.000146 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 32.8     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 696      |
|    iterations             | 298      |
|    time_elapsed           | 54       |
|    total_timesteps        | 38144    |
| train/                    |          |
|    explained_variance     | -34.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00808  |
|    learning_rate          | 0.001    |
|    n_updates              | 297      |
|    policy_objective       | 0.0187   |
|    value_loss             | 6.69e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 31.7     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 696      |
|    iterations             | 299      |
|    time_elapsed           | 54       |
|    total_timesteps        | 38272    |
| train/                    |          |
|    explained_variance     | -19.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00704  |
|    learning_rate          | 0.001    |
|    n_updates              | 298      |
|    policy_objective       | 0.0319   |
|    value_loss             | 5.37e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 31.7     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 696      |
|    iterations             | 300      |
|    time_elapsed           | 55       |
|    total_timesteps        | 38400    |
| train/                    |          |
|    explained_variance     | -6.79    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00647  |
|    learning_rate          | 0.001    |
|    n_updates              | 299      |
|    policy_objective       | 0.034    |
|    value_loss             | 7.95e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 32.4     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 695      |
|    iterations             | 301      |
|    time_elapsed           | 55       |
|    total_timesteps        | 38528    |
| train/                    |          |
|    explained_variance     | -3.24    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00333  |
|    learning_rate          | 0.001    |
|    n_updates              | 300      |
|    policy_objective       | 0.0309   |
|    value_loss             | 1.12e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 32.8     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 695      |
|    iterations             | 302      |
|    time_elapsed           | 55       |
|    total_timesteps        | 38656    |
| train/                    |          |
|    explained_variance     | -439     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00653  |
|    learning_rate          | 0.001    |
|    n_updates              | 301      |
|    policy_objective       | 1.16     |
|    value_loss             | 2.95e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 33.5     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 695      |
|    iterations             | 303      |
|    time_elapsed           | 55       |
|    total_timesteps        | 38784    |
| train/                    |          |
|    explained_variance     | -40.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00495  |
|    learning_rate          | 0.001    |
|    n_updates              | 302      |
|    policy_objective       | 0.0195   |
|    value_loss             | 7.71e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 34.2     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 694      |
|    iterations             | 304      |
|    time_elapsed           | 56       |
|    total_timesteps        | 38912    |
| train/                    |          |
|    explained_variance     | -24.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00282  |
|    learning_rate          | 0.001    |
|    n_updates              | 303      |
|    policy_objective       | 0.0179   |
|    value_loss             | 2.86e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 33.1     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 694      |
|    iterations             | 305      |
|    time_elapsed           | 56       |
|    total_timesteps        | 39040    |
| train/                    |          |
|    explained_variance     | -21.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00997  |
|    learning_rate          | 0.001    |
|    n_updates              | 304      |
|    policy_objective       | 0.0495   |
|    value_loss             | 6.11e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 32.1     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 693      |
|    iterations             | 306      |
|    time_elapsed           | 56       |
|    total_timesteps        | 39168    |
| train/                    |          |
|    explained_variance     | -12.6    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00665  |
|    learning_rate          | 0.001    |
|    n_updates              | 305      |
|    policy_objective       | 0.0237   |
|    value_loss             | 1.26e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 31.9     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 693      |
|    iterations             | 307      |
|    time_elapsed           | 56       |
|    total_timesteps        | 39296    |
| train/                    |          |
|    explained_variance     | -44.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00293  |
|    learning_rate          | 0.001    |
|    n_updates              | 306      |
|    policy_objective       | 0.0133   |
|    value_loss             | 6.29e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 32.2     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 693      |
|    iterations             | 308      |
|    time_elapsed           | 56       |
|    total_timesteps        | 39424    |
| train/                    |          |
|    explained_variance     | -14.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00547  |
|    learning_rate          | 0.001    |
|    n_updates              | 307      |
|    policy_objective       | 0.0286   |
|    value_loss             | 2.04e-08 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 32.5     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 693      |
|    iterations             | 309      |
|    time_elapsed           | 57       |
|    total_timesteps        | 39552    |
| train/                    |          |
|    explained_variance     | -8.65    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00486  |
|    learning_rate          | 0.001    |
|    n_updates              | 308      |
|    policy_objective       | 0.073    |
|    value_loss             | 4e-06    |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 32.4     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 693      |
|    iterations             | 310      |
|    time_elapsed           | 57       |
|    total_timesteps        | 39680    |
| train/                    |          |
|    explained_variance     | -3.17    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00734  |
|    learning_rate          | 0.001    |
|    n_updates              | 309      |
|    policy_objective       | 0.029    |
|    value_loss             | 1.65e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 32.2     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 692      |
|    iterations             | 311      |
|    time_elapsed           | 57       |
|    total_timesteps        | 39808    |
| train/                    |          |
|    explained_variance     | -19.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00497  |
|    learning_rate          | 0.001    |
|    n_updates              | 310      |
|    policy_objective       | 0.0193   |
|    value_loss             | 2.61e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 32.5     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 692      |
|    iterations             | 312      |
|    time_elapsed           | 57       |
|    total_timesteps        | 39936    |
| train/                    |          |
|    explained_variance     | -10.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00661  |
|    learning_rate          | 0.001    |
|    n_updates              | 311      |
|    policy_objective       | 0.0539   |
|    value_loss             | 2.52e-08 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 32.3     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 692      |
|    iterations             | 313      |
|    time_elapsed           | 57       |
|    total_timesteps        | 40064    |
| train/                    |          |
|    explained_variance     | -34.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00852  |
|    learning_rate          | 0.001    |
|    n_updates              | 312      |
|    policy_objective       | 0.326    |
|    value_loss             | 6.84e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 32.8     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 692      |
|    iterations             | 314      |
|    time_elapsed           | 58       |
|    total_timesteps        | 40192    |
| train/                    |          |
|    explained_variance     | -20.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00478  |
|    learning_rate          | 0.001    |
|    n_updates              | 313      |
|    policy_objective       | 0.0804   |
|    value_loss             | 5.24e-08 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 32.8     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 692      |
|    iterations             | 315      |
|    time_elapsed           | 58       |
|    total_timesteps        | 40320    |
| train/                    |          |
|    explained_variance     | -5.47    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0042   |
|    learning_rate          | 0.001    |
|    n_updates              | 314      |
|    policy_objective       | 0.0205   |
|    value_loss             | 2.46e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 33.5     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 692      |
|    iterations             | 316      |
|    time_elapsed           | 58       |
|    total_timesteps        | 40448    |
| train/                    |          |
|    explained_variance     | -14.7    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00544  |
|    learning_rate          | 0.001    |
|    n_updates              | 315      |
|    policy_objective       | 0.0199   |
|    value_loss             | 3.06e-08 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 33.4     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 692      |
|    iterations             | 317      |
|    time_elapsed           | 58       |
|    total_timesteps        | 40576    |
| train/                    |          |
|    explained_variance     | -14      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00314  |
|    learning_rate          | 0.001    |
|    n_updates              | 316      |
|    policy_objective       | 0.0331   |
|    value_loss             | 7.82e-09 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 32.9     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 692      |
|    iterations             | 318      |
|    time_elapsed           | 58       |
|    total_timesteps        | 40704    |
| train/                    |          |
|    explained_variance     | -6.27    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00698  |
|    learning_rate          | 0.001    |
|    n_updates              | 317      |
|    policy_objective       | 0.0977   |
|    value_loss             | 4.85e-08 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 33.6     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 692      |
|    iterations             | 319      |
|    time_elapsed           | 58       |
|    total_timesteps        | 40832    |
| train/                    |          |
|    explained_variance     | -44.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00737  |
|    learning_rate          | 0.001    |
|    n_updates              | 318      |
|    policy_objective       | 0.00628  |
|    value_loss             | 7.49e-08 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 33.9     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 692      |
|    iterations             | 320      |
|    time_elapsed           | 59       |
|    total_timesteps        | 40960    |
| train/                    |          |
|    explained_variance     | -3.53    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00522  |
|    learning_rate          | 0.001    |
|    n_updates              | 319      |
|    policy_objective       | 0.0488   |
|    value_loss             | 9.09e-09 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 33.8     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 692      |
|    iterations             | 321      |
|    time_elapsed           | 59       |
|    total_timesteps        | 41088    |
| train/                    |          |
|    explained_variance     | -28.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00527  |
|    learning_rate          | 0.001    |
|    n_updates              | 320      |
|    policy_objective       | 0.0228   |
|    value_loss             | 8.54e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 33.3     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 692      |
|    iterations             | 322      |
|    time_elapsed           | 59       |
|    total_timesteps        | 41216    |
| train/                    |          |
|    explained_variance     | -18.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00696  |
|    learning_rate          | 0.001    |
|    n_updates              | 321      |
|    policy_objective       | 0.0566   |
|    value_loss             | 8.03e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 34       |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 692      |
|    iterations             | 323      |
|    time_elapsed           | 59       |
|    total_timesteps        | 41344    |
| train/                    |          |
|    explained_variance     | -87.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00758  |
|    learning_rate          | 0.001    |
|    n_updates              | 322      |
|    policy_objective       | 0.0134   |
|    value_loss             | 2.28e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 33.9     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 692      |
|    iterations             | 324      |
|    time_elapsed           | 59       |
|    total_timesteps        | 41472    |
| train/                    |          |
|    explained_variance     | -61.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00159  |
|    learning_rate          | 0.001    |
|    n_updates              | 323      |
|    policy_objective       | 0.0602   |
|    value_loss             | 2.55e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 35.2     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 691      |
|    iterations             | 325      |
|    time_elapsed           | 60       |
|    total_timesteps        | 41600    |
| train/                    |          |
|    explained_variance     | -9.24    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00761  |
|    learning_rate          | 0.001    |
|    n_updates              | 324      |
|    policy_objective       | 0.103    |
|    value_loss             | 3.11e-09 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 35.2     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 691      |
|    iterations             | 326      |
|    time_elapsed           | 60       |
|    total_timesteps        | 41728    |
| train/                    |          |
|    explained_variance     | -66.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0036   |
|    learning_rate          | 0.001    |
|    n_updates              | 325      |
|    policy_objective       | 0.0052   |
|    value_loss             | 1.1e-07  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 35.8     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 690      |
|    iterations             | 327      |
|    time_elapsed           | 60       |
|    total_timesteps        | 41856    |
| train/                    |          |
|    explained_variance     | -29.7    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00554  |
|    learning_rate          | 0.001    |
|    n_updates              | 326      |
|    policy_objective       | 0.0253   |
|    value_loss             | 1.39e-09 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 36.2     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 690      |
|    iterations             | 328      |
|    time_elapsed           | 60       |
|    total_timesteps        | 41984    |
| train/                    |          |
|    explained_variance     | -2.37    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00734  |
|    learning_rate          | 0.001    |
|    n_updates              | 327      |
|    policy_objective       | 0.0318   |
|    value_loss             | 8.66e-11 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 36.1     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 329      |
|    time_elapsed           | 61       |
|    total_timesteps        | 42112    |
| train/                    |          |
|    explained_variance     | -57      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00506  |
|    learning_rate          | 0.001    |
|    n_updates              | 328      |
|    policy_objective       | 0.00757  |
|    value_loss             | 2.5e-09  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 35.1     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 330      |
|    time_elapsed           | 61       |
|    total_timesteps        | 42240    |
| train/                    |          |
|    explained_variance     | -357     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00395  |
|    learning_rate          | 0.001    |
|    n_updates              | 329      |
|    policy_objective       | 0.0464   |
|    value_loss             | 2e-05    |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 34.2     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 331      |
|    time_elapsed           | 61       |
|    total_timesteps        | 42368    |
| train/                    |          |
|    explained_variance     | -27.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00314  |
|    learning_rate          | 0.001    |
|    n_updates              | 330      |
|    policy_objective       | 0.322    |
|    value_loss             | 2.13e-08 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 34.2     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 688      |
|    iterations             | 332      |
|    time_elapsed           | 61       |
|    total_timesteps        | 42496    |
| train/                    |          |
|    explained_variance     | -68.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00336  |
|    learning_rate          | 0.001    |
|    n_updates              | 331      |
|    policy_objective       | 0.0615   |
|    value_loss             | 3.32e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 34.7     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 688      |
|    iterations             | 333      |
|    time_elapsed           | 61       |
|    total_timesteps        | 42624    |
| train/                    |          |
|    explained_variance     | -2.69    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00802  |
|    learning_rate          | 0.001    |
|    n_updates              | 332      |
|    policy_objective       | 0.0578   |
|    value_loss             | 4.73e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 35.4     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 688      |
|    iterations             | 334      |
|    time_elapsed           | 62       |
|    total_timesteps        | 42752    |
| train/                    |          |
|    explained_variance     | -25.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.000743 |
|    learning_rate          | 0.001    |
|    n_updates              | 333      |
|    policy_objective       | 0.0624   |
|    value_loss             | 2.35e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 36       |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 688      |
|    iterations             | 335      |
|    time_elapsed           | 62       |
|    total_timesteps        | 42880    |
| train/                    |          |
|    explained_variance     | -26.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00464  |
|    learning_rate          | 0.001    |
|    n_updates              | 334      |
|    policy_objective       | 0.0211   |
|    value_loss             | 1.32e-08 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 35.4     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 688      |
|    iterations             | 336      |
|    time_elapsed           | 62       |
|    total_timesteps        | 43008    |
| train/                    |          |
|    explained_variance     | -23.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00104  |
|    learning_rate          | 0.001    |
|    n_updates              | 335      |
|    policy_objective       | 0.0413   |
|    value_loss             | 1.24e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 35.2     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 688      |
|    iterations             | 337      |
|    time_elapsed           | 62       |
|    total_timesteps        | 43136    |
| train/                    |          |
|    explained_variance     | -12.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00549  |
|    learning_rate          | 0.001    |
|    n_updates              | 336      |
|    policy_objective       | 0.0207   |
|    value_loss             | 3.36e-08 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 35.8     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 688      |
|    iterations             | 338      |
|    time_elapsed           | 62       |
|    total_timesteps        | 43264    |
| train/                    |          |
|    explained_variance     | 0.173    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00214  |
|    learning_rate          | 0.001    |
|    n_updates              | 337      |
|    policy_objective       | 0.0448   |
|    value_loss             | 4.13e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 35.5     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 688      |
|    iterations             | 339      |
|    time_elapsed           | 62       |
|    total_timesteps        | 43392    |
| train/                    |          |
|    explained_variance     | -14.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00616  |
|    learning_rate          | 0.001    |
|    n_updates              | 338      |
|    policy_objective       | 0.032    |
|    value_loss             | 8.22e-08 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 35.9     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 688      |
|    iterations             | 340      |
|    time_elapsed           | 63       |
|    total_timesteps        | 43520    |
| train/                    |          |
|    explained_variance     | -5.6     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00259  |
|    learning_rate          | 0.001    |
|    n_updates              | 339      |
|    policy_objective       | 0.0194   |
|    value_loss             | 4.54e-08 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 36.4     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 688      |
|    iterations             | 341      |
|    time_elapsed           | 63       |
|    total_timesteps        | 43648    |
| train/                    |          |
|    explained_variance     | -13.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00503  |
|    learning_rate          | 0.001    |
|    n_updates              | 340      |
|    policy_objective       | 0.0225   |
|    value_loss             | 5.87e-09 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 36.5     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 688      |
|    iterations             | 342      |
|    time_elapsed           | 63       |
|    total_timesteps        | 43776    |
| train/                    |          |
|    explained_variance     | -17      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0083   |
|    learning_rate          | 0.001    |
|    n_updates              | 341      |
|    policy_objective       | 0.0366   |
|    value_loss             | 3.75e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 36.6     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 688      |
|    iterations             | 343      |
|    time_elapsed           | 63       |
|    total_timesteps        | 43904    |
| train/                    |          |
|    explained_variance     | -11.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00499  |
|    learning_rate          | 0.001    |
|    n_updates              | 342      |
|    policy_objective       | 0.0318   |
|    value_loss             | 1.09e-08 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 37.1     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 688      |
|    iterations             | 344      |
|    time_elapsed           | 63       |
|    total_timesteps        | 44032    |
| train/                    |          |
|    explained_variance     | -79.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00712  |
|    learning_rate          | 0.001    |
|    n_updates              | 343      |
|    policy_objective       | 0.00291  |
|    value_loss             | 3.35e-08 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 37.4     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 688      |
|    iterations             | 345      |
|    time_elapsed           | 64       |
|    total_timesteps        | 44160    |
| train/                    |          |
|    explained_variance     | -30.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00762  |
|    learning_rate          | 0.001    |
|    n_updates              | 344      |
|    policy_objective       | 0.0246   |
|    value_loss             | 7.04e-10 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 37.6     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 688      |
|    iterations             | 346      |
|    time_elapsed           | 64       |
|    total_timesteps        | 44288    |
| train/                    |          |
|    explained_variance     | -73.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00819  |
|    learning_rate          | 0.001    |
|    n_updates              | 345      |
|    policy_objective       | 0.00754  |
|    value_loss             | 9.59e-10 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 37.7     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 688      |
|    iterations             | 347      |
|    time_elapsed           | 64       |
|    total_timesteps        | 44416    |
| train/                    |          |
|    explained_variance     | -0.00456 |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00628  |
|    learning_rate          | 0.001    |
|    n_updates              | 346      |
|    policy_objective       | 0.246    |
|    value_loss             | 1.47e-10 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 37.9     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 688      |
|    iterations             | 348      |
|    time_elapsed           | 64       |
|    total_timesteps        | 44544    |
| train/                    |          |
|    explained_variance     | -20.6    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00664  |
|    learning_rate          | 0.001    |
|    n_updates              | 347      |
|    policy_objective       | 0.0804   |
|    value_loss             | 9.43e-11 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 38       |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 688      |
|    iterations             | 349      |
|    time_elapsed           | 64       |
|    total_timesteps        | 44672    |
| train/                    |          |
|    explained_variance     | -176     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00434  |
|    learning_rate          | 0.001    |
|    n_updates              | 348      |
|    policy_objective       | 0.00194  |
|    value_loss             | 9.7e-09  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 37.9     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 350      |
|    time_elapsed           | 65       |
|    total_timesteps        | 44800    |
| train/                    |          |
|    explained_variance     | -29.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0085   |
|    learning_rate          | 0.001    |
|    n_updates              | 349      |
|    policy_objective       | 0.0103   |
|    value_loss             | 9.67e-11 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 38.1     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 688      |
|    iterations             | 351      |
|    time_elapsed           | 65       |
|    total_timesteps        | 44928    |
| train/                    |          |
|    explained_variance     | -53.7    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00915  |
|    learning_rate          | 0.001    |
|    n_updates              | 350      |
|    policy_objective       | 0.0215   |
|    value_loss             | 1.05e-08 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 36.9     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 688      |
|    iterations             | 352      |
|    time_elapsed           | 65       |
|    total_timesteps        | 45056    |
| train/                    |          |
|    explained_variance     | -46.7    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0074   |
|    learning_rate          | 0.001    |
|    n_updates              | 351      |
|    policy_objective       | 0.0157   |
|    value_loss             | 2.47e-10 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 35       |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 353      |
|    time_elapsed           | 65       |
|    total_timesteps        | 45184    |
| train/                    |          |
|    explained_variance     | -62.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00723  |
|    learning_rate          | 0.001    |
|    n_updates              | 352      |
|    policy_objective       | 0.00628  |
|    value_loss             | 3.86e-10 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 35.8     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 354      |
|    time_elapsed           | 65       |
|    total_timesteps        | 45312    |
| train/                    |          |
|    explained_variance     | -6.9     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00639  |
|    learning_rate          | 0.001    |
|    n_updates              | 353      |
|    policy_objective       | 0.0372   |
|    value_loss             | 7.89e-12 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 34.7     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 355      |
|    time_elapsed           | 65       |
|    total_timesteps        | 45440    |
| train/                    |          |
|    explained_variance     | -22.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00381  |
|    learning_rate          | 0.001    |
|    n_updates              | 354      |
|    policy_objective       | 0.0207   |
|    value_loss             | 9.1e-12  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 35.2     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 356      |
|    time_elapsed           | 66       |
|    total_timesteps        | 45568    |
| train/                    |          |
|    explained_variance     | -10.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00228  |
|    learning_rate          | 0.001    |
|    n_updates              | 355      |
|    policy_objective       | 0.0141   |
|    value_loss             | 1.07e-12 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 36.1     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 357      |
|    time_elapsed           | 66       |
|    total_timesteps        | 45696    |
| train/                    |          |
|    explained_variance     | -2.92    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0052   |
|    learning_rate          | 0.001    |
|    n_updates              | 356      |
|    policy_objective       | 0.0201   |
|    value_loss             | 4.27e-10 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 36.4     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 358      |
|    time_elapsed           | 66       |
|    total_timesteps        | 45824    |
| train/                    |          |
|    explained_variance     | -1.61    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00212  |
|    learning_rate          | 0.001    |
|    n_updates              | 357      |
|    policy_objective       | 0.0364   |
|    value_loss             | 9.19e-11 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 36.6     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 359      |
|    time_elapsed           | 66       |
|    total_timesteps        | 45952    |
| train/                    |          |
|    explained_variance     | -1.83    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0057   |
|    learning_rate          | 0.001    |
|    n_updates              | 358      |
|    policy_objective       | 0.0208   |
|    value_loss             | 1.01e-10 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 36.9     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 360      |
|    time_elapsed           | 66       |
|    total_timesteps        | 46080    |
| train/                    |          |
|    explained_variance     | -0.245   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00627  |
|    learning_rate          | 0.001    |
|    n_updates              | 359      |
|    policy_objective       | 0.0312   |
|    value_loss             | 7.18e-11 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 36.2     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 361      |
|    time_elapsed           | 67       |
|    total_timesteps        | 46208    |
| train/                    |          |
|    explained_variance     | -0.996   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00766  |
|    learning_rate          | 0.001    |
|    n_updates              | 360      |
|    policy_objective       | 0.0691   |
|    value_loss             | 1.7e-11  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 36.8     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 362      |
|    time_elapsed           | 67       |
|    total_timesteps        | 46336    |
| train/                    |          |
|    explained_variance     | -0.194   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00833  |
|    learning_rate          | 0.001    |
|    n_updates              | 361      |
|    policy_objective       | 0.0397   |
|    value_loss             | 5.82e-12 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 35.6     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 363      |
|    time_elapsed           | 67       |
|    total_timesteps        | 46464    |
| train/                    |          |
|    explained_variance     | -24      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00811  |
|    learning_rate          | 0.001    |
|    n_updates              | 362      |
|    policy_objective       | 0.0235   |
|    value_loss             | 7.54e-12 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 35.6     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 364      |
|    time_elapsed           | 67       |
|    total_timesteps        | 46592    |
| train/                    |          |
|    explained_variance     | -59.6    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00445  |
|    learning_rate          | 0.001    |
|    n_updates              | 363      |
|    policy_objective       | 0.0468   |
|    value_loss             | 6.41e-08 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 34.7     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 365      |
|    time_elapsed           | 67       |
|    total_timesteps        | 46720    |
| train/                    |          |
|    explained_variance     | -21.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00857  |
|    learning_rate          | 0.001    |
|    n_updates              | 364      |
|    policy_objective       | 0.0119   |
|    value_loss             | 7.13e-10 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 34.8     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 366      |
|    time_elapsed           | 67       |
|    total_timesteps        | 46848    |
| train/                    |          |
|    explained_variance     | -7.59    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00774  |
|    learning_rate          | 0.001    |
|    n_updates              | 365      |
|    policy_objective       | 0.0469   |
|    value_loss             | 1.65e-11 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 35.8     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 367      |
|    time_elapsed           | 68       |
|    total_timesteps        | 46976    |
| train/                    |          |
|    explained_variance     | -1.01    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00491  |
|    learning_rate          | 0.001    |
|    n_updates              | 366      |
|    policy_objective       | 0.0216   |
|    value_loss             | 1.55e-09 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 36       |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 368      |
|    time_elapsed           | 68       |
|    total_timesteps        | 47104    |
| train/                    |          |
|    explained_variance     | -7.2     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00777  |
|    learning_rate          | 0.001    |
|    n_updates              | 367      |
|    policy_objective       | 0.0225   |
|    value_loss             | 4.2e-10  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 35.7     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 369      |
|    time_elapsed           | 68       |
|    total_timesteps        | 47232    |
| train/                    |          |
|    explained_variance     | -4.98    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00709  |
|    learning_rate          | 0.001    |
|    n_updates              | 368      |
|    policy_objective       | 0.0262   |
|    value_loss             | 4.19e-11 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 36.4     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 370      |
|    time_elapsed           | 68       |
|    total_timesteps        | 47360    |
| train/                    |          |
|    explained_variance     | -3.86    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00354  |
|    learning_rate          | 0.001    |
|    n_updates              | 369      |
|    policy_objective       | 0.0253   |
|    value_loss             | 3.39e-11 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 37.5     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 371      |
|    time_elapsed           | 68       |
|    total_timesteps        | 47488    |
| train/                    |          |
|    explained_variance     | -4.28    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00726  |
|    learning_rate          | 0.001    |
|    n_updates              | 370      |
|    policy_objective       | 0.0299   |
|    value_loss             | 6.73e-12 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 37.3     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 372      |
|    time_elapsed           | 69       |
|    total_timesteps        | 47616    |
| train/                    |          |
|    explained_variance     | -5.62    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00481  |
|    learning_rate          | 0.001    |
|    n_updates              | 371      |
|    policy_objective       | 0.0105   |
|    value_loss             | 1.14e-10 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 37.4     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 373      |
|    time_elapsed           | 69       |
|    total_timesteps        | 47744    |
| train/                    |          |
|    explained_variance     | -0.617   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00722  |
|    learning_rate          | 0.001    |
|    n_updates              | 372      |
|    policy_objective       | 0.0406   |
|    value_loss             | 3.22e-11 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 37.2     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 374      |
|    time_elapsed           | 69       |
|    total_timesteps        | 47872    |
| train/                    |          |
|    explained_variance     | -25.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00221  |
|    learning_rate          | 0.001    |
|    n_updates              | 373      |
|    policy_objective       | 0.00532  |
|    value_loss             | 1.19e-09 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 37.5     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 375      |
|    time_elapsed           | 69       |
|    total_timesteps        | 48000    |
| train/                    |          |
|    explained_variance     | -9.45    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00742  |
|    learning_rate          | 0.001    |
|    n_updates              | 374      |
|    policy_objective       | 0.0822   |
|    value_loss             | 1.45e-11 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 38.5     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 376      |
|    time_elapsed           | 69       |
|    total_timesteps        | 48128    |
| train/                    |          |
|    explained_variance     | -3.7     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0076   |
|    learning_rate          | 0.001    |
|    n_updates              | 375      |
|    policy_objective       | 0.035    |
|    value_loss             | 3.56e-11 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 39.3     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 377      |
|    time_elapsed           | 69       |
|    total_timesteps        | 48256    |
| train/                    |          |
|    explained_variance     | -18.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00806  |
|    learning_rate          | 0.001    |
|    n_updates              | 376      |
|    policy_objective       | 0.439    |
|    value_loss             | 8.14e-10 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 39.9     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 378      |
|    time_elapsed           | 70       |
|    total_timesteps        | 48384    |
| train/                    |          |
|    explained_variance     | -20.7    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00698  |
|    learning_rate          | 0.001    |
|    n_updates              | 377      |
|    policy_objective       | 0.053    |
|    value_loss             | 9.28e-11 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 40.9     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 379      |
|    time_elapsed           | 70       |
|    total_timesteps        | 48512    |
| train/                    |          |
|    explained_variance     | -4.57    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00813  |
|    learning_rate          | 0.001    |
|    n_updates              | 378      |
|    policy_objective       | 0.863    |
|    value_loss             | 5.43e-12 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 40.8     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 380      |
|    time_elapsed           | 70       |
|    total_timesteps        | 48640    |
| train/                    |          |
|    explained_variance     | -5.69    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00319  |
|    learning_rate          | 0.001    |
|    n_updates              | 379      |
|    policy_objective       | 0.0268   |
|    value_loss             | 4.43e-12 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 40.2     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 381      |
|    time_elapsed           | 70       |
|    total_timesteps        | 48768    |
| train/                    |          |
|    explained_variance     | -37.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00478  |
|    learning_rate          | 0.001    |
|    n_updates              | 380      |
|    policy_objective       | 0.0221   |
|    value_loss             | 1.02e-11 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 41.3     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 382      |
|    time_elapsed           | 70       |
|    total_timesteps        | 48896    |
| train/                    |          |
|    explained_variance     | -5.81    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00608  |
|    learning_rate          | 0.001    |
|    n_updates              | 381      |
|    policy_objective       | 0.0645   |
|    value_loss             | 1.82e-13 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 41.7     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 383      |
|    time_elapsed           | 71       |
|    total_timesteps        | 49024    |
| train/                    |          |
|    explained_variance     | -80.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00694  |
|    learning_rate          | 0.001    |
|    n_updates              | 382      |
|    policy_objective       | 0.00616  |
|    value_loss             | 3.6e-13  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 41.9     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 384      |
|    time_elapsed           | 71       |
|    total_timesteps        | 49152    |
| train/                    |          |
|    explained_variance     | -11.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00603  |
|    learning_rate          | 0.001    |
|    n_updates              | 383      |
|    policy_objective       | 0.0246   |
|    value_loss             | 5.06e-14 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 43       |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 385      |
|    time_elapsed           | 71       |
|    total_timesteps        | 49280    |
| train/                    |          |
|    explained_variance     | -3.4     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00758  |
|    learning_rate          | 0.001    |
|    n_updates              | 384      |
|    policy_objective       | 0.0212   |
|    value_loss             | 6.27e-15 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 43.6     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 386      |
|    time_elapsed           | 71       |
|    total_timesteps        | 49408    |
| train/                    |          |
|    explained_variance     | -26.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00861  |
|    learning_rate          | 0.001    |
|    n_updates              | 385      |
|    policy_objective       | 0.0137   |
|    value_loss             | 1.98e-14 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 44.4     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 387      |
|    time_elapsed           | 71       |
|    total_timesteps        | 49536    |
| train/                    |          |
|    explained_variance     | -32      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00726  |
|    learning_rate          | 0.001    |
|    n_updates              | 386      |
|    policy_objective       | 0.00404  |
|    value_loss             | 5.1e-14  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 44.1     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 388      |
|    time_elapsed           | 72       |
|    total_timesteps        | 49664    |
| train/                    |          |
|    explained_variance     | -23      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00448  |
|    learning_rate          | 0.001    |
|    n_updates              | 387      |
|    policy_objective       | 0.0083   |
|    value_loss             | 2.79e-14 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 43.9     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 389      |
|    time_elapsed           | 72       |
|    total_timesteps        | 49792    |
| train/                    |          |
|    explained_variance     | -42      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0042   |
|    learning_rate          | 0.001    |
|    n_updates              | 388      |
|    policy_objective       | 0.00422  |
|    value_loss             | 1.01e-15 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 45.2     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 390      |
|    time_elapsed           | 72       |
|    total_timesteps        | 49920    |
| train/                    |          |
|    explained_variance     | -23.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00796  |
|    learning_rate          | 0.001    |
|    n_updates              | 389      |
|    policy_objective       | 0.00806  |
|    value_loss             | 3.38e-17 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 43.6     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 391      |
|    time_elapsed           | 72       |
|    total_timesteps        | 50048    |
| train/                    |          |
|    explained_variance     | -50.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0047   |
|    learning_rate          | 0.001    |
|    n_updates              | 390      |
|    policy_objective       | 0.0107   |
|    value_loss             | 9.91e-16 |
----------------------------------------
wandb: WARNING Symlinked 1 file into the W&B run directory; call wandb.save again to sync new files.
wandb: updating run metadata
wandb: uploading model.zip; uploading output.log; uploading wandb-summary.json
wandb: uploading model.zip; uploading output.log; uploading wandb-summary.json; uploading config.yaml; uploading logs/FrozenLake_8x8_slip_prob_sine_Adaptive_20251218_002919_0/events.out.tfevents.1765993289.hungchan-Precision-7560.447088.0
wandb: uploading output.log; uploading logs/FrozenLake_8x8_slip_prob_sine_Adaptive_20251218_002919_0/events.out.tfevents.1765993289.hungchan-Precision-7560.447088.0
wandb: uploading output.log; uploading logs/FrozenLake_8x8_slip_prob_sine_Adaptive_20251218_002919_0/events.out.tfevents.1765993289.hungchan-Precision-7560.447088.0; uploading history steps 5077-6640, summary, console lines 9288-11351
wandb: uploading data
wandb: 
wandb: Run history:
wandb: adaptive/adaptation_factor â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:           adaptive/base_lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    adaptive/base_target_kl â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:   adaptive/drift_magnitude â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:     adaptive/learning_rate â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         adaptive/target_kl â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:             env/base_value â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:              env/slip_prob â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                global_step â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:        rollout/ep_len_mean â–ƒâ–‚â–â–â–ƒâ–„â–„â–„â–„â–„â–‚â–‚â–ƒâ–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–†â–‡â–†â–…â–…â–…â–…â–…â–„â–„â–ƒâ–ƒâ–‚â–ƒâ–„â–„â–ƒâ–„â–‡â–ˆâ–ˆ
wandb:                         +8 ...
wandb: 
wandb: Run summary:
wandb: adaptive/adaptation_factor 1
wandb:           adaptive/base_lr 0.001
wandb:    adaptive/base_target_kl 0.01
wandb:   adaptive/drift_magnitude 0
wandb:     adaptive/learning_rate 0.001
wandb:         adaptive/target_kl 0.01
wandb:             env/base_value 9.8
wandb:              env/slip_prob 9.8
wandb:                global_step 50048
wandb:        rollout/ep_len_mean 43.63
wandb:                         +8 ...
wandb: 
wandb: ðŸš€ View run FrozenLake_8x8_slip_prob_sine_Adaptive_20251218_002919 at: https://wandb.ai/hungtrab-hanoi-university-of-science-and-technology/FrozenLake_Drift_Research/runs/5r0kengu
wandb: â­ï¸ View project at: https://wandb.ai/hungtrab-hanoi-university-of-science-and-technology/FrozenLake_Drift_Research
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)
wandb: Find logs at: logs/FrozenLake_8x8_slip_prob_sine_Adaptive_20251218_002919/wandb/run-20251218_004128-5r0kengu/logs
>>> [DriftAdaptiveCallback] Training Ended
    Final LR: 0.001000
    Last Drift Magnitude: 0.0000
    Final Target KL: 0.0100
Model saved locally to: models/FrozenLake_8x8_slip_prob_sine_Adaptive_20251218_002919.zip
/home/hungchan/miniconda3/envs/rl_hf_course/lib/python3.10/site-packages/gymnasium/wrappers/rendering.py:293: UserWarning: [33mWARN: Overwriting existing videos at /home/hungchan/Work/Deep-RL/videos/FrozenLake_8x8_slip_prob_sine_Adaptive_20251218_002919 folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)[0m
  logger.warn(
/home/hungchan/miniconda3/envs/rl_hf_course/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run TRPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.
  warnings.warn(
>>> [Wrapper] Initialized Non-Stationary FrozenLake
    - slip_prob: sine (base=0.67)
Loading TRPO model from: models/FrozenLake_8x8_slip_prob_sine_Adaptive_20251218_002919.zip

Recording Episode 1/1...
Traceback (most recent call last):
  File "/home/hungchan/Work/Deep-RL/scripts/render.py", line 179, in <module>
    main()
  File "/home/hungchan/Work/Deep-RL/scripts/render.py", line 168, in main
    record_video(
  File "/home/hungchan/Work/Deep-RL/scripts/render.py", line 137, in record_video
    obs, reward, done, truncated, info = env.step(action)
  File "/home/hungchan/miniconda3/envs/rl_hf_course/lib/python3.10/site-packages/gymnasium/wrappers/rendering.py", line 363, in step
    obs, rew, terminated, truncated, info = self.env.step(action)
  File "/home/hungchan/Work/Deep-RL/scripts/../src/envs/multi_env_wrappers.py", line 378, in step
    obs, reward, terminated, truncated, info = self.env.step(action)
  File "/home/hungchan/miniconda3/envs/rl_hf_course/lib/python3.10/site-packages/gymnasium/wrappers/common.py", line 125, in step
    observation, reward, terminated, truncated, info = self.env.step(action)
  File "/home/hungchan/miniconda3/envs/rl_hf_course/lib/python3.10/site-packages/gymnasium/wrappers/common.py", line 393, in step
    return super().step(action)
  File "/home/hungchan/miniconda3/envs/rl_hf_course/lib/python3.10/site-packages/gymnasium/core.py", line 327, in step
    return self.env.step(action)
  File "/home/hungchan/miniconda3/envs/rl_hf_course/lib/python3.10/site-packages/gymnasium/wrappers/common.py", line 283, in step
    return env_step_passive_checker(self.env, action)
  File "/home/hungchan/miniconda3/envs/rl_hf_course/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py", line 207, in env_step_passive_checker
    result = env.step(action)
  File "/home/hungchan/miniconda3/envs/rl_hf_course/lib/python3.10/site-packages/gymnasium/envs/toy_text/frozen_lake.py", line 325, in step
    transitions = self.P[self.s][a]
TypeError: unhashable type: 'numpy.ndarray'
/home/hungchan/miniconda3/envs/rl_hf_course/lib/python3.10/site-packages/gymnasium/wrappers/rendering.py:434: UserWarning: [33mWARN: Unable to save last video! Did you call close()?[0m
  logger.warn("Unable to save last video! Did you call close()?")
