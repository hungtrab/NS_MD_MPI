wandb: Currently logged in as: hungtrab (hungtrab-hanoi-university-of-science-and-technology) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: setting up run dg4qjod0
wandb: Tracking run with wandb version 0.23.1
wandb: Run data is saved locally in logs/FrozenLake_4x4_slip_prob_linear_Adaptive_20251218_002919/wandb/run-20251218_003607-dg4qjod0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run FrozenLake_4x4_slip_prob_linear_Adaptive_20251218_002919
wandb: â­ï¸ View project at https://wandb.ai/hungtrab-hanoi-university-of-science-and-technology/FrozenLake_Drift_Research
wandb: ðŸš€ View run at https://wandb.ai/hungtrab-hanoi-university-of-science-and-technology/FrozenLake_Drift_Research/runs/dg4qjod0
/home/hungchan/miniconda3/envs/rl_hf_course/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run TRPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.
  warnings.warn(
--- Training Start: FrozenLake_4x4_slip_prob_linear_Adaptive_20251218_002919 ---
>>> [Wrapper] Initialized Non-Stationary FrozenLake
    - slip_prob: linear (base=0.67)
>>> Initializing TRPO with kwargs: ['policy', 'env', 'learning_rate', 'gamma', 'verbose', 'tensorboard_log', 'n_steps', 'batch_size']
Using cuda device
Wrapping the env in a DummyVecEnv.
Logging to logs/FrozenLake_4x4_slip_prob_linear_Adaptive_20251218_002919_0
>>> [DriftAdaptiveCallback] Training Started
    Algorithm: TRPO
    Target Param: slip_prob (base=9.8)
    Scale Factor: 0.2
    
    Adaptive Hyperparameters:
      - Learning Rate: 0.001000
      - Target KL: 0.0100 (adapt=True)
-----------------------------------
| adaptive/            |          |
|    adaptation_factor | 1        |
|    algorithm         | TRPO     |
|    base_lr           | 0.001    |
|    base_target_kl    | 0.01     |
|    drift_magnitude   | 0        |
|    learning_rate     | 0.001    |
|    target_kl         | 0.01     |
| env/                 |          |
|    base_value        | 9.8      |
|    slip_prob         | 9.8      |
| rollout/             |          |
|    ep_len_mean       | 6.63     |
|    ep_rew_mean       | 0        |
| time/                |          |
|    fps               | 393      |
|    iterations        | 1        |
|    time_elapsed      | 0        |
|    total_timesteps   | 128      |
-----------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.92     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 439      |
|    iterations             | 2        |
|    time_elapsed           | 0        |
|    total_timesteps        | 256      |
| train/                    |          |
|    explained_variance     | -53.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00467  |
|    learning_rate          | 0.001    |
|    n_updates              | 1        |
|    policy_objective       | 0.0387   |
|    value_loss             | 0.00171  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.4      |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 507      |
|    iterations             | 3        |
|    time_elapsed           | 0        |
|    total_timesteps        | 384      |
| train/                    |          |
|    explained_variance     | -40.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00255  |
|    learning_rate          | 0.001    |
|    n_updates              | 2        |
|    policy_objective       | 0.0484   |
|    value_loss             | 0.000727 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.85     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 546      |
|    iterations             | 4        |
|    time_elapsed           | 0        |
|    total_timesteps        | 512      |
| train/                    |          |
|    explained_variance     | -39      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00197  |
|    learning_rate          | 0.001    |
|    n_updates              | 3        |
|    policy_objective       | 0.0512   |
|    value_loss             | 0.000143 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.96     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 577      |
|    iterations             | 5        |
|    time_elapsed           | 1        |
|    total_timesteps        | 640      |
| train/                    |          |
|    explained_variance     | -8.78    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00222  |
|    learning_rate          | 0.001    |
|    n_updates              | 4        |
|    policy_objective       | 0.0419   |
|    value_loss             | 1.44e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.23     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 601      |
|    iterations             | 6        |
|    time_elapsed           | 1        |
|    total_timesteps        | 768      |
| train/                    |          |
|    explained_variance     | -106     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00117  |
|    learning_rate          | 0.001    |
|    n_updates              | 5        |
|    policy_objective       | 0.0605   |
|    value_loss             | 7.63e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.22     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 621      |
|    iterations             | 7        |
|    time_elapsed           | 1        |
|    total_timesteps        | 896      |
| train/                    |          |
|    explained_variance     | -15.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00256  |
|    learning_rate          | 0.001    |
|    n_updates              | 6        |
|    policy_objective       | 0.041    |
|    value_loss             | 6.7e-09  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.46     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 634      |
|    iterations             | 8        |
|    time_elapsed           | 1        |
|    total_timesteps        | 1024     |
| train/                    |          |
|    explained_variance     | -12.7    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0064   |
|    learning_rate          | 0.001    |
|    n_updates              | 7        |
|    policy_objective       | 0.064    |
|    value_loss             | 2.51e-10 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.33     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 644      |
|    iterations             | 9        |
|    time_elapsed           | 1        |
|    total_timesteps        | 1152     |
| train/                    |          |
|    explained_variance     | -21.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00184  |
|    learning_rate          | 0.001    |
|    n_updates              | 8        |
|    policy_objective       | 0.07     |
|    value_loss             | 1.23e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.56     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 655      |
|    iterations             | 10       |
|    time_elapsed           | 1        |
|    total_timesteps        | 1280     |
| train/                    |          |
|    explained_variance     | -52.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00367  |
|    learning_rate          | 0.001    |
|    n_updates              | 9        |
|    policy_objective       | 0.022    |
|    value_loss             | 1.1e-08  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.04     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 663      |
|    iterations             | 11       |
|    time_elapsed           | 2        |
|    total_timesteps        | 1408     |
| train/                    |          |
|    explained_variance     | -21.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00426  |
|    learning_rate          | 0.001    |
|    n_updates              | 10       |
|    policy_objective       | 0.0407   |
|    value_loss             | 3.49e-07 |
----------------------------------------
-----------------------------------------
| adaptive/                 |           |
|    adaptation_factor      | 1         |
|    algorithm              | TRPO      |
|    base_lr                | 0.001     |
|    base_target_kl         | 0.01      |
|    drift_magnitude        | 0         |
|    learning_rate          | 0.001     |
|    target_kl              | 0.01      |
| env/                      |           |
|    base_value             | 9.8       |
|    slip_prob              | 9.8       |
| rollout/                  |           |
|    ep_len_mean            | 8.91      |
|    ep_rew_mean            | 0.01      |
| time/                     |           |
|    fps                    | 672       |
|    iterations             | 12        |
|    time_elapsed           | 2         |
|    total_timesteps        | 1536      |
| train/                    |           |
|    explained_variance     | -0.000484 |
|    is_line_search_success | 1         |
|    kl_divergence_loss     | 0.00501   |
|    learning_rate          | 0.001     |
|    n_updates              | 11        |
|    policy_objective       | 0.0685    |
|    value_loss             | 0.0231    |
-----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.87     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 679      |
|    iterations             | 13       |
|    time_elapsed           | 2        |
|    total_timesteps        | 1664     |
| train/                    |          |
|    explained_variance     | -49.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00271  |
|    learning_rate          | 0.001    |
|    n_updates              | 12       |
|    policy_objective       | 0.0546   |
|    value_loss             | 0.00201  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.01     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 684      |
|    iterations             | 14       |
|    time_elapsed           | 2        |
|    total_timesteps        | 1792     |
| train/                    |          |
|    explained_variance     | 0.256    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00397  |
|    learning_rate          | 0.001    |
|    n_updates              | 13       |
|    policy_objective       | 0.0669   |
|    value_loss             | 0.0187   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.71     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 688      |
|    iterations             | 15       |
|    time_elapsed           | 2        |
|    total_timesteps        | 1920     |
| train/                    |          |
|    explained_variance     | -7.18    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00423  |
|    learning_rate          | 0.001    |
|    n_updates              | 14       |
|    policy_objective       | 0.0552   |
|    value_loss             | 0.00557  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.14     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 685      |
|    iterations             | 16       |
|    time_elapsed           | 2        |
|    total_timesteps        | 2048     |
| train/                    |          |
|    explained_variance     | -7.66    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00632  |
|    learning_rate          | 0.001    |
|    n_updates              | 15       |
|    policy_objective       | 0.0519   |
|    value_loss             | 0.000402 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.53     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 687      |
|    iterations             | 17       |
|    time_elapsed           | 3        |
|    total_timesteps        | 2176     |
| train/                    |          |
|    explained_variance     | -0.182   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00309  |
|    learning_rate          | 0.001    |
|    n_updates              | 16       |
|    policy_objective       | 0.0602   |
|    value_loss             | 0.0325   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.25     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 18       |
|    time_elapsed           | 3        |
|    total_timesteps        | 2304     |
| train/                    |          |
|    explained_variance     | -35.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00397  |
|    learning_rate          | 0.001    |
|    n_updates              | 17       |
|    policy_objective       | 0.0446   |
|    value_loss             | 0.00187  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.97     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 692      |
|    iterations             | 19       |
|    time_elapsed           | 3        |
|    total_timesteps        | 2432     |
| train/                    |          |
|    explained_variance     | -14      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00371  |
|    learning_rate          | 0.001    |
|    n_updates              | 18       |
|    policy_objective       | 0.0316   |
|    value_loss             | 0.00133  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.27     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 695      |
|    iterations             | 20       |
|    time_elapsed           | 3        |
|    total_timesteps        | 2560     |
| train/                    |          |
|    explained_variance     | -26.7    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0018   |
|    learning_rate          | 0.001    |
|    n_updates              | 19       |
|    policy_objective       | 0.0636   |
|    value_loss             | 1.9e-05  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.1      |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 690      |
|    iterations             | 21       |
|    time_elapsed           | 3        |
|    total_timesteps        | 2688     |
| train/                    |          |
|    explained_variance     | -11.7    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00381  |
|    learning_rate          | 0.001    |
|    n_updates              | 20       |
|    policy_objective       | 0.0583   |
|    value_loss             | 4.07e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.21     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 22       |
|    time_elapsed           | 4        |
|    total_timesteps        | 2816     |
| train/                    |          |
|    explained_variance     | -41      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00235  |
|    learning_rate          | 0.001    |
|    n_updates              | 21       |
|    policy_objective       | 0.0455   |
|    value_loss             | 4.08e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.39     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 687      |
|    iterations             | 23       |
|    time_elapsed           | 4        |
|    total_timesteps        | 2944     |
| train/                    |          |
|    explained_variance     | -8.57    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00519  |
|    learning_rate          | 0.001    |
|    n_updates              | 22       |
|    policy_objective       | 0.0462   |
|    value_loss             | 4.72e-09 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.77     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 686      |
|    iterations             | 24       |
|    time_elapsed           | 4        |
|    total_timesteps        | 3072     |
| train/                    |          |
|    explained_variance     | -16.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00481  |
|    learning_rate          | 0.001    |
|    n_updates              | 23       |
|    policy_objective       | 0.0573   |
|    value_loss             | 8.45e-11 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.57     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 684      |
|    iterations             | 25       |
|    time_elapsed           | 4        |
|    total_timesteps        | 3200     |
| train/                    |          |
|    explained_variance     | 0.0159   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00299  |
|    learning_rate          | 0.001    |
|    n_updates              | 24       |
|    policy_objective       | 0.0958   |
|    value_loss             | 0.03     |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.35     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 682      |
|    iterations             | 26       |
|    time_elapsed           | 4        |
|    total_timesteps        | 3328     |
| train/                    |          |
|    explained_variance     | 0.279    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00369  |
|    learning_rate          | 0.001    |
|    n_updates              | 25       |
|    policy_objective       | 0.0537   |
|    value_loss             | 0.0313   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.55     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 682      |
|    iterations             | 27       |
|    time_elapsed           | 5        |
|    total_timesteps        | 3456     |
| train/                    |          |
|    explained_variance     | -28.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00326  |
|    learning_rate          | 0.001    |
|    n_updates              | 26       |
|    policy_objective       | 0.054    |
|    value_loss             | 0.00122  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.83     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 683      |
|    iterations             | 28       |
|    time_elapsed           | 5        |
|    total_timesteps        | 3584     |
| train/                    |          |
|    explained_variance     | -14.7    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00499  |
|    learning_rate          | 0.001    |
|    n_updates              | 27       |
|    policy_objective       | 0.035    |
|    value_loss             | 2.49e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.97     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 684      |
|    iterations             | 29       |
|    time_elapsed           | 5        |
|    total_timesteps        | 3712     |
| train/                    |          |
|    explained_variance     | 0.129    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0044   |
|    learning_rate          | 0.001    |
|    n_updates              | 28       |
|    policy_objective       | 0.0507   |
|    value_loss             | 0.0361   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.04     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 686      |
|    iterations             | 30       |
|    time_elapsed           | 5        |
|    total_timesteps        | 3840     |
| train/                    |          |
|    explained_variance     | -6.75    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00495  |
|    learning_rate          | 0.001    |
|    n_updates              | 29       |
|    policy_objective       | 0.0646   |
|    value_loss             | 0.000915 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.82     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 687      |
|    iterations             | 31       |
|    time_elapsed           | 5        |
|    total_timesteps        | 3968     |
| train/                    |          |
|    explained_variance     | -9.16    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00568  |
|    learning_rate          | 0.001    |
|    n_updates              | 30       |
|    policy_objective       | 0.0558   |
|    value_loss             | 5.81e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.81     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 688      |
|    iterations             | 32       |
|    time_elapsed           | 5        |
|    total_timesteps        | 4096     |
| train/                    |          |
|    explained_variance     | -18.6    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00163  |
|    learning_rate          | 0.001    |
|    n_updates              | 31       |
|    policy_objective       | 0.05     |
|    value_loss             | 0.00407  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.87     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 33       |
|    time_elapsed           | 6        |
|    total_timesteps        | 4224     |
| train/                    |          |
|    explained_variance     | -9.95    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00505  |
|    learning_rate          | 0.001    |
|    n_updates              | 32       |
|    policy_objective       | 0.0483   |
|    value_loss             | 4.9e-05  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.28     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 687      |
|    iterations             | 34       |
|    time_elapsed           | 6        |
|    total_timesteps        | 4352     |
| train/                    |          |
|    explained_variance     | -22.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00248  |
|    learning_rate          | 0.001    |
|    n_updates              | 33       |
|    policy_objective       | 0.0597   |
|    value_loss             | 7.66e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.93     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 687      |
|    iterations             | 35       |
|    time_elapsed           | 6        |
|    total_timesteps        | 4480     |
| train/                    |          |
|    explained_variance     | -166     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0019   |
|    learning_rate          | 0.001    |
|    n_updates              | 34       |
|    policy_objective       | 0.0277   |
|    value_loss             | 4.73e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.28     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 687      |
|    iterations             | 36       |
|    time_elapsed           | 6        |
|    total_timesteps        | 4608     |
| train/                    |          |
|    explained_variance     | -67.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00303  |
|    learning_rate          | 0.001    |
|    n_updates              | 35       |
|    policy_objective       | 0.0378   |
|    value_loss             | 2.94e-09 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.43     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 37       |
|    time_elapsed           | 6        |
|    total_timesteps        | 4736     |
| train/                    |          |
|    explained_variance     | -30.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.000893 |
|    learning_rate          | 0.001    |
|    n_updates              | 36       |
|    policy_objective       | 0.0695   |
|    value_loss             | 2.77e-10 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.22     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 690      |
|    iterations             | 38       |
|    time_elapsed           | 7        |
|    total_timesteps        | 4864     |
| train/                    |          |
|    explained_variance     | -33.7    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00174  |
|    learning_rate          | 0.001    |
|    n_updates              | 37       |
|    policy_objective       | 0.0671   |
|    value_loss             | 5.79e-12 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.56     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 691      |
|    iterations             | 39       |
|    time_elapsed           | 7        |
|    total_timesteps        | 4992     |
| train/                    |          |
|    explained_variance     | 0.196    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00501  |
|    learning_rate          | 0.001    |
|    n_updates              | 38       |
|    policy_objective       | 0.0897   |
|    value_loss             | 0.0277   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.1      |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 691      |
|    iterations             | 40       |
|    time_elapsed           | 7        |
|    total_timesteps        | 5120     |
| train/                    |          |
|    explained_variance     | -31.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00444  |
|    learning_rate          | 0.001    |
|    n_updates              | 39       |
|    policy_objective       | 0.0461   |
|    value_loss             | 0.000388 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.22     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 692      |
|    iterations             | 41       |
|    time_elapsed           | 7        |
|    total_timesteps        | 5248     |
| train/                    |          |
|    explained_variance     | -72.6    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.000743 |
|    learning_rate          | 0.001    |
|    n_updates              | 40       |
|    policy_objective       | 0.0458   |
|    value_loss             | 0.00132  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.5      |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 693      |
|    iterations             | 42       |
|    time_elapsed           | 7        |
|    total_timesteps        | 5376     |
| train/                    |          |
|    explained_variance     | -66.7    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00378  |
|    learning_rate          | 0.001    |
|    n_updates              | 41       |
|    policy_objective       | 0.0466   |
|    value_loss             | 0.0013   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.88     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 693      |
|    iterations             | 43       |
|    time_elapsed           | 7        |
|    total_timesteps        | 5504     |
| train/                    |          |
|    explained_variance     | -19.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0056   |
|    learning_rate          | 0.001    |
|    n_updates              | 42       |
|    policy_objective       | 0.0553   |
|    value_loss             | 2.08e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.35     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 694      |
|    iterations             | 44       |
|    time_elapsed           | 8        |
|    total_timesteps        | 5632     |
| train/                    |          |
|    explained_variance     | -50.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00395  |
|    learning_rate          | 0.001    |
|    n_updates              | 43       |
|    policy_objective       | 0.0334   |
|    value_loss             | 0.00166  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.67     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 692      |
|    iterations             | 45       |
|    time_elapsed           | 8        |
|    total_timesteps        | 5760     |
| train/                    |          |
|    explained_variance     | -22.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00448  |
|    learning_rate          | 0.001    |
|    n_updates              | 44       |
|    policy_objective       | 0.0176   |
|    value_loss             | 0.00241  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.03     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 693      |
|    iterations             | 46       |
|    time_elapsed           | 8        |
|    total_timesteps        | 5888     |
| train/                    |          |
|    explained_variance     | -25      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00343  |
|    learning_rate          | 0.001    |
|    n_updates              | 45       |
|    policy_objective       | 0.0715   |
|    value_loss             | 2.19e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.12     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 693      |
|    iterations             | 47       |
|    time_elapsed           | 8        |
|    total_timesteps        | 6016     |
| train/                    |          |
|    explained_variance     | -19.6    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00411  |
|    learning_rate          | 0.001    |
|    n_updates              | 46       |
|    policy_objective       | 0.0592   |
|    value_loss             | 4.62e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.36     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 694      |
|    iterations             | 48       |
|    time_elapsed           | 8        |
|    total_timesteps        | 6144     |
| train/                    |          |
|    explained_variance     | -0.0117  |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00503  |
|    learning_rate          | 0.001    |
|    n_updates              | 47       |
|    policy_objective       | 0.0578   |
|    value_loss             | 0.0616   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.16     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 695      |
|    iterations             | 49       |
|    time_elapsed           | 9        |
|    total_timesteps        | 6272     |
| train/                    |          |
|    explained_variance     | 0.506    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00684  |
|    learning_rate          | 0.001    |
|    n_updates              | 48       |
|    policy_objective       | 0.0588   |
|    value_loss             | 0.0247   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.09     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 695      |
|    iterations             | 50       |
|    time_elapsed           | 9        |
|    total_timesteps        | 6400     |
| train/                    |          |
|    explained_variance     | -40.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00405  |
|    learning_rate          | 0.001    |
|    n_updates              | 49       |
|    policy_objective       | 0.0472   |
|    value_loss             | 0.00556  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.13     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 696      |
|    iterations             | 51       |
|    time_elapsed           | 9        |
|    total_timesteps        | 6528     |
| train/                    |          |
|    explained_variance     | -25.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00209  |
|    learning_rate          | 0.001    |
|    n_updates              | 50       |
|    policy_objective       | 0.0603   |
|    value_loss             | 0.000142 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.27     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 696      |
|    iterations             | 52       |
|    time_elapsed           | 9        |
|    total_timesteps        | 6656     |
| train/                    |          |
|    explained_variance     | -49.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00349  |
|    learning_rate          | 0.001    |
|    n_updates              | 51       |
|    policy_objective       | 0.0596   |
|    value_loss             | 8.53e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.31     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 697      |
|    iterations             | 53       |
|    time_elapsed           | 9        |
|    total_timesteps        | 6784     |
| train/                    |          |
|    explained_variance     | -26.6    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00354  |
|    learning_rate          | 0.001    |
|    n_updates              | 52       |
|    policy_objective       | 0.0386   |
|    value_loss             | 0.00302  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.08     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 697      |
|    iterations             | 54       |
|    time_elapsed           | 9        |
|    total_timesteps        | 6912     |
| train/                    |          |
|    explained_variance     | -9.04    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00406  |
|    learning_rate          | 0.001    |
|    n_updates              | 53       |
|    policy_objective       | 0.0621   |
|    value_loss             | 3.65e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.64     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 694      |
|    iterations             | 55       |
|    time_elapsed           | 10       |
|    total_timesteps        | 7040     |
| train/                    |          |
|    explained_variance     | -3.68    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00491  |
|    learning_rate          | 0.001    |
|    n_updates              | 54       |
|    policy_objective       | 0.062    |
|    value_loss             | 1.05e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.7      |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 695      |
|    iterations             | 56       |
|    time_elapsed           | 10       |
|    total_timesteps        | 7168     |
| train/                    |          |
|    explained_variance     | -10.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00679  |
|    learning_rate          | 0.001    |
|    n_updates              | 55       |
|    policy_objective       | 0.0524   |
|    value_loss             | 4.47e-08 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.88     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 696      |
|    iterations             | 57       |
|    time_elapsed           | 10       |
|    total_timesteps        | 7296     |
| train/                    |          |
|    explained_variance     | -2.14    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00572  |
|    learning_rate          | 0.001    |
|    n_updates              | 56       |
|    policy_objective       | 0.0351   |
|    value_loss             | 2.5e-09  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.45     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 697      |
|    iterations             | 58       |
|    time_elapsed           | 10       |
|    total_timesteps        | 7424     |
| train/                    |          |
|    explained_variance     | -17.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00382  |
|    learning_rate          | 0.001    |
|    n_updates              | 57       |
|    policy_objective       | 0.0395   |
|    value_loss             | 0.00236  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.97     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 697      |
|    iterations             | 59       |
|    time_elapsed           | 10       |
|    total_timesteps        | 7552     |
| train/                    |          |
|    explained_variance     | 0.00757  |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00574  |
|    learning_rate          | 0.001    |
|    n_updates              | 58       |
|    policy_objective       | 0.0448   |
|    value_loss             | 0.0461   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.66     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 697      |
|    iterations             | 60       |
|    time_elapsed           | 11       |
|    total_timesteps        | 7680     |
| train/                    |          |
|    explained_variance     | 0.657    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00502  |
|    learning_rate          | 0.001    |
|    n_updates              | 59       |
|    policy_objective       | 0.0681   |
|    value_loss             | 0.0107   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.92     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 697      |
|    iterations             | 61       |
|    time_elapsed           | 11       |
|    total_timesteps        | 7808     |
| train/                    |          |
|    explained_variance     | -42.7    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00299  |
|    learning_rate          | 0.001    |
|    n_updates              | 60       |
|    policy_objective       | 0.0466   |
|    value_loss             | 0.00365  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.14     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 698      |
|    iterations             | 62       |
|    time_elapsed           | 11       |
|    total_timesteps        | 7936     |
| train/                    |          |
|    explained_variance     | 0.245    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0041   |
|    learning_rate          | 0.001    |
|    n_updates              | 61       |
|    policy_objective       | 0.0969   |
|    value_loss             | 0.0236   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.05     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 698      |
|    iterations             | 63       |
|    time_elapsed           | 11       |
|    total_timesteps        | 8064     |
| train/                    |          |
|    explained_variance     | -49.7    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00207  |
|    learning_rate          | 0.001    |
|    n_updates              | 62       |
|    policy_objective       | 0.0611   |
|    value_loss             | 0.00654  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.92     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 698      |
|    iterations             | 64       |
|    time_elapsed           | 11       |
|    total_timesteps        | 8192     |
| train/                    |          |
|    explained_variance     | -67      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00279  |
|    learning_rate          | 0.001    |
|    n_updates              | 63       |
|    policy_objective       | 0.0615   |
|    value_loss             | 0.000358 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.48     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 699      |
|    iterations             | 65       |
|    time_elapsed           | 11       |
|    total_timesteps        | 8320     |
| train/                    |          |
|    explained_variance     | -92      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.003    |
|    learning_rate          | 0.001    |
|    n_updates              | 64       |
|    policy_objective       | 0.0443   |
|    value_loss             | 0.000113 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.61     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 700      |
|    iterations             | 66       |
|    time_elapsed           | 12       |
|    total_timesteps        | 8448     |
| train/                    |          |
|    explained_variance     | -28.6    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00232  |
|    learning_rate          | 0.001    |
|    n_updates              | 65       |
|    policy_objective       | 0.0399   |
|    value_loss             | 0.00108  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.72     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 700      |
|    iterations             | 67       |
|    time_elapsed           | 12       |
|    total_timesteps        | 8576     |
| train/                    |          |
|    explained_variance     | -30.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00151  |
|    learning_rate          | 0.001    |
|    n_updates              | 66       |
|    policy_objective       | 0.0493   |
|    value_loss             | 0.000109 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.24     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 701      |
|    iterations             | 68       |
|    time_elapsed           | 12       |
|    total_timesteps        | 8704     |
| train/                    |          |
|    explained_variance     | -52.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0041   |
|    learning_rate          | 0.001    |
|    n_updates              | 67       |
|    policy_objective       | 0.0718   |
|    value_loss             | 1.73e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.97     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 702      |
|    iterations             | 69       |
|    time_elapsed           | 12       |
|    total_timesteps        | 8832     |
| train/                    |          |
|    explained_variance     | -9.5     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00438  |
|    learning_rate          | 0.001    |
|    n_updates              | 68       |
|    policy_objective       | 0.0773   |
|    value_loss             | 2.17e-08 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.49     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 702      |
|    iterations             | 70       |
|    time_elapsed           | 12       |
|    total_timesteps        | 8960     |
| train/                    |          |
|    explained_variance     | -93.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00217  |
|    learning_rate          | 0.001    |
|    n_updates              | 69       |
|    policy_objective       | 0.0504   |
|    value_loss             | 1.17e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.44     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 703      |
|    iterations             | 71       |
|    time_elapsed           | 12       |
|    total_timesteps        | 9088     |
| train/                    |          |
|    explained_variance     | -45.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00248  |
|    learning_rate          | 0.001    |
|    n_updates              | 70       |
|    policy_objective       | 0.0432   |
|    value_loss             | 4e-07    |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.66     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 703      |
|    iterations             | 72       |
|    time_elapsed           | 13       |
|    total_timesteps        | 9216     |
| train/                    |          |
|    explained_variance     | -60.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00158  |
|    learning_rate          | 0.001    |
|    n_updates              | 71       |
|    policy_objective       | 0.0378   |
|    value_loss             | 4.83e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.66     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 73       |
|    time_elapsed           | 13       |
|    total_timesteps        | 9344     |
| train/                    |          |
|    explained_variance     | -30.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00165  |
|    learning_rate          | 0.001    |
|    n_updates              | 72       |
|    policy_objective       | 0.0894   |
|    value_loss             | 3.65e-08 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.1      |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 74       |
|    time_elapsed           | 13       |
|    total_timesteps        | 9472     |
| train/                    |          |
|    explained_variance     | -87.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.000752 |
|    learning_rate          | 0.001    |
|    n_updates              | 73       |
|    policy_objective       | 0.0703   |
|    value_loss             | 3.05e-08 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.36     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 705      |
|    iterations             | 75       |
|    time_elapsed           | 13       |
|    total_timesteps        | 9600     |
| train/                    |          |
|    explained_variance     | -37.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00395  |
|    learning_rate          | 0.001    |
|    n_updates              | 74       |
|    policy_objective       | 0.0559   |
|    value_loss             | 9.65e-11 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.78     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 705      |
|    iterations             | 76       |
|    time_elapsed           | 13       |
|    total_timesteps        | 9728     |
| train/                    |          |
|    explained_variance     | -48      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0039   |
|    learning_rate          | 0.001    |
|    n_updates              | 75       |
|    policy_objective       | 0.0714   |
|    value_loss             | 4.77e-12 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.5      |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 705      |
|    iterations             | 77       |
|    time_elapsed           | 13       |
|    total_timesteps        | 9856     |
| train/                    |          |
|    explained_variance     | -49      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00253  |
|    learning_rate          | 0.001    |
|    n_updates              | 76       |
|    policy_objective       | 0.0768   |
|    value_loss             | 6.69e-13 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.39     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 705      |
|    iterations             | 78       |
|    time_elapsed           | 14       |
|    total_timesteps        | 9984     |
| train/                    |          |
|    explained_variance     | -54.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00293  |
|    learning_rate          | 0.001    |
|    n_updates              | 77       |
|    policy_objective       | 0.0214   |
|    value_loss             | 7.88e-14 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.56     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 705      |
|    iterations             | 79       |
|    time_elapsed           | 14       |
|    total_timesteps        | 10112    |
| train/                    |          |
|    explained_variance     | -60.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0022   |
|    learning_rate          | 0.001    |
|    n_updates              | 78       |
|    policy_objective       | 0.0438   |
|    value_loss             | 2.47e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.02     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 705      |
|    iterations             | 80       |
|    time_elapsed           | 14       |
|    total_timesteps        | 10240    |
| train/                    |          |
|    explained_variance     | -178     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00592  |
|    learning_rate          | 0.001    |
|    n_updates              | 79       |
|    policy_objective       | 0.09     |
|    value_loss             | 1.68e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.29     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 705      |
|    iterations             | 81       |
|    time_elapsed           | 14       |
|    total_timesteps        | 10368    |
| train/                    |          |
|    explained_variance     | -67.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00295  |
|    learning_rate          | 0.001    |
|    n_updates              | 80       |
|    policy_objective       | 0.0773   |
|    value_loss             | 3.59e-09 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.48     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 706      |
|    iterations             | 82       |
|    time_elapsed           | 14       |
|    total_timesteps        | 10496    |
| train/                    |          |
|    explained_variance     | 0.0149   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00352  |
|    learning_rate          | 0.001    |
|    n_updates              | 81       |
|    policy_objective       | 0.059    |
|    value_loss             | 0.0328   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.64     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 706      |
|    iterations             | 83       |
|    time_elapsed           | 15       |
|    total_timesteps        | 10624    |
| train/                    |          |
|    explained_variance     | -19.7    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00312  |
|    learning_rate          | 0.001    |
|    n_updates              | 82       |
|    policy_objective       | 0.0817   |
|    value_loss             | 0.00599  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.33     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 705      |
|    iterations             | 84       |
|    time_elapsed           | 15       |
|    total_timesteps        | 10752    |
| train/                    |          |
|    explained_variance     | 0.047    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00586  |
|    learning_rate          | 0.001    |
|    n_updates              | 83       |
|    policy_objective       | 0.0764   |
|    value_loss             | 0.104    |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.37     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 706      |
|    iterations             | 85       |
|    time_elapsed           | 15       |
|    total_timesteps        | 10880    |
| train/                    |          |
|    explained_variance     | -13.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00398  |
|    learning_rate          | 0.001    |
|    n_updates              | 84       |
|    policy_objective       | 0.0528   |
|    value_loss             | 0.00543  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.93     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 706      |
|    iterations             | 86       |
|    time_elapsed           | 15       |
|    total_timesteps        | 11008    |
| train/                    |          |
|    explained_variance     | -33.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00445  |
|    learning_rate          | 0.001    |
|    n_updates              | 85       |
|    policy_objective       | 0.0713   |
|    value_loss             | 0.00124  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7        |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 706      |
|    iterations             | 87       |
|    time_elapsed           | 15       |
|    total_timesteps        | 11136    |
| train/                    |          |
|    explained_variance     | -13.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00301  |
|    learning_rate          | 0.001    |
|    n_updates              | 86       |
|    policy_objective       | 0.0656   |
|    value_loss             | 0.00167  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.18     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 707      |
|    iterations             | 88       |
|    time_elapsed           | 15       |
|    total_timesteps        | 11264    |
| train/                    |          |
|    explained_variance     | -15      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00542  |
|    learning_rate          | 0.001    |
|    n_updates              | 87       |
|    policy_objective       | 0.0653   |
|    value_loss             | 1.76e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.46     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 707      |
|    iterations             | 89       |
|    time_elapsed           | 16       |
|    total_timesteps        | 11392    |
| train/                    |          |
|    explained_variance     | 0.0356   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00405  |
|    learning_rate          | 0.001    |
|    n_updates              | 88       |
|    policy_objective       | 0.0553   |
|    value_loss             | 0.026    |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.57     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 706      |
|    iterations             | 90       |
|    time_elapsed           | 16       |
|    total_timesteps        | 11520    |
| train/                    |          |
|    explained_variance     | 0.48     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00548  |
|    learning_rate          | 0.001    |
|    n_updates              | 89       |
|    policy_objective       | 0.0362   |
|    value_loss             | 0.0326   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.8      |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 706      |
|    iterations             | 91       |
|    time_elapsed           | 16       |
|    total_timesteps        | 11648    |
| train/                    |          |
|    explained_variance     | -34.7    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00525  |
|    learning_rate          | 0.001    |
|    n_updates              | 90       |
|    policy_objective       | 0.0505   |
|    value_loss             | 0.00358  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.77     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 706      |
|    iterations             | 92       |
|    time_elapsed           | 16       |
|    total_timesteps        | 11776    |
| train/                    |          |
|    explained_variance     | -41.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00134  |
|    learning_rate          | 0.001    |
|    n_updates              | 91       |
|    policy_objective       | 0.0622   |
|    value_loss             | 0.000414 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.07     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 706      |
|    iterations             | 93       |
|    time_elapsed           | 16       |
|    total_timesteps        | 11904    |
| train/                    |          |
|    explained_variance     | -67.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00165  |
|    learning_rate          | 0.001    |
|    n_updates              | 92       |
|    policy_objective       | 0.0684   |
|    value_loss             | 0.000124 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.36     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 706      |
|    iterations             | 94       |
|    time_elapsed           | 17       |
|    total_timesteps        | 12032    |
| train/                    |          |
|    explained_variance     | -39.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00245  |
|    learning_rate          | 0.001    |
|    n_updates              | 93       |
|    policy_objective       | 0.0507   |
|    value_loss             | 5.2e-07  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.51     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 707      |
|    iterations             | 95       |
|    time_elapsed           | 17       |
|    total_timesteps        | 12160    |
| train/                    |          |
|    explained_variance     | 0.238    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00558  |
|    learning_rate          | 0.001    |
|    n_updates              | 94       |
|    policy_objective       | 0.0466   |
|    value_loss             | 0.0287   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.96     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 707      |
|    iterations             | 96       |
|    time_elapsed           | 17       |
|    total_timesteps        | 12288    |
| train/                    |          |
|    explained_variance     | -0.264   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00555  |
|    learning_rate          | 0.001    |
|    n_updates              | 95       |
|    policy_objective       | 0.0433   |
|    value_loss             | 0.0462   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.13     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 707      |
|    iterations             | 97       |
|    time_elapsed           | 17       |
|    total_timesteps        | 12416    |
| train/                    |          |
|    explained_variance     | -22.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00475  |
|    learning_rate          | 0.001    |
|    n_updates              | 96       |
|    policy_objective       | 0.0548   |
|    value_loss             | 0.00613  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.2      |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 707      |
|    iterations             | 98       |
|    time_elapsed           | 17       |
|    total_timesteps        | 12544    |
| train/                    |          |
|    explained_variance     | -14.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00595  |
|    learning_rate          | 0.001    |
|    n_updates              | 97       |
|    policy_objective       | 0.0579   |
|    value_loss             | 0.00319  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.04     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 707      |
|    iterations             | 99       |
|    time_elapsed           | 17       |
|    total_timesteps        | 12672    |
| train/                    |          |
|    explained_variance     | -13.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00314  |
|    learning_rate          | 0.001    |
|    n_updates              | 98       |
|    policy_objective       | 0.0337   |
|    value_loss             | 0.000165 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.56     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 708      |
|    iterations             | 100      |
|    time_elapsed           | 18       |
|    total_timesteps        | 12800    |
| train/                    |          |
|    explained_variance     | -0.0126  |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00323  |
|    learning_rate          | 0.001    |
|    n_updates              | 99       |
|    policy_objective       | 0.0743   |
|    value_loss             | 0.037    |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.27     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 708      |
|    iterations             | 101      |
|    time_elapsed           | 18       |
|    total_timesteps        | 12928    |
| train/                    |          |
|    explained_variance     | -0.414   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00581  |
|    learning_rate          | 0.001    |
|    n_updates              | 100      |
|    policy_objective       | 0.0671   |
|    value_loss             | 0.0477   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.45     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 708      |
|    iterations             | 102      |
|    time_elapsed           | 18       |
|    total_timesteps        | 13056    |
| train/                    |          |
|    explained_variance     | -0.327   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00439  |
|    learning_rate          | 0.001    |
|    n_updates              | 101      |
|    policy_objective       | 0.0573   |
|    value_loss             | 0.00934  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.06     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 708      |
|    iterations             | 103      |
|    time_elapsed           | 18       |
|    total_timesteps        | 13184    |
| train/                    |          |
|    explained_variance     | -7.89    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00257  |
|    learning_rate          | 0.001    |
|    n_updates              | 102      |
|    policy_objective       | 0.0456   |
|    value_loss             | 0.00119  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.18     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 708      |
|    iterations             | 104      |
|    time_elapsed           | 18       |
|    total_timesteps        | 13312    |
| train/                    |          |
|    explained_variance     | -10.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00334  |
|    learning_rate          | 0.001    |
|    n_updates              | 103      |
|    policy_objective       | 0.053    |
|    value_loss             | 0.00163  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.22     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 708      |
|    iterations             | 105      |
|    time_elapsed           | 18       |
|    total_timesteps        | 13440    |
| train/                    |          |
|    explained_variance     | 0.0209   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00591  |
|    learning_rate          | 0.001    |
|    n_updates              | 104      |
|    policy_objective       | 0.0859   |
|    value_loss             | 0.0494   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.25     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 708      |
|    iterations             | 106      |
|    time_elapsed           | 19       |
|    total_timesteps        | 13568    |
| train/                    |          |
|    explained_variance     | -13.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00618  |
|    learning_rate          | 0.001    |
|    n_updates              | 105      |
|    policy_objective       | 0.0526   |
|    value_loss             | 0.00186  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.22     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 708      |
|    iterations             | 107      |
|    time_elapsed           | 19       |
|    total_timesteps        | 13696    |
| train/                    |          |
|    explained_variance     | 0.184    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00568  |
|    learning_rate          | 0.001    |
|    n_updates              | 106      |
|    policy_objective       | 0.0755   |
|    value_loss             | 0.026    |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.42     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 708      |
|    iterations             | 108      |
|    time_elapsed           | 19       |
|    total_timesteps        | 13824    |
| train/                    |          |
|    explained_variance     | 0.0572   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00482  |
|    learning_rate          | 0.001    |
|    n_updates              | 107      |
|    policy_objective       | 0.0475   |
|    value_loss             | 0.00149  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.52     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 708      |
|    iterations             | 109      |
|    time_elapsed           | 19       |
|    total_timesteps        | 13952    |
| train/                    |          |
|    explained_variance     | -22.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00433  |
|    learning_rate          | 0.001    |
|    n_updates              | 108      |
|    policy_objective       | 0.0498   |
|    value_loss             | 0.0071   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.93     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 708      |
|    iterations             | 110      |
|    time_elapsed           | 19       |
|    total_timesteps        | 14080    |
| train/                    |          |
|    explained_variance     | -7.35    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00601  |
|    learning_rate          | 0.001    |
|    n_updates              | 109      |
|    policy_objective       | 0.0901   |
|    value_loss             | 0.000181 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.94     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 708      |
|    iterations             | 111      |
|    time_elapsed           | 20       |
|    total_timesteps        | 14208    |
| train/                    |          |
|    explained_variance     | -29.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00387  |
|    learning_rate          | 0.001    |
|    n_updates              | 110      |
|    policy_objective       | 0.0506   |
|    value_loss             | 0.000423 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.44     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 708      |
|    iterations             | 112      |
|    time_elapsed           | 20       |
|    total_timesteps        | 14336    |
| train/                    |          |
|    explained_variance     | -59.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00246  |
|    learning_rate          | 0.001    |
|    n_updates              | 111      |
|    policy_objective       | 0.0832   |
|    value_loss             | 7.7e-05  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.58     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 708      |
|    iterations             | 113      |
|    time_elapsed           | 20       |
|    total_timesteps        | 14464    |
| train/                    |          |
|    explained_variance     | -61.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00432  |
|    learning_rate          | 0.001    |
|    n_updates              | 112      |
|    policy_objective       | 0.08     |
|    value_loss             | 9.62e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.66     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 708      |
|    iterations             | 114      |
|    time_elapsed           | 20       |
|    total_timesteps        | 14592    |
| train/                    |          |
|    explained_variance     | -6.49    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00591  |
|    learning_rate          | 0.001    |
|    n_updates              | 113      |
|    policy_objective       | 0.0261   |
|    value_loss             | 3.22e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.39     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 708      |
|    iterations             | 115      |
|    time_elapsed           | 20       |
|    total_timesteps        | 14720    |
| train/                    |          |
|    explained_variance     | -52.7    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00275  |
|    learning_rate          | 0.001    |
|    n_updates              | 114      |
|    policy_objective       | 0.0267   |
|    value_loss             | 3.87e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.76     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 708      |
|    iterations             | 116      |
|    time_elapsed           | 20       |
|    total_timesteps        | 14848    |
| train/                    |          |
|    explained_variance     | -51.7    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00268  |
|    learning_rate          | 0.001    |
|    n_updates              | 115      |
|    policy_objective       | 0.0421   |
|    value_loss             | 1.5e-06  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.11     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 708      |
|    iterations             | 117      |
|    time_elapsed           | 21       |
|    total_timesteps        | 14976    |
| train/                    |          |
|    explained_variance     | -1.96    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00398  |
|    learning_rate          | 0.001    |
|    n_updates              | 116      |
|    policy_objective       | 0.0404   |
|    value_loss             | 1.54e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.62     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 708      |
|    iterations             | 118      |
|    time_elapsed           | 21       |
|    total_timesteps        | 15104    |
| train/                    |          |
|    explained_variance     | -47.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00277  |
|    learning_rate          | 0.001    |
|    n_updates              | 117      |
|    policy_objective       | 0.07     |
|    value_loss             | 0.000179 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.89     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 708      |
|    iterations             | 119      |
|    time_elapsed           | 21       |
|    total_timesteps        | 15232    |
| train/                    |          |
|    explained_variance     | -19.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00412  |
|    learning_rate          | 0.001    |
|    n_updates              | 118      |
|    policy_objective       | 0.0905   |
|    value_loss             | 0.000183 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.66     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 708      |
|    iterations             | 120      |
|    time_elapsed           | 21       |
|    total_timesteps        | 15360    |
| train/                    |          |
|    explained_variance     | -81.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00814  |
|    learning_rate          | 0.001    |
|    n_updates              | 119      |
|    policy_objective       | 0.0519   |
|    value_loss             | 1e-05    |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.43     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 709      |
|    iterations             | 121      |
|    time_elapsed           | 21       |
|    total_timesteps        | 15488    |
| train/                    |          |
|    explained_variance     | -57.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00163  |
|    learning_rate          | 0.001    |
|    n_updates              | 120      |
|    policy_objective       | 0.0725   |
|    value_loss             | 1.48e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.9      |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 709      |
|    iterations             | 122      |
|    time_elapsed           | 22       |
|    total_timesteps        | 15616    |
| train/                    |          |
|    explained_variance     | -49.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00196  |
|    learning_rate          | 0.001    |
|    n_updates              | 121      |
|    policy_objective       | 0.0264   |
|    value_loss             | 3.05e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.1      |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 708      |
|    iterations             | 123      |
|    time_elapsed           | 22       |
|    total_timesteps        | 15744    |
| train/                    |          |
|    explained_variance     | -16.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00152  |
|    learning_rate          | 0.001    |
|    n_updates              | 122      |
|    policy_objective       | 0.056    |
|    value_loss             | 2.07e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.49     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 709      |
|    iterations             | 124      |
|    time_elapsed           | 22       |
|    total_timesteps        | 15872    |
| train/                    |          |
|    explained_variance     | -8.34    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00666  |
|    learning_rate          | 0.001    |
|    n_updates              | 123      |
|    policy_objective       | 0.0653   |
|    value_loss             | 8.64e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.4      |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 709      |
|    iterations             | 125      |
|    time_elapsed           | 22       |
|    total_timesteps        | 16000    |
| train/                    |          |
|    explained_variance     | -10.6    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00393  |
|    learning_rate          | 0.001    |
|    n_updates              | 124      |
|    policy_objective       | 0.0319   |
|    value_loss             | 6.02e-08 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.83     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 709      |
|    iterations             | 126      |
|    time_elapsed           | 22       |
|    total_timesteps        | 16128    |
| train/                    |          |
|    explained_variance     | -86.6    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.004    |
|    learning_rate          | 0.001    |
|    n_updates              | 125      |
|    policy_objective       | 0.0202   |
|    value_loss             | 2.4e-07  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.42     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 709      |
|    iterations             | 127      |
|    time_elapsed           | 22       |
|    total_timesteps        | 16256    |
| train/                    |          |
|    explained_variance     | -26.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00367  |
|    learning_rate          | 0.001    |
|    n_updates              | 126      |
|    policy_objective       | 0.0573   |
|    value_loss             | 3.73e-09 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.43     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 709      |
|    iterations             | 128      |
|    time_elapsed           | 23       |
|    total_timesteps        | 16384    |
| train/                    |          |
|    explained_variance     | 0.00186  |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00638  |
|    learning_rate          | 0.001    |
|    n_updates              | 127      |
|    policy_objective       | 0.0503   |
|    value_loss             | 0.0496   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.63     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 709      |
|    iterations             | 129      |
|    time_elapsed           | 23       |
|    total_timesteps        | 16512    |
| train/                    |          |
|    explained_variance     | -9.2     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00618  |
|    learning_rate          | 0.001    |
|    n_updates              | 128      |
|    policy_objective       | 0.0538   |
|    value_loss             | 0.00351  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.58     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 709      |
|    iterations             | 130      |
|    time_elapsed           | 23       |
|    total_timesteps        | 16640    |
| train/                    |          |
|    explained_variance     | -4.42    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00657  |
|    learning_rate          | 0.001    |
|    n_updates              | 129      |
|    policy_objective       | 0.0249   |
|    value_loss             | 0.000173 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.9      |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 710      |
|    iterations             | 131      |
|    time_elapsed           | 23       |
|    total_timesteps        | 16768    |
| train/                    |          |
|    explained_variance     | 0.259    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00633  |
|    learning_rate          | 0.001    |
|    n_updates              | 130      |
|    policy_objective       | 0.0728   |
|    value_loss             | 0.0301   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.67     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 710      |
|    iterations             | 132      |
|    time_elapsed           | 23       |
|    total_timesteps        | 16896    |
| train/                    |          |
|    explained_variance     | 0.166    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00764  |
|    learning_rate          | 0.001    |
|    n_updates              | 131      |
|    policy_objective       | 0.0615   |
|    value_loss             | 0.0482   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.69     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 710      |
|    iterations             | 133      |
|    time_elapsed           | 23       |
|    total_timesteps        | 17024    |
| train/                    |          |
|    explained_variance     | 0.26     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00593  |
|    learning_rate          | 0.001    |
|    n_updates              | 132      |
|    policy_objective       | 0.103    |
|    value_loss             | 0.0277   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.58     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 710      |
|    iterations             | 134      |
|    time_elapsed           | 24       |
|    total_timesteps        | 17152    |
| train/                    |          |
|    explained_variance     | -3.72    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00493  |
|    learning_rate          | 0.001    |
|    n_updates              | 133      |
|    policy_objective       | 0.0585   |
|    value_loss             | 0.0312   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.42     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 710      |
|    iterations             | 135      |
|    time_elapsed           | 24       |
|    total_timesteps        | 17280    |
| train/                    |          |
|    explained_variance     | -2.43    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00822  |
|    learning_rate          | 0.001    |
|    n_updates              | 134      |
|    policy_objective       | 0.0628   |
|    value_loss             | 0.00225  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.52     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 710      |
|    iterations             | 136      |
|    time_elapsed           | 24       |
|    total_timesteps        | 17408    |
| train/                    |          |
|    explained_variance     | -1.56    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00745  |
|    learning_rate          | 0.001    |
|    n_updates              | 135      |
|    policy_objective       | 0.0426   |
|    value_loss             | 0.000156 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.15     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 710      |
|    iterations             | 137      |
|    time_elapsed           | 24       |
|    total_timesteps        | 17536    |
| train/                    |          |
|    explained_variance     | 0.0932   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00839  |
|    learning_rate          | 0.001    |
|    n_updates              | 136      |
|    policy_objective       | 0.0767   |
|    value_loss             | 0.037    |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.17     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 710      |
|    iterations             | 138      |
|    time_elapsed           | 24       |
|    total_timesteps        | 17664    |
| train/                    |          |
|    explained_variance     | -27.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00298  |
|    learning_rate          | 0.001    |
|    n_updates              | 137      |
|    policy_objective       | 0.0604   |
|    value_loss             | 0.00143  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.68     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 710      |
|    iterations             | 139      |
|    time_elapsed           | 25       |
|    total_timesteps        | 17792    |
| train/                    |          |
|    explained_variance     | -7.04    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00445  |
|    learning_rate          | 0.001    |
|    n_updates              | 138      |
|    policy_objective       | 0.0314   |
|    value_loss             | 0.00335  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.8      |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 710      |
|    iterations             | 140      |
|    time_elapsed           | 25       |
|    total_timesteps        | 17920    |
| train/                    |          |
|    explained_variance     | -7.7     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00415  |
|    learning_rate          | 0.001    |
|    n_updates              | 139      |
|    policy_objective       | 0.0543   |
|    value_loss             | 7.4e-05  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.17     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 710      |
|    iterations             | 141      |
|    time_elapsed           | 25       |
|    total_timesteps        | 18048    |
| train/                    |          |
|    explained_variance     | -14.7    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00219  |
|    learning_rate          | 0.001    |
|    n_updates              | 140      |
|    policy_objective       | 0.0789   |
|    value_loss             | 0.000145 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.96     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 710      |
|    iterations             | 142      |
|    time_elapsed           | 25       |
|    total_timesteps        | 18176    |
| train/                    |          |
|    explained_variance     | -22.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00348  |
|    learning_rate          | 0.001    |
|    n_updates              | 141      |
|    policy_objective       | 0.0833   |
|    value_loss             | 1.04e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.1      |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 710      |
|    iterations             | 143      |
|    time_elapsed           | 25       |
|    total_timesteps        | 18304    |
| train/                    |          |
|    explained_variance     | 0.0705   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00781  |
|    learning_rate          | 0.001    |
|    n_updates              | 142      |
|    policy_objective       | 0.0347   |
|    value_loss             | 0.0625   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.34     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 710      |
|    iterations             | 144      |
|    time_elapsed           | 25       |
|    total_timesteps        | 18432    |
| train/                    |          |
|    explained_variance     | -16.7    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00696  |
|    learning_rate          | 0.001    |
|    n_updates              | 143      |
|    policy_objective       | 0.032    |
|    value_loss             | 0.00486  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.48     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 710      |
|    iterations             | 145      |
|    time_elapsed           | 26       |
|    total_timesteps        | 18560    |
| train/                    |          |
|    explained_variance     | -23.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00635  |
|    learning_rate          | 0.001    |
|    n_updates              | 144      |
|    policy_objective       | 0.0291   |
|    value_loss             | 0.000651 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.68     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 710      |
|    iterations             | 146      |
|    time_elapsed           | 26       |
|    total_timesteps        | 18688    |
| train/                    |          |
|    explained_variance     | 0.136    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00745  |
|    learning_rate          | 0.001    |
|    n_updates              | 145      |
|    policy_objective       | 0.155    |
|    value_loss             | 0.0399   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.77     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 710      |
|    iterations             | 147      |
|    time_elapsed           | 26       |
|    total_timesteps        | 18816    |
| train/                    |          |
|    explained_variance     | -9.15    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00489  |
|    learning_rate          | 0.001    |
|    n_updates              | 146      |
|    policy_objective       | 0.0479   |
|    value_loss             | 0.00214  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.28     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 709      |
|    iterations             | 148      |
|    time_elapsed           | 26       |
|    total_timesteps        | 18944    |
| train/                    |          |
|    explained_variance     | -18.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00588  |
|    learning_rate          | 0.001    |
|    n_updates              | 147      |
|    policy_objective       | 0.0336   |
|    value_loss             | 0.000111 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.25     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 709      |
|    iterations             | 149      |
|    time_elapsed           | 26       |
|    total_timesteps        | 19072    |
| train/                    |          |
|    explained_variance     | -28.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00301  |
|    learning_rate          | 0.001    |
|    n_updates              | 148      |
|    policy_objective       | 0.0195   |
|    value_loss             | 8.52e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.26     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 709      |
|    iterations             | 150      |
|    time_elapsed           | 27       |
|    total_timesteps        | 19200    |
| train/                    |          |
|    explained_variance     | 0.199    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0077   |
|    learning_rate          | 0.001    |
|    n_updates              | 149      |
|    policy_objective       | 0.0407   |
|    value_loss             | 0.0605   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.2      |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 709      |
|    iterations             | 151      |
|    time_elapsed           | 27       |
|    total_timesteps        | 19328    |
| train/                    |          |
|    explained_variance     | -37.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00236  |
|    learning_rate          | 0.001    |
|    n_updates              | 150      |
|    policy_objective       | 0.0464   |
|    value_loss             | 0.00378  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.03     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 709      |
|    iterations             | 152      |
|    time_elapsed           | 27       |
|    total_timesteps        | 19456    |
| train/                    |          |
|    explained_variance     | -5.63    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00896  |
|    learning_rate          | 0.001    |
|    n_updates              | 151      |
|    policy_objective       | 0.0624   |
|    value_loss             | 7.22e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.82     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 709      |
|    iterations             | 153      |
|    time_elapsed           | 27       |
|    total_timesteps        | 19584    |
| train/                    |          |
|    explained_variance     | -29.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00441  |
|    learning_rate          | 0.001    |
|    n_updates              | 152      |
|    policy_objective       | 0.0251   |
|    value_loss             | 0.0032   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.83     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 709      |
|    iterations             | 154      |
|    time_elapsed           | 27       |
|    total_timesteps        | 19712    |
| train/                    |          |
|    explained_variance     | -34.6    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0042   |
|    learning_rate          | 0.001    |
|    n_updates              | 153      |
|    policy_objective       | 0.0207   |
|    value_loss             | 0.000979 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.26     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 709      |
|    iterations             | 155      |
|    time_elapsed           | 27       |
|    total_timesteps        | 19840    |
| train/                    |          |
|    explained_variance     | -52.6    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00337  |
|    learning_rate          | 0.001    |
|    n_updates              | 154      |
|    policy_objective       | 0.0484   |
|    value_loss             | 0.000103 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.44     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 709      |
|    iterations             | 156      |
|    time_elapsed           | 28       |
|    total_timesteps        | 19968    |
| train/                    |          |
|    explained_variance     | -72.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00181  |
|    learning_rate          | 0.001    |
|    n_updates              | 155      |
|    policy_objective       | 0.0605   |
|    value_loss             | 1e-05    |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.01     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 709      |
|    iterations             | 157      |
|    time_elapsed           | 28       |
|    total_timesteps        | 20096    |
| train/                    |          |
|    explained_variance     | -70.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00479  |
|    learning_rate          | 0.001    |
|    n_updates              | 156      |
|    policy_objective       | 0.0191   |
|    value_loss             | 9.62e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.98     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 708      |
|    iterations             | 158      |
|    time_elapsed           | 28       |
|    total_timesteps        | 20224    |
| train/                    |          |
|    explained_variance     | -8.62    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00336  |
|    learning_rate          | 0.001    |
|    n_updates              | 157      |
|    policy_objective       | 0.0436   |
|    value_loss             | 8.16e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.29     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 709      |
|    iterations             | 159      |
|    time_elapsed           | 28       |
|    total_timesteps        | 20352    |
| train/                    |          |
|    explained_variance     | -1.66    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00131  |
|    learning_rate          | 0.001    |
|    n_updates              | 158      |
|    policy_objective       | 0.0404   |
|    value_loss             | 1.13e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.57     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 709      |
|    iterations             | 160      |
|    time_elapsed           | 28       |
|    total_timesteps        | 20480    |
| train/                    |          |
|    explained_variance     | -23.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00701  |
|    learning_rate          | 0.001    |
|    n_updates              | 159      |
|    policy_objective       | 0.0558   |
|    value_loss             | 5.79e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.59     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 709      |
|    iterations             | 161      |
|    time_elapsed           | 29       |
|    total_timesteps        | 20608    |
| train/                    |          |
|    explained_variance     | -36.7    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00524  |
|    learning_rate          | 0.001    |
|    n_updates              | 160      |
|    policy_objective       | 0.0447   |
|    value_loss             | 2.83e-08 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.16     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 709      |
|    iterations             | 162      |
|    time_elapsed           | 29       |
|    total_timesteps        | 20736    |
| train/                    |          |
|    explained_variance     | -33.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00388  |
|    learning_rate          | 0.001    |
|    n_updates              | 161      |
|    policy_objective       | 0.0131   |
|    value_loss             | 4.09e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.44     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 709      |
|    iterations             | 163      |
|    time_elapsed           | 29       |
|    total_timesteps        | 20864    |
| train/                    |          |
|    explained_variance     | -94.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00683  |
|    learning_rate          | 0.001    |
|    n_updates              | 162      |
|    policy_objective       | 0.0415   |
|    value_loss             | 1.95e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.34     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 709      |
|    iterations             | 164      |
|    time_elapsed           | 29       |
|    total_timesteps        | 20992    |
| train/                    |          |
|    explained_variance     | -84.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00439  |
|    learning_rate          | 0.001    |
|    n_updates              | 163      |
|    policy_objective       | 0.0287   |
|    value_loss             | 1.43e-09 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.32     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 709      |
|    iterations             | 165      |
|    time_elapsed           | 29       |
|    total_timesteps        | 21120    |
| train/                    |          |
|    explained_variance     | -40      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00391  |
|    learning_rate          | 0.001    |
|    n_updates              | 164      |
|    policy_objective       | 0.0184   |
|    value_loss             | 4.92e-11 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.62     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 709      |
|    iterations             | 166      |
|    time_elapsed           | 29       |
|    total_timesteps        | 21248    |
| train/                    |          |
|    explained_variance     | 0.000327 |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00814  |
|    learning_rate          | 0.001    |
|    n_updates              | 165      |
|    policy_objective       | 0.0495   |
|    value_loss             | 0.0672   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.45     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 709      |
|    iterations             | 167      |
|    time_elapsed           | 30       |
|    total_timesteps        | 21376    |
| train/                    |          |
|    explained_variance     | -22      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0054   |
|    learning_rate          | 0.001    |
|    n_updates              | 166      |
|    policy_objective       | 0.064    |
|    value_loss             | 0.00458  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.28     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 709      |
|    iterations             | 168      |
|    time_elapsed           | 30       |
|    total_timesteps        | 21504    |
| train/                    |          |
|    explained_variance     | -12.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00558  |
|    learning_rate          | 0.001    |
|    n_updates              | 167      |
|    policy_objective       | 0.0271   |
|    value_loss             | 0.00201  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.25     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 709      |
|    iterations             | 169      |
|    time_elapsed           | 30       |
|    total_timesteps        | 21632    |
| train/                    |          |
|    explained_variance     | -84.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00649  |
|    learning_rate          | 0.001    |
|    n_updates              | 168      |
|    policy_objective       | 0.0297   |
|    value_loss             | 0.000321 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.26     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 709      |
|    iterations             | 170      |
|    time_elapsed           | 30       |
|    total_timesteps        | 21760    |
| train/                    |          |
|    explained_variance     | -27.7    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00194  |
|    learning_rate          | 0.001    |
|    n_updates              | 169      |
|    policy_objective       | 0.0559   |
|    value_loss             | 1.44e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.62     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 709      |
|    iterations             | 171      |
|    time_elapsed           | 30       |
|    total_timesteps        | 21888    |
| train/                    |          |
|    explained_variance     | -0.0279  |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00513  |
|    learning_rate          | 0.001    |
|    n_updates              | 170      |
|    policy_objective       | 0.1      |
|    value_loss             | 0.0632   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.06     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 709      |
|    iterations             | 172      |
|    time_elapsed           | 31       |
|    total_timesteps        | 22016    |
| train/                    |          |
|    explained_variance     | -9.4     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00668  |
|    learning_rate          | 0.001    |
|    n_updates              | 171      |
|    policy_objective       | 0.0305   |
|    value_loss             | 0.00647  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.05     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 710      |
|    iterations             | 173      |
|    time_elapsed           | 31       |
|    total_timesteps        | 22144    |
| train/                    |          |
|    explained_variance     | -0.00694 |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00716  |
|    learning_rate          | 0.001    |
|    n_updates              | 172      |
|    policy_objective       | 0.123    |
|    value_loss             | 0.00863  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.99     |
|    ep_rew_mean            | 0.05     |
| time/                     |          |
|    fps                    | 710      |
|    iterations             | 174      |
|    time_elapsed           | 31       |
|    total_timesteps        | 22272    |
| train/                    |          |
|    explained_variance     | 0.181    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00588  |
|    learning_rate          | 0.001    |
|    n_updates              | 173      |
|    policy_objective       | 0.0513   |
|    value_loss             | 0.0785   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.39     |
|    ep_rew_mean            | 0.06     |
| time/                     |          |
|    fps                    | 710      |
|    iterations             | 175      |
|    time_elapsed           | 31       |
|    total_timesteps        | 22400    |
| train/                    |          |
|    explained_variance     | 0.167    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00525  |
|    learning_rate          | 0.001    |
|    n_updates              | 174      |
|    policy_objective       | 0.025    |
|    value_loss             | 0.0392   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.29     |
|    ep_rew_mean            | 0.06     |
| time/                     |          |
|    fps                    | 710      |
|    iterations             | 176      |
|    time_elapsed           | 31       |
|    total_timesteps        | 22528    |
| train/                    |          |
|    explained_variance     | 0.372    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00786  |
|    learning_rate          | 0.001    |
|    n_updates              | 175      |
|    policy_objective       | 0.0363   |
|    value_loss             | 0.0361   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.75     |
|    ep_rew_mean            | 0.05     |
| time/                     |          |
|    fps                    | 710      |
|    iterations             | 177      |
|    time_elapsed           | 31       |
|    total_timesteps        | 22656    |
| train/                    |          |
|    explained_variance     | 0.653    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00628  |
|    learning_rate          | 0.001    |
|    n_updates              | 176      |
|    policy_objective       | 0.0356   |
|    value_loss             | 0.0138   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.72     |
|    ep_rew_mean            | 0.07     |
| time/                     |          |
|    fps                    | 710      |
|    iterations             | 178      |
|    time_elapsed           | 32       |
|    total_timesteps        | 22784    |
| train/                    |          |
|    explained_variance     | -19.7    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00511  |
|    learning_rate          | 0.001    |
|    n_updates              | 177      |
|    policy_objective       | 0.0237   |
|    value_loss             | 0.00603  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.76     |
|    ep_rew_mean            | 0.05     |
| time/                     |          |
|    fps                    | 710      |
|    iterations             | 179      |
|    time_elapsed           | 32       |
|    total_timesteps        | 22912    |
| train/                    |          |
|    explained_variance     | 0.158    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00544  |
|    learning_rate          | 0.001    |
|    n_updates              | 178      |
|    policy_objective       | 0.037    |
|    value_loss             | 0.0712   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.98     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 710      |
|    iterations             | 180      |
|    time_elapsed           | 32       |
|    total_timesteps        | 23040    |
| train/                    |          |
|    explained_variance     | -8.62    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00685  |
|    learning_rate          | 0.001    |
|    n_updates              | 179      |
|    policy_objective       | 0.0528   |
|    value_loss             | 0.00494  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.89     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 710      |
|    iterations             | 181      |
|    time_elapsed           | 32       |
|    total_timesteps        | 23168    |
| train/                    |          |
|    explained_variance     | -45.7    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00721  |
|    learning_rate          | 0.001    |
|    n_updates              | 180      |
|    policy_objective       | 0.0231   |
|    value_loss             | 0.00091  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.8      |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 710      |
|    iterations             | 182      |
|    time_elapsed           | 32       |
|    total_timesteps        | 23296    |
| train/                    |          |
|    explained_variance     | -16      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00668  |
|    learning_rate          | 0.001    |
|    n_updates              | 181      |
|    policy_objective       | 0.0384   |
|    value_loss             | 0.00222  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.36     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 711      |
|    iterations             | 183      |
|    time_elapsed           | 32       |
|    total_timesteps        | 23424    |
| train/                    |          |
|    explained_variance     | -19.6    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00932  |
|    learning_rate          | 0.001    |
|    n_updates              | 182      |
|    policy_objective       | 0.057    |
|    value_loss             | 0.00027  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.36     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 711      |
|    iterations             | 184      |
|    time_elapsed           | 33       |
|    total_timesteps        | 23552    |
| train/                    |          |
|    explained_variance     | -9.68    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00494  |
|    learning_rate          | 0.001    |
|    n_updates              | 183      |
|    policy_objective       | 0.0592   |
|    value_loss             | 1.26e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.21     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 711      |
|    iterations             | 185      |
|    time_elapsed           | 33       |
|    total_timesteps        | 23680    |
| train/                    |          |
|    explained_variance     | 0.00727  |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00535  |
|    learning_rate          | 0.001    |
|    n_updates              | 184      |
|    policy_objective       | 0.0384   |
|    value_loss             | 0.0369   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.95     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 711      |
|    iterations             | 186      |
|    time_elapsed           | 33       |
|    total_timesteps        | 23808    |
| train/                    |          |
|    explained_variance     | -19.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00673  |
|    learning_rate          | 0.001    |
|    n_updates              | 185      |
|    policy_objective       | 0.0582   |
|    value_loss             | 0.00244  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.05     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 711      |
|    iterations             | 187      |
|    time_elapsed           | 33       |
|    total_timesteps        | 23936    |
| train/                    |          |
|    explained_variance     | -19.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00459  |
|    learning_rate          | 0.001    |
|    n_updates              | 186      |
|    policy_objective       | 0.0941   |
|    value_loss             | 0.000408 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.11     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 711      |
|    iterations             | 188      |
|    time_elapsed           | 33       |
|    total_timesteps        | 24064    |
| train/                    |          |
|    explained_variance     | -53.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00473  |
|    learning_rate          | 0.001    |
|    n_updates              | 187      |
|    policy_objective       | 0.0488   |
|    value_loss             | 0.000327 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.47     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 711      |
|    iterations             | 189      |
|    time_elapsed           | 34       |
|    total_timesteps        | 24192    |
| train/                    |          |
|    explained_variance     | 0.08     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00685  |
|    learning_rate          | 0.001    |
|    n_updates              | 188      |
|    policy_objective       | 0.032    |
|    value_loss             | 0.0454   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.51     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 711      |
|    iterations             | 190      |
|    time_elapsed           | 34       |
|    total_timesteps        | 24320    |
| train/                    |          |
|    explained_variance     | -1.01    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00694  |
|    learning_rate          | 0.001    |
|    n_updates              | 189      |
|    policy_objective       | 0.0324   |
|    value_loss             | 0.00357  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.03     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 711      |
|    iterations             | 191      |
|    time_elapsed           | 34       |
|    total_timesteps        | 24448    |
| train/                    |          |
|    explained_variance     | -23.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00332  |
|    learning_rate          | 0.001    |
|    n_updates              | 190      |
|    policy_objective       | 0.0564   |
|    value_loss             | 0.000599 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.32     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 711      |
|    iterations             | 192      |
|    time_elapsed           | 34       |
|    total_timesteps        | 24576    |
| train/                    |          |
|    explained_variance     | -34.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00447  |
|    learning_rate          | 0.001    |
|    n_updates              | 191      |
|    policy_objective       | 0.0307   |
|    value_loss             | 0.00216  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.47     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 711      |
|    iterations             | 193      |
|    time_elapsed           | 34       |
|    total_timesteps        | 24704    |
| train/                    |          |
|    explained_variance     | -16.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00491  |
|    learning_rate          | 0.001    |
|    n_updates              | 192      |
|    policy_objective       | 0.0296   |
|    value_loss             | 5.09e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.3      |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 712      |
|    iterations             | 194      |
|    time_elapsed           | 34       |
|    total_timesteps        | 24832    |
| train/                    |          |
|    explained_variance     | -16.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00688  |
|    learning_rate          | 0.001    |
|    n_updates              | 193      |
|    policy_objective       | 0.0489   |
|    value_loss             | 0.00155  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.48     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 712      |
|    iterations             | 195      |
|    time_elapsed           | 35       |
|    total_timesteps        | 24960    |
| train/                    |          |
|    explained_variance     | -18      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00438  |
|    learning_rate          | 0.001    |
|    n_updates              | 194      |
|    policy_objective       | 0.0814   |
|    value_loss             | 6.3e-05  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.68     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 711      |
|    iterations             | 196      |
|    time_elapsed           | 35       |
|    total_timesteps        | 25088    |
| train/                    |          |
|    explained_variance     | -119     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00328  |
|    learning_rate          | 0.001    |
|    n_updates              | 195      |
|    policy_objective       | 0.0541   |
|    value_loss             | 3.37e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.58     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 711      |
|    iterations             | 197      |
|    time_elapsed           | 35       |
|    total_timesteps        | 25216    |
| train/                    |          |
|    explained_variance     | -37.6    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00516  |
|    learning_rate          | 0.001    |
|    n_updates              | 196      |
|    policy_objective       | 0.0352   |
|    value_loss             | 4.07e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.28     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 711      |
|    iterations             | 198      |
|    time_elapsed           | 35       |
|    total_timesteps        | 25344    |
| train/                    |          |
|    explained_variance     | -30.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00276  |
|    learning_rate          | 0.001    |
|    n_updates              | 197      |
|    policy_objective       | 0.0214   |
|    value_loss             | 9.21e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.99     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 711      |
|    iterations             | 199      |
|    time_elapsed           | 35       |
|    total_timesteps        | 25472    |
| train/                    |          |
|    explained_variance     | -63.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00195  |
|    learning_rate          | 0.001    |
|    n_updates              | 198      |
|    policy_objective       | 0.0601   |
|    value_loss             | 1.03e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.69     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 711      |
|    iterations             | 200      |
|    time_elapsed           | 35       |
|    total_timesteps        | 25600    |
| train/                    |          |
|    explained_variance     | -13.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00772  |
|    learning_rate          | 0.001    |
|    n_updates              | 199      |
|    policy_objective       | 0.0759   |
|    value_loss             | 1.18e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.74     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 711      |
|    iterations             | 201      |
|    time_elapsed           | 36       |
|    total_timesteps        | 25728    |
| train/                    |          |
|    explained_variance     | -47.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00486  |
|    learning_rate          | 0.001    |
|    n_updates              | 200      |
|    policy_objective       | 0.0542   |
|    value_loss             | 4.14e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.57     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 712      |
|    iterations             | 202      |
|    time_elapsed           | 36       |
|    total_timesteps        | 25856    |
| train/                    |          |
|    explained_variance     | -70.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00454  |
|    learning_rate          | 0.001    |
|    n_updates              | 201      |
|    policy_objective       | 0.0153   |
|    value_loss             | 7.34e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.22     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 712      |
|    iterations             | 203      |
|    time_elapsed           | 36       |
|    total_timesteps        | 25984    |
| train/                    |          |
|    explained_variance     | -7.43    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00453  |
|    learning_rate          | 0.001    |
|    n_updates              | 202      |
|    policy_objective       | 0.0435   |
|    value_loss             | 1.78e-08 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.79     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 712      |
|    iterations             | 204      |
|    time_elapsed           | 36       |
|    total_timesteps        | 26112    |
| train/                    |          |
|    explained_variance     | -30.6    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00581  |
|    learning_rate          | 0.001    |
|    n_updates              | 203      |
|    policy_objective       | 0.0402   |
|    value_loss             | 4.24e-09 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.89     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 712      |
|    iterations             | 205      |
|    time_elapsed           | 36       |
|    total_timesteps        | 26240    |
| train/                    |          |
|    explained_variance     | 0.00255  |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00512  |
|    learning_rate          | 0.001    |
|    n_updates              | 204      |
|    policy_objective       | 0.0455   |
|    value_loss             | 0.0401   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.11     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 712      |
|    iterations             | 206      |
|    time_elapsed           | 37       |
|    total_timesteps        | 26368    |
| train/                    |          |
|    explained_variance     | -56.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00611  |
|    learning_rate          | 0.001    |
|    n_updates              | 205      |
|    policy_objective       | 0.0524   |
|    value_loss             | 0.00155  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8        |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 712      |
|    iterations             | 207      |
|    time_elapsed           | 37       |
|    total_timesteps        | 26496    |
| train/                    |          |
|    explained_variance     | -37.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00338  |
|    learning_rate          | 0.001    |
|    n_updates              | 206      |
|    policy_objective       | 0.0614   |
|    value_loss             | 0.000634 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.16     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 712      |
|    iterations             | 208      |
|    time_elapsed           | 37       |
|    total_timesteps        | 26624    |
| train/                    |          |
|    explained_variance     | -45.6    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00679  |
|    learning_rate          | 0.001    |
|    n_updates              | 207      |
|    policy_objective       | 0.0727   |
|    value_loss             | 0.00059  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.23     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 209      |
|    time_elapsed           | 37       |
|    total_timesteps        | 26752    |
| train/                    |          |
|    explained_variance     | 0.0494   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00633  |
|    learning_rate          | 0.001    |
|    n_updates              | 208      |
|    policy_objective       | 0.0654   |
|    value_loss             | 0.0429   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.12     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 210      |
|    time_elapsed           | 37       |
|    total_timesteps        | 26880    |
| train/                    |          |
|    explained_variance     | -6.13    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00331  |
|    learning_rate          | 0.001    |
|    n_updates              | 209      |
|    policy_objective       | 0.0357   |
|    value_loss             | 0.00194  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.32     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 211      |
|    time_elapsed           | 37       |
|    total_timesteps        | 27008    |
| train/                    |          |
|    explained_variance     | -20.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00591  |
|    learning_rate          | 0.001    |
|    n_updates              | 210      |
|    policy_objective       | 0.0669   |
|    value_loss             | 0.00145  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.72     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 212      |
|    time_elapsed           | 38       |
|    total_timesteps        | 27136    |
| train/                    |          |
|    explained_variance     | 0.206    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00686  |
|    learning_rate          | 0.001    |
|    n_updates              | 211      |
|    policy_objective       | 0.0861   |
|    value_loss             | 0.0268   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.54     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 213      |
|    time_elapsed           | 38       |
|    total_timesteps        | 27264    |
| train/                    |          |
|    explained_variance     | -1.71    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00259  |
|    learning_rate          | 0.001    |
|    n_updates              | 212      |
|    policy_objective       | 0.0671   |
|    value_loss             | 0.00595  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.54     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 214      |
|    time_elapsed           | 38       |
|    total_timesteps        | 27392    |
| train/                    |          |
|    explained_variance     | -26.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00506  |
|    learning_rate          | 0.001    |
|    n_updates              | 213      |
|    policy_objective       | 0.0423   |
|    value_loss             | 0.000355 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.52     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 215      |
|    time_elapsed           | 38       |
|    total_timesteps        | 27520    |
| train/                    |          |
|    explained_variance     | 0.165    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0074   |
|    learning_rate          | 0.001    |
|    n_updates              | 214      |
|    policy_objective       | 0.0802   |
|    value_loss             | 0.0278   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.38     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 216      |
|    time_elapsed           | 38       |
|    total_timesteps        | 27648    |
| train/                    |          |
|    explained_variance     | -33.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00651  |
|    learning_rate          | 0.001    |
|    n_updates              | 215      |
|    policy_objective       | 0.0534   |
|    value_loss             | 0.000223 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.17     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 217      |
|    time_elapsed           | 38       |
|    total_timesteps        | 27776    |
| train/                    |          |
|    explained_variance     | -56.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00301  |
|    learning_rate          | 0.001    |
|    n_updates              | 216      |
|    policy_objective       | 0.0377   |
|    value_loss             | 0.00243  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.54     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 218      |
|    time_elapsed           | 39       |
|    total_timesteps        | 27904    |
| train/                    |          |
|    explained_variance     | -17.6    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00476  |
|    learning_rate          | 0.001    |
|    n_updates              | 217      |
|    policy_objective       | 0.0388   |
|    value_loss             | 0.00182  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.76     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 219      |
|    time_elapsed           | 39       |
|    total_timesteps        | 28032    |
| train/                    |          |
|    explained_variance     | 0.0539   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00691  |
|    learning_rate          | 0.001    |
|    n_updates              | 218      |
|    policy_objective       | 0.0529   |
|    value_loss             | 0.0383   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.96     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 220      |
|    time_elapsed           | 39       |
|    total_timesteps        | 28160    |
| train/                    |          |
|    explained_variance     | -11.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0052   |
|    learning_rate          | 0.001    |
|    n_updates              | 219      |
|    policy_objective       | 0.0404   |
|    value_loss             | 0.00113  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.14     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 221      |
|    time_elapsed           | 39       |
|    total_timesteps        | 28288    |
| train/                    |          |
|    explained_variance     | -45.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00337  |
|    learning_rate          | 0.001    |
|    n_updates              | 220      |
|    policy_objective       | 0.052    |
|    value_loss             | 0.000279 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.03     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 222      |
|    time_elapsed           | 39       |
|    total_timesteps        | 28416    |
| train/                    |          |
|    explained_variance     | -38.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00534  |
|    learning_rate          | 0.001    |
|    n_updates              | 221      |
|    policy_objective       | 0.0655   |
|    value_loss             | 7.86e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.47     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 223      |
|    time_elapsed           | 40       |
|    total_timesteps        | 28544    |
| train/                    |          |
|    explained_variance     | 0.149    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0047   |
|    learning_rate          | 0.001    |
|    n_updates              | 222      |
|    policy_objective       | 0.0474   |
|    value_loss             | 0.0319   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9        |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 224      |
|    time_elapsed           | 40       |
|    total_timesteps        | 28672    |
| train/                    |          |
|    explained_variance     | -36.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00124  |
|    learning_rate          | 0.001    |
|    n_updates              | 223      |
|    policy_objective       | 0.043    |
|    value_loss             | 0.00516  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.8      |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 225      |
|    time_elapsed           | 40       |
|    total_timesteps        | 28800    |
| train/                    |          |
|    explained_variance     | -3.69    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00562  |
|    learning_rate          | 0.001    |
|    n_updates              | 224      |
|    policy_objective       | 0.0401   |
|    value_loss             | 9.74e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.73     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 226      |
|    time_elapsed           | 40       |
|    total_timesteps        | 28928    |
| train/                    |          |
|    explained_variance     | -42.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00505  |
|    learning_rate          | 0.001    |
|    n_updates              | 225      |
|    policy_objective       | 0.0328   |
|    value_loss             | 9.47e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.74     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 712      |
|    iterations             | 227      |
|    time_elapsed           | 40       |
|    total_timesteps        | 29056    |
| train/                    |          |
|    explained_variance     | -56.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0055   |
|    learning_rate          | 0.001    |
|    n_updates              | 226      |
|    policy_objective       | 0.0132   |
|    value_loss             | 9.67e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.94     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 228      |
|    time_elapsed           | 40       |
|    total_timesteps        | 29184    |
| train/                    |          |
|    explained_variance     | 0.211    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00729  |
|    learning_rate          | 0.001    |
|    n_updates              | 227      |
|    policy_objective       | 0.0529   |
|    value_loss             | 0.031    |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.09     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 229      |
|    time_elapsed           | 41       |
|    total_timesteps        | 29312    |
| train/                    |          |
|    explained_variance     | -17.7    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00465  |
|    learning_rate          | 0.001    |
|    n_updates              | 228      |
|    policy_objective       | 0.029    |
|    value_loss             | 0.00104  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.45     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 230      |
|    time_elapsed           | 41       |
|    total_timesteps        | 29440    |
| train/                    |          |
|    explained_variance     | -83.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00234  |
|    learning_rate          | 0.001    |
|    n_updates              | 229      |
|    policy_objective       | 0.0611   |
|    value_loss             | 0.0033   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8        |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 231      |
|    time_elapsed           | 41       |
|    total_timesteps        | 29568    |
| train/                    |          |
|    explained_variance     | 0.126    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00491  |
|    learning_rate          | 0.001    |
|    n_updates              | 230      |
|    policy_objective       | 0.0392   |
|    value_loss             | 0.0362   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.6      |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 232      |
|    time_elapsed           | 41       |
|    total_timesteps        | 29696    |
| train/                    |          |
|    explained_variance     | -46.7    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00466  |
|    learning_rate          | 0.001    |
|    n_updates              | 231      |
|    policy_objective       | 0.0355   |
|    value_loss             | 0.00444  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.72     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 233      |
|    time_elapsed           | 41       |
|    total_timesteps        | 29824    |
| train/                    |          |
|    explained_variance     | 0.166    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00632  |
|    learning_rate          | 0.001    |
|    n_updates              | 232      |
|    policy_objective       | 0.0333   |
|    value_loss             | 0.0328   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.63     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 234      |
|    time_elapsed           | 41       |
|    total_timesteps        | 29952    |
| train/                    |          |
|    explained_variance     | -21.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00371  |
|    learning_rate          | 0.001    |
|    n_updates              | 233      |
|    policy_objective       | 0.0387   |
|    value_loss             | 0.0029   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.31     |
|    ep_rew_mean            | 0.05     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 235      |
|    time_elapsed           | 42       |
|    total_timesteps        | 30080    |
| train/                    |          |
|    explained_variance     | -5.94    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00583  |
|    learning_rate          | 0.001    |
|    n_updates              | 234      |
|    policy_objective       | 0.0377   |
|    value_loss             | 0.000124 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.55     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 236      |
|    time_elapsed           | 42       |
|    total_timesteps        | 30208    |
| train/                    |          |
|    explained_variance     | 0.15     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00751  |
|    learning_rate          | 0.001    |
|    n_updates              | 235      |
|    policy_objective       | 0.0334   |
|    value_loss             | 0.0795   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.81     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 237      |
|    time_elapsed           | 42       |
|    total_timesteps        | 30336    |
| train/                    |          |
|    explained_variance     | -25.6    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00135  |
|    learning_rate          | 0.001    |
|    n_updates              | 236      |
|    policy_objective       | 0.0532   |
|    value_loss             | 0.00601  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.65     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 238      |
|    time_elapsed           | 42       |
|    total_timesteps        | 30464    |
| train/                    |          |
|    explained_variance     | -29.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00389  |
|    learning_rate          | 0.001    |
|    n_updates              | 237      |
|    policy_objective       | 0.0409   |
|    value_loss             | 0.00175  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.31     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 239      |
|    time_elapsed           | 42       |
|    total_timesteps        | 30592    |
| train/                    |          |
|    explained_variance     | -1.95    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00756  |
|    learning_rate          | 0.001    |
|    n_updates              | 238      |
|    policy_objective       | 0.0617   |
|    value_loss             | 2.67e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.05     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 240      |
|    time_elapsed           | 43       |
|    total_timesteps        | 30720    |
| train/                    |          |
|    explained_variance     | -43.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00202  |
|    learning_rate          | 0.001    |
|    n_updates              | 239      |
|    policy_objective       | 0.0686   |
|    value_loss             | 0.000534 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.12     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 241      |
|    time_elapsed           | 43       |
|    total_timesteps        | 30848    |
| train/                    |          |
|    explained_variance     | -37.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00245  |
|    learning_rate          | 0.001    |
|    n_updates              | 240      |
|    policy_objective       | 0.0614   |
|    value_loss             | 0.00119  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.12     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 242      |
|    time_elapsed           | 43       |
|    total_timesteps        | 30976    |
| train/                    |          |
|    explained_variance     | -98      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00311  |
|    learning_rate          | 0.001    |
|    n_updates              | 241      |
|    policy_objective       | 0.0265   |
|    value_loss             | 2.4e-05  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.52     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 243      |
|    time_elapsed           | 43       |
|    total_timesteps        | 31104    |
| train/                    |          |
|    explained_variance     | -0.0177  |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00577  |
|    learning_rate          | 0.001    |
|    n_updates              | 242      |
|    policy_objective       | 0.0216   |
|    value_loss             | 0.0308   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.07     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 244      |
|    time_elapsed           | 43       |
|    total_timesteps        | 31232    |
| train/                    |          |
|    explained_variance     | 0.0713   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00502  |
|    learning_rate          | 0.001    |
|    n_updates              | 243      |
|    policy_objective       | 0.113    |
|    value_loss             | 0.0431   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.37     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 245      |
|    time_elapsed           | 43       |
|    total_timesteps        | 31360    |
| train/                    |          |
|    explained_variance     | -7.13    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00221  |
|    learning_rate          | 0.001    |
|    n_updates              | 244      |
|    policy_objective       | 0.0529   |
|    value_loss             | 0.00977  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.03     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 246      |
|    time_elapsed           | 44       |
|    total_timesteps        | 31488    |
| train/                    |          |
|    explained_variance     | 0.0654   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0086   |
|    learning_rate          | 0.001    |
|    n_updates              | 245      |
|    policy_objective       | 0.0215   |
|    value_loss             | 0.0301   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.81     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 247      |
|    time_elapsed           | 44       |
|    total_timesteps        | 31616    |
| train/                    |          |
|    explained_variance     | -0.465   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00863  |
|    learning_rate          | 0.001    |
|    n_updates              | 246      |
|    policy_objective       | 0.0247   |
|    value_loss             | 0.00508  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.01     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 248      |
|    time_elapsed           | 44       |
|    total_timesteps        | 31744    |
| train/                    |          |
|    explained_variance     | -42.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00611  |
|    learning_rate          | 0.001    |
|    n_updates              | 247      |
|    policy_objective       | 0.0258   |
|    value_loss             | 0.000383 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.01     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 249      |
|    time_elapsed           | 44       |
|    total_timesteps        | 31872    |
| train/                    |          |
|    explained_variance     | -49.7    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00725  |
|    learning_rate          | 0.001    |
|    n_updates              | 248      |
|    policy_objective       | 0.0357   |
|    value_loss             | 0.00031  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.84     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 250      |
|    time_elapsed           | 44       |
|    total_timesteps        | 32000    |
| train/                    |          |
|    explained_variance     | -47.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00428  |
|    learning_rate          | 0.001    |
|    n_updates              | 249      |
|    policy_objective       | 0.0241   |
|    value_loss             | 9.39e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.16     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 251      |
|    time_elapsed           | 45       |
|    total_timesteps        | 32128    |
| train/                    |          |
|    explained_variance     | -70.6    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00958  |
|    learning_rate          | 0.001    |
|    n_updates              | 250      |
|    policy_objective       | 0.00919  |
|    value_loss             | 2.99e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.51     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 252      |
|    time_elapsed           | 45       |
|    total_timesteps        | 32256    |
| train/                    |          |
|    explained_variance     | 0.0414   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00646  |
|    learning_rate          | 0.001    |
|    n_updates              | 251      |
|    policy_objective       | 0.0378   |
|    value_loss             | 0.0467   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.01     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 253      |
|    time_elapsed           | 45       |
|    total_timesteps        | 32384    |
| train/                    |          |
|    explained_variance     | 0.146    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00714  |
|    learning_rate          | 0.001    |
|    n_updates              | 252      |
|    policy_objective       | 0.0462   |
|    value_loss             | 0.0315   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.88     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 254      |
|    time_elapsed           | 45       |
|    total_timesteps        | 32512    |
| train/                    |          |
|    explained_variance     | 0.393    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00875  |
|    learning_rate          | 0.001    |
|    n_updates              | 253      |
|    policy_objective       | 0.0286   |
|    value_loss             | 0.0318   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.52     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 714      |
|    iterations             | 255      |
|    time_elapsed           | 45       |
|    total_timesteps        | 32640    |
| train/                    |          |
|    explained_variance     | -22.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00557  |
|    learning_rate          | 0.001    |
|    n_updates              | 254      |
|    policy_objective       | 0.0187   |
|    value_loss             | 0.00403  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.75     |
|    ep_rew_mean            | 0.05     |
| time/                     |          |
|    fps                    | 714      |
|    iterations             | 256      |
|    time_elapsed           | 45       |
|    total_timesteps        | 32768    |
| train/                    |          |
|    explained_variance     | -0.481   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00547  |
|    learning_rate          | 0.001    |
|    n_updates              | 255      |
|    policy_objective       | 0.0357   |
|    value_loss             | 0.0456   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.59     |
|    ep_rew_mean            | 0.06     |
| time/                     |          |
|    fps                    | 714      |
|    iterations             | 257      |
|    time_elapsed           | 46       |
|    total_timesteps        | 32896    |
| train/                    |          |
|    explained_variance     | 0.185    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00978  |
|    learning_rate          | 0.001    |
|    n_updates              | 256      |
|    policy_objective       | 0.0323   |
|    value_loss             | 0.0414   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.63     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 714      |
|    iterations             | 258      |
|    time_elapsed           | 46       |
|    total_timesteps        | 33024    |
| train/                    |          |
|    explained_variance     | 0.124    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00689  |
|    learning_rate          | 0.001    |
|    n_updates              | 257      |
|    policy_objective       | 0.0345   |
|    value_loss             | 0.0399   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.2      |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 714      |
|    iterations             | 259      |
|    time_elapsed           | 46       |
|    total_timesteps        | 33152    |
| train/                    |          |
|    explained_variance     | -17.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00496  |
|    learning_rate          | 0.001    |
|    n_updates              | 258      |
|    policy_objective       | 0.023    |
|    value_loss             | 0.00562  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.47     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 714      |
|    iterations             | 260      |
|    time_elapsed           | 46       |
|    total_timesteps        | 33280    |
| train/                    |          |
|    explained_variance     | -20.6    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00469  |
|    learning_rate          | 0.001    |
|    n_updates              | 259      |
|    policy_objective       | 0.0581   |
|    value_loss             | 0.000695 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.56     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 714      |
|    iterations             | 261      |
|    time_elapsed           | 46       |
|    total_timesteps        | 33408    |
| train/                    |          |
|    explained_variance     | -53.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0041   |
|    learning_rate          | 0.001    |
|    n_updates              | 260      |
|    policy_objective       | 0.0229   |
|    value_loss             | 0.000549 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.31     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 714      |
|    iterations             | 262      |
|    time_elapsed           | 46       |
|    total_timesteps        | 33536    |
| train/                    |          |
|    explained_variance     | -42.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00391  |
|    learning_rate          | 0.001    |
|    n_updates              | 261      |
|    policy_objective       | 0.106    |
|    value_loss             | 2.47e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.73     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 714      |
|    iterations             | 263      |
|    time_elapsed           | 47       |
|    total_timesteps        | 33664    |
| train/                    |          |
|    explained_variance     | -104     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00452  |
|    learning_rate          | 0.001    |
|    n_updates              | 262      |
|    policy_objective       | 0.0377   |
|    value_loss             | 9.53e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.63     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 714      |
|    iterations             | 264      |
|    time_elapsed           | 47       |
|    total_timesteps        | 33792    |
| train/                    |          |
|    explained_variance     | 0.0432   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00668  |
|    learning_rate          | 0.001    |
|    n_updates              | 263      |
|    policy_objective       | 0.0269   |
|    value_loss             | 0.0604   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.92     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 714      |
|    iterations             | 265      |
|    time_elapsed           | 47       |
|    total_timesteps        | 33920    |
| train/                    |          |
|    explained_variance     | -6.55    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00758  |
|    learning_rate          | 0.001    |
|    n_updates              | 264      |
|    policy_objective       | 0.0279   |
|    value_loss             | 0.0163   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.79     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 266      |
|    time_elapsed           | 47       |
|    total_timesteps        | 34048    |
| train/                    |          |
|    explained_variance     | -1.81    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00812  |
|    learning_rate          | 0.001    |
|    n_updates              | 265      |
|    policy_objective       | 0.0328   |
|    value_loss             | 0.000816 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.56     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 267      |
|    time_elapsed           | 47       |
|    total_timesteps        | 34176    |
| train/                    |          |
|    explained_variance     | -34.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00285  |
|    learning_rate          | 0.001    |
|    n_updates              | 266      |
|    policy_objective       | 0.0295   |
|    value_loss             | 0.000137 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.75     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 268      |
|    time_elapsed           | 48       |
|    total_timesteps        | 34304    |
| train/                    |          |
|    explained_variance     | -71.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00238  |
|    learning_rate          | 0.001    |
|    n_updates              | 267      |
|    policy_objective       | 0.0642   |
|    value_loss             | 0.000208 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.27     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 269      |
|    time_elapsed           | 48       |
|    total_timesteps        | 34432    |
| train/                    |          |
|    explained_variance     | 0.0404   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00611  |
|    learning_rate          | 0.001    |
|    n_updates              | 268      |
|    policy_objective       | 0.0174   |
|    value_loss             | 0.0406   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.61     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 270      |
|    time_elapsed           | 48       |
|    total_timesteps        | 34560    |
| train/                    |          |
|    explained_variance     | 0.202    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00537  |
|    learning_rate          | 0.001    |
|    n_updates              | 269      |
|    policy_objective       | 0.159    |
|    value_loss             | 0.0543   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.65     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 271      |
|    time_elapsed           | 48       |
|    total_timesteps        | 34688    |
| train/                    |          |
|    explained_variance     | -56.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.000765 |
|    learning_rate          | 0.001    |
|    n_updates              | 270      |
|    policy_objective       | 0.0319   |
|    value_loss             | 0.00625  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.65     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 713      |
|    iterations             | 272      |
|    time_elapsed           | 48       |
|    total_timesteps        | 34816    |
| train/                    |          |
|    explained_variance     | -27.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00373  |
|    learning_rate          | 0.001    |
|    n_updates              | 271      |
|    policy_objective       | 0.0275   |
|    value_loss             | 0.00756  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.96     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 712      |
|    iterations             | 273      |
|    time_elapsed           | 49       |
|    total_timesteps        | 34944    |
| train/                    |          |
|    explained_variance     | -28.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00583  |
|    learning_rate          | 0.001    |
|    n_updates              | 272      |
|    policy_objective       | 0.0308   |
|    value_loss             | 0.000312 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.43     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 712      |
|    iterations             | 274      |
|    time_elapsed           | 49       |
|    total_timesteps        | 35072    |
| train/                    |          |
|    explained_variance     | -48.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00693  |
|    learning_rate          | 0.001    |
|    n_updates              | 273      |
|    policy_objective       | 0.061    |
|    value_loss             | 0.000154 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.48     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 712      |
|    iterations             | 275      |
|    time_elapsed           | 49       |
|    total_timesteps        | 35200    |
| train/                    |          |
|    explained_variance     | 0.0144   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00977  |
|    learning_rate          | 0.001    |
|    n_updates              | 274      |
|    policy_objective       | 0.0376   |
|    value_loss             | 0.0528   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.07     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 712      |
|    iterations             | 276      |
|    time_elapsed           | 49       |
|    total_timesteps        | 35328    |
| train/                    |          |
|    explained_variance     | 0.0891   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00389  |
|    learning_rate          | 0.001    |
|    n_updates              | 275      |
|    policy_objective       | 0.19     |
|    value_loss             | 0.0304   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.68     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 711      |
|    iterations             | 277      |
|    time_elapsed           | 49       |
|    total_timesteps        | 35456    |
| train/                    |          |
|    explained_variance     | 0.154    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00572  |
|    learning_rate          | 0.001    |
|    n_updates              | 276      |
|    policy_objective       | 0.0273   |
|    value_loss             | 0.0436   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.28     |
|    ep_rew_mean            | 0.05     |
| time/                     |          |
|    fps                    | 711      |
|    iterations             | 278      |
|    time_elapsed           | 49       |
|    total_timesteps        | 35584    |
| train/                    |          |
|    explained_variance     | -11.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00634  |
|    learning_rate          | 0.001    |
|    n_updates              | 277      |
|    policy_objective       | 0.0473   |
|    value_loss             | 0.00366  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.5      |
|    ep_rew_mean            | 0.05     |
| time/                     |          |
|    fps                    | 711      |
|    iterations             | 279      |
|    time_elapsed           | 50       |
|    total_timesteps        | 35712    |
| train/                    |          |
|    explained_variance     | 0.125    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00725  |
|    learning_rate          | 0.001    |
|    n_updates              | 278      |
|    policy_objective       | 0.0334   |
|    value_loss             | 0.0678   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.77     |
|    ep_rew_mean            | 0.06     |
| time/                     |          |
|    fps                    | 711      |
|    iterations             | 280      |
|    time_elapsed           | 50       |
|    total_timesteps        | 35840    |
| train/                    |          |
|    explained_variance     | -8.13    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0043   |
|    learning_rate          | 0.001    |
|    n_updates              | 279      |
|    policy_objective       | 0.041    |
|    value_loss             | 0.00231  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.26     |
|    ep_rew_mean            | 0.05     |
| time/                     |          |
|    fps                    | 711      |
|    iterations             | 281      |
|    time_elapsed           | 50       |
|    total_timesteps        | 35968    |
| train/                    |          |
|    explained_variance     | 0.422    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00725  |
|    learning_rate          | 0.001    |
|    n_updates              | 280      |
|    policy_objective       | 0.0406   |
|    value_loss             | 0.0263   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.45     |
|    ep_rew_mean            | 0.07     |
| time/                     |          |
|    fps                    | 711      |
|    iterations             | 282      |
|    time_elapsed           | 50       |
|    total_timesteps        | 36096    |
| train/                    |          |
|    explained_variance     | -10.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00736  |
|    learning_rate          | 0.001    |
|    n_updates              | 281      |
|    policy_objective       | 0.0285   |
|    value_loss             | 0.00028  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.54     |
|    ep_rew_mean            | 0.05     |
| time/                     |          |
|    fps                    | 711      |
|    iterations             | 283      |
|    time_elapsed           | 50       |
|    total_timesteps        | 36224    |
| train/                    |          |
|    explained_variance     | 0.345    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00942  |
|    learning_rate          | 0.001    |
|    n_updates              | 282      |
|    policy_objective       | 0.228    |
|    value_loss             | 0.0548   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.46     |
|    ep_rew_mean            | 0.05     |
| time/                     |          |
|    fps                    | 711      |
|    iterations             | 284      |
|    time_elapsed           | 51       |
|    total_timesteps        | 36352    |
| train/                    |          |
|    explained_variance     | -15.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00164  |
|    learning_rate          | 0.001    |
|    n_updates              | 283      |
|    policy_objective       | 0.0369   |
|    value_loss             | 0.00302  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.22     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 711      |
|    iterations             | 285      |
|    time_elapsed           | 51       |
|    total_timesteps        | 36480    |
| train/                    |          |
|    explained_variance     | -33      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00275  |
|    learning_rate          | 0.001    |
|    n_updates              | 284      |
|    policy_objective       | 0.0432   |
|    value_loss             | 0.000526 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.06     |
|    ep_rew_mean            | 0.05     |
| time/                     |          |
|    fps                    | 711      |
|    iterations             | 286      |
|    time_elapsed           | 51       |
|    total_timesteps        | 36608    |
| train/                    |          |
|    explained_variance     | -46.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00246  |
|    learning_rate          | 0.001    |
|    n_updates              | 285      |
|    policy_objective       | 0.0423   |
|    value_loss             | 8.44e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.25     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 710      |
|    iterations             | 287      |
|    time_elapsed           | 51       |
|    total_timesteps        | 36736    |
| train/                    |          |
|    explained_variance     | 0.114    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00667  |
|    learning_rate          | 0.001    |
|    n_updates              | 286      |
|    policy_objective       | 0.0324   |
|    value_loss             | 0.0749   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.41     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 710      |
|    iterations             | 288      |
|    time_elapsed           | 51       |
|    total_timesteps        | 36864    |
| train/                    |          |
|    explained_variance     | -21      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00707  |
|    learning_rate          | 0.001    |
|    n_updates              | 287      |
|    policy_objective       | 0.0223   |
|    value_loss             | 0.00563  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.55     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 710      |
|    iterations             | 289      |
|    time_elapsed           | 52       |
|    total_timesteps        | 36992    |
| train/                    |          |
|    explained_variance     | -4.93    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00738  |
|    learning_rate          | 0.001    |
|    n_updates              | 288      |
|    policy_objective       | 0.0346   |
|    value_loss             | 0.000211 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.74     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 710      |
|    iterations             | 290      |
|    time_elapsed           | 52       |
|    total_timesteps        | 37120    |
| train/                    |          |
|    explained_variance     | -65.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00144  |
|    learning_rate          | 0.001    |
|    n_updates              | 289      |
|    policy_objective       | 0.0426   |
|    value_loss             | 0.000239 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.94     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 710      |
|    iterations             | 291      |
|    time_elapsed           | 52       |
|    total_timesteps        | 37248    |
| train/                    |          |
|    explained_variance     | 0.0872   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00813  |
|    learning_rate          | 0.001    |
|    n_updates              | 290      |
|    policy_objective       | 0.0254   |
|    value_loss             | 0.0364   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.67     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 710      |
|    iterations             | 292      |
|    time_elapsed           | 52       |
|    total_timesteps        | 37376    |
| train/                    |          |
|    explained_variance     | -30      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00421  |
|    learning_rate          | 0.001    |
|    n_updates              | 291      |
|    policy_objective       | 0.0519   |
|    value_loss             | 0.00162  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.62     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 709      |
|    iterations             | 293      |
|    time_elapsed           | 52       |
|    total_timesteps        | 37504    |
| train/                    |          |
|    explained_variance     | -37.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00205  |
|    learning_rate          | 0.001    |
|    n_updates              | 292      |
|    policy_objective       | 0.0379   |
|    value_loss             | 0.000255 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.86     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 709      |
|    iterations             | 294      |
|    time_elapsed           | 53       |
|    total_timesteps        | 37632    |
| train/                    |          |
|    explained_variance     | -23.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00672  |
|    learning_rate          | 0.001    |
|    n_updates              | 293      |
|    policy_objective       | 0.0554   |
|    value_loss             | 0.00172  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.17     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 709      |
|    iterations             | 295      |
|    time_elapsed           | 53       |
|    total_timesteps        | 37760    |
| train/                    |          |
|    explained_variance     | 0.00838  |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00494  |
|    learning_rate          | 0.001    |
|    n_updates              | 294      |
|    policy_objective       | 0.0458   |
|    value_loss             | 0.0385   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.17     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 709      |
|    iterations             | 296      |
|    time_elapsed           | 53       |
|    total_timesteps        | 37888    |
| train/                    |          |
|    explained_variance     | -26.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00679  |
|    learning_rate          | 0.001    |
|    n_updates              | 295      |
|    policy_objective       | 0.0411   |
|    value_loss             | 0.00362  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.05     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 709      |
|    iterations             | 297      |
|    time_elapsed           | 53       |
|    total_timesteps        | 38016    |
| train/                    |          |
|    explained_variance     | -0.303   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00898  |
|    learning_rate          | 0.001    |
|    n_updates              | 296      |
|    policy_objective       | 0.03     |
|    value_loss             | 0.00288  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.33     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 709      |
|    iterations             | 298      |
|    time_elapsed           | 53       |
|    total_timesteps        | 38144    |
| train/                    |          |
|    explained_variance     | -21.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00727  |
|    learning_rate          | 0.001    |
|    n_updates              | 297      |
|    policy_objective       | 0.0344   |
|    value_loss             | 0.000382 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.44     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 709      |
|    iterations             | 299      |
|    time_elapsed           | 53       |
|    total_timesteps        | 38272    |
| train/                    |          |
|    explained_variance     | 0.19     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00519  |
|    learning_rate          | 0.001    |
|    n_updates              | 298      |
|    policy_objective       | 0.0329   |
|    value_loss             | 0.0719   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.98     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 709      |
|    iterations             | 300      |
|    time_elapsed           | 54       |
|    total_timesteps        | 38400    |
| train/                    |          |
|    explained_variance     | -10.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00204  |
|    learning_rate          | 0.001    |
|    n_updates              | 299      |
|    policy_objective       | 0.0347   |
|    value_loss             | 0.00442  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.95     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 709      |
|    iterations             | 301      |
|    time_elapsed           | 54       |
|    total_timesteps        | 38528    |
| train/                    |          |
|    explained_variance     | 0.167    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0056   |
|    learning_rate          | 0.001    |
|    n_updates              | 300      |
|    policy_objective       | 0.0446   |
|    value_loss             | 0.0377   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.87     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 709      |
|    iterations             | 302      |
|    time_elapsed           | 54       |
|    total_timesteps        | 38656    |
| train/                    |          |
|    explained_variance     | -17.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00617  |
|    learning_rate          | 0.001    |
|    n_updates              | 301      |
|    policy_objective       | 0.045    |
|    value_loss             | 0.00223  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.09     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 709      |
|    iterations             | 303      |
|    time_elapsed           | 54       |
|    total_timesteps        | 38784    |
| train/                    |          |
|    explained_variance     | -5.14    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00213  |
|    learning_rate          | 0.001    |
|    n_updates              | 302      |
|    policy_objective       | 0.0273   |
|    value_loss             | 0.00535  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.43     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 709      |
|    iterations             | 304      |
|    time_elapsed           | 54       |
|    total_timesteps        | 38912    |
| train/                    |          |
|    explained_variance     | -65.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00154  |
|    learning_rate          | 0.001    |
|    n_updates              | 303      |
|    policy_objective       | 0.0395   |
|    value_loss             | 0.000834 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.62     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 709      |
|    iterations             | 305      |
|    time_elapsed           | 55       |
|    total_timesteps        | 39040    |
| train/                    |          |
|    explained_variance     | -26.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00761  |
|    learning_rate          | 0.001    |
|    n_updates              | 304      |
|    policy_objective       | 0.0374   |
|    value_loss             | 0.000336 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.89     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 709      |
|    iterations             | 306      |
|    time_elapsed           | 55       |
|    total_timesteps        | 39168    |
| train/                    |          |
|    explained_variance     | 0.00748  |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0044   |
|    learning_rate          | 0.001    |
|    n_updates              | 305      |
|    policy_objective       | 0.0735   |
|    value_loss             | 0.0453   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.87     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 709      |
|    iterations             | 307      |
|    time_elapsed           | 55       |
|    total_timesteps        | 39296    |
| train/                    |          |
|    explained_variance     | 0.206    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00644  |
|    learning_rate          | 0.001    |
|    n_updates              | 306      |
|    policy_objective       | 0.101    |
|    value_loss             | 0.0539   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.04     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 709      |
|    iterations             | 308      |
|    time_elapsed           | 55       |
|    total_timesteps        | 39424    |
| train/                    |          |
|    explained_variance     | -0.861   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00684  |
|    learning_rate          | 0.001    |
|    n_updates              | 307      |
|    policy_objective       | 0.0399   |
|    value_loss             | 0.048    |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.71     |
|    ep_rew_mean            | 0.06     |
| time/                     |          |
|    fps                    | 709      |
|    iterations             | 309      |
|    time_elapsed           | 55       |
|    total_timesteps        | 39552    |
| train/                    |          |
|    explained_variance     | -5.64    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00326  |
|    learning_rate          | 0.001    |
|    n_updates              | 308      |
|    policy_objective       | 0.0355   |
|    value_loss             | 0.00302  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.82     |
|    ep_rew_mean            | 0.07     |
| time/                     |          |
|    fps                    | 709      |
|    iterations             | 310      |
|    time_elapsed           | 55       |
|    total_timesteps        | 39680    |
| train/                    |          |
|    explained_variance     | 0.17     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00817  |
|    learning_rate          | 0.001    |
|    n_updates              | 309      |
|    policy_objective       | 0.0724   |
|    value_loss             | 0.069    |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.42     |
|    ep_rew_mean            | 0.06     |
| time/                     |          |
|    fps                    | 709      |
|    iterations             | 311      |
|    time_elapsed           | 56       |
|    total_timesteps        | 39808    |
| train/                    |          |
|    explained_variance     | -0.125   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00777  |
|    learning_rate          | 0.001    |
|    n_updates              | 310      |
|    policy_objective       | 0.0369   |
|    value_loss             | 0.0533   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.36     |
|    ep_rew_mean            | 0.05     |
| time/                     |          |
|    fps                    | 709      |
|    iterations             | 312      |
|    time_elapsed           | 56       |
|    total_timesteps        | 39936    |
| train/                    |          |
|    explained_variance     | -2.62    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00583  |
|    learning_rate          | 0.001    |
|    n_updates              | 311      |
|    policy_objective       | 0.0434   |
|    value_loss             | 0.00113  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.62     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 708      |
|    iterations             | 313      |
|    time_elapsed           | 56       |
|    total_timesteps        | 40064    |
| train/                    |          |
|    explained_variance     | -1.98    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00595  |
|    learning_rate          | 0.001    |
|    n_updates              | 312      |
|    policy_objective       | 0.0581   |
|    value_loss             | 0.000371 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.96     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 708      |
|    iterations             | 314      |
|    time_elapsed           | 56       |
|    total_timesteps        | 40192    |
| train/                    |          |
|    explained_variance     | -55.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0062   |
|    learning_rate          | 0.001    |
|    n_updates              | 313      |
|    policy_objective       | 0.0356   |
|    value_loss             | 0.000566 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.74     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 708      |
|    iterations             | 315      |
|    time_elapsed           | 56       |
|    total_timesteps        | 40320    |
| train/                    |          |
|    explained_variance     | -37.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00363  |
|    learning_rate          | 0.001    |
|    n_updates              | 314      |
|    policy_objective       | 0.0517   |
|    value_loss             | 0.00297  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.96     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 708      |
|    iterations             | 316      |
|    time_elapsed           | 57       |
|    total_timesteps        | 40448    |
| train/                    |          |
|    explained_variance     | 0.197    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00568  |
|    learning_rate          | 0.001    |
|    n_updates              | 315      |
|    policy_objective       | 0.0415   |
|    value_loss             | 0.0334   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.88     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 708      |
|    iterations             | 317      |
|    time_elapsed           | 57       |
|    total_timesteps        | 40576    |
| train/                    |          |
|    explained_variance     | -4.69    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00791  |
|    learning_rate          | 0.001    |
|    n_updates              | 316      |
|    policy_objective       | 0.0342   |
|    value_loss             | 0.000935 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.37     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 708      |
|    iterations             | 318      |
|    time_elapsed           | 57       |
|    total_timesteps        | 40704    |
| train/                    |          |
|    explained_variance     | -21.6    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00416  |
|    learning_rate          | 0.001    |
|    n_updates              | 317      |
|    policy_objective       | 0.0422   |
|    value_loss             | 0.0016   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.79     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 708      |
|    iterations             | 319      |
|    time_elapsed           | 57       |
|    total_timesteps        | 40832    |
| train/                    |          |
|    explained_variance     | -38.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00595  |
|    learning_rate          | 0.001    |
|    n_updates              | 318      |
|    policy_objective       | 0.0534   |
|    value_loss             | 8.49e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.53     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 708      |
|    iterations             | 320      |
|    time_elapsed           | 57       |
|    total_timesteps        | 40960    |
| train/                    |          |
|    explained_variance     | -33.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00292  |
|    learning_rate          | 0.001    |
|    n_updates              | 319      |
|    policy_objective       | 0.0501   |
|    value_loss             | 0.000251 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.1      |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 708      |
|    iterations             | 321      |
|    time_elapsed           | 57       |
|    total_timesteps        | 41088    |
| train/                    |          |
|    explained_variance     | -25.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00491  |
|    learning_rate          | 0.001    |
|    n_updates              | 320      |
|    policy_objective       | 0.0536   |
|    value_loss             | 6.9e-06  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.86     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 708      |
|    iterations             | 322      |
|    time_elapsed           | 58       |
|    total_timesteps        | 41216    |
| train/                    |          |
|    explained_variance     | -26.7    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00131  |
|    learning_rate          | 0.001    |
|    n_updates              | 321      |
|    policy_objective       | 0.0704   |
|    value_loss             | 0.00325  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.17     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 708      |
|    iterations             | 323      |
|    time_elapsed           | 58       |
|    total_timesteps        | 41344    |
| train/                    |          |
|    explained_variance     | 0.2      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0064   |
|    learning_rate          | 0.001    |
|    n_updates              | 322      |
|    policy_objective       | 0.0575   |
|    value_loss             | 0.0463   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.57     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 708      |
|    iterations             | 324      |
|    time_elapsed           | 58       |
|    total_timesteps        | 41472    |
| train/                    |          |
|    explained_variance     | -7.72    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00469  |
|    learning_rate          | 0.001    |
|    n_updates              | 323      |
|    policy_objective       | 0.0607   |
|    value_loss             | 0.00689  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9        |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 708      |
|    iterations             | 325      |
|    time_elapsed           | 58       |
|    total_timesteps        | 41600    |
| train/                    |          |
|    explained_variance     | 0.0617   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00847  |
|    learning_rate          | 0.001    |
|    n_updates              | 324      |
|    policy_objective       | 0.0673   |
|    value_loss             | 0.0502   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.6      |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 708      |
|    iterations             | 326      |
|    time_elapsed           | 58       |
|    total_timesteps        | 41728    |
| train/                    |          |
|    explained_variance     | 0.0929   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00511  |
|    learning_rate          | 0.001    |
|    n_updates              | 325      |
|    policy_objective       | 0.0436   |
|    value_loss             | 0.0403   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.93     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 708      |
|    iterations             | 327      |
|    time_elapsed           | 59       |
|    total_timesteps        | 41856    |
| train/                    |          |
|    explained_variance     | -13.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00661  |
|    learning_rate          | 0.001    |
|    n_updates              | 326      |
|    policy_objective       | 0.0291   |
|    value_loss             | 0.0041   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.52     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 708      |
|    iterations             | 328      |
|    time_elapsed           | 59       |
|    total_timesteps        | 41984    |
| train/                    |          |
|    explained_variance     | -21      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0042   |
|    learning_rate          | 0.001    |
|    n_updates              | 327      |
|    policy_objective       | 0.0637   |
|    value_loss             | 0.0046   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.06     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 708      |
|    iterations             | 329      |
|    time_elapsed           | 59       |
|    total_timesteps        | 42112    |
| train/                    |          |
|    explained_variance     | -0.224   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00663  |
|    learning_rate          | 0.001    |
|    n_updates              | 328      |
|    policy_objective       | 0.0551   |
|    value_loss             | 0.000955 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.44     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 708      |
|    iterations             | 330      |
|    time_elapsed           | 59       |
|    total_timesteps        | 42240    |
| train/                    |          |
|    explained_variance     | 0.186    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00235  |
|    learning_rate          | 0.001    |
|    n_updates              | 329      |
|    policy_objective       | 0.0424   |
|    value_loss             | 0.0197   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.33     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 708      |
|    iterations             | 331      |
|    time_elapsed           | 59       |
|    total_timesteps        | 42368    |
| train/                    |          |
|    explained_variance     | 0.178    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00518  |
|    learning_rate          | 0.001    |
|    n_updates              | 330      |
|    policy_objective       | 0.0376   |
|    value_loss             | 0.0467   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.46     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 708      |
|    iterations             | 332      |
|    time_elapsed           | 59       |
|    total_timesteps        | 42496    |
| train/                    |          |
|    explained_variance     | -1.88    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00466  |
|    learning_rate          | 0.001    |
|    n_updates              | 331      |
|    policy_objective       | 0.0533   |
|    value_loss             | 0.00469  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.34     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 708      |
|    iterations             | 333      |
|    time_elapsed           | 60       |
|    total_timesteps        | 42624    |
| train/                    |          |
|    explained_variance     | -25.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00448  |
|    learning_rate          | 0.001    |
|    n_updates              | 332      |
|    policy_objective       | 0.0231   |
|    value_loss             | 0.00417  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.47     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 708      |
|    iterations             | 334      |
|    time_elapsed           | 60       |
|    total_timesteps        | 42752    |
| train/                    |          |
|    explained_variance     | -1.94    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00704  |
|    learning_rate          | 0.001    |
|    n_updates              | 333      |
|    policy_objective       | 0.0323   |
|    value_loss             | 9.14e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.34     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 707      |
|    iterations             | 335      |
|    time_elapsed           | 60       |
|    total_timesteps        | 42880    |
| train/                    |          |
|    explained_variance     | -42.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00682  |
|    learning_rate          | 0.001    |
|    n_updates              | 334      |
|    policy_objective       | 0.0234   |
|    value_loss             | 1.19e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.16     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 707      |
|    iterations             | 336      |
|    time_elapsed           | 60       |
|    total_timesteps        | 43008    |
| train/                    |          |
|    explained_variance     | -0.00033 |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00326  |
|    learning_rate          | 0.001    |
|    n_updates              | 335      |
|    policy_objective       | 0.246    |
|    value_loss             | 0.0481   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.81     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 707      |
|    iterations             | 337      |
|    time_elapsed           | 60       |
|    total_timesteps        | 43136    |
| train/                    |          |
|    explained_variance     | -3.93    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00632  |
|    learning_rate          | 0.001    |
|    n_updates              | 336      |
|    policy_objective       | 0.0524   |
|    value_loss             | 0.00414  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.94     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 707      |
|    iterations             | 338      |
|    time_elapsed           | 61       |
|    total_timesteps        | 43264    |
| train/                    |          |
|    explained_variance     | -0.728   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00619  |
|    learning_rate          | 0.001    |
|    n_updates              | 337      |
|    policy_objective       | 0.0391   |
|    value_loss             | 0.000339 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.16     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 707      |
|    iterations             | 339      |
|    time_elapsed           | 61       |
|    total_timesteps        | 43392    |
| train/                    |          |
|    explained_variance     | 0.0297   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00611  |
|    learning_rate          | 0.001    |
|    n_updates              | 338      |
|    policy_objective       | 0.0528   |
|    value_loss             | 0.0425   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.75     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 707      |
|    iterations             | 340      |
|    time_elapsed           | 61       |
|    total_timesteps        | 43520    |
| train/                    |          |
|    explained_variance     | -14.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00615  |
|    learning_rate          | 0.001    |
|    n_updates              | 339      |
|    policy_objective       | 0.0514   |
|    value_loss             | 0.00152  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.64     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 707      |
|    iterations             | 341      |
|    time_elapsed           | 61       |
|    total_timesteps        | 43648    |
| train/                    |          |
|    explained_variance     | -11.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00654  |
|    learning_rate          | 0.001    |
|    n_updates              | 340      |
|    policy_objective       | 0.0281   |
|    value_loss             | 0.00019  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.05     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 707      |
|    iterations             | 342      |
|    time_elapsed           | 61       |
|    total_timesteps        | 43776    |
| train/                    |          |
|    explained_variance     | 0.102    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00387  |
|    learning_rate          | 0.001    |
|    n_updates              | 341      |
|    policy_objective       | 0.054    |
|    value_loss             | 0.0419   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.19     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 707      |
|    iterations             | 343      |
|    time_elapsed           | 62       |
|    total_timesteps        | 43904    |
| train/                    |          |
|    explained_variance     | 0.218    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00774  |
|    learning_rate          | 0.001    |
|    n_updates              | 342      |
|    policy_objective       | 0.0542   |
|    value_loss             | 0.0638   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.38     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 707      |
|    iterations             | 344      |
|    time_elapsed           | 62       |
|    total_timesteps        | 44032    |
| train/                    |          |
|    explained_variance     | -33.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00189  |
|    learning_rate          | 0.001    |
|    n_updates              | 343      |
|    policy_objective       | 0.0299   |
|    value_loss             | 0.00395  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.04     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 707      |
|    iterations             | 345      |
|    time_elapsed           | 62       |
|    total_timesteps        | 44160    |
| train/                    |          |
|    explained_variance     | -14.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00454  |
|    learning_rate          | 0.001    |
|    n_updates              | 344      |
|    policy_objective       | 0.0272   |
|    value_loss             | 0.00351  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.82     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 707      |
|    iterations             | 346      |
|    time_elapsed           | 62       |
|    total_timesteps        | 44288    |
| train/                    |          |
|    explained_variance     | -32.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00424  |
|    learning_rate          | 0.001    |
|    n_updates              | 345      |
|    policy_objective       | 0.051    |
|    value_loss             | 0.000178 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.68     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 707      |
|    iterations             | 347      |
|    time_elapsed           | 62       |
|    total_timesteps        | 44416    |
| train/                    |          |
|    explained_variance     | -6.29    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00428  |
|    learning_rate          | 0.001    |
|    n_updates              | 346      |
|    policy_objective       | 0.0624   |
|    value_loss             | 4.5e-06  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.07     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 707      |
|    iterations             | 348      |
|    time_elapsed           | 62       |
|    total_timesteps        | 44544    |
| train/                    |          |
|    explained_variance     | -24.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00303  |
|    learning_rate          | 0.001    |
|    n_updates              | 347      |
|    policy_objective       | 0.0478   |
|    value_loss             | 2.22e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.45     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 707      |
|    iterations             | 349      |
|    time_elapsed           | 63       |
|    total_timesteps        | 44672    |
| train/                    |          |
|    explained_variance     | -25.7    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00899  |
|    learning_rate          | 0.001    |
|    n_updates              | 348      |
|    policy_objective       | 0.055    |
|    value_loss             | 1.3e-06  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.32     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 707      |
|    iterations             | 350      |
|    time_elapsed           | 63       |
|    total_timesteps        | 44800    |
| train/                    |          |
|    explained_variance     | -1.83    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00608  |
|    learning_rate          | 0.001    |
|    n_updates              | 349      |
|    policy_objective       | 0.0314   |
|    value_loss             | 2.53e-08 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.36     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 707      |
|    iterations             | 351      |
|    time_elapsed           | 63       |
|    total_timesteps        | 44928    |
| train/                    |          |
|    explained_variance     | -169     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00272  |
|    learning_rate          | 0.001    |
|    n_updates              | 350      |
|    policy_objective       | 0.0462   |
|    value_loss             | 3.44e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.14     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 707      |
|    iterations             | 352      |
|    time_elapsed           | 63       |
|    total_timesteps        | 45056    |
| train/                    |          |
|    explained_variance     | -0.0318  |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00832  |
|    learning_rate          | 0.001    |
|    n_updates              | 351      |
|    policy_objective       | 0.0621   |
|    value_loss             | 6.06e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.02     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 706      |
|    iterations             | 353      |
|    time_elapsed           | 63       |
|    total_timesteps        | 45184    |
| train/                    |          |
|    explained_variance     | -41.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00334  |
|    learning_rate          | 0.001    |
|    n_updates              | 352      |
|    policy_objective       | 0.0413   |
|    value_loss             | 9.06e-08 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.56     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 706      |
|    iterations             | 354      |
|    time_elapsed           | 64       |
|    total_timesteps        | 45312    |
| train/                    |          |
|    explained_variance     | -37.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00391  |
|    learning_rate          | 0.001    |
|    n_updates              | 353      |
|    policy_objective       | 0.0437   |
|    value_loss             | 1.17e-09 |
----------------------------------------
-----------------------------------------
| adaptive/                 |           |
|    adaptation_factor      | 1         |
|    algorithm              | TRPO      |
|    base_lr                | 0.001     |
|    base_target_kl         | 0.01      |
|    drift_magnitude        | 0         |
|    learning_rate          | 0.001     |
|    target_kl              | 0.01      |
| env/                      |           |
|    base_value             | 9.8       |
|    slip_prob              | 9.8       |
| rollout/                  |           |
|    ep_len_mean            | 7.67      |
|    ep_rew_mean            | 0.03      |
| time/                     |           |
|    fps                    | 706       |
|    iterations             | 355       |
|    time_elapsed           | 64        |
|    total_timesteps        | 45440     |
| train/                    |           |
|    explained_variance     | -5.19e-05 |
|    is_line_search_success | 1         |
|    kl_divergence_loss     | 0.0056    |
|    learning_rate          | 0.001     |
|    n_updates              | 354       |
|    policy_objective       | 0.0543    |
|    value_loss             | 0.0758    |
-----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.77     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 706      |
|    iterations             | 356      |
|    time_elapsed           | 64       |
|    total_timesteps        | 45568    |
| train/                    |          |
|    explained_variance     | 0.425    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00387  |
|    learning_rate          | 0.001    |
|    n_updates              | 355      |
|    policy_objective       | 0.0754   |
|    value_loss             | 0.0176   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.88     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 705      |
|    iterations             | 357      |
|    time_elapsed           | 64       |
|    total_timesteps        | 45696    |
| train/                    |          |
|    explained_variance     | -20.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00164  |
|    learning_rate          | 0.001    |
|    n_updates              | 356      |
|    policy_objective       | 0.0442   |
|    value_loss             | 0.00417  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.02     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 705      |
|    iterations             | 358      |
|    time_elapsed           | 64       |
|    total_timesteps        | 45824    |
| train/                    |          |
|    explained_variance     | -29.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00404  |
|    learning_rate          | 0.001    |
|    n_updates              | 357      |
|    policy_objective       | 0.0296   |
|    value_loss             | 0.00111  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.82     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 705      |
|    iterations             | 359      |
|    time_elapsed           | 65       |
|    total_timesteps        | 45952    |
| train/                    |          |
|    explained_variance     | -0.927   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00608  |
|    learning_rate          | 0.001    |
|    n_updates              | 358      |
|    policy_objective       | 0.0561   |
|    value_loss             | 6.89e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.78     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 360      |
|    time_elapsed           | 65       |
|    total_timesteps        | 46080    |
| train/                    |          |
|    explained_variance     | -27.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0039   |
|    learning_rate          | 0.001    |
|    n_updates              | 359      |
|    policy_objective       | 0.0549   |
|    value_loss             | 0.0026   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.69     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 361      |
|    time_elapsed           | 65       |
|    total_timesteps        | 46208    |
| train/                    |          |
|    explained_variance     | -5.85    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00799  |
|    learning_rate          | 0.001    |
|    n_updates              | 360      |
|    policy_objective       | 0.0575   |
|    value_loss             | 1.47e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.64     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 362      |
|    time_elapsed           | 65       |
|    total_timesteps        | 46336    |
| train/                    |          |
|    explained_variance     | -95.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00419  |
|    learning_rate          | 0.001    |
|    n_updates              | 361      |
|    policy_objective       | 0.0816   |
|    value_loss             | 0.000422 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.13     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 363      |
|    time_elapsed           | 65       |
|    total_timesteps        | 46464    |
| train/                    |          |
|    explained_variance     | -43.6    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00813  |
|    learning_rate          | 0.001    |
|    n_updates              | 362      |
|    policy_objective       | 0.0383   |
|    value_loss             | 1.16e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.14     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 364      |
|    time_elapsed           | 66       |
|    total_timesteps        | 46592    |
| train/                    |          |
|    explained_variance     | -145     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00249  |
|    learning_rate          | 0.001    |
|    n_updates              | 363      |
|    policy_objective       | 0.0199   |
|    value_loss             | 1.42e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.99     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 365      |
|    time_elapsed           | 66       |
|    total_timesteps        | 46720    |
| train/                    |          |
|    explained_variance     | -417     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00179  |
|    learning_rate          | 0.001    |
|    n_updates              | 364      |
|    policy_objective       | 0.0577   |
|    value_loss             | 2.08e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.1      |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 366      |
|    time_elapsed           | 66       |
|    total_timesteps        | 46848    |
| train/                    |          |
|    explained_variance     | 0.00283  |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0064   |
|    learning_rate          | 0.001    |
|    n_updates              | 365      |
|    policy_objective       | 0.0353   |
|    value_loss             | 0.0344   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.72     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 704      |
|    iterations             | 367      |
|    time_elapsed           | 66       |
|    total_timesteps        | 46976    |
| train/                    |          |
|    explained_variance     | 0.17     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00576  |
|    learning_rate          | 0.001    |
|    n_updates              | 366      |
|    policy_objective       | 0.0361   |
|    value_loss             | 0.0444   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.04     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 703      |
|    iterations             | 368      |
|    time_elapsed           | 66       |
|    total_timesteps        | 47104    |
| train/                    |          |
|    explained_variance     | -8.45    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00618  |
|    learning_rate          | 0.001    |
|    n_updates              | 367      |
|    policy_objective       | 0.0397   |
|    value_loss             | 0.00199  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.39     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 703      |
|    iterations             | 369      |
|    time_elapsed           | 67       |
|    total_timesteps        | 47232    |
| train/                    |          |
|    explained_variance     | -18.7    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00351  |
|    learning_rate          | 0.001    |
|    n_updates              | 368      |
|    policy_objective       | 0.0523   |
|    value_loss             | 0.00342  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.52     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 703      |
|    iterations             | 370      |
|    time_elapsed           | 67       |
|    total_timesteps        | 47360    |
| train/                    |          |
|    explained_variance     | -8.3     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00414  |
|    learning_rate          | 0.001    |
|    n_updates              | 369      |
|    policy_objective       | 0.0486   |
|    value_loss             | 0.000449 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.03     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 703      |
|    iterations             | 371      |
|    time_elapsed           | 67       |
|    total_timesteps        | 47488    |
| train/                    |          |
|    explained_variance     | 0.0341   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0044   |
|    learning_rate          | 0.001    |
|    n_updates              | 370      |
|    policy_objective       | 0.0667   |
|    value_loss             | 0.0384   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.51     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 703      |
|    iterations             | 372      |
|    time_elapsed           | 67       |
|    total_timesteps        | 47616    |
| train/                    |          |
|    explained_variance     | 0.173    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00403  |
|    learning_rate          | 0.001    |
|    n_updates              | 371      |
|    policy_objective       | 0.0462   |
|    value_loss             | 0.029    |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.57     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 703      |
|    iterations             | 373      |
|    time_elapsed           | 67       |
|    total_timesteps        | 47744    |
| train/                    |          |
|    explained_variance     | -32.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00359  |
|    learning_rate          | 0.001    |
|    n_updates              | 372      |
|    policy_objective       | 0.0331   |
|    value_loss             | 0.00294  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.39     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 703      |
|    iterations             | 374      |
|    time_elapsed           | 68       |
|    total_timesteps        | 47872    |
| train/                    |          |
|    explained_variance     | -28.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00307  |
|    learning_rate          | 0.001    |
|    n_updates              | 373      |
|    policy_objective       | 0.0397   |
|    value_loss             | 0.00293  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.52     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 703      |
|    iterations             | 375      |
|    time_elapsed           | 68       |
|    total_timesteps        | 48000    |
| train/                    |          |
|    explained_variance     | -15.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00865  |
|    learning_rate          | 0.001    |
|    n_updates              | 374      |
|    policy_objective       | 0.0811   |
|    value_loss             | 3.64e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.42     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 703      |
|    iterations             | 376      |
|    time_elapsed           | 68       |
|    total_timesteps        | 48128    |
| train/                    |          |
|    explained_variance     | 0.179    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00399  |
|    learning_rate          | 0.001    |
|    n_updates              | 375      |
|    policy_objective       | 0.0406   |
|    value_loss             | 0.0357   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.02     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 703      |
|    iterations             | 377      |
|    time_elapsed           | 68       |
|    total_timesteps        | 48256    |
| train/                    |          |
|    explained_variance     | -0.0733  |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0046   |
|    learning_rate          | 0.001    |
|    n_updates              | 376      |
|    policy_objective       | 0.0952   |
|    value_loss             | 0.051    |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9        |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 703      |
|    iterations             | 378      |
|    time_elapsed           | 68       |
|    total_timesteps        | 48384    |
| train/                    |          |
|    explained_variance     | -7.51    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00237  |
|    learning_rate          | 0.001    |
|    n_updates              | 377      |
|    policy_objective       | 0.0634   |
|    value_loss             | 0.0049   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.93     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 703      |
|    iterations             | 379      |
|    time_elapsed           | 68       |
|    total_timesteps        | 48512    |
| train/                    |          |
|    explained_variance     | -22.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00248  |
|    learning_rate          | 0.001    |
|    n_updates              | 378      |
|    policy_objective       | 0.0369   |
|    value_loss             | 0.002    |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.4      |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 703      |
|    iterations             | 380      |
|    time_elapsed           | 69       |
|    total_timesteps        | 48640    |
| train/                    |          |
|    explained_variance     | 0.00536  |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00541  |
|    learning_rate          | 0.001    |
|    n_updates              | 379      |
|    policy_objective       | 0.0616   |
|    value_loss             | 0.0404   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.49     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 703      |
|    iterations             | 381      |
|    time_elapsed           | 69       |
|    total_timesteps        | 48768    |
| train/                    |          |
|    explained_variance     | -12.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00405  |
|    learning_rate          | 0.001    |
|    n_updates              | 380      |
|    policy_objective       | 0.0332   |
|    value_loss             | 0.00348  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.44     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 703      |
|    iterations             | 382      |
|    time_elapsed           | 69       |
|    total_timesteps        | 48896    |
| train/                    |          |
|    explained_variance     | -5.31    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00573  |
|    learning_rate          | 0.001    |
|    n_updates              | 381      |
|    policy_objective       | 0.0445   |
|    value_loss             | 3.33e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.96     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 703      |
|    iterations             | 383      |
|    time_elapsed           | 69       |
|    total_timesteps        | 49024    |
| train/                    |          |
|    explained_variance     | 0.0621   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00724  |
|    learning_rate          | 0.001    |
|    n_updates              | 382      |
|    policy_objective       | 0.0702   |
|    value_loss             | 0.031    |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.18     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 703      |
|    iterations             | 384      |
|    time_elapsed           | 69       |
|    total_timesteps        | 49152    |
| train/                    |          |
|    explained_variance     | -7.55    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00158  |
|    learning_rate          | 0.001    |
|    n_updates              | 383      |
|    policy_objective       | 0.0377   |
|    value_loss             | 0.00259  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.64     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 703      |
|    iterations             | 385      |
|    time_elapsed           | 70       |
|    total_timesteps        | 49280    |
| train/                    |          |
|    explained_variance     | -12.6    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00614  |
|    learning_rate          | 0.001    |
|    n_updates              | 384      |
|    policy_objective       | 0.0544   |
|    value_loss             | 0.000167 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.27     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 703      |
|    iterations             | 386      |
|    time_elapsed           | 70       |
|    total_timesteps        | 49408    |
| train/                    |          |
|    explained_variance     | -18.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00274  |
|    learning_rate          | 0.001    |
|    n_updates              | 385      |
|    policy_objective       | 0.0606   |
|    value_loss             | 1.03e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.97     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 703      |
|    iterations             | 387      |
|    time_elapsed           | 70       |
|    total_timesteps        | 49536    |
| train/                    |          |
|    explained_variance     | -34      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00181  |
|    learning_rate          | 0.001    |
|    n_updates              | 386      |
|    policy_objective       | 0.0488   |
|    value_loss             | 0.00029  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.89     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 702      |
|    iterations             | 388      |
|    time_elapsed           | 70       |
|    total_timesteps        | 49664    |
| train/                    |          |
|    explained_variance     | -59.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0063   |
|    learning_rate          | 0.001    |
|    n_updates              | 387      |
|    policy_objective       | 0.036    |
|    value_loss             | 5.27e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.04     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 702      |
|    iterations             | 389      |
|    time_elapsed           | 70       |
|    total_timesteps        | 49792    |
| train/                    |          |
|    explained_variance     | -2.05    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00424  |
|    learning_rate          | 0.001    |
|    n_updates              | 388      |
|    policy_objective       | 0.0333   |
|    value_loss             | 4.77e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.26     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 702      |
|    iterations             | 390      |
|    time_elapsed           | 71       |
|    total_timesteps        | 49920    |
| train/                    |          |
|    explained_variance     | 0.041    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00311  |
|    learning_rate          | 0.001    |
|    n_updates              | 389      |
|    policy_objective       | 0.178    |
|    value_loss             | 0.0341   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.41     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 702      |
|    iterations             | 391      |
|    time_elapsed           | 71       |
|    total_timesteps        | 50048    |
| train/                    |          |
|    explained_variance     | -9.42    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00533  |
|    learning_rate          | 0.001    |
|    n_updates              | 390      |
|    policy_objective       | 0.0541   |
|    value_loss             | 0.00313  |
----------------------------------------
wandb: WARNING Symlinked 1 file into the W&B run directory; call wandb.save again to sync new files.
wandb: updating run metadata
wandb: uploading wandb-summary.json; uploading model.zip; uploading output.log
wandb: uploading model.zip; uploading output.log; uploading config.yaml; uploading logs/FrozenLake_4x4_slip_prob_linear_Adaptive_20251218_002919_0/events.out.tfevents.1765992969.hungchan-Precision-7560.441336.0
wandb: uploading model.zip; uploading output.log; uploading logs/FrozenLake_4x4_slip_prob_linear_Adaptive_20251218_002919_0/events.out.tfevents.1765992969.hungchan-Precision-7560.441336.0
wandb: uploading output.log; uploading logs/FrozenLake_4x4_slip_prob_linear_Adaptive_20251218_002919_0/events.out.tfevents.1765992969.hungchan-Precision-7560.441336.0
wandb: uploading logs/FrozenLake_4x4_slip_prob_linear_Adaptive_20251218_002919_0/events.out.tfevents.1765992969.hungchan-Precision-7560.441336.0
wandb: uploading history steps 5179-6640, summary, console lines 9520-11351
wandb: 
wandb: Run history:
wandb: adaptive/adaptation_factor â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:           adaptive/base_lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    adaptive/base_target_kl â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:   adaptive/drift_magnitude â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:     adaptive/learning_rate â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         adaptive/target_kl â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:             env/base_value â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:              env/slip_prob â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                global_step â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆ
wandb:        rollout/ep_len_mean â–„â–…â–‚â–…â–ƒâ–ƒâ–ƒâ–…â–„â–…â–…â–†â–…â–†â–‚â–†â–…â–„â–…â–†â–…â–…â–‚â–‚â–†â–â–ƒâ–ƒâ–†â–…â–„â–ƒâ–…â–†â–†â–‚â–„â–ˆâ–ˆâ–ˆ
wandb:                         +8 ...
wandb: 
wandb: Run summary:
wandb: adaptive/adaptation_factor 1
wandb:           adaptive/base_lr 0.001
wandb:    adaptive/base_target_kl 0.01
wandb:   adaptive/drift_magnitude 0
wandb:     adaptive/learning_rate 0.001
wandb:         adaptive/target_kl 0.01
wandb:             env/base_value 9.8
wandb:              env/slip_prob 9.8
wandb:                global_step 50048
wandb:        rollout/ep_len_mean 9.41
wandb:                         +8 ...
wandb: 
wandb: ðŸš€ View run FrozenLake_4x4_slip_prob_linear_Adaptive_20251218_002919 at: https://wandb.ai/hungtrab-hanoi-university-of-science-and-technology/FrozenLake_Drift_Research/runs/dg4qjod0
wandb: â­ï¸ View project at: https://wandb.ai/hungtrab-hanoi-university-of-science-and-technology/FrozenLake_Drift_Research
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)
wandb: Find logs at: logs/FrozenLake_4x4_slip_prob_linear_Adaptive_20251218_002919/wandb/run-20251218_003607-dg4qjod0/logs
>>> [DriftAdaptiveCallback] Training Ended
    Final LR: 0.001000
    Last Drift Magnitude: 0.0000
    Final Target KL: 0.0100
Model saved locally to: models/FrozenLake_4x4_slip_prob_linear_Adaptive_20251218_002919.zip
/home/hungchan/miniconda3/envs/rl_hf_course/lib/python3.10/site-packages/gymnasium/wrappers/rendering.py:293: UserWarning: [33mWARN: Overwriting existing videos at /home/hungchan/Work/Deep-RL/videos/FrozenLake_4x4_slip_prob_linear_Adaptive_20251218_002919 folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)[0m
  logger.warn(
/home/hungchan/miniconda3/envs/rl_hf_course/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run TRPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.
  warnings.warn(
>>> [Wrapper] Initialized Non-Stationary FrozenLake
    - slip_prob: linear (base=0.67)
Loading TRPO model from: models/FrozenLake_4x4_slip_prob_linear_Adaptive_20251218_002919.zip

Recording Episode 1/1...
  Episode finished: 8 steps, reward = 0.0

Videos saved to: videos/FrozenLake_4x4_slip_prob_linear_Adaptive_20251218_002919
