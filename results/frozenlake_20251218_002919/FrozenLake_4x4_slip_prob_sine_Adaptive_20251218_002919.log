wandb: Currently logged in as: hungtrab (hungtrab-hanoi-university-of-science-and-technology) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: setting up run y7pdblx6
wandb: Tracking run with wandb version 0.23.1
wandb: Run data is saved locally in logs/FrozenLake_4x4_slip_prob_sine_Adaptive_20251218_002919/wandb/run-20251218_003322-y7pdblx6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run FrozenLake_4x4_slip_prob_sine_Adaptive_20251218_002919
wandb: â­ï¸ View project at https://wandb.ai/hungtrab-hanoi-university-of-science-and-technology/FrozenLake_Drift_Research
wandb: ðŸš€ View run at https://wandb.ai/hungtrab-hanoi-university-of-science-and-technology/FrozenLake_Drift_Research/runs/y7pdblx6
/home/hungchan/miniconda3/envs/rl_hf_course/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run TRPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.
  warnings.warn(
--- Training Start: FrozenLake_4x4_slip_prob_sine_Adaptive_20251218_002919 ---
>>> [Wrapper] Initialized Non-Stationary FrozenLake
    - slip_prob: sine (base=0.67)
>>> Initializing TRPO with kwargs: ['policy', 'env', 'learning_rate', 'gamma', 'verbose', 'tensorboard_log', 'n_steps', 'batch_size']
Using cuda device
Wrapping the env in a DummyVecEnv.
Logging to logs/FrozenLake_4x4_slip_prob_sine_Adaptive_20251218_002919_0
>>> [DriftAdaptiveCallback] Training Started
    Algorithm: TRPO
    Target Param: slip_prob (base=9.8)
    Scale Factor: 0.2
    
    Adaptive Hyperparameters:
      - Learning Rate: 0.001000
      - Target KL: 0.0100 (adapt=True)
-----------------------------------
| adaptive/            |          |
|    adaptation_factor | 1        |
|    algorithm         | TRPO     |
|    base_lr           | 0.001    |
|    base_target_kl    | 0.01     |
|    drift_magnitude   | 0        |
|    learning_rate     | 0.001    |
|    target_kl         | 0.01     |
| env/                 |          |
|    base_value        | 9.8      |
|    slip_prob         | 9.8      |
| rollout/             |          |
|    ep_len_mean       | 7.5      |
|    ep_rew_mean       | 0        |
| time/                |          |
|    fps               | 363      |
|    iterations        | 1        |
|    time_elapsed      | 0        |
|    total_timesteps   | 128      |
-----------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.06     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 403      |
|    iterations             | 2        |
|    time_elapsed           | 0        |
|    total_timesteps        | 256      |
| train/                    |          |
|    explained_variance     | -12.6    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00437  |
|    learning_rate          | 0.001    |
|    n_updates              | 1        |
|    policy_objective       | 0.0295   |
|    value_loss             | 0.0211   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.27     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 469      |
|    iterations             | 3        |
|    time_elapsed           | 0        |
|    total_timesteps        | 384      |
| train/                    |          |
|    explained_variance     | -24.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00356  |
|    learning_rate          | 0.001    |
|    n_updates              | 2        |
|    policy_objective       | 0.0533   |
|    value_loss             | 0.000248 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.88     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 512      |
|    iterations             | 4        |
|    time_elapsed           | 0        |
|    total_timesteps        | 512      |
| train/                    |          |
|    explained_variance     | -9.67    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00195  |
|    learning_rate          | 0.001    |
|    n_updates              | 3        |
|    policy_objective       | 0.0516   |
|    value_loss             | 7.11e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.11     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 545      |
|    iterations             | 5        |
|    time_elapsed           | 1        |
|    total_timesteps        | 640      |
| train/                    |          |
|    explained_variance     | -2.69    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00265  |
|    learning_rate          | 0.001    |
|    n_updates              | 4        |
|    policy_objective       | 0.0502   |
|    value_loss             | 2.16e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.34     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 570      |
|    iterations             | 6        |
|    time_elapsed           | 1        |
|    total_timesteps        | 768      |
| train/                    |          |
|    explained_variance     | -14.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00526  |
|    learning_rate          | 0.001    |
|    n_updates              | 5        |
|    policy_objective       | 0.0506   |
|    value_loss             | 1.25e-08 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.3      |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 582      |
|    iterations             | 7        |
|    time_elapsed           | 1        |
|    total_timesteps        | 896      |
| train/                    |          |
|    explained_variance     | -7.25    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00391  |
|    learning_rate          | 0.001    |
|    n_updates              | 6        |
|    policy_objective       | 0.0506   |
|    value_loss             | 8.7e-10  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.51     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 593      |
|    iterations             | 8        |
|    time_elapsed           | 1        |
|    total_timesteps        | 1024     |
| train/                    |          |
|    explained_variance     | -13.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00577  |
|    learning_rate          | 0.001    |
|    n_updates              | 7        |
|    policy_objective       | 0.0427   |
|    value_loss             | 6.71e-11 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.39     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 601      |
|    iterations             | 9        |
|    time_elapsed           | 1        |
|    total_timesteps        | 1152     |
| train/                    |          |
|    explained_variance     | -36.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00583  |
|    learning_rate          | 0.001    |
|    n_updates              | 8        |
|    policy_objective       | 0.0512   |
|    value_loss             | 2.26e-12 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.86     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 611      |
|    iterations             | 10       |
|    time_elapsed           | 2        |
|    total_timesteps        | 1280     |
| train/                    |          |
|    explained_variance     | -35.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00272  |
|    learning_rate          | 0.001    |
|    n_updates              | 9        |
|    policy_objective       | 0.0355   |
|    value_loss             | 1.89e-13 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.8      |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 620      |
|    iterations             | 11       |
|    time_elapsed           | 2        |
|    total_timesteps        | 1408     |
| train/                    |          |
|    explained_variance     | -69.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00101  |
|    learning_rate          | 0.001    |
|    n_updates              | 10       |
|    policy_objective       | 0.0535   |
|    value_loss             | 0.000193 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.86     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 630      |
|    iterations             | 12       |
|    time_elapsed           | 2        |
|    total_timesteps        | 1536     |
| train/                    |          |
|    explained_variance     | -24.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00255  |
|    learning_rate          | 0.001    |
|    n_updates              | 11       |
|    policy_objective       | 0.048    |
|    value_loss             | 2.59e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.24     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 637      |
|    iterations             | 13       |
|    time_elapsed           | 2        |
|    total_timesteps        | 1664     |
| train/                    |          |
|    explained_variance     | 0.00104  |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00308  |
|    learning_rate          | 0.001    |
|    n_updates              | 12       |
|    policy_objective       | 0.0496   |
|    value_loss             | 0.0228   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.94     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 643      |
|    iterations             | 14       |
|    time_elapsed           | 2        |
|    total_timesteps        | 1792     |
| train/                    |          |
|    explained_variance     | -0.229   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00559  |
|    learning_rate          | 0.001    |
|    n_updates              | 13       |
|    policy_objective       | 0.0542   |
|    value_loss             | 0.0471   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.03     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 647      |
|    iterations             | 15       |
|    time_elapsed           | 2        |
|    total_timesteps        | 1920     |
| train/                    |          |
|    explained_variance     | -4.71    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00443  |
|    learning_rate          | 0.001    |
|    n_updates              | 14       |
|    policy_objective       | 0.0394   |
|    value_loss             | 0.00121  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.9      |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 651      |
|    iterations             | 16       |
|    time_elapsed           | 3        |
|    total_timesteps        | 2048     |
| train/                    |          |
|    explained_variance     | -101     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00267  |
|    learning_rate          | 0.001    |
|    n_updates              | 15       |
|    policy_objective       | 0.0562   |
|    value_loss             | 0.00103  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.05     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 654      |
|    iterations             | 17       |
|    time_elapsed           | 3        |
|    total_timesteps        | 2176     |
| train/                    |          |
|    explained_variance     | -31.7    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00331  |
|    learning_rate          | 0.001    |
|    n_updates              | 16       |
|    policy_objective       | 0.072    |
|    value_loss             | 1.48e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.71     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 659      |
|    iterations             | 18       |
|    time_elapsed           | 3        |
|    total_timesteps        | 2304     |
| train/                    |          |
|    explained_variance     | -95.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00235  |
|    learning_rate          | 0.001    |
|    n_updates              | 17       |
|    policy_objective       | 0.036    |
|    value_loss             | 0.00244  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.6      |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 663      |
|    iterations             | 19       |
|    time_elapsed           | 3        |
|    total_timesteps        | 2432     |
| train/                    |          |
|    explained_variance     | -34.6    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00282  |
|    learning_rate          | 0.001    |
|    n_updates              | 18       |
|    policy_objective       | 0.0427   |
|    value_loss             | 1.95e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.52     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 667      |
|    iterations             | 20       |
|    time_elapsed           | 3        |
|    total_timesteps        | 2560     |
| train/                    |          |
|    explained_variance     | -186     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00143  |
|    learning_rate          | 0.001    |
|    n_updates              | 19       |
|    policy_objective       | 0.0496   |
|    value_loss             | 9.27e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.49     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 670      |
|    iterations             | 21       |
|    time_elapsed           | 4        |
|    total_timesteps        | 2688     |
| train/                    |          |
|    explained_variance     | -141     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00182  |
|    learning_rate          | 0.001    |
|    n_updates              | 20       |
|    policy_objective       | 0.0746   |
|    value_loss             | 6e-08    |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.3      |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 672      |
|    iterations             | 22       |
|    time_elapsed           | 4        |
|    total_timesteps        | 2816     |
| train/                    |          |
|    explained_variance     | -116     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00291  |
|    learning_rate          | 0.001    |
|    n_updates              | 21       |
|    policy_objective       | 0.0511   |
|    value_loss             | 1.7e-09  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.85     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 675      |
|    iterations             | 23       |
|    time_elapsed           | 4        |
|    total_timesteps        | 2944     |
| train/                    |          |
|    explained_variance     | -75.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00379  |
|    learning_rate          | 0.001    |
|    n_updates              | 22       |
|    policy_objective       | 0.0696   |
|    value_loss             | 4.94e-11 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.77     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 676      |
|    iterations             | 24       |
|    time_elapsed           | 4        |
|    total_timesteps        | 3072     |
| train/                    |          |
|    explained_variance     | -20.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00342  |
|    learning_rate          | 0.001    |
|    n_updates              | 23       |
|    policy_objective       | 0.0756   |
|    value_loss             | 1.2e-12  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7        |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 677      |
|    iterations             | 25       |
|    time_elapsed           | 4        |
|    total_timesteps        | 3200     |
| train/                    |          |
|    explained_variance     | -12.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00313  |
|    learning_rate          | 0.001    |
|    n_updates              | 24       |
|    policy_objective       | 0.045    |
|    value_loss             | 1.53e-14 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.1      |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 677      |
|    iterations             | 26       |
|    time_elapsed           | 4        |
|    total_timesteps        | 3328     |
| train/                    |          |
|    explained_variance     | -80.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00199  |
|    learning_rate          | 0.001    |
|    n_updates              | 25       |
|    policy_objective       | 0.0523   |
|    value_loss             | 2.02e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.67     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 678      |
|    iterations             | 27       |
|    time_elapsed           | 5        |
|    total_timesteps        | 3456     |
| train/                    |          |
|    explained_variance     | -54.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00232  |
|    learning_rate          | 0.001    |
|    n_updates              | 26       |
|    policy_objective       | 0.0583   |
|    value_loss             | 6.33e-09 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.53     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 681      |
|    iterations             | 28       |
|    time_elapsed           | 5        |
|    total_timesteps        | 3584     |
| train/                    |          |
|    explained_variance     | -84.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.003    |
|    learning_rate          | 0.001    |
|    n_updates              | 27       |
|    policy_objective       | 0.104    |
|    value_loss             | 1.22e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.82     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 682      |
|    iterations             | 29       |
|    time_elapsed           | 5        |
|    total_timesteps        | 3712     |
| train/                    |          |
|    explained_variance     | -31.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00553  |
|    learning_rate          | 0.001    |
|    n_updates              | 28       |
|    policy_objective       | 0.0415   |
|    value_loss             | 4.8e-10  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.17     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 682      |
|    iterations             | 30       |
|    time_elapsed           | 5        |
|    total_timesteps        | 3840     |
| train/                    |          |
|    explained_variance     | -72.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00117  |
|    learning_rate          | 0.001    |
|    n_updates              | 29       |
|    policy_objective       | 0.0682   |
|    value_loss             | 3.08e-10 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.53     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 683      |
|    iterations             | 31       |
|    time_elapsed           | 5        |
|    total_timesteps        | 3968     |
| train/                    |          |
|    explained_variance     | -73.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00258  |
|    learning_rate          | 0.001    |
|    n_updates              | 30       |
|    policy_objective       | 0.0558   |
|    value_loss             | 1.04e-10 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.61     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 683      |
|    iterations             | 32       |
|    time_elapsed           | 5        |
|    total_timesteps        | 4096     |
| train/                    |          |
|    explained_variance     | -60.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00167  |
|    learning_rate          | 0.001    |
|    n_updates              | 31       |
|    policy_objective       | 0.0169   |
|    value_loss             | 4.63e-10 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.07     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 683      |
|    iterations             | 33       |
|    time_elapsed           | 6        |
|    total_timesteps        | 4224     |
| train/                    |          |
|    explained_variance     | 4.95e-05 |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00587  |
|    learning_rate          | 0.001    |
|    n_updates              | 32       |
|    policy_objective       | 0.0366   |
|    value_loss             | 0.0286   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.11     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 684      |
|    iterations             | 34       |
|    time_elapsed           | 6        |
|    total_timesteps        | 4352     |
| train/                    |          |
|    explained_variance     | -15.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00591  |
|    learning_rate          | 0.001    |
|    n_updates              | 33       |
|    policy_objective       | 0.0808   |
|    value_loss             | 0.00178  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.35     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 684      |
|    iterations             | 35       |
|    time_elapsed           | 6        |
|    total_timesteps        | 4480     |
| train/                    |          |
|    explained_variance     | -34.7    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00394  |
|    learning_rate          | 0.001    |
|    n_updates              | 34       |
|    policy_objective       | 0.0301   |
|    value_loss             | 0.00106  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.06     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 685      |
|    iterations             | 36       |
|    time_elapsed           | 6        |
|    total_timesteps        | 4608     |
| train/                    |          |
|    explained_variance     | -3.03    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00634  |
|    learning_rate          | 0.001    |
|    n_updates              | 35       |
|    policy_objective       | 0.0493   |
|    value_loss             | 6.75e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.17     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 685      |
|    iterations             | 37       |
|    time_elapsed           | 6        |
|    total_timesteps        | 4736     |
| train/                    |          |
|    explained_variance     | -32.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00357  |
|    learning_rate          | 0.001    |
|    n_updates              | 36       |
|    policy_objective       | 0.0401   |
|    value_loss             | 0.0019   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.49     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 684      |
|    iterations             | 38       |
|    time_elapsed           | 7        |
|    total_timesteps        | 4864     |
| train/                    |          |
|    explained_variance     | -7.62    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0037   |
|    learning_rate          | 0.001    |
|    n_updates              | 37       |
|    policy_objective       | 0.0549   |
|    value_loss             | 3.56e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.73     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 684      |
|    iterations             | 39       |
|    time_elapsed           | 7        |
|    total_timesteps        | 4992     |
| train/                    |          |
|    explained_variance     | -66.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00315  |
|    learning_rate          | 0.001    |
|    n_updates              | 38       |
|    policy_objective       | 0.0267   |
|    value_loss             | 4.33e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.78     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 684      |
|    iterations             | 40       |
|    time_elapsed           | 7        |
|    total_timesteps        | 5120     |
| train/                    |          |
|    explained_variance     | -21.6    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0048   |
|    learning_rate          | 0.001    |
|    n_updates              | 39       |
|    policy_objective       | 0.0459   |
|    value_loss             | 2.36e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.69     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 684      |
|    iterations             | 41       |
|    time_elapsed           | 7        |
|    total_timesteps        | 5248     |
| train/                    |          |
|    explained_variance     | -0.00226 |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00535  |
|    learning_rate          | 0.001    |
|    n_updates              | 40       |
|    policy_objective       | 0.0726   |
|    value_loss             | 0.0436   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.89     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 684      |
|    iterations             | 42       |
|    time_elapsed           | 7        |
|    total_timesteps        | 5376     |
| train/                    |          |
|    explained_variance     | 0.215    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00517  |
|    learning_rate          | 0.001    |
|    n_updates              | 41       |
|    policy_objective       | 0.0787   |
|    value_loss             | 0.0448   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.71     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 684      |
|    iterations             | 43       |
|    time_elapsed           | 8        |
|    total_timesteps        | 5504     |
| train/                    |          |
|    explained_variance     | -7.3     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00348  |
|    learning_rate          | 0.001    |
|    n_updates              | 42       |
|    policy_objective       | 0.0412   |
|    value_loss             | 0.00301  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.95     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 684      |
|    iterations             | 44       |
|    time_elapsed           | 8        |
|    total_timesteps        | 5632     |
| train/                    |          |
|    explained_variance     | -8.99    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00397  |
|    learning_rate          | 0.001    |
|    n_updates              | 43       |
|    policy_objective       | 0.0514   |
|    value_loss             | 0.000211 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.29     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 685      |
|    iterations             | 45       |
|    time_elapsed           | 8        |
|    total_timesteps        | 5760     |
| train/                    |          |
|    explained_variance     | -8.76    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00349  |
|    learning_rate          | 0.001    |
|    n_updates              | 44       |
|    policy_objective       | 0.0562   |
|    value_loss             | 0.00765  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.18     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 686      |
|    iterations             | 46       |
|    time_elapsed           | 8        |
|    total_timesteps        | 5888     |
| train/                    |          |
|    explained_variance     | -15.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00122  |
|    learning_rate          | 0.001    |
|    n_updates              | 45       |
|    policy_objective       | 0.0485   |
|    value_loss             | 0.000232 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.24     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 686      |
|    iterations             | 47       |
|    time_elapsed           | 8        |
|    total_timesteps        | 6016     |
| train/                    |          |
|    explained_variance     | -43.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00497  |
|    learning_rate          | 0.001    |
|    n_updates              | 46       |
|    policy_objective       | 0.0369   |
|    value_loss             | 3.56e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.14     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 687      |
|    iterations             | 48       |
|    time_elapsed           | 8        |
|    total_timesteps        | 6144     |
| train/                    |          |
|    explained_variance     | -20.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00563  |
|    learning_rate          | 0.001    |
|    n_updates              | 47       |
|    policy_objective       | 0.0317   |
|    value_loss             | 1.66e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.46     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 688      |
|    iterations             | 49       |
|    time_elapsed           | 9        |
|    total_timesteps        | 6272     |
| train/                    |          |
|    explained_variance     | 0.0147   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00509  |
|    learning_rate          | 0.001    |
|    n_updates              | 48       |
|    policy_objective       | 0.05     |
|    value_loss             | 0.0339   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.87     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 50       |
|    time_elapsed           | 9        |
|    total_timesteps        | 6400     |
| train/                    |          |
|    explained_variance     | -0.271   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00591  |
|    learning_rate          | 0.001    |
|    n_updates              | 49       |
|    policy_objective       | 0.053    |
|    value_loss             | 0.00708  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.59     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 51       |
|    time_elapsed           | 9        |
|    total_timesteps        | 6528     |
| train/                    |          |
|    explained_variance     | -0.0463  |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00553  |
|    learning_rate          | 0.001    |
|    n_updates              | 50       |
|    policy_objective       | 0.0633   |
|    value_loss             | 0.0311   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.35     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 688      |
|    iterations             | 52       |
|    time_elapsed           | 9        |
|    total_timesteps        | 6656     |
| train/                    |          |
|    explained_variance     | -8.19    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00384  |
|    learning_rate          | 0.001    |
|    n_updates              | 51       |
|    policy_objective       | 0.0494   |
|    value_loss             | 0.000392 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.62     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 53       |
|    time_elapsed           | 9        |
|    total_timesteps        | 6784     |
| train/                    |          |
|    explained_variance     | -44      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00208  |
|    learning_rate          | 0.001    |
|    n_updates              | 52       |
|    policy_objective       | 0.0596   |
|    value_loss             | 0.00125  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.99     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 54       |
|    time_elapsed           | 10       |
|    total_timesteps        | 6912     |
| train/                    |          |
|    explained_variance     | -37.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00425  |
|    learning_rate          | 0.001    |
|    n_updates              | 53       |
|    policy_objective       | 0.0813   |
|    value_loss             | 1.8e-05  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.69     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 55       |
|    time_elapsed           | 10       |
|    total_timesteps        | 7040     |
| train/                    |          |
|    explained_variance     | -10.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00728  |
|    learning_rate          | 0.001    |
|    n_updates              | 54       |
|    policy_objective       | 0.0456   |
|    value_loss             | 3.6e-06  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.33     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 56       |
|    time_elapsed           | 10       |
|    total_timesteps        | 7168     |
| train/                    |          |
|    explained_variance     | -2.24    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00527  |
|    learning_rate          | 0.001    |
|    n_updates              | 55       |
|    policy_objective       | 0.0605   |
|    value_loss             | 2.44e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.2      |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 690      |
|    iterations             | 57       |
|    time_elapsed           | 10       |
|    total_timesteps        | 7296     |
| train/                    |          |
|    explained_variance     | -14      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00415  |
|    learning_rate          | 0.001    |
|    n_updates              | 56       |
|    policy_objective       | 0.0227   |
|    value_loss             | 0.00452  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.13     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 691      |
|    iterations             | 58       |
|    time_elapsed           | 10       |
|    total_timesteps        | 7424     |
| train/                    |          |
|    explained_variance     | -17.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00641  |
|    learning_rate          | 0.001    |
|    n_updates              | 57       |
|    policy_objective       | 0.0467   |
|    value_loss             | 5.09e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.95     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 691      |
|    iterations             | 59       |
|    time_elapsed           | 10       |
|    total_timesteps        | 7552     |
| train/                    |          |
|    explained_variance     | -10.6    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00179  |
|    learning_rate          | 0.001    |
|    n_updates              | 58       |
|    policy_objective       | 0.0744   |
|    value_loss             | 7.71e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.74     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 692      |
|    iterations             | 60       |
|    time_elapsed           | 11       |
|    total_timesteps        | 7680     |
| train/                    |          |
|    explained_variance     | -11.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00515  |
|    learning_rate          | 0.001    |
|    n_updates              | 59       |
|    policy_objective       | 0.0559   |
|    value_loss             | 6.97e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.87     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 692      |
|    iterations             | 61       |
|    time_elapsed           | 11       |
|    total_timesteps        | 7808     |
| train/                    |          |
|    explained_variance     | -58.7    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00473  |
|    learning_rate          | 0.001    |
|    n_updates              | 60       |
|    policy_objective       | 0.0339   |
|    value_loss             | 1e-07    |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.23     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 693      |
|    iterations             | 62       |
|    time_elapsed           | 11       |
|    total_timesteps        | 7936     |
| train/                    |          |
|    explained_variance     | 0.0231   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00363  |
|    learning_rate          | 0.001    |
|    n_updates              | 61       |
|    policy_objective       | 0.115    |
|    value_loss             | 0.0532   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.01     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 692      |
|    iterations             | 63       |
|    time_elapsed           | 11       |
|    total_timesteps        | 8064     |
| train/                    |          |
|    explained_variance     | -7.51    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00439  |
|    learning_rate          | 0.001    |
|    n_updates              | 62       |
|    policy_objective       | 0.0535   |
|    value_loss             | 0.0134   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.27     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 692      |
|    iterations             | 64       |
|    time_elapsed           | 11       |
|    total_timesteps        | 8192     |
| train/                    |          |
|    explained_variance     | 0.0972   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00445  |
|    learning_rate          | 0.001    |
|    n_updates              | 63       |
|    policy_objective       | 0.0448   |
|    value_loss             | 0.0331   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.32     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 692      |
|    iterations             | 65       |
|    time_elapsed           | 12       |
|    total_timesteps        | 8320     |
| train/                    |          |
|    explained_variance     | -12.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00337  |
|    learning_rate          | 0.001    |
|    n_updates              | 64       |
|    policy_objective       | 0.0649   |
|    value_loss             | 0.00593  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.34     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 691      |
|    iterations             | 66       |
|    time_elapsed           | 12       |
|    total_timesteps        | 8448     |
| train/                    |          |
|    explained_variance     | -10.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00604  |
|    learning_rate          | 0.001    |
|    n_updates              | 65       |
|    policy_objective       | 0.0491   |
|    value_loss             | 0.0001   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.73     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 692      |
|    iterations             | 67       |
|    time_elapsed           | 12       |
|    total_timesteps        | 8576     |
| train/                    |          |
|    explained_variance     | -16.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.004    |
|    learning_rate          | 0.001    |
|    n_updates              | 66       |
|    policy_objective       | 0.0411   |
|    value_loss             | 0.000266 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.06     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 692      |
|    iterations             | 68       |
|    time_elapsed           | 12       |
|    total_timesteps        | 8704     |
| train/                    |          |
|    explained_variance     | -49.6    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00174  |
|    learning_rate          | 0.001    |
|    n_updates              | 67       |
|    policy_objective       | 0.0769   |
|    value_loss             | 0.000102 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.36     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 692      |
|    iterations             | 69       |
|    time_elapsed           | 12       |
|    total_timesteps        | 8832     |
| train/                    |          |
|    explained_variance     | 0.0348   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00741  |
|    learning_rate          | 0.001    |
|    n_updates              | 68       |
|    policy_objective       | 0.0492   |
|    value_loss             | 0.0483   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.08     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 692      |
|    iterations             | 70       |
|    time_elapsed           | 12       |
|    total_timesteps        | 8960     |
| train/                    |          |
|    explained_variance     | -9.16    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00471  |
|    learning_rate          | 0.001    |
|    n_updates              | 69       |
|    policy_objective       | 0.0499   |
|    value_loss             | 0.00178  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.14     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 692      |
|    iterations             | 71       |
|    time_elapsed           | 13       |
|    total_timesteps        | 9088     |
| train/                    |          |
|    explained_variance     | -13.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00646  |
|    learning_rate          | 0.001    |
|    n_updates              | 70       |
|    policy_objective       | 0.0671   |
|    value_loss             | 0.000712 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.28     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 692      |
|    iterations             | 72       |
|    time_elapsed           | 13       |
|    total_timesteps        | 9216     |
| train/                    |          |
|    explained_variance     | -25.7    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0017   |
|    learning_rate          | 0.001    |
|    n_updates              | 71       |
|    policy_objective       | 0.0642   |
|    value_loss             | 8.9e-06  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.57     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 692      |
|    iterations             | 73       |
|    time_elapsed           | 13       |
|    total_timesteps        | 9344     |
| train/                    |          |
|    explained_variance     | -23.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00536  |
|    learning_rate          | 0.001    |
|    n_updates              | 72       |
|    policy_objective       | 0.0614   |
|    value_loss             | 0.000432 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.4      |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 693      |
|    iterations             | 74       |
|    time_elapsed           | 13       |
|    total_timesteps        | 9472     |
| train/                    |          |
|    explained_variance     | -72.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00309  |
|    learning_rate          | 0.001    |
|    n_updates              | 73       |
|    policy_objective       | 0.0353   |
|    value_loss             | 4.91e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.93     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 693      |
|    iterations             | 75       |
|    time_elapsed           | 13       |
|    total_timesteps        | 9600     |
| train/                    |          |
|    explained_variance     | 0.0366   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00372  |
|    learning_rate          | 0.001    |
|    n_updates              | 74       |
|    policy_objective       | 0.0364   |
|    value_loss             | 0.0309   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.37     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 693      |
|    iterations             | 76       |
|    time_elapsed           | 14       |
|    total_timesteps        | 9728     |
| train/                    |          |
|    explained_variance     | -17.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00286  |
|    learning_rate          | 0.001    |
|    n_updates              | 75       |
|    policy_objective       | 0.0299   |
|    value_loss             | 0.00746  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.4      |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 693      |
|    iterations             | 77       |
|    time_elapsed           | 14       |
|    total_timesteps        | 9856     |
| train/                    |          |
|    explained_variance     | -13.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00648  |
|    learning_rate          | 0.001    |
|    n_updates              | 76       |
|    policy_objective       | 0.0579   |
|    value_loss             | 0.000269 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.5      |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 694      |
|    iterations             | 78       |
|    time_elapsed           | 14       |
|    total_timesteps        | 9984     |
| train/                    |          |
|    explained_variance     | -22.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0035   |
|    learning_rate          | 0.001    |
|    n_updates              | 77       |
|    policy_objective       | 0.0267   |
|    value_loss             | 1.01e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.06     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 692      |
|    iterations             | 79       |
|    time_elapsed           | 14       |
|    total_timesteps        | 10112    |
| train/                    |          |
|    explained_variance     | -9.48    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00361  |
|    learning_rate          | 0.001    |
|    n_updates              | 78       |
|    policy_objective       | 0.0499   |
|    value_loss             | 1.64e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.25     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 692      |
|    iterations             | 80       |
|    time_elapsed           | 14       |
|    total_timesteps        | 10240    |
| train/                    |          |
|    explained_variance     | 0.0743   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00269  |
|    learning_rate          | 0.001    |
|    n_updates              | 79       |
|    policy_objective       | 0.116    |
|    value_loss             | 0.0312   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.69     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 691      |
|    iterations             | 81       |
|    time_elapsed           | 14       |
|    total_timesteps        | 10368    |
| train/                    |          |
|    explained_variance     | -12.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00355  |
|    learning_rate          | 0.001    |
|    n_updates              | 80       |
|    policy_objective       | 0.0322   |
|    value_loss             | 0.00285  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.96     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 690      |
|    iterations             | 82       |
|    time_elapsed           | 15       |
|    total_timesteps        | 10496    |
| train/                    |          |
|    explained_variance     | 0.108    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00334  |
|    learning_rate          | 0.001    |
|    n_updates              | 81       |
|    policy_objective       | 0.0183   |
|    value_loss             | 0.0385   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.8      |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 83       |
|    time_elapsed           | 15       |
|    total_timesteps        | 10624    |
| train/                    |          |
|    explained_variance     | -22.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00409  |
|    learning_rate          | 0.001    |
|    n_updates              | 82       |
|    policy_objective       | 0.0461   |
|    value_loss             | 0.00107  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.28     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 688      |
|    iterations             | 84       |
|    time_elapsed           | 15       |
|    total_timesteps        | 10752    |
| train/                    |          |
|    explained_variance     | -0.306   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00354  |
|    learning_rate          | 0.001    |
|    n_updates              | 83       |
|    policy_objective       | 0.0391   |
|    value_loss             | 0.00504  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.39     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 687      |
|    iterations             | 85       |
|    time_elapsed           | 15       |
|    total_timesteps        | 10880    |
| train/                    |          |
|    explained_variance     | -27.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00429  |
|    learning_rate          | 0.001    |
|    n_updates              | 84       |
|    policy_objective       | 0.026    |
|    value_loss             | 0.00126  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.34     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 686      |
|    iterations             | 86       |
|    time_elapsed           | 16       |
|    total_timesteps        | 11008    |
| train/                    |          |
|    explained_variance     | -7.32    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00222  |
|    learning_rate          | 0.001    |
|    n_updates              | 85       |
|    policy_objective       | 0.0575   |
|    value_loss             | 0.000191 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.03     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 685      |
|    iterations             | 87       |
|    time_elapsed           | 16       |
|    total_timesteps        | 11136    |
| train/                    |          |
|    explained_variance     | -45.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00651  |
|    learning_rate          | 0.001    |
|    n_updates              | 86       |
|    policy_objective       | 0.0327   |
|    value_loss             | 2.73e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.54     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 685      |
|    iterations             | 88       |
|    time_elapsed           | 16       |
|    total_timesteps        | 11264    |
| train/                    |          |
|    explained_variance     | -113     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0016   |
|    learning_rate          | 0.001    |
|    n_updates              | 87       |
|    policy_objective       | 0.0321   |
|    value_loss             | 7.14e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.65     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 685      |
|    iterations             | 89       |
|    time_elapsed           | 16       |
|    total_timesteps        | 11392    |
| train/                    |          |
|    explained_variance     | -68.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00287  |
|    learning_rate          | 0.001    |
|    n_updates              | 88       |
|    policy_objective       | 0.0328   |
|    value_loss             | 5.19e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.64     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 685      |
|    iterations             | 90       |
|    time_elapsed           | 16       |
|    total_timesteps        | 11520    |
| train/                    |          |
|    explained_variance     | 0.11     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00556  |
|    learning_rate          | 0.001    |
|    n_updates              | 89       |
|    policy_objective       | 0.0355   |
|    value_loss             | 0.0349   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.08     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 684      |
|    iterations             | 91       |
|    time_elapsed           | 17       |
|    total_timesteps        | 11648    |
| train/                    |          |
|    explained_variance     | -24.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00956  |
|    learning_rate          | 0.001    |
|    n_updates              | 90       |
|    policy_objective       | 0.0738   |
|    value_loss             | 0.000876 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.91     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 684      |
|    iterations             | 92       |
|    time_elapsed           | 17       |
|    total_timesteps        | 11776    |
| train/                    |          |
|    explained_variance     | -27.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00683  |
|    learning_rate          | 0.001    |
|    n_updates              | 91       |
|    policy_objective       | 0.0307   |
|    value_loss             | 2.5e-05  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.04     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 683      |
|    iterations             | 93       |
|    time_elapsed           | 17       |
|    total_timesteps        | 11904    |
| train/                    |          |
|    explained_variance     | -17.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00566  |
|    learning_rate          | 0.001    |
|    n_updates              | 92       |
|    policy_objective       | 0.0404   |
|    value_loss             | 8.05e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.54     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 683      |
|    iterations             | 94       |
|    time_elapsed           | 17       |
|    total_timesteps        | 12032    |
| train/                    |          |
|    explained_variance     | -73.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00593  |
|    learning_rate          | 0.001    |
|    n_updates              | 93       |
|    policy_objective       | 0.224    |
|    value_loss             | 2.24e-08 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.14     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 684      |
|    iterations             | 95       |
|    time_elapsed           | 17       |
|    total_timesteps        | 12160    |
| train/                    |          |
|    explained_variance     | -38.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00674  |
|    learning_rate          | 0.001    |
|    n_updates              | 94       |
|    policy_objective       | 0.0457   |
|    value_loss             | 2.79e-10 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.74     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 684      |
|    iterations             | 96       |
|    time_elapsed           | 17       |
|    total_timesteps        | 12288    |
| train/                    |          |
|    explained_variance     | 0.114    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00736  |
|    learning_rate          | 0.001    |
|    n_updates              | 95       |
|    policy_objective       | 0.0197   |
|    value_loss             | 0.0331   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.87     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 684      |
|    iterations             | 97       |
|    time_elapsed           | 18       |
|    total_timesteps        | 12416    |
| train/                    |          |
|    explained_variance     | -21.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00704  |
|    learning_rate          | 0.001    |
|    n_updates              | 96       |
|    policy_objective       | 0.0208   |
|    value_loss             | 0.00226  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.69     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 684      |
|    iterations             | 98       |
|    time_elapsed           | 18       |
|    total_timesteps        | 12544    |
| train/                    |          |
|    explained_variance     | -14.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00101  |
|    learning_rate          | 0.001    |
|    n_updates              | 97       |
|    policy_objective       | 0.0464   |
|    value_loss             | 0.00426  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.08     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 684      |
|    iterations             | 99       |
|    time_elapsed           | 18       |
|    total_timesteps        | 12672    |
| train/                    |          |
|    explained_variance     | 0.207    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00855  |
|    learning_rate          | 0.001    |
|    n_updates              | 98       |
|    policy_objective       | 0.024    |
|    value_loss             | 0.0259   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.86     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 684      |
|    iterations             | 100      |
|    time_elapsed           | 18       |
|    total_timesteps        | 12800    |
| train/                    |          |
|    explained_variance     | -10.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.000682 |
|    learning_rate          | 0.001    |
|    n_updates              | 99       |
|    policy_objective       | 0.0307   |
|    value_loss             | 0.0124   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.31     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 684      |
|    iterations             | 101      |
|    time_elapsed           | 18       |
|    total_timesteps        | 12928    |
| train/                    |          |
|    explained_variance     | -13.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00795  |
|    learning_rate          | 0.001    |
|    n_updates              | 100      |
|    policy_objective       | 0.0519   |
|    value_loss             | 0.000333 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.63     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 684      |
|    iterations             | 102      |
|    time_elapsed           | 19       |
|    total_timesteps        | 13056    |
| train/                    |          |
|    explained_variance     | -33.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00844  |
|    learning_rate          | 0.001    |
|    n_updates              | 101      |
|    policy_objective       | 0.0267   |
|    value_loss             | 1.2e-05  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.15     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 684      |
|    iterations             | 103      |
|    time_elapsed           | 19       |
|    total_timesteps        | 13184    |
| train/                    |          |
|    explained_variance     | -27.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00863  |
|    learning_rate          | 0.001    |
|    n_updates              | 102      |
|    policy_objective       | 0.0288   |
|    value_loss             | 1.37e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9.26     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 684      |
|    iterations             | 104      |
|    time_elapsed           | 19       |
|    total_timesteps        | 13312    |
| train/                    |          |
|    explained_variance     | -57      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00463  |
|    learning_rate          | 0.001    |
|    n_updates              | 103      |
|    policy_objective       | 0.0226   |
|    value_loss             | 0.000152 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.35     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 684      |
|    iterations             | 105      |
|    time_elapsed           | 19       |
|    total_timesteps        | 13440    |
| train/                    |          |
|    explained_variance     | -67.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00385  |
|    learning_rate          | 0.001    |
|    n_updates              | 104      |
|    policy_objective       | 0.0286   |
|    value_loss             | 4.41e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.1      |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 684      |
|    iterations             | 106      |
|    time_elapsed           | 19       |
|    total_timesteps        | 13568    |
| train/                    |          |
|    explained_variance     | -39.7    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00317  |
|    learning_rate          | 0.001    |
|    n_updates              | 105      |
|    policy_objective       | 0.0265   |
|    value_loss             | 8.44e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.89     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 684      |
|    iterations             | 107      |
|    time_elapsed           | 20       |
|    total_timesteps        | 13696    |
| train/                    |          |
|    explained_variance     | -17      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00421  |
|    learning_rate          | 0.001    |
|    n_updates              | 106      |
|    policy_objective       | 0.0314   |
|    value_loss             | 2.99e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.63     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 684      |
|    iterations             | 108      |
|    time_elapsed           | 20       |
|    total_timesteps        | 13824    |
| train/                    |          |
|    explained_variance     | -84.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00376  |
|    learning_rate          | 0.001    |
|    n_updates              | 107      |
|    policy_objective       | 0.0226   |
|    value_loss             | 1.15e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.43     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 684      |
|    iterations             | 109      |
|    time_elapsed           | 20       |
|    total_timesteps        | 13952    |
| train/                    |          |
|    explained_variance     | -84.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0023   |
|    learning_rate          | 0.001    |
|    n_updates              | 108      |
|    policy_objective       | 0.0277   |
|    value_loss             | 2.67e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.47     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 684      |
|    iterations             | 110      |
|    time_elapsed           | 20       |
|    total_timesteps        | 14080    |
| train/                    |          |
|    explained_variance     | -25      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00457  |
|    learning_rate          | 0.001    |
|    n_updates              | 109      |
|    policy_objective       | 0.0134   |
|    value_loss             | 5.11e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.28     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 685      |
|    iterations             | 111      |
|    time_elapsed           | 20       |
|    total_timesteps        | 14208    |
| train/                    |          |
|    explained_variance     | -91.6    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0065   |
|    learning_rate          | 0.001    |
|    n_updates              | 110      |
|    policy_objective       | 0.049    |
|    value_loss             | 5.68e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.44     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 685      |
|    iterations             | 112      |
|    time_elapsed           | 20       |
|    total_timesteps        | 14336    |
| train/                    |          |
|    explained_variance     | -40.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00351  |
|    learning_rate          | 0.001    |
|    n_updates              | 111      |
|    policy_objective       | 0.0684   |
|    value_loss             | 4.26e-08 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.51     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 685      |
|    iterations             | 113      |
|    time_elapsed           | 21       |
|    total_timesteps        | 14464    |
| train/                    |          |
|    explained_variance     | -57.6    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00651  |
|    learning_rate          | 0.001    |
|    n_updates              | 112      |
|    policy_objective       | 0.0252   |
|    value_loss             | 1.26e-10 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.79     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 685      |
|    iterations             | 114      |
|    time_elapsed           | 21       |
|    total_timesteps        | 14592    |
| train/                    |          |
|    explained_variance     | 0.0111   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00615  |
|    learning_rate          | 0.001    |
|    n_updates              | 113      |
|    policy_objective       | 0.125    |
|    value_loss             | 0.043    |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.71     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 685      |
|    iterations             | 115      |
|    time_elapsed           | 21       |
|    total_timesteps        | 14720    |
| train/                    |          |
|    explained_variance     | -0.0685  |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00624  |
|    learning_rate          | 0.001    |
|    n_updates              | 114      |
|    policy_objective       | 0.0801   |
|    value_loss             | 0.0729   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.71     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 685      |
|    iterations             | 116      |
|    time_elapsed           | 21       |
|    total_timesteps        | 14848    |
| train/                    |          |
|    explained_variance     | 0.233    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00685  |
|    learning_rate          | 0.001    |
|    n_updates              | 115      |
|    policy_objective       | 0.066    |
|    value_loss             | 0.0299   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.72     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 685      |
|    iterations             | 117      |
|    time_elapsed           | 21       |
|    total_timesteps        | 14976    |
| train/                    |          |
|    explained_variance     | -14.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00357  |
|    learning_rate          | 0.001    |
|    n_updates              | 116      |
|    policy_objective       | 0.0407   |
|    value_loss             | 0.00482  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.61     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 685      |
|    iterations             | 118      |
|    time_elapsed           | 22       |
|    total_timesteps        | 15104    |
| train/                    |          |
|    explained_variance     | -64.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00552  |
|    learning_rate          | 0.001    |
|    n_updates              | 117      |
|    policy_objective       | 0.0572   |
|    value_loss             | 0.00167  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.65     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 685      |
|    iterations             | 119      |
|    time_elapsed           | 22       |
|    total_timesteps        | 15232    |
| train/                    |          |
|    explained_variance     | -13.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00912  |
|    learning_rate          | 0.001    |
|    n_updates              | 118      |
|    policy_objective       | 0.0246   |
|    value_loss             | 0.000808 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.81     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 686      |
|    iterations             | 120      |
|    time_elapsed           | 22       |
|    total_timesteps        | 15360    |
| train/                    |          |
|    explained_variance     | 0.0308   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00821  |
|    learning_rate          | 0.001    |
|    n_updates              | 119      |
|    policy_objective       | 0.0392   |
|    value_loss             | 0.03     |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.03     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 686      |
|    iterations             | 121      |
|    time_elapsed           | 22       |
|    total_timesteps        | 15488    |
| train/                    |          |
|    explained_variance     | -20.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00335  |
|    learning_rate          | 0.001    |
|    n_updates              | 120      |
|    policy_objective       | 0.0606   |
|    value_loss             | 0.00214  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.04     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 686      |
|    iterations             | 122      |
|    time_elapsed           | 22       |
|    total_timesteps        | 15616    |
| train/                    |          |
|    explained_variance     | -26.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00399  |
|    learning_rate          | 0.001    |
|    n_updates              | 121      |
|    policy_objective       | 0.0204   |
|    value_loss             | 0.00625  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.08     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 686      |
|    iterations             | 123      |
|    time_elapsed           | 22       |
|    total_timesteps        | 15744    |
| train/                    |          |
|    explained_variance     | 0.052    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0073   |
|    learning_rate          | 0.001    |
|    n_updates              | 122      |
|    policy_objective       | 0.0554   |
|    value_loss             | 0.0581   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.2      |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 686      |
|    iterations             | 124      |
|    time_elapsed           | 23       |
|    total_timesteps        | 15872    |
| train/                    |          |
|    explained_variance     | -4.2     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0036   |
|    learning_rate          | 0.001    |
|    n_updates              | 123      |
|    policy_objective       | 0.0549   |
|    value_loss             | 0.00686  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.21     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 686      |
|    iterations             | 125      |
|    time_elapsed           | 23       |
|    total_timesteps        | 16000    |
| train/                    |          |
|    explained_variance     | -19.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00729  |
|    learning_rate          | 0.001    |
|    n_updates              | 124      |
|    policy_objective       | 0.0478   |
|    value_loss             | 0.000639 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.09     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 686      |
|    iterations             | 126      |
|    time_elapsed           | 23       |
|    total_timesteps        | 16128    |
| train/                    |          |
|    explained_variance     | -36.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00825  |
|    learning_rate          | 0.001    |
|    n_updates              | 125      |
|    policy_objective       | 0.0348   |
|    value_loss             | 0.00178  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.4      |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 686      |
|    iterations             | 127      |
|    time_elapsed           | 23       |
|    total_timesteps        | 16256    |
| train/                    |          |
|    explained_variance     | -23.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00255  |
|    learning_rate          | 0.001    |
|    n_updates              | 126      |
|    policy_objective       | 0.071    |
|    value_loss             | 3.08e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.38     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 687      |
|    iterations             | 128      |
|    time_elapsed           | 23       |
|    total_timesteps        | 16384    |
| train/                    |          |
|    explained_variance     | 0.134    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00789  |
|    learning_rate          | 0.001    |
|    n_updates              | 127      |
|    policy_objective       | 0.0489   |
|    value_loss             | 0.0628   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.8      |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 687      |
|    iterations             | 129      |
|    time_elapsed           | 24       |
|    total_timesteps        | 16512    |
| train/                    |          |
|    explained_variance     | -29.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00693  |
|    learning_rate          | 0.001    |
|    n_updates              | 128      |
|    policy_objective       | 0.0337   |
|    value_loss             | 0.0065   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.54     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 687      |
|    iterations             | 130      |
|    time_elapsed           | 24       |
|    total_timesteps        | 16640    |
| train/                    |          |
|    explained_variance     | 0.153    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00398  |
|    learning_rate          | 0.001    |
|    n_updates              | 129      |
|    policy_objective       | 0.0209   |
|    value_loss             | 0.0351   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.43     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 687      |
|    iterations             | 131      |
|    time_elapsed           | 24       |
|    total_timesteps        | 16768    |
| train/                    |          |
|    explained_variance     | -15.7    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00576  |
|    learning_rate          | 0.001    |
|    n_updates              | 130      |
|    policy_objective       | 0.0328   |
|    value_loss             | 0.00339  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.62     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 687      |
|    iterations             | 132      |
|    time_elapsed           | 24       |
|    total_timesteps        | 16896    |
| train/                    |          |
|    explained_variance     | 0.255    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0082   |
|    learning_rate          | 0.001    |
|    n_updates              | 131      |
|    policy_objective       | 0.0356   |
|    value_loss             | 0.0429   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.56     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 687      |
|    iterations             | 133      |
|    time_elapsed           | 24       |
|    total_timesteps        | 17024    |
| train/                    |          |
|    explained_variance     | 0.486    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00928  |
|    learning_rate          | 0.001    |
|    n_updates              | 132      |
|    policy_objective       | 0.0181   |
|    value_loss             | 0.0227   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.51     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 687      |
|    iterations             | 134      |
|    time_elapsed           | 24       |
|    total_timesteps        | 17152    |
| train/                    |          |
|    explained_variance     | -0.317   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00849  |
|    learning_rate          | 0.001    |
|    n_updates              | 133      |
|    policy_objective       | 0.0267   |
|    value_loss             | 0.0543   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.01     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 686      |
|    iterations             | 135      |
|    time_elapsed           | 25       |
|    total_timesteps        | 17280    |
| train/                    |          |
|    explained_variance     | -10.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00441  |
|    learning_rate          | 0.001    |
|    n_updates              | 134      |
|    policy_objective       | 0.0299   |
|    value_loss             | 0.00164  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.12     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 686      |
|    iterations             | 136      |
|    time_elapsed           | 25       |
|    total_timesteps        | 17408    |
| train/                    |          |
|    explained_variance     | -17.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00848  |
|    learning_rate          | 0.001    |
|    n_updates              | 135      |
|    policy_objective       | 0.0294   |
|    value_loss             | 0.00247  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.19     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 687      |
|    iterations             | 137      |
|    time_elapsed           | 25       |
|    total_timesteps        | 17536    |
| train/                    |          |
|    explained_variance     | -53.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00901  |
|    learning_rate          | 0.001    |
|    n_updates              | 136      |
|    policy_objective       | 0.0436   |
|    value_loss             | 0.000339 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.53     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 687      |
|    iterations             | 138      |
|    time_elapsed           | 25       |
|    total_timesteps        | 17664    |
| train/                    |          |
|    explained_variance     | -59.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00553  |
|    learning_rate          | 0.001    |
|    n_updates              | 137      |
|    policy_objective       | 0.0672   |
|    value_loss             | 7.37e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.78     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 687      |
|    iterations             | 139      |
|    time_elapsed           | 25       |
|    total_timesteps        | 17792    |
| train/                    |          |
|    explained_variance     | 0.075    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00741  |
|    learning_rate          | 0.001    |
|    n_updates              | 138      |
|    policy_objective       | 0.0346   |
|    value_loss             | 0.0397   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.31     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 687      |
|    iterations             | 140      |
|    time_elapsed           | 26       |
|    total_timesteps        | 17920    |
| train/                    |          |
|    explained_variance     | 0.263    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00718  |
|    learning_rate          | 0.001    |
|    n_updates              | 139      |
|    policy_objective       | 0.101    |
|    value_loss             | 0.0256   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.13     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 687      |
|    iterations             | 141      |
|    time_elapsed           | 26       |
|    total_timesteps        | 18048    |
| train/                    |          |
|    explained_variance     | 0.145    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00628  |
|    learning_rate          | 0.001    |
|    n_updates              | 140      |
|    policy_objective       | 0.04     |
|    value_loss             | 0.0523   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.03     |
|    ep_rew_mean            | 0.05     |
| time/                     |          |
|    fps                    | 686      |
|    iterations             | 142      |
|    time_elapsed           | 26       |
|    total_timesteps        | 18176    |
| train/                    |          |
|    explained_variance     | -7.59    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00748  |
|    learning_rate          | 0.001    |
|    n_updates              | 141      |
|    policy_objective       | 0.043    |
|    value_loss             | 0.00941  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.23     |
|    ep_rew_mean            | 0.06     |
| time/                     |          |
|    fps                    | 686      |
|    iterations             | 143      |
|    time_elapsed           | 26       |
|    total_timesteps        | 18304    |
| train/                    |          |
|    explained_variance     | 0.134    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0071   |
|    learning_rate          | 0.001    |
|    n_updates              | 142      |
|    policy_objective       | 0.0519   |
|    value_loss             | 0.0689   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.51     |
|    ep_rew_mean            | 0.06     |
| time/                     |          |
|    fps                    | 687      |
|    iterations             | 144      |
|    time_elapsed           | 26       |
|    total_timesteps        | 18432    |
| train/                    |          |
|    explained_variance     | 0.316    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0047   |
|    learning_rate          | 0.001    |
|    n_updates              | 143      |
|    policy_objective       | 0.0323   |
|    value_loss             | 0.0343   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.22     |
|    ep_rew_mean            | 0.05     |
| time/                     |          |
|    fps                    | 687      |
|    iterations             | 145      |
|    time_elapsed           | 26       |
|    total_timesteps        | 18560    |
| train/                    |          |
|    explained_variance     | -18.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00378  |
|    learning_rate          | 0.001    |
|    n_updates              | 144      |
|    policy_objective       | 0.0305   |
|    value_loss             | 0.00614  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.95     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 687      |
|    iterations             | 146      |
|    time_elapsed           | 27       |
|    total_timesteps        | 18688    |
| train/                    |          |
|    explained_variance     | 0.314    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00908  |
|    learning_rate          | 0.001    |
|    n_updates              | 145      |
|    policy_objective       | 0.0284   |
|    value_loss             | 0.0127   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.43     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 687      |
|    iterations             | 147      |
|    time_elapsed           | 27       |
|    total_timesteps        | 18816    |
| train/                    |          |
|    explained_variance     | -26.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00589  |
|    learning_rate          | 0.001    |
|    n_updates              | 146      |
|    policy_objective       | 0.0234   |
|    value_loss             | 0.00736  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.52     |
|    ep_rew_mean            | 0.05     |
| time/                     |          |
|    fps                    | 688      |
|    iterations             | 148      |
|    time_elapsed           | 27       |
|    total_timesteps        | 18944    |
| train/                    |          |
|    explained_variance     | 0.154    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00627  |
|    learning_rate          | 0.001    |
|    n_updates              | 147      |
|    policy_objective       | 0.067    |
|    value_loss             | 0.0373   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.43     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 688      |
|    iterations             | 149      |
|    time_elapsed           | 27       |
|    total_timesteps        | 19072    |
| train/                    |          |
|    explained_variance     | 0.248    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0085   |
|    learning_rate          | 0.001    |
|    n_updates              | 148      |
|    policy_objective       | 0.0458   |
|    value_loss             | 0.0256   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.3      |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 688      |
|    iterations             | 150      |
|    time_elapsed           | 27       |
|    total_timesteps        | 19200    |
| train/                    |          |
|    explained_variance     | -37.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00391  |
|    learning_rate          | 0.001    |
|    n_updates              | 149      |
|    policy_objective       | 0.0335   |
|    value_loss             | 0.00194  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.23     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 688      |
|    iterations             | 151      |
|    time_elapsed           | 28       |
|    total_timesteps        | 19328    |
| train/                    |          |
|    explained_variance     | 0.192    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00474  |
|    learning_rate          | 0.001    |
|    n_updates              | 150      |
|    policy_objective       | 0.0585   |
|    value_loss             | 0.0351   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8        |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 688      |
|    iterations             | 152      |
|    time_elapsed           | 28       |
|    total_timesteps        | 19456    |
| train/                    |          |
|    explained_variance     | -3.9     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0021   |
|    learning_rate          | 0.001    |
|    n_updates              | 151      |
|    policy_objective       | 0.0469   |
|    value_loss             | 0.011    |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.46     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 153      |
|    time_elapsed           | 28       |
|    total_timesteps        | 19584    |
| train/                    |          |
|    explained_variance     | -20.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00442  |
|    learning_rate          | 0.001    |
|    n_updates              | 152      |
|    policy_objective       | 0.0262   |
|    value_loss             | 0.000544 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.51     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 154      |
|    time_elapsed           | 28       |
|    total_timesteps        | 19712    |
| train/                    |          |
|    explained_variance     | -36.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00729  |
|    learning_rate          | 0.001    |
|    n_updates              | 153      |
|    policy_objective       | 0.0175   |
|    value_loss             | 5.13e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.58     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 155      |
|    time_elapsed           | 28       |
|    total_timesteps        | 19840    |
| train/                    |          |
|    explained_variance     | 0.384    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00935  |
|    learning_rate          | 0.001    |
|    n_updates              | 154      |
|    policy_objective       | 0.169    |
|    value_loss             | 0.0299   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.88     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 156      |
|    time_elapsed           | 28       |
|    total_timesteps        | 19968    |
| train/                    |          |
|    explained_variance     | -16.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.005    |
|    learning_rate          | 0.001    |
|    n_updates              | 155      |
|    policy_objective       | 0.0376   |
|    value_loss             | 0.00399  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.3      |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 157      |
|    time_elapsed           | 29       |
|    total_timesteps        | 20096    |
| train/                    |          |
|    explained_variance     | 0.219    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00714  |
|    learning_rate          | 0.001    |
|    n_updates              | 156      |
|    policy_objective       | 0.0314   |
|    value_loss             | 0.0466   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.42     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 158      |
|    time_elapsed           | 29       |
|    total_timesteps        | 20224    |
| train/                    |          |
|    explained_variance     | -25.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00584  |
|    learning_rate          | 0.001    |
|    n_updates              | 157      |
|    policy_objective       | 0.0179   |
|    value_loss             | 0.00464  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.98     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 159      |
|    time_elapsed           | 29       |
|    total_timesteps        | 20352    |
| train/                    |          |
|    explained_variance     | 0.0448   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0067   |
|    learning_rate          | 0.001    |
|    n_updates              | 158      |
|    policy_objective       | 0.0338   |
|    value_loss             | 0.0445   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.71     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 160      |
|    time_elapsed           | 29       |
|    total_timesteps        | 20480    |
| train/                    |          |
|    explained_variance     | -15.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00564  |
|    learning_rate          | 0.001    |
|    n_updates              | 159      |
|    policy_objective       | 0.0332   |
|    value_loss             | 0.00374  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.46     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 161      |
|    time_elapsed           | 29       |
|    total_timesteps        | 20608    |
| train/                    |          |
|    explained_variance     | 0.142    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00706  |
|    learning_rate          | 0.001    |
|    n_updates              | 160      |
|    policy_objective       | 0.0208   |
|    value_loss             | 0.0313   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.16     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 162      |
|    time_elapsed           | 30       |
|    total_timesteps        | 20736    |
| train/                    |          |
|    explained_variance     | -4.93    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00739  |
|    learning_rate          | 0.001    |
|    n_updates              | 161      |
|    policy_objective       | 0.0432   |
|    value_loss             | 0.000363 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.38     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 163      |
|    time_elapsed           | 30       |
|    total_timesteps        | 20864    |
| train/                    |          |
|    explained_variance     | 0.228    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00473  |
|    learning_rate          | 0.001    |
|    n_updates              | 162      |
|    policy_objective       | 0.306    |
|    value_loss             | 0.0344   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.66     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 164      |
|    time_elapsed           | 30       |
|    total_timesteps        | 20992    |
| train/                    |          |
|    explained_variance     | -0.457   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00644  |
|    learning_rate          | 0.001    |
|    n_updates              | 163      |
|    policy_objective       | 0.0553   |
|    value_loss             | 0.0431   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.11     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 165      |
|    time_elapsed           | 30       |
|    total_timesteps        | 21120    |
| train/                    |          |
|    explained_variance     | -5.83    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00335  |
|    learning_rate          | 0.001    |
|    n_updates              | 164      |
|    policy_objective       | 0.0475   |
|    value_loss             | 0.00348  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.33     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 166      |
|    time_elapsed           | 30       |
|    total_timesteps        | 21248    |
| train/                    |          |
|    explained_variance     | -20.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00263  |
|    learning_rate          | 0.001    |
|    n_updates              | 165      |
|    policy_objective       | 0.0487   |
|    value_loss             | 0.000461 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.44     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 690      |
|    iterations             | 167      |
|    time_elapsed           | 30       |
|    total_timesteps        | 21376    |
| train/                    |          |
|    explained_variance     | 0.103    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00728  |
|    learning_rate          | 0.001    |
|    n_updates              | 166      |
|    policy_objective       | 0.0177   |
|    value_loss             | 0.0423   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.23     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 690      |
|    iterations             | 168      |
|    time_elapsed           | 31       |
|    total_timesteps        | 21504    |
| train/                    |          |
|    explained_variance     | -1.32    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00229  |
|    learning_rate          | 0.001    |
|    n_updates              | 167      |
|    policy_objective       | 0.0446   |
|    value_loss             | 0.00227  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.55     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 690      |
|    iterations             | 169      |
|    time_elapsed           | 31       |
|    total_timesteps        | 21632    |
| train/                    |          |
|    explained_variance     | -35.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00755  |
|    learning_rate          | 0.001    |
|    n_updates              | 168      |
|    policy_objective       | 0.0239   |
|    value_loss             | 0.000911 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.01     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 690      |
|    iterations             | 170      |
|    time_elapsed           | 31       |
|    total_timesteps        | 21760    |
| train/                    |          |
|    explained_variance     | 0.262    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0092   |
|    learning_rate          | 0.001    |
|    n_updates              | 169      |
|    policy_objective       | 0.016    |
|    value_loss             | 0.0376   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.85     |
|    ep_rew_mean            | 0.05     |
| time/                     |          |
|    fps                    | 690      |
|    iterations             | 171      |
|    time_elapsed           | 31       |
|    total_timesteps        | 21888    |
| train/                    |          |
|    explained_variance     | 0.255    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00803  |
|    learning_rate          | 0.001    |
|    n_updates              | 170      |
|    policy_objective       | 0.0675   |
|    value_loss             | 0.069    |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.15     |
|    ep_rew_mean            | 0.06     |
| time/                     |          |
|    fps                    | 690      |
|    iterations             | 172      |
|    time_elapsed           | 31       |
|    total_timesteps        | 22016    |
| train/                    |          |
|    explained_variance     | -0.00514 |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00699  |
|    learning_rate          | 0.001    |
|    n_updates              | 171      |
|    policy_objective       | 0.0252   |
|    value_loss             | 0.0502   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.2      |
|    ep_rew_mean            | 0.05     |
| time/                     |          |
|    fps                    | 690      |
|    iterations             | 173      |
|    time_elapsed           | 32       |
|    total_timesteps        | 22144    |
| train/                    |          |
|    explained_variance     | -0.12    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00621  |
|    learning_rate          | 0.001    |
|    n_updates              | 172      |
|    policy_objective       | 0.0227   |
|    value_loss             | 0.0494   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.28     |
|    ep_rew_mean            | 0.05     |
| time/                     |          |
|    fps                    | 690      |
|    iterations             | 174      |
|    time_elapsed           | 32       |
|    total_timesteps        | 22272    |
| train/                    |          |
|    explained_variance     | -1.05    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00662  |
|    learning_rate          | 0.001    |
|    n_updates              | 173      |
|    policy_objective       | 0.029    |
|    value_loss             | 0.00334  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.2      |
|    ep_rew_mean            | 0.06     |
| time/                     |          |
|    fps                    | 690      |
|    iterations             | 175      |
|    time_elapsed           | 32       |
|    total_timesteps        | 22400    |
| train/                    |          |
|    explained_variance     | -3.33    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00524  |
|    learning_rate          | 0.001    |
|    n_updates              | 174      |
|    policy_objective       | 0.0397   |
|    value_loss             | 0.000538 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8        |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 690      |
|    iterations             | 176      |
|    time_elapsed           | 32       |
|    total_timesteps        | 22528    |
| train/                    |          |
|    explained_variance     | 0.187    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00628  |
|    learning_rate          | 0.001    |
|    n_updates              | 175      |
|    policy_objective       | 0.0801   |
|    value_loss             | 0.0367   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.08     |
|    ep_rew_mean            | 0.07     |
| time/                     |          |
|    fps                    | 690      |
|    iterations             | 177      |
|    time_elapsed           | 32       |
|    total_timesteps        | 22656    |
| train/                    |          |
|    explained_variance     | 0.269    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00483  |
|    learning_rate          | 0.001    |
|    n_updates              | 176      |
|    policy_objective       | 0.0406   |
|    value_loss             | 0.0305   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.79     |
|    ep_rew_mean            | 0.05     |
| time/                     |          |
|    fps                    | 690      |
|    iterations             | 178      |
|    time_elapsed           | 32       |
|    total_timesteps        | 22784    |
| train/                    |          |
|    explained_variance     | 0.291    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00859  |
|    learning_rate          | 0.001    |
|    n_updates              | 177      |
|    policy_objective       | 0.0306   |
|    value_loss             | 0.0783   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.56     |
|    ep_rew_mean            | 0.05     |
| time/                     |          |
|    fps                    | 691      |
|    iterations             | 179      |
|    time_elapsed           | 33       |
|    total_timesteps        | 22912    |
| train/                    |          |
|    explained_variance     | -11.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00835  |
|    learning_rate          | 0.001    |
|    n_updates              | 178      |
|    policy_objective       | 0.0187   |
|    value_loss             | 0.0107   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.95     |
|    ep_rew_mean            | 0.05     |
| time/                     |          |
|    fps                    | 691      |
|    iterations             | 180      |
|    time_elapsed           | 33       |
|    total_timesteps        | 23040    |
| train/                    |          |
|    explained_variance     | -22.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0063   |
|    learning_rate          | 0.001    |
|    n_updates              | 179      |
|    policy_objective       | 0.0204   |
|    value_loss             | 0.00421  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.33     |
|    ep_rew_mean            | 0.05     |
| time/                     |          |
|    fps                    | 691      |
|    iterations             | 181      |
|    time_elapsed           | 33       |
|    total_timesteps        | 23168    |
| train/                    |          |
|    explained_variance     | 0.00554  |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00894  |
|    learning_rate          | 0.001    |
|    n_updates              | 180      |
|    policy_objective       | 0.0357   |
|    value_loss             | 0.000671 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.54     |
|    ep_rew_mean            | 0.06     |
| time/                     |          |
|    fps                    | 691      |
|    iterations             | 182      |
|    time_elapsed           | 33       |
|    total_timesteps        | 23296    |
| train/                    |          |
|    explained_variance     | -36.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00361  |
|    learning_rate          | 0.001    |
|    n_updates              | 181      |
|    policy_objective       | 0.0635   |
|    value_loss             | 0.000444 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.71     |
|    ep_rew_mean            | 0.05     |
| time/                     |          |
|    fps                    | 690      |
|    iterations             | 183      |
|    time_elapsed           | 33       |
|    total_timesteps        | 23424    |
| train/                    |          |
|    explained_variance     | 0.00369  |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00845  |
|    learning_rate          | 0.001    |
|    n_updates              | 182      |
|    policy_objective       | 0.116    |
|    value_loss             | 0.0782   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.47     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 690      |
|    iterations             | 184      |
|    time_elapsed           | 34       |
|    total_timesteps        | 23552    |
| train/                    |          |
|    explained_variance     | -0.503   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0064   |
|    learning_rate          | 0.001    |
|    n_updates              | 183      |
|    policy_objective       | 0.0349   |
|    value_loss             | 0.0126   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.18     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 185      |
|    time_elapsed           | 34       |
|    total_timesteps        | 23680    |
| train/                    |          |
|    explained_variance     | -2.57    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00689  |
|    learning_rate          | 0.001    |
|    n_updates              | 184      |
|    policy_objective       | 0.0296   |
|    value_loss             | 0.00105  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.8      |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 688      |
|    iterations             | 186      |
|    time_elapsed           | 34       |
|    total_timesteps        | 23808    |
| train/                    |          |
|    explained_variance     | -32      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00578  |
|    learning_rate          | 0.001    |
|    n_updates              | 185      |
|    policy_objective       | 0.0298   |
|    value_loss             | 0.00376  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.38     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 687      |
|    iterations             | 187      |
|    time_elapsed           | 34       |
|    total_timesteps        | 23936    |
| train/                    |          |
|    explained_variance     | -45.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00592  |
|    learning_rate          | 0.001    |
|    n_updates              | 186      |
|    policy_objective       | 0.0491   |
|    value_loss             | 0.000828 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.5      |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 686      |
|    iterations             | 188      |
|    time_elapsed           | 35       |
|    total_timesteps        | 24064    |
| train/                    |          |
|    explained_variance     | -28.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0054   |
|    learning_rate          | 0.001    |
|    n_updates              | 187      |
|    policy_objective       | 0.0793   |
|    value_loss             | 2.95e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.28     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 686      |
|    iterations             | 189      |
|    time_elapsed           | 35       |
|    total_timesteps        | 24192    |
| train/                    |          |
|    explained_variance     | 0.0782   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00797  |
|    learning_rate          | 0.001    |
|    n_updates              | 188      |
|    policy_objective       | 0.0489   |
|    value_loss             | 0.0484   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.33     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 686      |
|    iterations             | 190      |
|    time_elapsed           | 35       |
|    total_timesteps        | 24320    |
| train/                    |          |
|    explained_variance     | -15.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00366  |
|    learning_rate          | 0.001    |
|    n_updates              | 189      |
|    policy_objective       | 0.048    |
|    value_loss             | 0.00301  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.66     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 686      |
|    iterations             | 191      |
|    time_elapsed           | 35       |
|    total_timesteps        | 24448    |
| train/                    |          |
|    explained_variance     | -17.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00457  |
|    learning_rate          | 0.001    |
|    n_updates              | 190      |
|    policy_objective       | 0.0302   |
|    value_loss             | 0.000692 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.59     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 686      |
|    iterations             | 192      |
|    time_elapsed           | 35       |
|    total_timesteps        | 24576    |
| train/                    |          |
|    explained_variance     | 0.0178   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00672  |
|    learning_rate          | 0.001    |
|    n_updates              | 191      |
|    policy_objective       | 0.0652   |
|    value_loss             | 0.043    |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.72     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 685      |
|    iterations             | 193      |
|    time_elapsed           | 36       |
|    total_timesteps        | 24704    |
| train/                    |          |
|    explained_variance     | -18.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00457  |
|    learning_rate          | 0.001    |
|    n_updates              | 192      |
|    policy_objective       | 0.0597   |
|    value_loss             | 0.00302  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.35     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 685      |
|    iterations             | 194      |
|    time_elapsed           | 36       |
|    total_timesteps        | 24832    |
| train/                    |          |
|    explained_variance     | -14.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00691  |
|    learning_rate          | 0.001    |
|    n_updates              | 193      |
|    policy_objective       | 0.0234   |
|    value_loss             | 9.3e-05  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.04     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 685      |
|    iterations             | 195      |
|    time_elapsed           | 36       |
|    total_timesteps        | 24960    |
| train/                    |          |
|    explained_variance     | -30.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00507  |
|    learning_rate          | 0.001    |
|    n_updates              | 194      |
|    policy_objective       | 0.0249   |
|    value_loss             | 3.44e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.06     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 685      |
|    iterations             | 196      |
|    time_elapsed           | 36       |
|    total_timesteps        | 25088    |
| train/                    |          |
|    explained_variance     | -89.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00469  |
|    learning_rate          | 0.001    |
|    n_updates              | 195      |
|    policy_objective       | 0.0223   |
|    value_loss             | 6.19e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.01     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 685      |
|    iterations             | 197      |
|    time_elapsed           | 36       |
|    total_timesteps        | 25216    |
| train/                    |          |
|    explained_variance     | -22.7    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00434  |
|    learning_rate          | 0.001    |
|    n_updates              | 196      |
|    policy_objective       | 0.0235   |
|    value_loss             | 0.00318  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.96     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 685      |
|    iterations             | 198      |
|    time_elapsed           | 36       |
|    total_timesteps        | 25344    |
| train/                    |          |
|    explained_variance     | -52.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00311  |
|    learning_rate          | 0.001    |
|    n_updates              | 197      |
|    policy_objective       | 0.0397   |
|    value_loss             | 0.000339 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.9      |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 685      |
|    iterations             | 199      |
|    time_elapsed           | 37       |
|    total_timesteps        | 25472    |
| train/                    |          |
|    explained_variance     | -24.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00257  |
|    learning_rate          | 0.001    |
|    n_updates              | 198      |
|    policy_objective       | 0.0686   |
|    value_loss             | 0.000244 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.06     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 686      |
|    iterations             | 200      |
|    time_elapsed           | 37       |
|    total_timesteps        | 25600    |
| train/                    |          |
|    explained_variance     | -41.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00623  |
|    learning_rate          | 0.001    |
|    n_updates              | 199      |
|    policy_objective       | 0.0723   |
|    value_loss             | 3.95e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.75     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 686      |
|    iterations             | 201      |
|    time_elapsed           | 37       |
|    total_timesteps        | 25728    |
| train/                    |          |
|    explained_variance     | -11.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00695  |
|    learning_rate          | 0.001    |
|    n_updates              | 200      |
|    policy_objective       | 0.0785   |
|    value_loss             | 0.000233 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.25     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 686      |
|    iterations             | 202      |
|    time_elapsed           | 37       |
|    total_timesteps        | 25856    |
| train/                    |          |
|    explained_variance     | -29.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00241  |
|    learning_rate          | 0.001    |
|    n_updates              | 201      |
|    policy_objective       | 0.0364   |
|    value_loss             | 1.35e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.53     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 686      |
|    iterations             | 203      |
|    time_elapsed           | 37       |
|    total_timesteps        | 25984    |
| train/                    |          |
|    explained_variance     | -59.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00153  |
|    learning_rate          | 0.001    |
|    n_updates              | 202      |
|    policy_objective       | 0.0751   |
|    value_loss             | 1.63e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.54     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 686      |
|    iterations             | 204      |
|    time_elapsed           | 38       |
|    total_timesteps        | 26112    |
| train/                    |          |
|    explained_variance     | 0.00898  |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00413  |
|    learning_rate          | 0.001    |
|    n_updates              | 203      |
|    policy_objective       | 0.0799   |
|    value_loss             | 0.0294   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.71     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 686      |
|    iterations             | 205      |
|    time_elapsed           | 38       |
|    total_timesteps        | 26240    |
| train/                    |          |
|    explained_variance     | -13      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00871  |
|    learning_rate          | 0.001    |
|    n_updates              | 204      |
|    policy_objective       | 0.0286   |
|    value_loss             | 0.000675 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.22     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 686      |
|    iterations             | 206      |
|    time_elapsed           | 38       |
|    total_timesteps        | 26368    |
| train/                    |          |
|    explained_variance     | 0.147    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00673  |
|    learning_rate          | 0.001    |
|    n_updates              | 205      |
|    policy_objective       | 0.0663   |
|    value_loss             | 0.0274   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.61     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 686      |
|    iterations             | 207      |
|    time_elapsed           | 38       |
|    total_timesteps        | 26496    |
| train/                    |          |
|    explained_variance     | -0.0233  |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00607  |
|    learning_rate          | 0.001    |
|    n_updates              | 206      |
|    policy_objective       | 0.156    |
|    value_loss             | 0.0366   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.39     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 686      |
|    iterations             | 208      |
|    time_elapsed           | 38       |
|    total_timesteps        | 26624    |
| train/                    |          |
|    explained_variance     | -8.06    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00575  |
|    learning_rate          | 0.001    |
|    n_updates              | 207      |
|    policy_objective       | 0.064    |
|    value_loss             | 0.00117  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.89     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 686      |
|    iterations             | 209      |
|    time_elapsed           | 38       |
|    total_timesteps        | 26752    |
| train/                    |          |
|    explained_variance     | 0.114    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00682  |
|    learning_rate          | 0.001    |
|    n_updates              | 208      |
|    policy_objective       | 0.0736   |
|    value_loss             | 0.0373   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.37     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 687      |
|    iterations             | 210      |
|    time_elapsed           | 39       |
|    total_timesteps        | 26880    |
| train/                    |          |
|    explained_variance     | -22.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0021   |
|    learning_rate          | 0.001    |
|    n_updates              | 209      |
|    policy_objective       | 0.0667   |
|    value_loss             | 0.00103  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.14     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 687      |
|    iterations             | 211      |
|    time_elapsed           | 39       |
|    total_timesteps        | 27008    |
| train/                    |          |
|    explained_variance     | -8.46    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00351  |
|    learning_rate          | 0.001    |
|    n_updates              | 210      |
|    policy_objective       | 0.0118   |
|    value_loss             | 0.00241  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.65     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 687      |
|    iterations             | 212      |
|    time_elapsed           | 39       |
|    total_timesteps        | 27136    |
| train/                    |          |
|    explained_variance     | -22.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00787  |
|    learning_rate          | 0.001    |
|    n_updates              | 211      |
|    policy_objective       | 0.0646   |
|    value_loss             | 0.000505 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.34     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 687      |
|    iterations             | 213      |
|    time_elapsed           | 39       |
|    total_timesteps        | 27264    |
| train/                    |          |
|    explained_variance     | -16.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00319  |
|    learning_rate          | 0.001    |
|    n_updates              | 212      |
|    policy_objective       | 0.0637   |
|    value_loss             | 0.000118 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.91     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 687      |
|    iterations             | 214      |
|    time_elapsed           | 39       |
|    total_timesteps        | 27392    |
| train/                    |          |
|    explained_variance     | -23.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00322  |
|    learning_rate          | 0.001    |
|    n_updates              | 213      |
|    policy_objective       | 0.0452   |
|    value_loss             | 2.98e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.98     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 687      |
|    iterations             | 215      |
|    time_elapsed           | 40       |
|    total_timesteps        | 27520    |
| train/                    |          |
|    explained_variance     | 0.0418   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00585  |
|    learning_rate          | 0.001    |
|    n_updates              | 214      |
|    policy_objective       | 0.0403   |
|    value_loss             | 0.0506   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.16     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 687      |
|    iterations             | 216      |
|    time_elapsed           | 40       |
|    total_timesteps        | 27648    |
| train/                    |          |
|    explained_variance     | -3.57    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00364  |
|    learning_rate          | 0.001    |
|    n_updates              | 215      |
|    policy_objective       | 0.0505   |
|    value_loss             | 0.00186  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.53     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 687      |
|    iterations             | 217      |
|    time_elapsed           | 40       |
|    total_timesteps        | 27776    |
| train/                    |          |
|    explained_variance     | 0.16     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0067   |
|    learning_rate          | 0.001    |
|    n_updates              | 216      |
|    policy_objective       | 0.0352   |
|    value_loss             | 0.0319   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.42     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 687      |
|    iterations             | 218      |
|    time_elapsed           | 40       |
|    total_timesteps        | 27904    |
| train/                    |          |
|    explained_variance     | -26.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00776  |
|    learning_rate          | 0.001    |
|    n_updates              | 217      |
|    policy_objective       | 0.0459   |
|    value_loss             | 0.00025  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.5      |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 687      |
|    iterations             | 219      |
|    time_elapsed           | 40       |
|    total_timesteps        | 28032    |
| train/                    |          |
|    explained_variance     | 0.201    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00636  |
|    learning_rate          | 0.001    |
|    n_updates              | 218      |
|    policy_objective       | 0.0323   |
|    value_loss             | 0.0333   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.42     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 687      |
|    iterations             | 220      |
|    time_elapsed           | 40       |
|    total_timesteps        | 28160    |
| train/                    |          |
|    explained_variance     | -0.59    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00329  |
|    learning_rate          | 0.001    |
|    n_updates              | 219      |
|    policy_objective       | 0.0329   |
|    value_loss             | 0.0211   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.59     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 687      |
|    iterations             | 221      |
|    time_elapsed           | 41       |
|    total_timesteps        | 28288    |
| train/                    |          |
|    explained_variance     | -4.64    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00275  |
|    learning_rate          | 0.001    |
|    n_updates              | 220      |
|    policy_objective       | 0.031    |
|    value_loss             | 0.00153  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.61     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 687      |
|    iterations             | 222      |
|    time_elapsed           | 41       |
|    total_timesteps        | 28416    |
| train/                    |          |
|    explained_variance     | 0.117    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0077   |
|    learning_rate          | 0.001    |
|    n_updates              | 221      |
|    policy_objective       | 0.0279   |
|    value_loss             | 0.0414   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.57     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 687      |
|    iterations             | 223      |
|    time_elapsed           | 41       |
|    total_timesteps        | 28544    |
| train/                    |          |
|    explained_variance     | -7.76    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00898  |
|    learning_rate          | 0.001    |
|    n_updates              | 222      |
|    policy_objective       | 0.0215   |
|    value_loss             | 0.00113  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.3      |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 687      |
|    iterations             | 224      |
|    time_elapsed           | 41       |
|    total_timesteps        | 28672    |
| train/                    |          |
|    explained_variance     | -28.6    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00544  |
|    learning_rate          | 0.001    |
|    n_updates              | 223      |
|    policy_objective       | 0.0203   |
|    value_loss             | 0.000712 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.25     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 687      |
|    iterations             | 225      |
|    time_elapsed           | 41       |
|    total_timesteps        | 28800    |
| train/                    |          |
|    explained_variance     | -46.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00312  |
|    learning_rate          | 0.001    |
|    n_updates              | 224      |
|    policy_objective       | 0.043    |
|    value_loss             | 0.000691 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.93     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 688      |
|    iterations             | 226      |
|    time_elapsed           | 42       |
|    total_timesteps        | 28928    |
| train/                    |          |
|    explained_variance     | -37.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00733  |
|    learning_rate          | 0.001    |
|    n_updates              | 225      |
|    policy_objective       | 0.0327   |
|    value_loss             | 0.000446 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.82     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 688      |
|    iterations             | 227      |
|    time_elapsed           | 42       |
|    total_timesteps        | 29056    |
| train/                    |          |
|    explained_variance     | 0.0499   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00915  |
|    learning_rate          | 0.001    |
|    n_updates              | 226      |
|    policy_objective       | 0.0869   |
|    value_loss             | 0.0347   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.88     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 688      |
|    iterations             | 228      |
|    time_elapsed           | 42       |
|    total_timesteps        | 29184    |
| train/                    |          |
|    explained_variance     | -21.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00939  |
|    learning_rate          | 0.001    |
|    n_updates              | 227      |
|    policy_objective       | 0.0702   |
|    value_loss             | 0.00147  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.71     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 688      |
|    iterations             | 229      |
|    time_elapsed           | 42       |
|    total_timesteps        | 29312    |
| train/                    |          |
|    explained_variance     | -0.31    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00643  |
|    learning_rate          | 0.001    |
|    n_updates              | 228      |
|    policy_objective       | 0.0405   |
|    value_loss             | 0.000416 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.54     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 688      |
|    iterations             | 230      |
|    time_elapsed           | 42       |
|    total_timesteps        | 29440    |
| train/                    |          |
|    explained_variance     | -14.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00514  |
|    learning_rate          | 0.001    |
|    n_updates              | 229      |
|    policy_objective       | 0.0269   |
|    value_loss             | 0.000327 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.76     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 688      |
|    iterations             | 231      |
|    time_elapsed           | 42       |
|    total_timesteps        | 29568    |
| train/                    |          |
|    explained_variance     | -15.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00842  |
|    learning_rate          | 0.001    |
|    n_updates              | 230      |
|    policy_objective       | 0.0426   |
|    value_loss             | 3.33e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.33     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 688      |
|    iterations             | 232      |
|    time_elapsed           | 43       |
|    total_timesteps        | 29696    |
| train/                    |          |
|    explained_variance     | -98.7    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00245  |
|    learning_rate          | 0.001    |
|    n_updates              | 231      |
|    policy_objective       | 0.0248   |
|    value_loss             | 2.5e-05  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.53     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 688      |
|    iterations             | 233      |
|    time_elapsed           | 43       |
|    total_timesteps        | 29824    |
| train/                    |          |
|    explained_variance     | -23.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00573  |
|    learning_rate          | 0.001    |
|    n_updates              | 232      |
|    policy_objective       | 0.0288   |
|    value_loss             | 0.000264 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.57     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 234      |
|    time_elapsed           | 43       |
|    total_timesteps        | 29952    |
| train/                    |          |
|    explained_variance     | -24.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00548  |
|    learning_rate          | 0.001    |
|    n_updates              | 233      |
|    policy_objective       | 0.135    |
|    value_loss             | 2.86e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.13     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 235      |
|    time_elapsed           | 43       |
|    total_timesteps        | 30080    |
| train/                    |          |
|    explained_variance     | -41.7    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00426  |
|    learning_rate          | 0.001    |
|    n_updates              | 234      |
|    policy_objective       | 0.0194   |
|    value_loss             | 4.19e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.13     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 236      |
|    time_elapsed           | 43       |
|    total_timesteps        | 30208    |
| train/                    |          |
|    explained_variance     | -0.00394 |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0032   |
|    learning_rate          | 0.001    |
|    n_updates              | 235      |
|    policy_objective       | 0.151    |
|    value_loss             | 0.0515   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.58     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 237      |
|    time_elapsed           | 44       |
|    total_timesteps        | 30336    |
| train/                    |          |
|    explained_variance     | -2.7     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00361  |
|    learning_rate          | 0.001    |
|    n_updates              | 236      |
|    policy_objective       | 0.0609   |
|    value_loss             | 0.00219  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.11     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 238      |
|    time_elapsed           | 44       |
|    total_timesteps        | 30464    |
| train/                    |          |
|    explained_variance     | -20      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0042   |
|    learning_rate          | 0.001    |
|    n_updates              | 237      |
|    policy_objective       | 0.0597   |
|    value_loss             | 0.000485 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.74     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 239      |
|    time_elapsed           | 44       |
|    total_timesteps        | 30592    |
| train/                    |          |
|    explained_variance     | -29.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00441  |
|    learning_rate          | 0.001    |
|    n_updates              | 238      |
|    policy_objective       | 0.0818   |
|    value_loss             | 0.000158 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.65     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 240      |
|    time_elapsed           | 44       |
|    total_timesteps        | 30720    |
| train/                    |          |
|    explained_variance     | -48.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00295  |
|    learning_rate          | 0.001    |
|    n_updates              | 239      |
|    policy_objective       | 0.0877   |
|    value_loss             | 8.62e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.59     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 241      |
|    time_elapsed           | 44       |
|    total_timesteps        | 30848    |
| train/                    |          |
|    explained_variance     | -67.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00635  |
|    learning_rate          | 0.001    |
|    n_updates              | 240      |
|    policy_objective       | 0.0333   |
|    value_loss             | 0.0011   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.5      |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 242      |
|    time_elapsed           | 44       |
|    total_timesteps        | 30976    |
| train/                    |          |
|    explained_variance     | 0.157    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00521  |
|    learning_rate          | 0.001    |
|    n_updates              | 241      |
|    policy_objective       | 0.0909   |
|    value_loss             | 0.0199   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.99     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 243      |
|    time_elapsed           | 45       |
|    total_timesteps        | 31104    |
| train/                    |          |
|    explained_variance     | -43.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00392  |
|    learning_rate          | 0.001    |
|    n_updates              | 242      |
|    policy_objective       | 0.0512   |
|    value_loss             | 0.00299  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.09     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 244      |
|    time_elapsed           | 45       |
|    total_timesteps        | 31232    |
| train/                    |          |
|    explained_variance     | -12.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00626  |
|    learning_rate          | 0.001    |
|    n_updates              | 243      |
|    policy_objective       | 0.0802   |
|    value_loss             | 1.91e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.48     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 245      |
|    time_elapsed           | 45       |
|    total_timesteps        | 31360    |
| train/                    |          |
|    explained_variance     | -0.51    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00401  |
|    learning_rate          | 0.001    |
|    n_updates              | 244      |
|    policy_objective       | 0.0273   |
|    value_loss             | 0.00156  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.48     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 246      |
|    time_elapsed           | 45       |
|    total_timesteps        | 31488    |
| train/                    |          |
|    explained_variance     | 0.122    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00693  |
|    learning_rate          | 0.001    |
|    n_updates              | 245      |
|    policy_objective       | 0.072    |
|    value_loss             | 0.0751   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.5      |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 690      |
|    iterations             | 247      |
|    time_elapsed           | 45       |
|    total_timesteps        | 31616    |
| train/                    |          |
|    explained_variance     | 0.123    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00662  |
|    learning_rate          | 0.001    |
|    n_updates              | 246      |
|    policy_objective       | 0.131    |
|    value_loss             | 0.0436   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.59     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 690      |
|    iterations             | 248      |
|    time_elapsed           | 45       |
|    total_timesteps        | 31744    |
| train/                    |          |
|    explained_variance     | 0.141    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00774  |
|    learning_rate          | 0.001    |
|    n_updates              | 247      |
|    policy_objective       | 0.0301   |
|    value_loss             | 0.0438   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.88     |
|    ep_rew_mean            | 0.05     |
| time/                     |          |
|    fps                    | 690      |
|    iterations             | 249      |
|    time_elapsed           | 46       |
|    total_timesteps        | 31872    |
| train/                    |          |
|    explained_variance     | -5.68    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00799  |
|    learning_rate          | 0.001    |
|    n_updates              | 248      |
|    policy_objective       | 0.053    |
|    value_loss             | 0.0161   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.67     |
|    ep_rew_mean            | 0.05     |
| time/                     |          |
|    fps                    | 690      |
|    iterations             | 250      |
|    time_elapsed           | 46       |
|    total_timesteps        | 32000    |
| train/                    |          |
|    explained_variance     | 0.0574   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00608  |
|    learning_rate          | 0.001    |
|    n_updates              | 249      |
|    policy_objective       | 0.0574   |
|    value_loss             | 0.0467   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.25     |
|    ep_rew_mean            | 0.05     |
| time/                     |          |
|    fps                    | 690      |
|    iterations             | 251      |
|    time_elapsed           | 46       |
|    total_timesteps        | 32128    |
| train/                    |          |
|    explained_variance     | -3.86    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00497  |
|    learning_rate          | 0.001    |
|    n_updates              | 250      |
|    policy_objective       | 0.0242   |
|    value_loss             | 0.00532  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.77     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 690      |
|    iterations             | 252      |
|    time_elapsed           | 46       |
|    total_timesteps        | 32256    |
| train/                    |          |
|    explained_variance     | -5.76    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0043   |
|    learning_rate          | 0.001    |
|    n_updates              | 251      |
|    policy_objective       | 0.0609   |
|    value_loss             | 0.000663 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.67     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 690      |
|    iterations             | 253      |
|    time_elapsed           | 46       |
|    total_timesteps        | 32384    |
| train/                    |          |
|    explained_variance     | 0.16     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00576  |
|    learning_rate          | 0.001    |
|    n_updates              | 252      |
|    policy_objective       | 0.0258   |
|    value_loss             | 0.034    |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.93     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 691      |
|    iterations             | 254      |
|    time_elapsed           | 47       |
|    total_timesteps        | 32512    |
| train/                    |          |
|    explained_variance     | 0.136    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00685  |
|    learning_rate          | 0.001    |
|    n_updates              | 253      |
|    policy_objective       | 0.0754   |
|    value_loss             | 0.0339   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.22     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 691      |
|    iterations             | 255      |
|    time_elapsed           | 47       |
|    total_timesteps        | 32640    |
| train/                    |          |
|    explained_variance     | -44.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00347  |
|    learning_rate          | 0.001    |
|    n_updates              | 254      |
|    policy_objective       | 0.0217   |
|    value_loss             | 0.00155  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.34     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 691      |
|    iterations             | 256      |
|    time_elapsed           | 47       |
|    total_timesteps        | 32768    |
| train/                    |          |
|    explained_variance     | -19.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00475  |
|    learning_rate          | 0.001    |
|    n_updates              | 255      |
|    policy_objective       | 0.0564   |
|    value_loss             | 0.00299  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.59     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 691      |
|    iterations             | 257      |
|    time_elapsed           | 47       |
|    total_timesteps        | 32896    |
| train/                    |          |
|    explained_variance     | -28.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00479  |
|    learning_rate          | 0.001    |
|    n_updates              | 256      |
|    policy_objective       | 0.0638   |
|    value_loss             | 3.49e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.21     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 691      |
|    iterations             | 258      |
|    time_elapsed           | 47       |
|    total_timesteps        | 33024    |
| train/                    |          |
|    explained_variance     | 0.155    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0062   |
|    learning_rate          | 0.001    |
|    n_updates              | 257      |
|    policy_objective       | 0.108    |
|    value_loss             | 0.0372   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.31     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 691      |
|    iterations             | 259      |
|    time_elapsed           | 47       |
|    total_timesteps        | 33152    |
| train/                    |          |
|    explained_variance     | -18.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0054   |
|    learning_rate          | 0.001    |
|    n_updates              | 258      |
|    policy_objective       | 0.0561   |
|    value_loss             | 0.00138  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.4      |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 691      |
|    iterations             | 260      |
|    time_elapsed           | 48       |
|    total_timesteps        | 33280    |
| train/                    |          |
|    explained_variance     | -37.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00469  |
|    learning_rate          | 0.001    |
|    n_updates              | 259      |
|    policy_objective       | 0.0632   |
|    value_loss             | 0.000623 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.61     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 691      |
|    iterations             | 261      |
|    time_elapsed           | 48       |
|    total_timesteps        | 33408    |
| train/                    |          |
|    explained_variance     | -23.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0041   |
|    learning_rate          | 0.001    |
|    n_updates              | 260      |
|    policy_objective       | 0.0447   |
|    value_loss             | 0.0022   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.5      |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 691      |
|    iterations             | 262      |
|    time_elapsed           | 48       |
|    total_timesteps        | 33536    |
| train/                    |          |
|    explained_variance     | -18.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0038   |
|    learning_rate          | 0.001    |
|    n_updates              | 261      |
|    policy_objective       | 0.0623   |
|    value_loss             | 0.00146  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.68     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 691      |
|    iterations             | 263      |
|    time_elapsed           | 48       |
|    total_timesteps        | 33664    |
| train/                    |          |
|    explained_variance     | -9.03    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00546  |
|    learning_rate          | 0.001    |
|    n_updates              | 262      |
|    policy_objective       | 0.0629   |
|    value_loss             | 0.00218  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.49     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 691      |
|    iterations             | 264      |
|    time_elapsed           | 48       |
|    total_timesteps        | 33792    |
| train/                    |          |
|    explained_variance     | -2.88    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00415  |
|    learning_rate          | 0.001    |
|    n_updates              | 263      |
|    policy_objective       | 0.0523   |
|    value_loss             | 0.000246 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.6      |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 691      |
|    iterations             | 265      |
|    time_elapsed           | 49       |
|    total_timesteps        | 33920    |
| train/                    |          |
|    explained_variance     | 0.0388   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00435  |
|    learning_rate          | 0.001    |
|    n_updates              | 264      |
|    policy_objective       | 0.0941   |
|    value_loss             | 0.0339   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.64     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 690      |
|    iterations             | 266      |
|    time_elapsed           | 49       |
|    total_timesteps        | 34048    |
| train/                    |          |
|    explained_variance     | -9.71    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00657  |
|    learning_rate          | 0.001    |
|    n_updates              | 265      |
|    policy_objective       | 0.0352   |
|    value_loss             | 0.000203 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.78     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 690      |
|    iterations             | 267      |
|    time_elapsed           | 49       |
|    total_timesteps        | 34176    |
| train/                    |          |
|    explained_variance     | -16.6    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00109  |
|    learning_rate          | 0.001    |
|    n_updates              | 266      |
|    policy_objective       | 0.0551   |
|    value_loss             | 0.00115  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.16     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 690      |
|    iterations             | 268      |
|    time_elapsed           | 49       |
|    total_timesteps        | 34304    |
| train/                    |          |
|    explained_variance     | -25      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00462  |
|    learning_rate          | 0.001    |
|    n_updates              | 267      |
|    policy_objective       | 0.0373   |
|    value_loss             | 2.94e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.44     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 269      |
|    time_elapsed           | 49       |
|    total_timesteps        | 34432    |
| train/                    |          |
|    explained_variance     | -66.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00294  |
|    learning_rate          | 0.001    |
|    n_updates              | 268      |
|    policy_objective       | 0.0464   |
|    value_loss             | 3.95e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.48     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 270      |
|    time_elapsed           | 50       |
|    total_timesteps        | 34560    |
| train/                    |          |
|    explained_variance     | 0.149    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00684  |
|    learning_rate          | 0.001    |
|    n_updates              | 269      |
|    policy_objective       | 0.0391   |
|    value_loss             | 0.0875   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.54     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 271      |
|    time_elapsed           | 50       |
|    total_timesteps        | 34688    |
| train/                    |          |
|    explained_variance     | -2.86    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00861  |
|    learning_rate          | 0.001    |
|    n_updates              | 270      |
|    policy_objective       | 0.041    |
|    value_loss             | 0.002    |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.67     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 272      |
|    time_elapsed           | 50       |
|    total_timesteps        | 34816    |
| train/                    |          |
|    explained_variance     | -0.0533  |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00631  |
|    learning_rate          | 0.001    |
|    n_updates              | 271      |
|    policy_objective       | 0.0472   |
|    value_loss             | 0.0575   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.84     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 273      |
|    time_elapsed           | 50       |
|    total_timesteps        | 34944    |
| train/                    |          |
|    explained_variance     | -3.52    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00407  |
|    learning_rate          | 0.001    |
|    n_updates              | 272      |
|    policy_objective       | 0.0614   |
|    value_loss             | 0.00269  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.98     |
|    ep_rew_mean            | 0.06     |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 274      |
|    time_elapsed           | 50       |
|    total_timesteps        | 35072    |
| train/                    |          |
|    explained_variance     | -9.85    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00449  |
|    learning_rate          | 0.001    |
|    n_updates              | 273      |
|    policy_objective       | 0.0512   |
|    value_loss             | 0.000165 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.12     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 275      |
|    time_elapsed           | 51       |
|    total_timesteps        | 35200    |
| train/                    |          |
|    explained_variance     | 0.171    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00696  |
|    learning_rate          | 0.001    |
|    n_updates              | 274      |
|    policy_objective       | 0.0512   |
|    value_loss             | 0.0538   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.73     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 276      |
|    time_elapsed           | 51       |
|    total_timesteps        | 35328    |
| train/                    |          |
|    explained_variance     | -31.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00497  |
|    learning_rate          | 0.001    |
|    n_updates              | 275      |
|    policy_objective       | 0.0595   |
|    value_loss             | 0.00674  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.2      |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 277      |
|    time_elapsed           | 51       |
|    total_timesteps        | 35456    |
| train/                    |          |
|    explained_variance     | 0.247    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00753  |
|    learning_rate          | 0.001    |
|    n_updates              | 276      |
|    policy_objective       | 0.0781   |
|    value_loss             | 0.0116   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.43     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 278      |
|    time_elapsed           | 51       |
|    total_timesteps        | 35584    |
| train/                    |          |
|    explained_variance     | 0.405    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00513  |
|    learning_rate          | 0.001    |
|    n_updates              | 277      |
|    policy_objective       | 0.0425   |
|    value_loss             | 0.0361   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.6      |
|    ep_rew_mean            | 0.05     |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 279      |
|    time_elapsed           | 51       |
|    total_timesteps        | 35712    |
| train/                    |          |
|    explained_variance     | -22.7    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00198  |
|    learning_rate          | 0.001    |
|    n_updates              | 278      |
|    policy_objective       | 0.0664   |
|    value_loss             | 0.00388  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.9      |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 280      |
|    time_elapsed           | 51       |
|    total_timesteps        | 35840    |
| train/                    |          |
|    explained_variance     | 0.349    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00857  |
|    learning_rate          | 0.001    |
|    n_updates              | 279      |
|    policy_objective       | 0.0373   |
|    value_loss             | 0.066    |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.86     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 281      |
|    time_elapsed           | 52       |
|    total_timesteps        | 35968    |
| train/                    |          |
|    explained_variance     | -0.0262  |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00879  |
|    learning_rate          | 0.001    |
|    n_updates              | 280      |
|    policy_objective       | 0.0421   |
|    value_loss             | 0.0493   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.13     |
|    ep_rew_mean            | 0.05     |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 282      |
|    time_elapsed           | 52       |
|    total_timesteps        | 36096    |
| train/                    |          |
|    explained_variance     | -9.09    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0043   |
|    learning_rate          | 0.001    |
|    n_updates              | 281      |
|    policy_objective       | 0.0385   |
|    value_loss             | 0.00503  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.13     |
|    ep_rew_mean            | 0.05     |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 283      |
|    time_elapsed           | 52       |
|    total_timesteps        | 36224    |
| train/                    |          |
|    explained_variance     | 0.00496  |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00951  |
|    learning_rate          | 0.001    |
|    n_updates              | 282      |
|    policy_objective       | 0.0451   |
|    value_loss             | 0.0441   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.05     |
|    ep_rew_mean            | 0.06     |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 284      |
|    time_elapsed           | 52       |
|    total_timesteps        | 36352    |
| train/                    |          |
|    explained_variance     | 0.116    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00466  |
|    learning_rate          | 0.001    |
|    n_updates              | 283      |
|    policy_objective       | 0.091    |
|    value_loss             | 0.0383   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.02     |
|    ep_rew_mean            | 0.05     |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 285      |
|    time_elapsed           | 52       |
|    total_timesteps        | 36480    |
| train/                    |          |
|    explained_variance     | 0.177    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00664  |
|    learning_rate          | 0.001    |
|    n_updates              | 284      |
|    policy_objective       | 0.0288   |
|    value_loss             | 0.0311   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.32     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 286      |
|    time_elapsed           | 53       |
|    total_timesteps        | 36608    |
| train/                    |          |
|    explained_variance     | 0.224    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00487  |
|    learning_rate          | 0.001    |
|    n_updates              | 285      |
|    policy_objective       | 0.0372   |
|    value_loss             | 0.0259   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.61     |
|    ep_rew_mean            | 0.05     |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 287      |
|    time_elapsed           | 53       |
|    total_timesteps        | 36736    |
| train/                    |          |
|    explained_variance     | -6.29    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00437  |
|    learning_rate          | 0.001    |
|    n_updates              | 286      |
|    policy_objective       | 0.0319   |
|    value_loss             | 0.00528  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.36     |
|    ep_rew_mean            | 0.06     |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 288      |
|    time_elapsed           | 53       |
|    total_timesteps        | 36864    |
| train/                    |          |
|    explained_variance     | 0.284    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00628  |
|    learning_rate          | 0.001    |
|    n_updates              | 287      |
|    policy_objective       | 0.0341   |
|    value_loss             | 0.0274   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.25     |
|    ep_rew_mean            | 0.05     |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 289      |
|    time_elapsed           | 53       |
|    total_timesteps        | 36992    |
| train/                    |          |
|    explained_variance     | 0.0996   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00643  |
|    learning_rate          | 0.001    |
|    n_updates              | 288      |
|    policy_objective       | 0.0469   |
|    value_loss             | 0.0472   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.08     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 290      |
|    time_elapsed           | 53       |
|    total_timesteps        | 37120    |
| train/                    |          |
|    explained_variance     | -10.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00579  |
|    learning_rate          | 0.001    |
|    n_updates              | 289      |
|    policy_objective       | 0.0285   |
|    value_loss             | 0.00881  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.9      |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 291      |
|    time_elapsed           | 53       |
|    total_timesteps        | 37248    |
| train/                    |          |
|    explained_variance     | -7.06    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00465  |
|    learning_rate          | 0.001    |
|    n_updates              | 290      |
|    policy_objective       | 0.0596   |
|    value_loss             | 0.000869 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.53     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 690      |
|    iterations             | 292      |
|    time_elapsed           | 54       |
|    total_timesteps        | 37376    |
| train/                    |          |
|    explained_variance     | 0.035    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00498  |
|    learning_rate          | 0.001    |
|    n_updates              | 291      |
|    policy_objective       | 0.0699   |
|    value_loss             | 0.0469   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.54     |
|    ep_rew_mean            | 0.05     |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 293      |
|    time_elapsed           | 54       |
|    total_timesteps        | 37504    |
| train/                    |          |
|    explained_variance     | 0.207    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00552  |
|    learning_rate          | 0.001    |
|    n_updates              | 292      |
|    policy_objective       | 0.0529   |
|    value_loss             | 0.0263   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.95     |
|    ep_rew_mean            | 0.05     |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 294      |
|    time_elapsed           | 54       |
|    total_timesteps        | 37632    |
| train/                    |          |
|    explained_variance     | 0.239    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00437  |
|    learning_rate          | 0.001    |
|    n_updates              | 293      |
|    policy_objective       | 0.0592   |
|    value_loss             | 0.0709   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.79     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 688      |
|    iterations             | 295      |
|    time_elapsed           | 54       |
|    total_timesteps        | 37760    |
| train/                    |          |
|    explained_variance     | -6.93    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00562  |
|    learning_rate          | 0.001    |
|    n_updates              | 294      |
|    policy_objective       | 0.0335   |
|    value_loss             | 0.0164   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.1      |
|    ep_rew_mean            | 0.05     |
| time/                     |          |
|    fps                    | 688      |
|    iterations             | 296      |
|    time_elapsed           | 55       |
|    total_timesteps        | 37888    |
| train/                    |          |
|    explained_variance     | -1.5     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00398  |
|    learning_rate          | 0.001    |
|    n_updates              | 295      |
|    policy_objective       | 0.0305   |
|    value_loss             | 0.00106  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.46     |
|    ep_rew_mean            | 0.05     |
| time/                     |          |
|    fps                    | 688      |
|    iterations             | 297      |
|    time_elapsed           | 55       |
|    total_timesteps        | 38016    |
| train/                    |          |
|    explained_variance     | 0.167    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00938  |
|    learning_rate          | 0.001    |
|    n_updates              | 296      |
|    policy_objective       | 0.0361   |
|    value_loss             | 0.0424   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.18     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 688      |
|    iterations             | 298      |
|    time_elapsed           | 55       |
|    total_timesteps        | 38144    |
| train/                    |          |
|    explained_variance     | -40.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00734  |
|    learning_rate          | 0.001    |
|    n_updates              | 297      |
|    policy_objective       | 0.0443   |
|    value_loss             | 0.00119  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.67     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 688      |
|    iterations             | 299      |
|    time_elapsed           | 55       |
|    total_timesteps        | 38272    |
| train/                    |          |
|    explained_variance     | -32.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0089   |
|    learning_rate          | 0.001    |
|    n_updates              | 298      |
|    policy_objective       | 0.0333   |
|    value_loss             | 7.85e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.94     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 688      |
|    iterations             | 300      |
|    time_elapsed           | 55       |
|    total_timesteps        | 38400    |
| train/                    |          |
|    explained_variance     | -36.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00351  |
|    learning_rate          | 0.001    |
|    n_updates              | 299      |
|    policy_objective       | 0.0386   |
|    value_loss             | 0.000612 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.06     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 688      |
|    iterations             | 301      |
|    time_elapsed           | 55       |
|    total_timesteps        | 38528    |
| train/                    |          |
|    explained_variance     | 0.323    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00682  |
|    learning_rate          | 0.001    |
|    n_updates              | 300      |
|    policy_objective       | 0.0899   |
|    value_loss             | 0.0612   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.92     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 688      |
|    iterations             | 302      |
|    time_elapsed           | 56       |
|    total_timesteps        | 38656    |
| train/                    |          |
|    explained_variance     | -10.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0035   |
|    learning_rate          | 0.001    |
|    n_updates              | 301      |
|    policy_objective       | 0.0478   |
|    value_loss             | 0.0119   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.07     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 688      |
|    iterations             | 303      |
|    time_elapsed           | 56       |
|    total_timesteps        | 38784    |
| train/                    |          |
|    explained_variance     | 0.163    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00963  |
|    learning_rate          | 0.001    |
|    n_updates              | 302      |
|    policy_objective       | 0.0781   |
|    value_loss             | 0.0357   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.27     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 688      |
|    iterations             | 304      |
|    time_elapsed           | 56       |
|    total_timesteps        | 38912    |
| train/                    |          |
|    explained_variance     | -25.6    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00812  |
|    learning_rate          | 0.001    |
|    n_updates              | 303      |
|    policy_objective       | 0.0982   |
|    value_loss             | 0.00213  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.11     |
|    ep_rew_mean            | 0.05     |
| time/                     |          |
|    fps                    | 688      |
|    iterations             | 305      |
|    time_elapsed           | 56       |
|    total_timesteps        | 39040    |
| train/                    |          |
|    explained_variance     | -16.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00492  |
|    learning_rate          | 0.001    |
|    n_updates              | 304      |
|    policy_objective       | 0.0897   |
|    value_loss             | 0.00479  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.14     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 688      |
|    iterations             | 306      |
|    time_elapsed           | 56       |
|    total_timesteps        | 39168    |
| train/                    |          |
|    explained_variance     | 0.119    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00727  |
|    learning_rate          | 0.001    |
|    n_updates              | 305      |
|    policy_objective       | 0.107    |
|    value_loss             | 0.0616   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.14     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 688      |
|    iterations             | 307      |
|    time_elapsed           | 57       |
|    total_timesteps        | 39296    |
| train/                    |          |
|    explained_variance     | -18.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00514  |
|    learning_rate          | 0.001    |
|    n_updates              | 306      |
|    policy_objective       | 0.0434   |
|    value_loss             | 0.0117   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.41     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 688      |
|    iterations             | 308      |
|    time_elapsed           | 57       |
|    total_timesteps        | 39424    |
| train/                    |          |
|    explained_variance     | -0.188   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00631  |
|    learning_rate          | 0.001    |
|    n_updates              | 307      |
|    policy_objective       | 0.0265   |
|    value_loss             | 0.00435  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.15     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 688      |
|    iterations             | 309      |
|    time_elapsed           | 57       |
|    total_timesteps        | 39552    |
| train/                    |          |
|    explained_variance     | 0.149    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00657  |
|    learning_rate          | 0.001    |
|    n_updates              | 308      |
|    policy_objective       | 0.0279   |
|    value_loss             | 0.0493   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.38     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 688      |
|    iterations             | 310      |
|    time_elapsed           | 57       |
|    total_timesteps        | 39680    |
| train/                    |          |
|    explained_variance     | -1.07    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00397  |
|    learning_rate          | 0.001    |
|    n_updates              | 309      |
|    policy_objective       | 0.0227   |
|    value_loss             | 0.00142  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.21     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 688      |
|    iterations             | 311      |
|    time_elapsed           | 57       |
|    total_timesteps        | 39808    |
| train/                    |          |
|    explained_variance     | -8.58    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00867  |
|    learning_rate          | 0.001    |
|    n_updates              | 310      |
|    policy_objective       | 0.0236   |
|    value_loss             | 0.0105   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.86     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 312      |
|    time_elapsed           | 57       |
|    total_timesteps        | 39936    |
| train/                    |          |
|    explained_variance     | -18.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00597  |
|    learning_rate          | 0.001    |
|    n_updates              | 311      |
|    policy_objective       | 0.0455   |
|    value_loss             | 0.0011   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8        |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 313      |
|    time_elapsed           | 58       |
|    total_timesteps        | 40064    |
| train/                    |          |
|    explained_variance     | -87.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0071   |
|    learning_rate          | 0.001    |
|    n_updates              | 312      |
|    policy_objective       | 0.0521   |
|    value_loss             | 0.000175 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.01     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 314      |
|    time_elapsed           | 58       |
|    total_timesteps        | 40192    |
| train/                    |          |
|    explained_variance     | 0.0155   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00869  |
|    learning_rate          | 0.001    |
|    n_updates              | 313      |
|    policy_objective       | 0.0277   |
|    value_loss             | 0.0488   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.9      |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 315      |
|    time_elapsed           | 58       |
|    total_timesteps        | 40320    |
| train/                    |          |
|    explained_variance     | -6.13    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00709  |
|    learning_rate          | 0.001    |
|    n_updates              | 314      |
|    policy_objective       | 0.0305   |
|    value_loss             | 0.00466  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.56     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 316      |
|    time_elapsed           | 58       |
|    total_timesteps        | 40448    |
| train/                    |          |
|    explained_variance     | -5.9     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0057   |
|    learning_rate          | 0.001    |
|    n_updates              | 315      |
|    policy_objective       | 0.0813   |
|    value_loss             | 0.00183  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.9      |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 317      |
|    time_elapsed           | 58       |
|    total_timesteps        | 40576    |
| train/                    |          |
|    explained_variance     | -3.58    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00346  |
|    learning_rate          | 0.001    |
|    n_updates              | 316      |
|    policy_objective       | 0.0303   |
|    value_loss             | 0.000126 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.48     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 318      |
|    time_elapsed           | 59       |
|    total_timesteps        | 40704    |
| train/                    |          |
|    explained_variance     | -13.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00682  |
|    learning_rate          | 0.001    |
|    n_updates              | 317      |
|    policy_objective       | 0.0421   |
|    value_loss             | 0.000528 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.95     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 319      |
|    time_elapsed           | 59       |
|    total_timesteps        | 40832    |
| train/                    |          |
|    explained_variance     | -10.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00757  |
|    learning_rate          | 0.001    |
|    n_updates              | 318      |
|    policy_objective       | 0.0846   |
|    value_loss             | 2.8e-05  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.69     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 320      |
|    time_elapsed           | 59       |
|    total_timesteps        | 40960    |
| train/                    |          |
|    explained_variance     | -38.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00786  |
|    learning_rate          | 0.001    |
|    n_updates              | 319      |
|    policy_objective       | 0.0331   |
|    value_loss             | 0.000204 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.41     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 321      |
|    time_elapsed           | 59       |
|    total_timesteps        | 41088    |
| train/                    |          |
|    explained_variance     | 0.0612   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00495  |
|    learning_rate          | 0.001    |
|    n_updates              | 320      |
|    policy_objective       | 0.0377   |
|    value_loss             | 0.0676   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.33     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 322      |
|    time_elapsed           | 59       |
|    total_timesteps        | 41216    |
| train/                    |          |
|    explained_variance     | -7.68    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00642  |
|    learning_rate          | 0.001    |
|    n_updates              | 321      |
|    policy_objective       | 0.0429   |
|    value_loss             | 0.00477  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.49     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 323      |
|    time_elapsed           | 59       |
|    total_timesteps        | 41344    |
| train/                    |          |
|    explained_variance     | -13.7    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00499  |
|    learning_rate          | 0.001    |
|    n_updates              | 322      |
|    policy_objective       | 0.0303   |
|    value_loss             | 0.000438 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.2      |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 324      |
|    time_elapsed           | 60       |
|    total_timesteps        | 41472    |
| train/                    |          |
|    explained_variance     | 0.159    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00684  |
|    learning_rate          | 0.001    |
|    n_updates              | 323      |
|    policy_objective       | 0.0281   |
|    value_loss             | 0.0359   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.14     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 325      |
|    time_elapsed           | 60       |
|    total_timesteps        | 41600    |
| train/                    |          |
|    explained_variance     | -2.27    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0044   |
|    learning_rate          | 0.001    |
|    n_updates              | 324      |
|    policy_objective       | 0.0289   |
|    value_loss             | 0.00266  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.7      |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 326      |
|    time_elapsed           | 60       |
|    total_timesteps        | 41728    |
| train/                    |          |
|    explained_variance     | -31.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00502  |
|    learning_rate          | 0.001    |
|    n_updates              | 325      |
|    policy_objective       | 0.045    |
|    value_loss             | 0.000356 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.89     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 327      |
|    time_elapsed           | 60       |
|    total_timesteps        | 41856    |
| train/                    |          |
|    explained_variance     | -22.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00502  |
|    learning_rate          | 0.001    |
|    n_updates              | 326      |
|    policy_objective       | 0.0622   |
|    value_loss             | 0.0038   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.67     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 328      |
|    time_elapsed           | 60       |
|    total_timesteps        | 41984    |
| train/                    |          |
|    explained_variance     | -18.4    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00351  |
|    learning_rate          | 0.001    |
|    n_updates              | 327      |
|    policy_objective       | 0.0436   |
|    value_loss             | 2.78e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 6.85     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 329      |
|    time_elapsed           | 61       |
|    total_timesteps        | 42112    |
| train/                    |          |
|    explained_variance     | 0.0865   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00576  |
|    learning_rate          | 0.001    |
|    n_updates              | 328      |
|    policy_objective       | 0.0376   |
|    value_loss             | 0.0473   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.6      |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 330      |
|    time_elapsed           | 61       |
|    total_timesteps        | 42240    |
| train/                    |          |
|    explained_variance     | -7.53    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00236  |
|    learning_rate          | 0.001    |
|    n_updates              | 329      |
|    policy_objective       | 0.0475   |
|    value_loss             | 0.00248  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.6      |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 331      |
|    time_elapsed           | 61       |
|    total_timesteps        | 42368    |
| train/                    |          |
|    explained_variance     | 0.177    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00625  |
|    learning_rate          | 0.001    |
|    n_updates              | 330      |
|    policy_objective       | 0.021    |
|    value_loss             | 0.0446   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.95     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 332      |
|    time_elapsed           | 61       |
|    total_timesteps        | 42496    |
| train/                    |          |
|    explained_variance     | 0.398    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00482  |
|    learning_rate          | 0.001    |
|    n_updates              | 331      |
|    policy_objective       | 0.0436   |
|    value_loss             | 0.0196   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.66     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 333      |
|    time_elapsed           | 61       |
|    total_timesteps        | 42624    |
| train/                    |          |
|    explained_variance     | -23.6    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00255  |
|    learning_rate          | 0.001    |
|    n_updates              | 332      |
|    policy_objective       | 0.0276   |
|    value_loss             | 0.00893  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.57     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 689      |
|    iterations             | 334      |
|    time_elapsed           | 61       |
|    total_timesteps        | 42752    |
| train/                    |          |
|    explained_variance     | -5.66    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00779  |
|    learning_rate          | 0.001    |
|    n_updates              | 333      |
|    policy_objective       | 0.0736   |
|    value_loss             | 0.000143 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.41     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 690      |
|    iterations             | 335      |
|    time_elapsed           | 62       |
|    total_timesteps        | 42880    |
| train/                    |          |
|    explained_variance     | -44.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00128  |
|    learning_rate          | 0.001    |
|    n_updates              | 334      |
|    policy_objective       | 0.0728   |
|    value_loss             | 0.000128 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.17     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 690      |
|    iterations             | 336      |
|    time_elapsed           | 62       |
|    total_timesteps        | 43008    |
| train/                    |          |
|    explained_variance     | -36.5    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0052   |
|    learning_rate          | 0.001    |
|    n_updates              | 335      |
|    policy_objective       | 0.115    |
|    value_loss             | 4.56e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.16     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 690      |
|    iterations             | 337      |
|    time_elapsed           | 62       |
|    total_timesteps        | 43136    |
| train/                    |          |
|    explained_variance     | 0.205    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00699  |
|    learning_rate          | 0.001    |
|    n_updates              | 336      |
|    policy_objective       | 0.0242   |
|    value_loss             | 0.027    |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.44     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 690      |
|    iterations             | 338      |
|    time_elapsed           | 62       |
|    total_timesteps        | 43264    |
| train/                    |          |
|    explained_variance     | 0.0481   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00789  |
|    learning_rate          | 0.001    |
|    n_updates              | 337      |
|    policy_objective       | 0.0479   |
|    value_loss             | 0.0405   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.62     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 690      |
|    iterations             | 339      |
|    time_elapsed           | 62       |
|    total_timesteps        | 43392    |
| train/                    |          |
|    explained_variance     | 0.16     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00419  |
|    learning_rate          | 0.001    |
|    n_updates              | 338      |
|    policy_objective       | 0.0176   |
|    value_loss             | 0.0368   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.77     |
|    ep_rew_mean            | 0.05     |
| time/                     |          |
|    fps                    | 690      |
|    iterations             | 340      |
|    time_elapsed           | 63       |
|    total_timesteps        | 43520    |
| train/                    |          |
|    explained_variance     | 0.36     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00775  |
|    learning_rate          | 0.001    |
|    n_updates              | 339      |
|    policy_objective       | 0.03     |
|    value_loss             | 0.0299   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.66     |
|    ep_rew_mean            | 0.05     |
| time/                     |          |
|    fps                    | 690      |
|    iterations             | 341      |
|    time_elapsed           | 63       |
|    total_timesteps        | 43648    |
| train/                    |          |
|    explained_variance     | 0.29     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00337  |
|    learning_rate          | 0.001    |
|    n_updates              | 340      |
|    policy_objective       | 0.0252   |
|    value_loss             | 0.0464   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.72     |
|    ep_rew_mean            | 0.05     |
| time/                     |          |
|    fps                    | 690      |
|    iterations             | 342      |
|    time_elapsed           | 63       |
|    total_timesteps        | 43776    |
| train/                    |          |
|    explained_variance     | -13.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00392  |
|    learning_rate          | 0.001    |
|    n_updates              | 341      |
|    policy_objective       | 0.0456   |
|    value_loss             | 0.00671  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.7      |
|    ep_rew_mean            | 0.05     |
| time/                     |          |
|    fps                    | 690      |
|    iterations             | 343      |
|    time_elapsed           | 63       |
|    total_timesteps        | 43904    |
| train/                    |          |
|    explained_variance     | 0.164    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00811  |
|    learning_rate          | 0.001    |
|    n_updates              | 342      |
|    policy_objective       | 0.0341   |
|    value_loss             | 0.0471   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.28     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 690      |
|    iterations             | 344      |
|    time_elapsed           | 63       |
|    total_timesteps        | 44032    |
| train/                    |          |
|    explained_variance     | 0.198    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00741  |
|    learning_rate          | 0.001    |
|    n_updates              | 343      |
|    policy_objective       | 0.0377   |
|    value_loss             | 0.0432   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.01     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 690      |
|    iterations             | 345      |
|    time_elapsed           | 63       |
|    total_timesteps        | 44160    |
| train/                    |          |
|    explained_variance     | -0.607   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00584  |
|    learning_rate          | 0.001    |
|    n_updates              | 344      |
|    policy_objective       | 0.0779   |
|    value_loss             | 0.0277   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.11     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 690      |
|    iterations             | 346      |
|    time_elapsed           | 64       |
|    total_timesteps        | 44288    |
| train/                    |          |
|    explained_variance     | 0.341    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00789  |
|    learning_rate          | 0.001    |
|    n_updates              | 345      |
|    policy_objective       | 0.0336   |
|    value_loss             | 0.0165   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.64     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 690      |
|    iterations             | 347      |
|    time_elapsed           | 64       |
|    total_timesteps        | 44416    |
| train/                    |          |
|    explained_variance     | -24.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00809  |
|    learning_rate          | 0.001    |
|    n_updates              | 346      |
|    policy_objective       | 0.0763   |
|    value_loss             | 0.000329 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.13     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 691      |
|    iterations             | 348      |
|    time_elapsed           | 64       |
|    total_timesteps        | 44544    |
| train/                    |          |
|    explained_variance     | -0.524   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00924  |
|    learning_rate          | 0.001    |
|    n_updates              | 347      |
|    policy_objective       | 0.0392   |
|    value_loss             | 0.00122  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.83     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 691      |
|    iterations             | 349      |
|    time_elapsed           | 64       |
|    total_timesteps        | 44672    |
| train/                    |          |
|    explained_variance     | 0.0695   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00618  |
|    learning_rate          | 0.001    |
|    n_updates              | 348      |
|    policy_objective       | 0.0167   |
|    value_loss             | 0.00727  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.11     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 691      |
|    iterations             | 350      |
|    time_elapsed           | 64       |
|    total_timesteps        | 44800    |
| train/                    |          |
|    explained_variance     | 0.74     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00302  |
|    learning_rate          | 0.001    |
|    n_updates              | 349      |
|    policy_objective       | 0.0364   |
|    value_loss             | 0.00228  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.62     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 691      |
|    iterations             | 351      |
|    time_elapsed           | 64       |
|    total_timesteps        | 44928    |
| train/                    |          |
|    explained_variance     | -17.6    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00548  |
|    learning_rate          | 0.001    |
|    n_updates              | 350      |
|    policy_objective       | 0.0144   |
|    value_loss             | 0.000725 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.53     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 691      |
|    iterations             | 352      |
|    time_elapsed           | 65       |
|    total_timesteps        | 45056    |
| train/                    |          |
|    explained_variance     | -42      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.006    |
|    learning_rate          | 0.001    |
|    n_updates              | 351      |
|    policy_objective       | 0.0443   |
|    value_loss             | 0.000108 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.75     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 691      |
|    iterations             | 353      |
|    time_elapsed           | 65       |
|    total_timesteps        | 45184    |
| train/                    |          |
|    explained_variance     | -56.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00747  |
|    learning_rate          | 0.001    |
|    n_updates              | 352      |
|    policy_objective       | 0.0369   |
|    value_loss             | 0.00457  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.35     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 691      |
|    iterations             | 354      |
|    time_elapsed           | 65       |
|    total_timesteps        | 45312    |
| train/                    |          |
|    explained_variance     | 0.175    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00747  |
|    learning_rate          | 0.001    |
|    n_updates              | 353      |
|    policy_objective       | 0.0184   |
|    value_loss             | 0.0324   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.36     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 691      |
|    iterations             | 355      |
|    time_elapsed           | 65       |
|    total_timesteps        | 45440    |
| train/                    |          |
|    explained_variance     | -4.81    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00703  |
|    learning_rate          | 0.001    |
|    n_updates              | 354      |
|    policy_objective       | 0.024    |
|    value_loss             | 0.000267 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.62     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 691      |
|    iterations             | 356      |
|    time_elapsed           | 65       |
|    total_timesteps        | 45568    |
| train/                    |          |
|    explained_variance     | -29.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00246  |
|    learning_rate          | 0.001    |
|    n_updates              | 355      |
|    policy_objective       | 0.0205   |
|    value_loss             | 0.000502 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.14     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 691      |
|    iterations             | 357      |
|    time_elapsed           | 66       |
|    total_timesteps        | 45696    |
| train/                    |          |
|    explained_variance     | 0.232    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00629  |
|    learning_rate          | 0.001    |
|    n_updates              | 356      |
|    policy_objective       | 0.0385   |
|    value_loss             | 0.0348   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.24     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 691      |
|    iterations             | 358      |
|    time_elapsed           | 66       |
|    total_timesteps        | 45824    |
| train/                    |          |
|    explained_variance     | -16.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00653  |
|    learning_rate          | 0.001    |
|    n_updates              | 357      |
|    policy_objective       | 0.0687   |
|    value_loss             | 0.00736  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.81     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 691      |
|    iterations             | 359      |
|    time_elapsed           | 66       |
|    total_timesteps        | 45952    |
| train/                    |          |
|    explained_variance     | -22.9    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00388  |
|    learning_rate          | 0.001    |
|    n_updates              | 358      |
|    policy_objective       | 0.0468   |
|    value_loss             | 0.00164  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.71     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 691      |
|    iterations             | 360      |
|    time_elapsed           | 66       |
|    total_timesteps        | 46080    |
| train/                    |          |
|    explained_variance     | 0.0422   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00375  |
|    learning_rate          | 0.001    |
|    n_updates              | 359      |
|    policy_objective       | 0.0335   |
|    value_loss             | 0.0475   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.26     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 691      |
|    iterations             | 361      |
|    time_elapsed           | 66       |
|    total_timesteps        | 46208    |
| train/                    |          |
|    explained_variance     | -3.72    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00674  |
|    learning_rate          | 0.001    |
|    n_updates              | 360      |
|    policy_objective       | 0.0402   |
|    value_loss             | 0.00161  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.18     |
|    ep_rew_mean            | 0.05     |
| time/                     |          |
|    fps                    | 691      |
|    iterations             | 362      |
|    time_elapsed           | 67       |
|    total_timesteps        | 46336    |
| train/                    |          |
|    explained_variance     | 0.0988   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00611  |
|    learning_rate          | 0.001    |
|    n_updates              | 361      |
|    policy_objective       | 0.0327   |
|    value_loss             | 0.0485   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.34     |
|    ep_rew_mean            | 0.06     |
| time/                     |          |
|    fps                    | 691      |
|    iterations             | 363      |
|    time_elapsed           | 67       |
|    total_timesteps        | 46464    |
| train/                    |          |
|    explained_variance     | 0.156    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00512  |
|    learning_rate          | 0.001    |
|    n_updates              | 362      |
|    policy_objective       | 0.0995   |
|    value_loss             | 0.0691   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.49     |
|    ep_rew_mean            | 0.07     |
| time/                     |          |
|    fps                    | 690      |
|    iterations             | 364      |
|    time_elapsed           | 67       |
|    total_timesteps        | 46592    |
| train/                    |          |
|    explained_variance     | 0.371    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00584  |
|    learning_rate          | 0.001    |
|    n_updates              | 363      |
|    policy_objective       | 0.024    |
|    value_loss             | 0.0536   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.3      |
|    ep_rew_mean            | 0.07     |
| time/                     |          |
|    fps                    | 691      |
|    iterations             | 365      |
|    time_elapsed           | 67       |
|    total_timesteps        | 46720    |
| train/                    |          |
|    explained_variance     | 0.319    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00584  |
|    learning_rate          | 0.001    |
|    n_updates              | 364      |
|    policy_objective       | 0.014    |
|    value_loss             | 0.038    |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.31     |
|    ep_rew_mean            | 0.07     |
| time/                     |          |
|    fps                    | 691      |
|    iterations             | 366      |
|    time_elapsed           | 67       |
|    total_timesteps        | 46848    |
| train/                    |          |
|    explained_variance     | -13.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0077   |
|    learning_rate          | 0.001    |
|    n_updates              | 365      |
|    policy_objective       | 0.038    |
|    value_loss             | 0.00314  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.94     |
|    ep_rew_mean            | 0.08     |
| time/                     |          |
|    fps                    | 691      |
|    iterations             | 367      |
|    time_elapsed           | 67       |
|    total_timesteps        | 46976    |
| train/                    |          |
|    explained_variance     | 0.0351   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00644  |
|    learning_rate          | 0.001    |
|    n_updates              | 366      |
|    policy_objective       | 0.031    |
|    value_loss             | 0.0288   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.79     |
|    ep_rew_mean            | 0.05     |
| time/                     |          |
|    fps                    | 691      |
|    iterations             | 368      |
|    time_elapsed           | 68       |
|    total_timesteps        | 47104    |
| train/                    |          |
|    explained_variance     | 0.191    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00608  |
|    learning_rate          | 0.001    |
|    n_updates              | 367      |
|    policy_objective       | 0.0149   |
|    value_loss             | 0.0425   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.75     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 691      |
|    iterations             | 369      |
|    time_elapsed           | 68       |
|    total_timesteps        | 47232    |
| train/                    |          |
|    explained_variance     | -7.32    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00537  |
|    learning_rate          | 0.001    |
|    n_updates              | 368      |
|    policy_objective       | 0.0282   |
|    value_loss             | 0.00543  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.01     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 691      |
|    iterations             | 370      |
|    time_elapsed           | 68       |
|    total_timesteps        | 47360    |
| train/                    |          |
|    explained_variance     | -6.89    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00415  |
|    learning_rate          | 0.001    |
|    n_updates              | 369      |
|    policy_objective       | 0.0336   |
|    value_loss             | 0.000147 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.22     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 691      |
|    iterations             | 371      |
|    time_elapsed           | 68       |
|    total_timesteps        | 47488    |
| train/                    |          |
|    explained_variance     | -24      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00101  |
|    learning_rate          | 0.001    |
|    n_updates              | 370      |
|    policy_objective       | 0.0618   |
|    value_loss             | 8.68e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.38     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 691      |
|    iterations             | 372      |
|    time_elapsed           | 68       |
|    total_timesteps        | 47616    |
| train/                    |          |
|    explained_variance     | -27.7    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00371  |
|    learning_rate          | 0.001    |
|    n_updates              | 371      |
|    policy_objective       | 0.0406   |
|    value_loss             | 0.000772 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.44     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 691      |
|    iterations             | 373      |
|    time_elapsed           | 69       |
|    total_timesteps        | 47744    |
| train/                    |          |
|    explained_variance     | -18.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00776  |
|    learning_rate          | 0.001    |
|    n_updates              | 372      |
|    policy_objective       | 0.0638   |
|    value_loss             | 4.88e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.63     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 691      |
|    iterations             | 374      |
|    time_elapsed           | 69       |
|    total_timesteps        | 47872    |
| train/                    |          |
|    explained_variance     | -58.2    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00583  |
|    learning_rate          | 0.001    |
|    n_updates              | 373      |
|    policy_objective       | 0.0252   |
|    value_loss             | 8.18e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.09     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 691      |
|    iterations             | 375      |
|    time_elapsed           | 69       |
|    total_timesteps        | 48000    |
| train/                    |          |
|    explained_variance     | -60.8    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00101  |
|    learning_rate          | 0.001    |
|    n_updates              | 374      |
|    policy_objective       | 0.0293   |
|    value_loss             | 6.24e-06 |
----------------------------------------
-----------------------------------------
| adaptive/                 |           |
|    adaptation_factor      | 1         |
|    algorithm              | TRPO      |
|    base_lr                | 0.001     |
|    base_target_kl         | 0.01      |
|    drift_magnitude        | 0         |
|    learning_rate          | 0.001     |
|    target_kl              | 0.01      |
| env/                      |           |
|    base_value             | 9.8       |
|    slip_prob              | 9.8       |
| rollout/                  |           |
|    ep_len_mean            | 8.11      |
|    ep_rew_mean            | 0.02      |
| time/                     |           |
|    fps                    | 691       |
|    iterations             | 376       |
|    time_elapsed           | 69        |
|    total_timesteps        | 48128     |
| train/                    |           |
|    explained_variance     | -0.000745 |
|    is_line_search_success | 1         |
|    kl_divergence_loss     | 0.0073    |
|    learning_rate          | 0.001     |
|    n_updates              | 375       |
|    policy_objective       | 0.03      |
|    value_loss             | 0.0748    |
-----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.45     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 691      |
|    iterations             | 377      |
|    time_elapsed           | 69       |
|    total_timesteps        | 48256    |
| train/                    |          |
|    explained_variance     | -5.42    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00497  |
|    learning_rate          | 0.001    |
|    n_updates              | 376      |
|    policy_objective       | 0.0225   |
|    value_loss             | 0.00598  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.63     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 691      |
|    iterations             | 378      |
|    time_elapsed           | 69       |
|    total_timesteps        | 48384    |
| train/                    |          |
|    explained_variance     | -9.21    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00879  |
|    learning_rate          | 0.001    |
|    n_updates              | 377      |
|    policy_objective       | 0.028    |
|    value_loss             | 0.000603 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 9        |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 691      |
|    iterations             | 379      |
|    time_elapsed           | 70       |
|    total_timesteps        | 48512    |
| train/                    |          |
|    explained_variance     | -68.7    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00612  |
|    learning_rate          | 0.001    |
|    n_updates              | 378      |
|    policy_objective       | 0.0566   |
|    value_loss             | 0.00018  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.72     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 691      |
|    iterations             | 380      |
|    time_elapsed           | 70       |
|    total_timesteps        | 48640    |
| train/                    |          |
|    explained_variance     | -10.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00789  |
|    learning_rate          | 0.001    |
|    n_updates              | 379      |
|    policy_objective       | 0.0339   |
|    value_loss             | 0.00575  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.09     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 691      |
|    iterations             | 381      |
|    time_elapsed           | 70       |
|    total_timesteps        | 48768    |
| train/                    |          |
|    explained_variance     | -3.12    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0062   |
|    learning_rate          | 0.001    |
|    n_updates              | 380      |
|    policy_objective       | 0.0386   |
|    value_loss             | 0.000163 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.8      |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 691      |
|    iterations             | 382      |
|    time_elapsed           | 70       |
|    total_timesteps        | 48896    |
| train/                    |          |
|    explained_variance     | 0.0544   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00934  |
|    learning_rate          | 0.001    |
|    n_updates              | 381      |
|    policy_objective       | 0.0538   |
|    value_loss             | 0.0345   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.84     |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 691      |
|    iterations             | 383      |
|    time_elapsed           | 70       |
|    total_timesteps        | 49024    |
| train/                    |          |
|    explained_variance     | 0.184    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00495  |
|    learning_rate          | 0.001    |
|    n_updates              | 382      |
|    policy_objective       | 0.221    |
|    value_loss             | 0.0337   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.46     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 691      |
|    iterations             | 384      |
|    time_elapsed           | 71       |
|    total_timesteps        | 49152    |
| train/                    |          |
|    explained_variance     | 0.216    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00379  |
|    learning_rate          | 0.001    |
|    n_updates              | 383      |
|    policy_objective       | 0.0179   |
|    value_loss             | 0.0397   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.25     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 691      |
|    iterations             | 385      |
|    time_elapsed           | 71       |
|    total_timesteps        | 49280    |
| train/                    |          |
|    explained_variance     | 0.169    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00926  |
|    learning_rate          | 0.001    |
|    n_updates              | 384      |
|    policy_objective       | 0.0388   |
|    value_loss             | 0.0366   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.89     |
|    ep_rew_mean            | 0.04     |
| time/                     |          |
|    fps                    | 691      |
|    iterations             | 386      |
|    time_elapsed           | 71       |
|    total_timesteps        | 49408    |
| train/                    |          |
|    explained_variance     | -34.6    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00269  |
|    learning_rate          | 0.001    |
|    n_updates              | 385      |
|    policy_objective       | 0.015    |
|    value_loss             | 0.0131   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8        |
|    ep_rew_mean            | 0.03     |
| time/                     |          |
|    fps                    | 691      |
|    iterations             | 387      |
|    time_elapsed           | 71       |
|    total_timesteps        | 49536    |
| train/                    |          |
|    explained_variance     | -4.37    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00436  |
|    learning_rate          | 0.001    |
|    n_updates              | 386      |
|    policy_objective       | 0.0361   |
|    value_loss             | 0.00039  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 8.14     |
|    ep_rew_mean            | 0.02     |
| time/                     |          |
|    fps                    | 691      |
|    iterations             | 388      |
|    time_elapsed           | 71       |
|    total_timesteps        | 49664    |
| train/                    |          |
|    explained_variance     | -24.3    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00314  |
|    learning_rate          | 0.001    |
|    n_updates              | 387      |
|    policy_objective       | 0.0357   |
|    value_loss             | 2.53e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.62     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 690      |
|    iterations             | 389      |
|    time_elapsed           | 72       |
|    total_timesteps        | 49792    |
| train/                    |          |
|    explained_variance     | -0.826   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00356  |
|    learning_rate          | 0.001    |
|    n_updates              | 388      |
|    policy_objective       | 0.0523   |
|    value_loss             | 4.57e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.26     |
|    ep_rew_mean            | 0        |
| time/                     |          |
|    fps                    | 690      |
|    iterations             | 390      |
|    time_elapsed           | 72       |
|    total_timesteps        | 49920    |
| train/                    |          |
|    explained_variance     | -205     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00444  |
|    learning_rate          | 0.001    |
|    n_updates              | 389      |
|    policy_objective       | 0.0782   |
|    value_loss             | 7.04e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.001    |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.001    |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    slip_prob              | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 7.06     |
|    ep_rew_mean            | 0.01     |
| time/                     |          |
|    fps                    | 690      |
|    iterations             | 391      |
|    time_elapsed           | 72       |
|    total_timesteps        | 50048    |
| train/                    |          |
|    explained_variance     | -58.1    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00644  |
|    learning_rate          | 0.001    |
|    n_updates              | 390      |
|    policy_objective       | 0.0554   |
|    value_loss             | 0.000845 |
----------------------------------------
wandb: WARNING Symlinked 1 file into the W&B run directory; call wandb.save again to sync new files.
wandb: updating run metadata
wandb: uploading model.zip; uploading output.log; uploading wandb-summary.json
wandb: uploading model.zip; uploading output.log; uploading config.yaml; uploading logs/FrozenLake_4x4_slip_prob_sine_Adaptive_20251218_002919_0/events.out.tfevents.1765992804.hungchan-Precision-7560.438509.0
wandb: uploading output.log; uploading logs/FrozenLake_4x4_slip_prob_sine_Adaptive_20251218_002919_0/events.out.tfevents.1765992804.hungchan-Precision-7560.438509.0
wandb: uploading history steps 5026-6640, summary, console lines 9259-11351
wandb: uploading data
wandb: 
wandb: Run history:
wandb: adaptive/adaptation_factor â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:           adaptive/base_lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    adaptive/base_target_kl â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:   adaptive/drift_magnitude â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:     adaptive/learning_rate â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         adaptive/target_kl â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:             env/base_value â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:              env/slip_prob â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                global_step â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:        rollout/ep_len_mean â–ƒâ–â–…â–ƒâ–ƒâ–…â–‡â–†â–…â–‚â–‚â–ˆâ–„â–ƒâ–…â–„â–†â–â–„â–…â–ƒâ–‚â–ƒâ–‚â–ƒâ–„â–„â–…â–„â–‡â–â–‚â–â–ƒâ–…â–…â–„â–…â–ˆâ–‚
wandb:                         +8 ...
wandb: 
wandb: Run summary:
wandb: adaptive/adaptation_factor 1
wandb:           adaptive/base_lr 0.001
wandb:    adaptive/base_target_kl 0.01
wandb:   adaptive/drift_magnitude 0
wandb:     adaptive/learning_rate 0.001
wandb:         adaptive/target_kl 0.01
wandb:             env/base_value 9.8
wandb:              env/slip_prob 9.8
wandb:                global_step 50048
wandb:        rollout/ep_len_mean 7.06
wandb:                         +8 ...
wandb: 
wandb: ðŸš€ View run FrozenLake_4x4_slip_prob_sine_Adaptive_20251218_002919 at: https://wandb.ai/hungtrab-hanoi-university-of-science-and-technology/FrozenLake_Drift_Research/runs/y7pdblx6
wandb: â­ï¸ View project at: https://wandb.ai/hungtrab-hanoi-university-of-science-and-technology/FrozenLake_Drift_Research
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)
wandb: Find logs at: logs/FrozenLake_4x4_slip_prob_sine_Adaptive_20251218_002919/wandb/run-20251218_003322-y7pdblx6/logs
>>> [DriftAdaptiveCallback] Training Ended
    Final LR: 0.001000
    Last Drift Magnitude: 0.0000
    Final Target KL: 0.0100
Model saved locally to: models/FrozenLake_4x4_slip_prob_sine_Adaptive_20251218_002919.zip
/home/hungchan/miniconda3/envs/rl_hf_course/lib/python3.10/site-packages/gymnasium/wrappers/rendering.py:293: UserWarning: [33mWARN: Overwriting existing videos at /home/hungchan/Work/Deep-RL/videos/FrozenLake_4x4_slip_prob_sine_Adaptive_20251218_002919 folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)[0m
  logger.warn(
/home/hungchan/miniconda3/envs/rl_hf_course/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run TRPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.
  warnings.warn(
>>> [Wrapper] Initialized Non-Stationary FrozenLake
    - slip_prob: sine (base=0.67)
Loading TRPO model from: models/FrozenLake_4x4_slip_prob_sine_Adaptive_20251218_002919.zip

Recording Episode 1/1...
Traceback (most recent call last):
  File "/home/hungchan/Work/Deep-RL/scripts/render.py", line 179, in <module>
    main()
  File "/home/hungchan/Work/Deep-RL/scripts/render.py", line 168, in main
    record_video(
  File "/home/hungchan/Work/Deep-RL/scripts/render.py", line 137, in record_video
    obs, reward, done, truncated, info = env.step(action)
  File "/home/hungchan/miniconda3/envs/rl_hf_course/lib/python3.10/site-packages/gymnasium/wrappers/rendering.py", line 363, in step
    obs, rew, terminated, truncated, info = self.env.step(action)
  File "/home/hungchan/Work/Deep-RL/scripts/../src/envs/multi_env_wrappers.py", line 378, in step
    obs, reward, terminated, truncated, info = self.env.step(action)
  File "/home/hungchan/miniconda3/envs/rl_hf_course/lib/python3.10/site-packages/gymnasium/wrappers/common.py", line 125, in step
    observation, reward, terminated, truncated, info = self.env.step(action)
  File "/home/hungchan/miniconda3/envs/rl_hf_course/lib/python3.10/site-packages/gymnasium/wrappers/common.py", line 393, in step
    return super().step(action)
  File "/home/hungchan/miniconda3/envs/rl_hf_course/lib/python3.10/site-packages/gymnasium/core.py", line 327, in step
    return self.env.step(action)
  File "/home/hungchan/miniconda3/envs/rl_hf_course/lib/python3.10/site-packages/gymnasium/wrappers/common.py", line 285, in step
    return self.env.step(action)
  File "/home/hungchan/miniconda3/envs/rl_hf_course/lib/python3.10/site-packages/gymnasium/envs/toy_text/frozen_lake.py", line 325, in step
    transitions = self.P[self.s][a]
TypeError: unhashable type: 'numpy.ndarray'
/home/hungchan/miniconda3/envs/rl_hf_course/lib/python3.10/site-packages/gymnasium/wrappers/rendering.py:434: UserWarning: [33mWARN: Unable to save last video! Did you call close()?[0m
  logger.warn("Unable to save last video! Did you call close()?")
