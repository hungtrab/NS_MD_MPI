wandb: Currently logged in as: hungtrab (hungtrab-hanoi-university-of-science-and-technology) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: setting up run vw3eksd9
wandb: Tracking run with wandb version 0.23.1
wandb: Run data is saved locally in logs/CartPole_length_linear_Adaptive_20251217_125255/wandb/run-20251217_130417-vw3eksd9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run CartPole_length_linear_Adaptive_20251217_125255
wandb: â­ï¸ View project at https://wandb.ai/hungtrab-hanoi-university-of-science-and-technology/CartPole_Drift_Research_TRPO
wandb: ðŸš€ View run at https://wandb.ai/hungtrab-hanoi-university-of-science-and-technology/CartPole_Drift_Research_TRPO/runs/vw3eksd9
/home/hungchan/miniconda3/envs/rl_hf_course/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run TRPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.
  warnings.warn(
--- Training Start: CartPole_length_linear_Adaptive_20251217_125255 ---
>>> [Wrapper] Initialized Non-Stationary CartPole
    - length: linear (magnitude=0.3, period=25000)
>>> Initializing TRPO with kwargs: ['policy', 'env', 'learning_rate', 'gamma', 'verbose', 'tensorboard_log', 'n_steps', 'batch_size']
Using cuda device
Wrapping the env in a DummyVecEnv.
Logging to logs/CartPole_length_linear_Adaptive_20251217_125255_0
>>> [DriftAdaptiveCallback] Training Started
    Algorithm: TRPO
    Target Param: length (base=0.5)
    Scale Factor: 0.1
    
    Adaptive Hyperparameters:
      - Learning Rate: 0.000300
      - Target KL: 0.0100 (adapt=True)
-----------------------------------
| adaptive/            |          |
|    adaptation_factor | 1        |
|    algorithm         | TRPO     |
|    base_lr           | 0.0003   |
|    base_target_kl    | 0.01     |
|    drift_magnitude   | 0.048    |
|    learning_rate     | 0.000301 |
|    target_kl         | 0.00995  |
| env/                 |          |
|    base_value        | 0.5      |
|    length            | 0.524    |
| rollout/             |          |
|    ep_len_mean       | 20.4     |
|    ep_rew_mean       | 20.4     |
| time/                |          |
|    fps               | 1366     |
|    iterations        | 1        |
|    time_elapsed      | 1        |
|    total_timesteps   | 2048     |
-----------------------------------
-----------------------------------------
| adaptive/                 |           |
|    adaptation_factor      | 1.01      |
|    algorithm              | TRPO      |
|    base_lr                | 0.0003    |
|    base_target_kl         | 0.01      |
|    drift_magnitude        | 0.096     |
|    learning_rate          | 0.000303  |
|    target_kl              | 0.0099    |
| env/                      |           |
|    base_value             | 0.5       |
|    length                 | 0.548     |
| rollout/                  |           |
|    ep_len_mean            | 27.2      |
|    ep_rew_mean            | 27.2      |
| time/                     |           |
|    fps                    | 1292      |
|    iterations             | 2         |
|    time_elapsed           | 3         |
|    total_timesteps        | 4096      |
| train/                    |           |
|    explained_variance     | -0.000366 |
|    is_line_search_success | 1         |
|    kl_divergence_loss     | 0.00862   |
|    learning_rate          | 0.0003    |
|    n_updates              | 1         |
|    policy_objective       | 0.0211    |
|    value_loss             | 43.7      |
-----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.01     |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.146    |
|    learning_rate          | 0.000304 |
|    target_kl              | 0.00986  |
| env/                      |          |
|    base_value             | 0.5      |
|    length                 | 0.573    |
| rollout/                  |          |
|    ep_len_mean            | 35.2     |
|    ep_rew_mean            | 35.2     |
| time/                     |          |
|    fps                    | 1271     |
|    iterations             | 3        |
|    time_elapsed           | 4        |
|    total_timesteps        | 6144     |
| train/                    |          |
|    explained_variance     | 0.0634   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00786  |
|    learning_rate          | 0.0003   |
|    n_updates              | 2        |
|    policy_objective       | 0.0203   |
|    value_loss             | 34.7     |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.02     |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.194    |
|    learning_rate          | 0.000306 |
|    target_kl              | 0.00981  |
| env/                      |          |
|    base_value             | 0.5      |
|    length                 | 0.597    |
| rollout/                  |          |
|    ep_len_mean            | 43.1     |
|    ep_rew_mean            | 43.1     |
| time/                     |          |
|    fps                    | 1267     |
|    iterations             | 4        |
|    time_elapsed           | 6        |
|    total_timesteps        | 8192     |
| train/                    |          |
|    explained_variance     | 0.178    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0069   |
|    learning_rate          | 0.0003   |
|    n_updates              | 3        |
|    policy_objective       | 0.0232   |
|    value_loss             | 46.6     |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.02     |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.245    |
|    learning_rate          | 0.000307 |
|    target_kl              | 0.00976  |
| env/                      |          |
|    base_value             | 0.5      |
|    length                 | 0.622    |
| rollout/                  |          |
|    ep_len_mean            | 56.8     |
|    ep_rew_mean            | 56.8     |
| time/                     |          |
|    fps                    | 1257     |
|    iterations             | 5        |
|    time_elapsed           | 8        |
|    total_timesteps        | 10240    |
| train/                    |          |
|    explained_variance     | 0.186    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00741  |
|    learning_rate          | 0.0003   |
|    n_updates              | 4        |
|    policy_objective       | 0.0258   |
|    value_loss             | 70.7     |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.03     |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.293    |
|    learning_rate          | 0.000309 |
|    target_kl              | 0.00972  |
| env/                      |          |
|    base_value             | 0.5      |
|    length                 | 0.646    |
| rollout/                  |          |
|    ep_len_mean            | 68       |
|    ep_rew_mean            | 68       |
| time/                     |          |
|    fps                    | 1264     |
|    iterations             | 6        |
|    time_elapsed           | 9        |
|    total_timesteps        | 12288    |
| train/                    |          |
|    explained_variance     | 0.166    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00671  |
|    learning_rate          | 0.0003   |
|    n_updates              | 5        |
|    policy_objective       | 0.0159   |
|    value_loss             | 65.8     |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.06     |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.557    |
|    learning_rate          | 0.000317 |
|    target_kl              | 0.00947  |
| env/                      |          |
|    base_value             | 0.5      |
|    length                 | 0.778    |
| rollout/                  |          |
|    ep_len_mean            | 83.3     |
|    ep_rew_mean            | 83.3     |
| time/                     |          |
|    fps                    | 1262     |
|    iterations             | 7        |
|    time_elapsed           | 11       |
|    total_timesteps        | 14336    |
| train/                    |          |
|    explained_variance     | 0.536    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0071   |
|    learning_rate          | 0.0003   |
|    n_updates              | 6        |
|    policy_objective       | 0.0139   |
|    value_loss             | 60.5     |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.05     |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.509    |
|    learning_rate          | 0.000315 |
|    target_kl              | 0.00952  |
| env/                      |          |
|    base_value             | 0.5      |
|    length                 | 0.754    |
| rollout/                  |          |
|    ep_len_mean            | 98.2     |
|    ep_rew_mean            | 98.2     |
| time/                     |          |
|    fps                    | 1256     |
|    iterations             | 8        |
|    time_elapsed           | 13       |
|    total_timesteps        | 16384    |
| train/                    |          |
|    explained_variance     | 0.588    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00573  |
|    learning_rate          | 0.0003   |
|    n_updates              | 7        |
|    policy_objective       | 0.00932  |
|    value_loss             | 57.4     |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.05     |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.458    |
|    learning_rate          | 0.000314 |
|    target_kl              | 0.00956  |
| env/                      |          |
|    base_value             | 0.5      |
|    length                 | 0.729    |
| rollout/                  |          |
|    ep_len_mean            | 116      |
|    ep_rew_mean            | 116      |
| time/                     |          |
|    fps                    | 1242     |
|    iterations             | 9        |
|    time_elapsed           | 14       |
|    total_timesteps        | 18432    |
| train/                    |          |
|    explained_variance     | 0.459    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00234  |
|    learning_rate          | 0.0003   |
|    n_updates              | 8        |
|    policy_objective       | 0.00876  |
|    value_loss             | 53.2     |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.04     |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.41     |
|    learning_rate          | 0.000312 |
|    target_kl              | 0.00961  |
| env/                      |          |
|    base_value             | 0.5      |
|    length                 | 0.705    |
| rollout/                  |          |
|    ep_len_mean            | 133      |
|    ep_rew_mean            | 133      |
| time/                     |          |
|    fps                    | 1231     |
|    iterations             | 10       |
|    time_elapsed           | 16       |
|    total_timesteps        | 20480    |
| train/                    |          |
|    explained_variance     | 0.806    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00748  |
|    learning_rate          | 0.0003   |
|    n_updates              | 9        |
|    policy_objective       | 0.0196   |
|    value_loss             | 27       |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.04     |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.36     |
|    learning_rate          | 0.000311 |
|    target_kl              | 0.00965  |
| env/                      |          |
|    base_value             | 0.5      |
|    length                 | 0.68     |
| rollout/                  |          |
|    ep_len_mean            | 150      |
|    ep_rew_mean            | 150      |
| time/                     |          |
|    fps                    | 1217     |
|    iterations             | 11       |
|    time_elapsed           | 18       |
|    total_timesteps        | 22528    |
| train/                    |          |
|    explained_variance     | 0.935    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00711  |
|    learning_rate          | 0.0003   |
|    n_updates              | 10       |
|    policy_objective       | 0.017    |
|    value_loss             | 13.6     |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.03     |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.312    |
|    learning_rate          | 0.000309 |
|    target_kl              | 0.0097   |
| env/                      |          |
|    base_value             | 0.5      |
|    length                 | 0.656    |
| rollout/                  |          |
|    ep_len_mean            | 167      |
|    ep_rew_mean            | 167      |
| time/                     |          |
|    fps                    | 1213     |
|    iterations             | 12       |
|    time_elapsed           | 20       |
|    total_timesteps        | 24576    |
| train/                    |          |
|    explained_variance     | 0.907    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00604  |
|    learning_rate          | 0.0003   |
|    n_updates              | 11       |
|    policy_objective       | 0.0103   |
|    value_loss             | 10.4     |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.0384   |
|    learning_rate          | 0.000301 |
|    target_kl              | 0.00996  |
| env/                      |          |
|    base_value             | 0.5      |
|    length                 | 0.519    |
| rollout/                  |          |
|    ep_len_mean            | 190      |
|    ep_rew_mean            | 190      |
| time/                     |          |
|    fps                    | 1218     |
|    iterations             | 13       |
|    time_elapsed           | 21       |
|    total_timesteps        | 26624    |
| train/                    |          |
|    explained_variance     | 0.938    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00747  |
|    learning_rate          | 0.0003   |
|    n_updates              | 12       |
|    policy_objective       | 0.025    |
|    value_loss             | 7.21     |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.01     |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.0864   |
|    learning_rate          | 0.000303 |
|    target_kl              | 0.00991  |
| env/                      |          |
|    base_value             | 0.5      |
|    length                 | 0.543    |
| rollout/                  |          |
|    ep_len_mean            | 205      |
|    ep_rew_mean            | 205      |
| time/                     |          |
|    fps                    | 1217     |
|    iterations             | 14       |
|    time_elapsed           | 23       |
|    total_timesteps        | 28672    |
| train/                    |          |
|    explained_variance     | 0.205    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00932  |
|    learning_rate          | 0.0003   |
|    n_updates              | 13       |
|    policy_objective       | 0.00711  |
|    value_loss             | 4.66     |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.01     |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.137    |
|    learning_rate          | 0.000304 |
|    target_kl              | 0.00987  |
| env/                      |          |
|    base_value             | 0.5      |
|    length                 | 0.568    |
| rollout/                  |          |
|    ep_len_mean            | 225      |
|    ep_rew_mean            | 225      |
| time/                     |          |
|    fps                    | 1215     |
|    iterations             | 15       |
|    time_elapsed           | 25       |
|    total_timesteps        | 30720    |
| train/                    |          |
|    explained_variance     | 0.00597  |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.008    |
|    learning_rate          | 0.0003   |
|    n_updates              | 14       |
|    policy_objective       | 0.0194   |
|    value_loss             | 67.8     |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.02     |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.185    |
|    learning_rate          | 0.000306 |
|    target_kl              | 0.00982  |
| env/                      |          |
|    base_value             | 0.5      |
|    length                 | 0.592    |
| rollout/                  |          |
|    ep_len_mean            | 245      |
|    ep_rew_mean            | 245      |
| time/                     |          |
|    fps                    | 1204     |
|    iterations             | 16       |
|    time_elapsed           | 27       |
|    total_timesteps        | 32768    |
| train/                    |          |
|    explained_variance     | 0.958    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00836  |
|    learning_rate          | 0.0003   |
|    n_updates              | 15       |
|    policy_objective       | 0.00915  |
|    value_loss             | 7        |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.02     |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.235    |
|    learning_rate          | 0.000307 |
|    target_kl              | 0.00977  |
| env/                      |          |
|    base_value             | 0.5      |
|    length                 | 0.618    |
| rollout/                  |          |
|    ep_len_mean            | 260      |
|    ep_rew_mean            | 260      |
| time/                     |          |
|    fps                    | 1200     |
|    iterations             | 17       |
|    time_elapsed           | 28       |
|    total_timesteps        | 34816    |
| train/                    |          |
|    explained_variance     | 0.421    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00915  |
|    learning_rate          | 0.0003   |
|    n_updates              | 16       |
|    policy_objective       | 0.0245   |
|    value_loss             | 2.26     |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.03     |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.283    |
|    learning_rate          | 0.000308 |
|    target_kl              | 0.00972  |
| env/                      |          |
|    base_value             | 0.5      |
|    length                 | 0.642    |
| rollout/                  |          |
|    ep_len_mean            | 277      |
|    ep_rew_mean            | 277      |
| time/                     |          |
|    fps                    | 1200     |
|    iterations             | 18       |
|    time_elapsed           | 30       |
|    total_timesteps        | 36864    |
| train/                    |          |
|    explained_variance     | 0.218    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00734  |
|    learning_rate          | 0.0003   |
|    n_updates              | 17       |
|    policy_objective       | 0.0032   |
|    value_loss             | 1.09     |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.06     |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.566    |
|    learning_rate          | 0.000317 |
|    target_kl              | 0.00946  |
| env/                      |          |
|    base_value             | 0.5      |
|    length                 | 0.783    |
| rollout/                  |          |
|    ep_len_mean            | 291      |
|    ep_rew_mean            | 291      |
| time/                     |          |
|    fps                    | 1198     |
|    iterations             | 19       |
|    time_elapsed           | 32       |
|    total_timesteps        | 38912    |
| train/                    |          |
|    explained_variance     | 0.106    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00872  |
|    learning_rate          | 0.0003   |
|    n_updates              | 18       |
|    policy_objective       | 0.00687  |
|    value_loss             | 0.713    |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.05     |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.518    |
|    learning_rate          | 0.000316 |
|    target_kl              | 0.00951  |
| env/                      |          |
|    base_value             | 0.5      |
|    length                 | 0.759    |
| rollout/                  |          |
|    ep_len_mean            | 307      |
|    ep_rew_mean            | 307      |
| time/                     |          |
|    fps                    | 1190     |
|    iterations             | 20       |
|    time_elapsed           | 34       |
|    total_timesteps        | 40960    |
| train/                    |          |
|    explained_variance     | 0.308    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00592  |
|    learning_rate          | 0.0003   |
|    n_updates              | 19       |
|    policy_objective       | 0.0029   |
|    value_loss             | 0.553    |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.05     |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.468    |
|    learning_rate          | 0.000314 |
|    target_kl              | 0.00955  |
| env/                      |          |
|    base_value             | 0.5      |
|    length                 | 0.734    |
| rollout/                  |          |
|    ep_len_mean            | 322      |
|    ep_rew_mean            | 322      |
| time/                     |          |
|    fps                    | 1184     |
|    iterations             | 21       |
|    time_elapsed           | 36       |
|    total_timesteps        | 43008    |
| train/                    |          |
|    explained_variance     | 0.131    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0086   |
|    learning_rate          | 0.0003   |
|    n_updates              | 20       |
|    policy_objective       | 0.00664  |
|    value_loss             | 0.295    |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.04     |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.42     |
|    learning_rate          | 0.000313 |
|    target_kl              | 0.0096   |
| env/                      |          |
|    base_value             | 0.5      |
|    length                 | 0.71     |
| rollout/                  |          |
|    ep_len_mean            | 339      |
|    ep_rew_mean            | 339      |
| time/                     |          |
|    fps                    | 1178     |
|    iterations             | 22       |
|    time_elapsed           | 38       |
|    total_timesteps        | 45056    |
| train/                    |          |
|    explained_variance     | 0.0051   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00761  |
|    learning_rate          | 0.0003   |
|    n_updates              | 21       |
|    policy_objective       | 0.0129   |
|    value_loss             | 30       |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.04     |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.37     |
|    learning_rate          | 0.000311 |
|    target_kl              | 0.00964  |
| env/                      |          |
|    base_value             | 0.5      |
|    length                 | 0.685    |
| rollout/                  |          |
|    ep_len_mean            | 359      |
|    ep_rew_mean            | 359      |
| time/                     |          |
|    fps                    | 1171     |
|    iterations             | 23       |
|    time_elapsed           | 40       |
|    total_timesteps        | 47104    |
| train/                    |          |
|    explained_variance     | -2.46    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00801  |
|    learning_rate          | 0.0003   |
|    n_updates              | 22       |
|    policy_objective       | 0.0105   |
|    value_loss             | 0.251    |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.03     |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.322    |
|    learning_rate          | 0.00031  |
|    target_kl              | 0.00969  |
| env/                      |          |
|    base_value             | 0.5      |
|    length                 | 0.661    |
| rollout/                  |          |
|    ep_len_mean            | 374      |
|    ep_rew_mean            | 374      |
| time/                     |          |
|    fps                    | 1170     |
|    iterations             | 24       |
|    time_elapsed           | 41       |
|    total_timesteps        | 49152    |
| train/                    |          |
|    explained_variance     | 0.32     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00793  |
|    learning_rate          | 0.0003   |
|    n_updates              | 23       |
|    policy_objective       | 0.0041   |
|    value_loss             | 0.376    |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.0288   |
|    learning_rate          | 0.000301 |
|    target_kl              | 0.00997  |
| env/                      |          |
|    base_value             | 0.5      |
|    length                 | 0.514    |
| rollout/                  |          |
|    ep_len_mean            | 389      |
|    ep_rew_mean            | 389      |
| time/                     |          |
|    fps                    | 1173     |
|    iterations             | 25       |
|    time_elapsed           | 43       |
|    total_timesteps        | 51200    |
| train/                    |          |
|    explained_variance     | 0.976    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00758  |
|    learning_rate          | 0.0003   |
|    n_updates              | 24       |
|    policy_objective       | 0.00591  |
|    value_loss             | 0.322    |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.01     |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.0768   |
|    learning_rate          | 0.000302 |
|    target_kl              | 0.00992  |
| env/                      |          |
|    base_value             | 0.5      |
|    length                 | 0.538    |
| rollout/                  |          |
|    ep_len_mean            | 402      |
|    ep_rew_mean            | 402      |
| time/                     |          |
|    fps                    | 1171     |
|    iterations             | 26       |
|    time_elapsed           | 45       |
|    total_timesteps        | 53248    |
| train/                    |          |
|    explained_variance     | 0.682    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00882  |
|    learning_rate          | 0.0003   |
|    n_updates              | 25       |
|    policy_objective       | 0.00819  |
|    value_loss             | 0.0838   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.01     |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.125    |
|    learning_rate          | 0.000304 |
|    target_kl              | 0.00988  |
| env/                      |          |
|    base_value             | 0.5      |
|    length                 | 0.562    |
| rollout/                  |          |
|    ep_len_mean            | 416      |
|    ep_rew_mean            | 416      |
| time/                     |          |
|    fps                    | 1171     |
|    iterations             | 27       |
|    time_elapsed           | 47       |
|    total_timesteps        | 55296    |
| train/                    |          |
|    explained_variance     | -0.0777  |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00822  |
|    learning_rate          | 0.0003   |
|    n_updates              | 26       |
|    policy_objective       | 0.0034   |
|    value_loss             | 0.0259   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.02     |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.175    |
|    learning_rate          | 0.000305 |
|    target_kl              | 0.00983  |
| env/                      |          |
|    base_value             | 0.5      |
|    length                 | 0.588    |
| rollout/                  |          |
|    ep_len_mean            | 430      |
|    ep_rew_mean            | 430      |
| time/                     |          |
|    fps                    | 1174     |
|    iterations             | 28       |
|    time_elapsed           | 48       |
|    total_timesteps        | 57344    |
| train/                    |          |
|    explained_variance     | -0.368   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00963  |
|    learning_rate          | 0.0003   |
|    n_updates              | 27       |
|    policy_objective       | 0.0113   |
|    value_loss             | 0.0202   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.02     |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.223    |
|    learning_rate          | 0.000307 |
|    target_kl              | 0.00978  |
| env/                      |          |
|    base_value             | 0.5      |
|    length                 | 0.612    |
| rollout/                  |          |
|    ep_len_mean            | 441      |
|    ep_rew_mean            | 441      |
| time/                     |          |
|    fps                    | 1176     |
|    iterations             | 29       |
|    time_elapsed           | 50       |
|    total_timesteps        | 59392    |
| train/                    |          |
|    explained_variance     | -0.193   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00941  |
|    learning_rate          | 0.0003   |
|    n_updates              | 28       |
|    policy_objective       | 0.00513  |
|    value_loss             | 0.0104   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.03     |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.274    |
|    learning_rate          | 0.000308 |
|    target_kl              | 0.00973  |
| env/                      |          |
|    base_value             | 0.5      |
|    length                 | 0.637    |
| rollout/                  |          |
|    ep_len_mean            | 453      |
|    ep_rew_mean            | 453      |
| time/                     |          |
|    fps                    | 1177     |
|    iterations             | 30       |
|    time_elapsed           | 52       |
|    total_timesteps        | 61440    |
| train/                    |          |
|    explained_variance     | 0.357    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00733  |
|    learning_rate          | 0.0003   |
|    n_updates              | 29       |
|    policy_objective       | 0.00636  |
|    value_loss             | 0.0104   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.06     |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.578    |
|    learning_rate          | 0.000317 |
|    target_kl              | 0.00945  |
| env/                      |          |
|    base_value             | 0.5      |
|    length                 | 0.789    |
| rollout/                  |          |
|    ep_len_mean            | 464      |
|    ep_rew_mean            | 464      |
| time/                     |          |
|    fps                    | 1177     |
|    iterations             | 31       |
|    time_elapsed           | 53       |
|    total_timesteps        | 63488    |
| train/                    |          |
|    explained_variance     | 0.055    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00814  |
|    learning_rate          | 0.0003   |
|    n_updates              | 30       |
|    policy_objective       | 0.00637  |
|    value_loss             | 0.00426  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.05     |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.528    |
|    learning_rate          | 0.000316 |
|    target_kl              | 0.0095   |
| env/                      |          |
|    base_value             | 0.5      |
|    length                 | 0.764    |
| rollout/                  |          |
|    ep_len_mean            | 474      |
|    ep_rew_mean            | 474      |
| time/                     |          |
|    fps                    | 1175     |
|    iterations             | 32       |
|    time_elapsed           | 55       |
|    total_timesteps        | 65536    |
| train/                    |          |
|    explained_variance     | 0.232    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00816  |
|    learning_rate          | 0.0003   |
|    n_updates              | 31       |
|    policy_objective       | 0.00718  |
|    value_loss             | 0.00334  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.05     |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.48     |
|    learning_rate          | 0.000314 |
|    target_kl              | 0.00954  |
| env/                      |          |
|    base_value             | 0.5      |
|    length                 | 0.74     |
| rollout/                  |          |
|    ep_len_mean            | 484      |
|    ep_rew_mean            | 484      |
| time/                     |          |
|    fps                    | 1176     |
|    iterations             | 33       |
|    time_elapsed           | 57       |
|    total_timesteps        | 67584    |
| train/                    |          |
|    explained_variance     | -0.201   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00649  |
|    learning_rate          | 0.0003   |
|    n_updates              | 32       |
|    policy_objective       | 0.00964  |
|    value_loss             | 0.00244  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.04     |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.43     |
|    learning_rate          | 0.000313 |
|    target_kl              | 0.00959  |
| env/                      |          |
|    base_value             | 0.5      |
|    length                 | 0.715    |
| rollout/                  |          |
|    ep_len_mean            | 489      |
|    ep_rew_mean            | 489      |
| time/                     |          |
|    fps                    | 1178     |
|    iterations             | 34       |
|    time_elapsed           | 59       |
|    total_timesteps        | 69632    |
| train/                    |          |
|    explained_variance     | -0.0465  |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00545  |
|    learning_rate          | 0.0003   |
|    n_updates              | 33       |
|    policy_objective       | 0.00525  |
|    value_loss             | 0.0015   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.04     |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.382    |
|    learning_rate          | 0.000311 |
|    target_kl              | 0.00963  |
| env/                      |          |
|    base_value             | 0.5      |
|    length                 | 0.691    |
| rollout/                  |          |
|    ep_len_mean            | 494      |
|    ep_rew_mean            | 494      |
| time/                     |          |
|    fps                    | 1179     |
|    iterations             | 35       |
|    time_elapsed           | 60       |
|    total_timesteps        | 71680    |
| train/                    |          |
|    explained_variance     | 0.0772   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00909  |
|    learning_rate          | 0.0003   |
|    n_updates              | 34       |
|    policy_objective       | 0.0104   |
|    value_loss             | 0.000963 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.03     |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.331    |
|    learning_rate          | 0.00031  |
|    target_kl              | 0.00968  |
| env/                      |          |
|    base_value             | 0.5      |
|    length                 | 0.666    |
| rollout/                  |          |
|    ep_len_mean            | 495      |
|    ep_rew_mean            | 495      |
| time/                     |          |
|    fps                    | 1181     |
|    iterations             | 36       |
|    time_elapsed           | 62       |
|    total_timesteps        | 73728    |
| train/                    |          |
|    explained_variance     | -0.112   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00805  |
|    learning_rate          | 0.0003   |
|    n_updates              | 35       |
|    policy_objective       | 0.00644  |
|    value_loss             | 0.000602 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.0168   |
|    learning_rate          | 0.000301 |
|    target_kl              | 0.00998  |
| env/                      |          |
|    base_value             | 0.5      |
|    length                 | 0.508    |
| rollout/                  |          |
|    ep_len_mean            | 495      |
|    ep_rew_mean            | 495      |
| time/                     |          |
|    fps                    | 1183     |
|    iterations             | 37       |
|    time_elapsed           | 64       |
|    total_timesteps        | 75776    |
| train/                    |          |
|    explained_variance     | 0.703    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00708  |
|    learning_rate          | 0.0003   |
|    n_updates              | 36       |
|    policy_objective       | 0.00835  |
|    value_loss             | 0.00064  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.01     |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.0672   |
|    learning_rate          | 0.000302 |
|    target_kl              | 0.00993  |
| env/                      |          |
|    base_value             | 0.5      |
|    length                 | 0.534    |
| rollout/                  |          |
|    ep_len_mean            | 495      |
|    ep_rew_mean            | 495      |
| time/                     |          |
|    fps                    | 1180     |
|    iterations             | 38       |
|    time_elapsed           | 65       |
|    total_timesteps        | 77824    |
| train/                    |          |
|    explained_variance     | 0.118    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00907  |
|    learning_rate          | 0.0003   |
|    n_updates              | 37       |
|    policy_objective       | 0.00481  |
|    value_loss             | 0.000367 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.01     |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.115    |
|    learning_rate          | 0.000303 |
|    target_kl              | 0.00989  |
| env/                      |          |
|    base_value             | 0.5      |
|    length                 | 0.558    |
| rollout/                  |          |
|    ep_len_mean            | 499      |
|    ep_rew_mean            | 499      |
| time/                     |          |
|    fps                    | 1180     |
|    iterations             | 39       |
|    time_elapsed           | 67       |
|    total_timesteps        | 79872    |
| train/                    |          |
|    explained_variance     | -0.512   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00563  |
|    learning_rate          | 0.0003   |
|    n_updates              | 38       |
|    policy_objective       | 0.00647  |
|    value_loss             | 0.000272 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.02     |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.166    |
|    learning_rate          | 0.000305 |
|    target_kl              | 0.00984  |
| env/                      |          |
|    base_value             | 0.5      |
|    length                 | 0.583    |
| rollout/                  |          |
|    ep_len_mean            | 499      |
|    ep_rew_mean            | 499      |
| time/                     |          |
|    fps                    | 1181     |
|    iterations             | 40       |
|    time_elapsed           | 69       |
|    total_timesteps        | 81920    |
| train/                    |          |
|    explained_variance     | -0.644   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0067   |
|    learning_rate          | 0.0003   |
|    n_updates              | 39       |
|    policy_objective       | 0.00227  |
|    value_loss             | 0.000196 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.02     |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.214    |
|    learning_rate          | 0.000306 |
|    target_kl              | 0.00979  |
| env/                      |          |
|    base_value             | 0.5      |
|    length                 | 0.607    |
| rollout/                  |          |
|    ep_len_mean            | 499      |
|    ep_rew_mean            | 499      |
| time/                     |          |
|    fps                    | 1182     |
|    iterations             | 41       |
|    time_elapsed           | 70       |
|    total_timesteps        | 83968    |
| train/                    |          |
|    explained_variance     | -0.508   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00633  |
|    learning_rate          | 0.0003   |
|    n_updates              | 40       |
|    policy_objective       | 0.00357  |
|    value_loss             | 0.00021  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.03     |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.264    |
|    learning_rate          | 0.000308 |
|    target_kl              | 0.00974  |
| env/                      |          |
|    base_value             | 0.5      |
|    length                 | 0.632    |
| rollout/                  |          |
|    ep_len_mean            | 499      |
|    ep_rew_mean            | 499      |
| time/                     |          |
|    fps                    | 1182     |
|    iterations             | 42       |
|    time_elapsed           | 72       |
|    total_timesteps        | 86016    |
| train/                    |          |
|    explained_variance     | 0.27     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00602  |
|    learning_rate          | 0.0003   |
|    n_updates              | 41       |
|    policy_objective       | 0.0091   |
|    value_loss             | 0.00016  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.06     |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.588    |
|    learning_rate          | 0.000318 |
|    target_kl              | 0.00944  |
| env/                      |          |
|    base_value             | 0.5      |
|    length                 | 0.794    |
| rollout/                  |          |
|    ep_len_mean            | 499      |
|    ep_rew_mean            | 499      |
| time/                     |          |
|    fps                    | 1181     |
|    iterations             | 43       |
|    time_elapsed           | 74       |
|    total_timesteps        | 88064    |
| train/                    |          |
|    explained_variance     | -0.593   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00652  |
|    learning_rate          | 0.0003   |
|    n_updates              | 42       |
|    policy_objective       | 0.00701  |
|    value_loss             | 6.04e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.05     |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.538    |
|    learning_rate          | 0.000316 |
|    target_kl              | 0.00949  |
| env/                      |          |
|    base_value             | 0.5      |
|    length                 | 0.769    |
| rollout/                  |          |
|    ep_len_mean            | 499      |
|    ep_rew_mean            | 499      |
| time/                     |          |
|    fps                    | 1180     |
|    iterations             | 44       |
|    time_elapsed           | 76       |
|    total_timesteps        | 90112    |
| train/                    |          |
|    explained_variance     | 0.0206   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00856  |
|    learning_rate          | 0.0003   |
|    n_updates              | 43       |
|    policy_objective       | 0.00497  |
|    value_loss             | 7.69e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.05     |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.49     |
|    learning_rate          | 0.000315 |
|    target_kl              | 0.00953  |
| env/                      |          |
|    base_value             | 0.5      |
|    length                 | 0.745    |
| rollout/                  |          |
|    ep_len_mean            | 500      |
|    ep_rew_mean            | 500      |
| time/                     |          |
|    fps                    | 1182     |
|    iterations             | 45       |
|    time_elapsed           | 77       |
|    total_timesteps        | 92160    |
| train/                    |          |
|    explained_variance     | -0.483   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00761  |
|    learning_rate          | 0.0003   |
|    n_updates              | 44       |
|    policy_objective       | 0.00649  |
|    value_loss             | 2.77e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.04     |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.439    |
|    learning_rate          | 0.000313 |
|    target_kl              | 0.00958  |
| env/                      |          |
|    base_value             | 0.5      |
|    length                 | 0.72     |
| rollout/                  |          |
|    ep_len_mean            | 500      |
|    ep_rew_mean            | 500      |
| time/                     |          |
|    fps                    | 1182     |
|    iterations             | 46       |
|    time_elapsed           | 79       |
|    total_timesteps        | 94208    |
| train/                    |          |
|    explained_variance     | 0.491    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00745  |
|    learning_rate          | 0.0003   |
|    n_updates              | 45       |
|    policy_objective       | 0.00553  |
|    value_loss             | 3.98e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.04     |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.391    |
|    learning_rate          | 0.000312 |
|    target_kl              | 0.00962  |
| env/                      |          |
|    base_value             | 0.5      |
|    length                 | 0.696    |
| rollout/                  |          |
|    ep_len_mean            | 500      |
|    ep_rew_mean            | 500      |
| time/                     |          |
|    fps                    | 1183     |
|    iterations             | 47       |
|    time_elapsed           | 81       |
|    total_timesteps        | 96256    |
| train/                    |          |
|    explained_variance     | -1.02    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00662  |
|    learning_rate          | 0.0003   |
|    n_updates              | 46       |
|    policy_objective       | 0.0042   |
|    value_loss             | 2.24e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.03     |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.341    |
|    learning_rate          | 0.00031  |
|    target_kl              | 0.00967  |
| env/                      |          |
|    base_value             | 0.5      |
|    length                 | 0.67     |
| rollout/                  |          |
|    ep_len_mean            | 500      |
|    ep_rew_mean            | 500      |
| time/                     |          |
|    fps                    | 1184     |
|    iterations             | 48       |
|    time_elapsed           | 83       |
|    total_timesteps        | 98304    |
| train/                    |          |
|    explained_variance     | -0.717   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00398  |
|    learning_rate          | 0.0003   |
|    n_updates              | 47       |
|    policy_objective       | 0.00164  |
|    value_loss             | 1.99e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.00718  |
|    learning_rate          | 0.0003   |
|    target_kl              | 0.00999  |
| env/                      |          |
|    base_value             | 0.5      |
|    length                 | 0.504    |
| rollout/                  |          |
|    ep_len_mean            | 500      |
|    ep_rew_mean            | 500      |
| time/                     |          |
|    fps                    | 1183     |
|    iterations             | 49       |
|    time_elapsed           | 84       |
|    total_timesteps        | 100352   |
| train/                    |          |
|    explained_variance     | -1.09    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00491  |
|    learning_rate          | 0.0003   |
|    n_updates              | 48       |
|    policy_objective       | 0.00245  |
|    value_loss             | 1.85e-05 |
----------------------------------------
wandb: WARNING Symlinked 1 file into the W&B run directory; call wandb.save again to sync new files.
wandb: updating run metadata
wandb: uploading output.log; uploading wandb-summary.json; uploading model.zip
wandb: uploading wandb-summary.json; uploading model.zip; uploading config.yaml; uploading logs/CartPole_length_linear_Adaptive_20251217_125255_0/events.out.tfevents.1765951459.hungchan-Precision-7560.45281.0
wandb: uploading model.zip; uploading config.yaml; uploading logs/CartPole_length_linear_Adaptive_20251217_125255_0/events.out.tfevents.1765951459.hungchan-Precision-7560.45281.0
wandb: uploading history steps 674-826, summary, console lines 1226-1433
wandb: 
wandb: Run history:
wandb: adaptive/adaptation_factor â–â–‚â–ƒâ–ƒâ–„â–ˆâ–‡â–†â–†â–…â–â–‚â–ƒâ–ƒâ–„â–ˆâ–‡â–‡â–†â–…â–â–‚â–‚â–ƒâ–„â–ˆâ–‡â–‡â–†â–†â–â–‚â–‚â–ƒâ–ƒâ–ˆâ–‡â–‡â–†â–
wandb:           adaptive/base_lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    adaptive/base_target_kl â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:   adaptive/drift_magnitude â–‚â–ƒâ–ƒâ–„â–…â–ˆâ–‡â–†â–†â–…â–‚â–ƒâ–ƒâ–„â–…â–ˆâ–‡â–†â–†â–…â–‚â–ƒâ–ƒâ–„â–…â–ˆâ–‡â–‡â–†â–…â–‚â–‚â–ƒâ–„â–„â–ˆâ–‡â–‡â–†â–
wandb:     adaptive/learning_rate â–‚â–‚â–ƒâ–ƒâ–„â–ˆâ–‡â–‡â–†â–…â–â–‚â–ƒâ–ƒâ–„â–ˆâ–‡â–‡â–†â–…â–‚â–‚â–ƒâ–„â–„â–ˆâ–‡â–†â–†â–…â–‚â–‚â–ƒâ–„â–„â–ˆâ–‡â–†â–†â–
wandb:         adaptive/target_kl â–‡â–‡â–†â–†â–…â–â–‚â–‚â–ƒâ–„â–ˆâ–‡â–†â–†â–…â–â–‚â–‚â–ƒâ–„â–ˆâ–‡â–‡â–†â–…â–â–‚â–‚â–ƒâ–ƒâ–ˆâ–‡â–‡â–†â–…â–â–‚â–ƒâ–ƒâ–ˆ
wandb:             env/base_value â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 env/length â–‚â–ƒâ–ƒâ–„â–…â–ˆâ–‡â–†â–†â–…â–‚â–ƒâ–ƒâ–„â–…â–ˆâ–‡â–†â–†â–…â–‚â–ƒâ–ƒâ–„â–…â–ˆâ–‡â–‡â–†â–…â–‚â–‚â–ƒâ–„â–„â–ˆâ–‡â–‡â–†â–
wandb:                global_step â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆ
wandb:        rollout/ep_len_mean â–â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–…â–…â–…â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                         +8 ...
wandb: 
wandb: Run summary:
wandb: adaptive/adaptation_factor 1.00072
wandb:           adaptive/base_lr 0.0003
wandb:    adaptive/base_target_kl 0.01
wandb:   adaptive/drift_magnitude 0.00718
wandb:     adaptive/learning_rate 0.0003
wandb:         adaptive/target_kl 0.00999
wandb:             env/base_value 0.5
wandb:                 env/length 0.50359
wandb:                global_step 100352
wandb:        rollout/ep_len_mean 500
wandb:                         +8 ...
wandb: 
wandb: ðŸš€ View run CartPole_length_linear_Adaptive_20251217_125255 at: https://wandb.ai/hungtrab-hanoi-university-of-science-and-technology/CartPole_Drift_Research_TRPO/runs/vw3eksd9
wandb: â­ï¸ View project at: https://wandb.ai/hungtrab-hanoi-university-of-science-and-technology/CartPole_Drift_Research_TRPO
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)
wandb: Find logs at: logs/CartPole_length_linear_Adaptive_20251217_125255/wandb/run-20251217_130417-vw3eksd9/logs
>>> [DriftAdaptiveCallback] Training Ended
    Final LR: 0.000300
    Last Drift Magnitude: 0.0084
    Final Target KL: 0.0100
Model saved locally to: models/CartPole_length_linear_Adaptive_20251217_125255.zip
