wandb: W&B API key is configured. Use `wandb login --relogin` to force relogin
wandb: setting up run dos688zr
wandb: Tracking run with wandb version 0.23.1
wandb: Run data is saved locally in logs/CartPole_gravity_sine_Adaptive_20251217_125255/wandb/run-20251217_125737-dos688zr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run CartPole_gravity_sine_Adaptive_20251217_125255
wandb: â­ï¸ View project at https://wandb.ai/hungtrab-hanoi-university-of-science-and-technology/CartPole_Drift_Research_TRPO
wandb: ðŸš€ View run at https://wandb.ai/hungtrab-hanoi-university-of-science-and-technology/CartPole_Drift_Research_TRPO/runs/dos688zr
/home/hungchan/miniconda3/envs/rl_hf_course/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run TRPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.
  warnings.warn(
--- Training Start: CartPole_gravity_sine_Adaptive_20251217_125255 ---
>>> [Wrapper] Initialized Non-Stationary CartPole
    - gravity: sine (magnitude=5.0, period=20000)
>>> Initializing TRPO with kwargs: ['policy', 'env', 'learning_rate', 'gamma', 'verbose', 'tensorboard_log', 'n_steps', 'batch_size']
Using cuda device
Wrapping the env in a DummyVecEnv.
Logging to logs/CartPole_gravity_sine_Adaptive_20251217_125255_0
>>> [DriftAdaptiveCallback] Training Started
    Algorithm: TRPO
    Target Param: gravity (base=9.8)
    Scale Factor: 0.1
    
    Adaptive Hyperparameters:
      - Learning Rate: 0.000300
      - Target KL: 0.0100 (adapt=True)
-----------------------------------
| adaptive/            |          |
|    adaptation_factor | 1.03     |
|    algorithm         | TRPO     |
|    base_lr           | 0.0003   |
|    base_target_kl    | 0.01     |
|    drift_magnitude   | 0.3      |
|    learning_rate     | 0.000309 |
|    target_kl         | 0.00971  |
| env/                 |          |
|    base_value        | 9.8      |
|    gravity           | 12.7     |
| rollout/             |          |
|    ep_len_mean       | 21.7     |
|    ep_rew_mean       | 21.7     |
| time/                |          |
|    fps               | 1355     |
|    iterations        | 1        |
|    time_elapsed      | 1        |
|    total_timesteps   | 2048     |
-----------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.05     |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.485    |
|    learning_rate          | 0.000315 |
|    target_kl              | 0.00954  |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 14.6     |
| rollout/                  |          |
|    ep_len_mean            | 23.5     |
|    ep_rew_mean            | 23.5     |
| time/                     |          |
|    fps                    | 1243     |
|    iterations             | 2        |
|    time_elapsed           | 3        |
|    total_timesteps        | 4096     |
| train/                    |          |
|    explained_variance     | -0.00162 |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00794  |
|    learning_rate          | 0.0003   |
|    n_updates              | 1        |
|    policy_objective       | 0.0192   |
|    value_loss             | 52.1     |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.05     |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.48     |
|    learning_rate          | 0.000314 |
|    target_kl              | 0.00954  |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 14.5     |
| rollout/                  |          |
|    ep_len_mean            | 28.6     |
|    ep_rew_mean            | 28.6     |
| time/                     |          |
|    fps                    | 1260     |
|    iterations             | 3        |
|    time_elapsed           | 4        |
|    total_timesteps        | 6144     |
| train/                    |          |
|    explained_variance     | 0.053    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00763  |
|    learning_rate          | 0.0003   |
|    n_updates              | 2        |
|    policy_objective       | 0.0201   |
|    value_loss             | 34.4     |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.03     |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.287    |
|    learning_rate          | 0.000309 |
|    target_kl              | 0.00972  |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 12.6     |
| rollout/                  |          |
|    ep_len_mean            | 35.2     |
|    ep_rew_mean            | 35.2     |
| time/                     |          |
|    fps                    | 1273     |
|    iterations             | 4        |
|    time_elapsed           | 6        |
|    total_timesteps        | 8192     |
| train/                    |          |
|    explained_variance     | 0.203    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00764  |
|    learning_rate          | 0.0003   |
|    n_updates              | 3        |
|    policy_objective       | 0.0238   |
|    value_loss             | 43       |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.0319   |
|    learning_rate          | 0.000301 |
|    target_kl              | 0.00997  |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 9.49     |
| rollout/                  |          |
|    ep_len_mean            | 46.6     |
|    ep_rew_mean            | 46.6     |
| time/                     |          |
|    fps                    | 1282     |
|    iterations             | 5        |
|    time_elapsed           | 7        |
|    total_timesteps        | 10240    |
| train/                    |          |
|    explained_variance     | 0.317    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00736  |
|    learning_rate          | 0.0003   |
|    n_updates              | 4        |
|    policy_objective       | 0.0296   |
|    value_loss             | 50.7     |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.03     |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.325    |
|    learning_rate          | 0.00031  |
|    target_kl              | 0.00969  |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 6.61     |
| rollout/                  |          |
|    ep_len_mean            | 63.8     |
|    ep_rew_mean            | 63.8     |
| time/                     |          |
|    fps                    | 1291     |
|    iterations             | 6        |
|    time_elapsed           | 9        |
|    total_timesteps        | 12288    |
| train/                    |          |
|    explained_variance     | 0.291    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00719  |
|    learning_rate          | 0.0003   |
|    n_updates              | 5        |
|    policy_objective       | 0.0292   |
|    value_loss             | 63.7     |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.05     |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.498    |
|    learning_rate          | 0.000315 |
|    target_kl              | 0.00953  |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 4.92     |
| rollout/                  |          |
|    ep_len_mean            | 81.5     |
|    ep_rew_mean            | 81.5     |
| time/                     |          |
|    fps                    | 1293     |
|    iterations             | 7        |
|    time_elapsed           | 11       |
|    total_timesteps        | 14336    |
| train/                    |          |
|    explained_variance     | 0.318    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00645  |
|    learning_rate          | 0.0003   |
|    n_updates              | 6        |
|    policy_objective       | 0.0214   |
|    value_loss             | 53.3     |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.05     |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.468    |
|    learning_rate          | 0.000314 |
|    target_kl              | 0.00955  |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 5.21     |
| rollout/                  |          |
|    ep_len_mean            | 97.4     |
|    ep_rew_mean            | 97.4     |
| time/                     |          |
|    fps                    | 1295     |
|    iterations             | 8        |
|    time_elapsed           | 12       |
|    total_timesteps        | 16384    |
| train/                    |          |
|    explained_variance     | 0.421    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0069   |
|    learning_rate          | 0.0003   |
|    n_updates              | 7        |
|    policy_objective       | 0.0134   |
|    value_loss             | 44.4     |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.02     |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.246    |
|    learning_rate          | 0.000307 |
|    target_kl              | 0.00976  |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 7.39     |
| rollout/                  |          |
|    ep_len_mean            | 115      |
|    ep_rew_mean            | 115      |
| time/                     |          |
|    fps                    | 1299     |
|    iterations             | 9        |
|    time_elapsed           | 14       |
|    total_timesteps        | 18432    |
| train/                    |          |
|    explained_variance     | 0.798    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00668  |
|    learning_rate          | 0.0003   |
|    n_updates              | 8        |
|    policy_objective       | 0.00565  |
|    value_loss             | 23.5     |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.01     |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.0638   |
|    learning_rate          | 0.000302 |
|    target_kl              | 0.00994  |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 10.4     |
| rollout/                  |          |
|    ep_len_mean            | 133      |
|    ep_rew_mean            | 133      |
| time/                     |          |
|    fps                    | 1301     |
|    iterations             | 10       |
|    time_elapsed           | 15       |
|    total_timesteps        | 20480    |
| train/                    |          |
|    explained_variance     | 0.881    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00875  |
|    learning_rate          | 0.0003   |
|    n_updates              | 9        |
|    policy_objective       | 0.00949  |
|    value_loss             | 19.8     |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.04     |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.361    |
|    learning_rate          | 0.000311 |
|    target_kl              | 0.00965  |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 13.3     |
| rollout/                  |          |
|    ep_len_mean            | 154      |
|    ep_rew_mean            | 154      |
| time/                     |          |
|    fps                    | 1303     |
|    iterations             | 11       |
|    time_elapsed           | 17       |
|    total_timesteps        | 22528    |
| train/                    |          |
|    explained_variance     | 0.149    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00672  |
|    learning_rate          | 0.0003   |
|    n_updates              | 10       |
|    policy_objective       | 0.0176   |
|    value_loss             | 75.7     |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.05     |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.504    |
|    learning_rate          | 0.000315 |
|    target_kl              | 0.00952  |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 14.7     |
| rollout/                  |          |
|    ep_len_mean            | 171      |
|    ep_rew_mean            | 171      |
| time/                     |          |
|    fps                    | 1298     |
|    iterations             | 12       |
|    time_elapsed           | 18       |
|    total_timesteps        | 24576    |
| train/                    |          |
|    explained_variance     | 0.358    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00632  |
|    learning_rate          | 0.0003   |
|    n_updates              | 11       |
|    policy_objective       | 0.0182   |
|    value_loss             | 55.6     |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.04     |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.447    |
|    learning_rate          | 0.000313 |
|    target_kl              | 0.00957  |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 14.2     |
| rollout/                  |          |
|    ep_len_mean            | 189      |
|    ep_rew_mean            | 189      |
| time/                     |          |
|    fps                    | 1295     |
|    iterations             | 13       |
|    time_elapsed           | 20       |
|    total_timesteps        | 26624    |
| train/                    |          |
|    explained_variance     | 0.903    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0084   |
|    learning_rate          | 0.0003   |
|    n_updates              | 12       |
|    policy_objective       | 0.0102   |
|    value_loss             | 15.8     |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.02     |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.217    |
|    learning_rate          | 0.000307 |
|    target_kl              | 0.00979  |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 11.9     |
| rollout/                  |          |
|    ep_len_mean            | 206      |
|    ep_rew_mean            | 206      |
| time/                     |          |
|    fps                    | 1293     |
|    iterations             | 14       |
|    time_elapsed           | 22       |
|    total_timesteps        | 28672    |
| train/                    |          |
|    explained_variance     | 0.761    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00467  |
|    learning_rate          | 0.0003   |
|    n_updates              | 13       |
|    policy_objective       | 0.00982  |
|    value_loss             | 28.8     |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.01     |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.111    |
|    learning_rate          | 0.000303 |
|    target_kl              | 0.00989  |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 8.71     |
| rollout/                  |          |
|    ep_len_mean            | 228      |
|    ep_rew_mean            | 228      |
| time/                     |          |
|    fps                    | 1291     |
|    iterations             | 15       |
|    time_elapsed           | 23       |
|    total_timesteps        | 30720    |
| train/                    |          |
|    explained_variance     | 0.872    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00514  |
|    learning_rate          | 0.0003   |
|    n_updates              | 14       |
|    policy_objective       | 0.014    |
|    value_loss             | 7.71     |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.04     |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.383    |
|    learning_rate          | 0.000311 |
|    target_kl              | 0.00963  |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 6.05     |
| rollout/                  |          |
|    ep_len_mean            | 247      |
|    ep_rew_mean            | 247      |
| time/                     |          |
|    fps                    | 1288     |
|    iterations             | 16       |
|    time_elapsed           | 25       |
|    total_timesteps        | 32768    |
| train/                    |          |
|    explained_variance     | 0.939    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00794  |
|    learning_rate          | 0.0003   |
|    n_updates              | 15       |
|    policy_objective       | 0.0161   |
|    value_loss             | 5.44     |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.05     |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.509    |
|    learning_rate          | 0.000315 |
|    target_kl              | 0.00952  |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 4.81     |
| rollout/                  |          |
|    ep_len_mean            | 265      |
|    ep_rew_mean            | 265      |
| time/                     |          |
|    fps                    | 1289     |
|    iterations             | 17       |
|    time_elapsed           | 27       |
|    total_timesteps        | 34816    |
| train/                    |          |
|    explained_variance     | 0.474    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00628  |
|    learning_rate          | 0.0003   |
|    n_updates              | 16       |
|    policy_objective       | 0.00719  |
|    value_loss             | 1.53     |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.04     |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.431    |
|    learning_rate          | 0.000313 |
|    target_kl              | 0.00959  |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 5.58     |
| rollout/                  |          |
|    ep_len_mean            | 282      |
|    ep_rew_mean            | 282      |
| time/                     |          |
|    fps                    | 1289     |
|    iterations             | 18       |
|    time_elapsed           | 28       |
|    total_timesteps        | 36864    |
| train/                    |          |
|    explained_variance     | 0.43     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00694  |
|    learning_rate          | 0.0003   |
|    n_updates              | 17       |
|    policy_objective       | 0.00635  |
|    value_loss             | 1        |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.02     |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.173    |
|    learning_rate          | 0.000305 |
|    target_kl              | 0.00983  |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 8.1      |
| rollout/                  |          |
|    ep_len_mean            | 300      |
|    ep_rew_mean            | 300      |
| time/                     |          |
|    fps                    | 1287     |
|    iterations             | 19       |
|    time_elapsed           | 30       |
|    total_timesteps        | 38912    |
| train/                    |          |
|    explained_variance     | 0.098    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0071   |
|    learning_rate          | 0.0003   |
|    n_updates              | 18       |
|    policy_objective       | 0.005    |
|    value_loss             | 0.655    |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.01     |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.142    |
|    learning_rate          | 0.000304 |
|    target_kl              | 0.00986  |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 11.2     |
| rollout/                  |          |
|    ep_len_mean            | 318      |
|    ep_rew_mean            | 318      |
| time/                     |          |
|    fps                    | 1285     |
|    iterations             | 20       |
|    time_elapsed           | 31       |
|    total_timesteps        | 40960    |
| train/                    |          |
|    explained_variance     | 0.927    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.009    |
|    learning_rate          | 0.0003   |
|    n_updates              | 19       |
|    policy_objective       | 0.0209   |
|    value_loss             | 0.527    |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.04     |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.413    |
|    learning_rate          | 0.000312 |
|    target_kl              | 0.0096   |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 13.8     |
| rollout/                  |          |
|    ep_len_mean            | 334      |
|    ep_rew_mean            | 334      |
| time/                     |          |
|    fps                    | 1284     |
|    iterations             | 21       |
|    time_elapsed           | 33       |
|    total_timesteps        | 43008    |
| train/                    |          |
|    explained_variance     | 0.559    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00872  |
|    learning_rate          | 0.0003   |
|    n_updates              | 20       |
|    policy_objective       | 0.0133   |
|    value_loss             | 0.285    |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.05     |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.51     |
|    learning_rate          | 0.000315 |
|    target_kl              | 0.00951  |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 14.8     |
| rollout/                  |          |
|    ep_len_mean            | 352      |
|    ep_rew_mean            | 352      |
| time/                     |          |
|    fps                    | 1282     |
|    iterations             | 22       |
|    time_elapsed           | 35       |
|    total_timesteps        | 45056    |
| train/                    |          |
|    explained_variance     | 0.0108   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00857  |
|    learning_rate          | 0.0003   |
|    n_updates              | 21       |
|    policy_objective       | 0.00335  |
|    value_loss             | 0.174    |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.04     |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.403    |
|    learning_rate          | 0.000312 |
|    target_kl              | 0.00961  |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 13.8     |
| rollout/                  |          |
|    ep_len_mean            | 367      |
|    ep_rew_mean            | 367      |
| time/                     |          |
|    fps                    | 1282     |
|    iterations             | 23       |
|    time_elapsed           | 36       |
|    total_timesteps        | 47104    |
| train/                    |          |
|    explained_variance     | 0.154    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00793  |
|    learning_rate          | 0.0003   |
|    n_updates              | 22       |
|    policy_objective       | 0.00725  |
|    value_loss             | 0.111    |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.01     |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.142    |
|    learning_rate          | 0.000304 |
|    target_kl              | 0.00986  |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 11.2     |
| rollout/                  |          |
|    ep_len_mean            | 387      |
|    ep_rew_mean            | 387      |
| time/                     |          |
|    fps                    | 1281     |
|    iterations             | 24       |
|    time_elapsed           | 38       |
|    total_timesteps        | 49152    |
| train/                    |          |
|    explained_variance     | 0.0444   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00849  |
|    learning_rate          | 0.0003   |
|    n_updates              | 23       |
|    policy_objective       | 0.00393  |
|    value_loss             | 0.0709   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.02     |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.188    |
|    learning_rate          | 0.000306 |
|    target_kl              | 0.00982  |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 7.96     |
| rollout/                  |          |
|    ep_len_mean            | 401      |
|    ep_rew_mean            | 401      |
| time/                     |          |
|    fps                    | 1282     |
|    iterations             | 25       |
|    time_elapsed           | 39       |
|    total_timesteps        | 51200    |
| train/                    |          |
|    explained_variance     | 0.00466  |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00696  |
|    learning_rate          | 0.0003   |
|    n_updates              | 24       |
|    policy_objective       | 0.0049   |
|    value_loss             | 0.0465   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.04     |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.431    |
|    learning_rate          | 0.000313 |
|    target_kl              | 0.00959  |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 5.58     |
| rollout/                  |          |
|    ep_len_mean            | 412      |
|    ep_rew_mean            | 412      |
| time/                     |          |
|    fps                    | 1280     |
|    iterations             | 26       |
|    time_elapsed           | 41       |
|    total_timesteps        | 53248    |
| train/                    |          |
|    explained_variance     | -0.00882 |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00776  |
|    learning_rate          | 0.0003   |
|    n_updates              | 25       |
|    policy_objective       | 0.00192  |
|    value_loss             | 0.0292   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.05     |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.509    |
|    learning_rate          | 0.000315 |
|    target_kl              | 0.00952  |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 4.81     |
| rollout/                  |          |
|    ep_len_mean            | 424      |
|    ep_rew_mean            | 424      |
| time/                     |          |
|    fps                    | 1277     |
|    iterations             | 27       |
|    time_elapsed           | 43       |
|    total_timesteps        | 55296    |
| train/                    |          |
|    explained_variance     | -0.0389  |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00659  |
|    learning_rate          | 0.0003   |
|    n_updates              | 26       |
|    policy_objective       | 0.0019   |
|    value_loss             | 0.0189   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.04     |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.383    |
|    learning_rate          | 0.000311 |
|    target_kl              | 0.00963  |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 6.05     |
| rollout/                  |          |
|    ep_len_mean            | 435      |
|    ep_rew_mean            | 435      |
| time/                     |          |
|    fps                    | 1276     |
|    iterations             | 28       |
|    time_elapsed           | 44       |
|    total_timesteps        | 57344    |
| train/                    |          |
|    explained_variance     | -0.0663  |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00839  |
|    learning_rate          | 0.0003   |
|    n_updates              | 27       |
|    policy_objective       | 0.0071   |
|    value_loss             | 0.0126   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.01     |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.111    |
|    learning_rate          | 0.000303 |
|    target_kl              | 0.00989  |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 8.71     |
| rollout/                  |          |
|    ep_len_mean            | 445      |
|    ep_rew_mean            | 445      |
| time/                     |          |
|    fps                    | 1274     |
|    iterations             | 29       |
|    time_elapsed           | 46       |
|    total_timesteps        | 59392    |
| train/                    |          |
|    explained_variance     | 0.00484  |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0068   |
|    learning_rate          | 0.0003   |
|    n_updates              | 28       |
|    policy_objective       | 0.0091   |
|    value_loss             | 0.00812  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.02     |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.217    |
|    learning_rate          | 0.000307 |
|    target_kl              | 0.00979  |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 11.9     |
| rollout/                  |          |
|    ep_len_mean            | 455      |
|    ep_rew_mean            | 455      |
| time/                     |          |
|    fps                    | 1274     |
|    iterations             | 30       |
|    time_elapsed           | 48       |
|    total_timesteps        | 61440    |
| train/                    |          |
|    explained_variance     | -0.0202  |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00889  |
|    learning_rate          | 0.0003   |
|    n_updates              | 29       |
|    policy_objective       | 0.00679  |
|    value_loss             | 0.00529  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.04     |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.447    |
|    learning_rate          | 0.000313 |
|    target_kl              | 0.00957  |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 14.2     |
| rollout/                  |          |
|    ep_len_mean            | 461      |
|    ep_rew_mean            | 461      |
| time/                     |          |
|    fps                    | 1272     |
|    iterations             | 31       |
|    time_elapsed           | 49       |
|    total_timesteps        | 63488    |
| train/                    |          |
|    explained_variance     | -0.0376  |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00689  |
|    learning_rate          | 0.0003   |
|    n_updates              | 30       |
|    policy_objective       | 0.00648  |
|    value_loss             | 0.00356  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.05     |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.504    |
|    learning_rate          | 0.000315 |
|    target_kl              | 0.00952  |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 14.7     |
| rollout/                  |          |
|    ep_len_mean            | 464      |
|    ep_rew_mean            | 464      |
| time/                     |          |
|    fps                    | 1271     |
|    iterations             | 32       |
|    time_elapsed           | 51       |
|    total_timesteps        | 65536    |
| train/                    |          |
|    explained_variance     | -0.11    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00915  |
|    learning_rate          | 0.0003   |
|    n_updates              | 31       |
|    policy_objective       | 0.00708  |
|    value_loss             | 0.00239  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.04     |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.361    |
|    learning_rate          | 0.000311 |
|    target_kl              | 0.00965  |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 13.3     |
| rollout/                  |          |
|    ep_len_mean            | 471      |
|    ep_rew_mean            | 471      |
| time/                     |          |
|    fps                    | 1270     |
|    iterations             | 33       |
|    time_elapsed           | 53       |
|    total_timesteps        | 67584    |
| train/                    |          |
|    explained_variance     | -0.0344  |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00709  |
|    learning_rate          | 0.0003   |
|    n_updates              | 32       |
|    policy_objective       | 0.0124   |
|    value_loss             | 0.00166  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.01     |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.0641   |
|    learning_rate          | 0.000302 |
|    target_kl              | 0.00994  |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 10.4     |
| rollout/                  |          |
|    ep_len_mean            | 481      |
|    ep_rew_mean            | 481      |
| time/                     |          |
|    fps                    | 1270     |
|    iterations             | 34       |
|    time_elapsed           | 54       |
|    total_timesteps        | 69632    |
| train/                    |          |
|    explained_variance     | -0.0298  |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00649  |
|    learning_rate          | 0.0003   |
|    n_updates              | 33       |
|    policy_objective       | 0.00586  |
|    value_loss             | 0.00103  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.02     |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.246    |
|    learning_rate          | 0.000307 |
|    target_kl              | 0.00976  |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 7.39     |
| rollout/                  |          |
|    ep_len_mean            | 487      |
|    ep_rew_mean            | 487      |
| time/                     |          |
|    fps                    | 1271     |
|    iterations             | 35       |
|    time_elapsed           | 56       |
|    total_timesteps        | 71680    |
| train/                    |          |
|    explained_variance     | -0.0977  |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00695  |
|    learning_rate          | 0.0003   |
|    n_updates              | 34       |
|    policy_objective       | 0.00618  |
|    value_loss             | 0.000724 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.05     |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.468    |
|    learning_rate          | 0.000314 |
|    target_kl              | 0.00955  |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 5.21     |
| rollout/                  |          |
|    ep_len_mean            | 493      |
|    ep_rew_mean            | 493      |
| time/                     |          |
|    fps                    | 1271     |
|    iterations             | 36       |
|    time_elapsed           | 57       |
|    total_timesteps        | 73728    |
| train/                    |          |
|    explained_variance     | -0.0303  |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00813  |
|    learning_rate          | 0.0003   |
|    n_updates              | 35       |
|    policy_objective       | 0.0068   |
|    value_loss             | 0.00052  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.05     |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.498    |
|    learning_rate          | 0.000315 |
|    target_kl              | 0.00953  |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 4.92     |
| rollout/                  |          |
|    ep_len_mean            | 497      |
|    ep_rew_mean            | 497      |
| time/                     |          |
|    fps                    | 1272     |
|    iterations             | 37       |
|    time_elapsed           | 59       |
|    total_timesteps        | 75776    |
| train/                    |          |
|    explained_variance     | -0.144   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00707  |
|    learning_rate          | 0.0003   |
|    n_updates              | 36       |
|    policy_objective       | 0.00616  |
|    value_loss             | 0.000346 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.03     |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.325    |
|    learning_rate          | 0.00031  |
|    target_kl              | 0.00968  |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 6.61     |
| rollout/                  |          |
|    ep_len_mean            | 497      |
|    ep_rew_mean            | 497      |
| time/                     |          |
|    fps                    | 1272     |
|    iterations             | 38       |
|    time_elapsed           | 61       |
|    total_timesteps        | 77824    |
| train/                    |          |
|    explained_variance     | -0.252   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00607  |
|    learning_rate          | 0.0003   |
|    n_updates              | 37       |
|    policy_objective       | 0.00393  |
|    value_loss             | 0.000238 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.0322   |
|    learning_rate          | 0.000301 |
|    target_kl              | 0.00997  |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 9.48     |
| rollout/                  |          |
|    ep_len_mean            | 500      |
|    ep_rew_mean            | 500      |
| time/                     |          |
|    fps                    | 1273     |
|    iterations             | 39       |
|    time_elapsed           | 62       |
|    total_timesteps        | 79872    |
| train/                    |          |
|    explained_variance     | -0.491   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00672  |
|    learning_rate          | 0.0003   |
|    n_updates              | 38       |
|    policy_objective       | 0.00227  |
|    value_loss             | 0.000183 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.03     |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.287    |
|    learning_rate          | 0.000309 |
|    target_kl              | 0.00972  |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 12.6     |
| rollout/                  |          |
|    ep_len_mean            | 500      |
|    ep_rew_mean            | 500      |
| time/                     |          |
|    fps                    | 1273     |
|    iterations             | 40       |
|    time_elapsed           | 64       |
|    total_timesteps        | 81920    |
| train/                    |          |
|    explained_variance     | -0.375   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00775  |
|    learning_rate          | 0.0003   |
|    n_updates              | 39       |
|    policy_objective       | 0.00694  |
|    value_loss             | 0.000138 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.05     |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.48     |
|    learning_rate          | 0.000314 |
|    target_kl              | 0.00954  |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 14.5     |
| rollout/                  |          |
|    ep_len_mean            | 500      |
|    ep_rew_mean            | 500      |
| time/                     |          |
|    fps                    | 1274     |
|    iterations             | 41       |
|    time_elapsed           | 65       |
|    total_timesteps        | 83968    |
| train/                    |          |
|    explained_variance     | -0.644   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0061   |
|    learning_rate          | 0.0003   |
|    n_updates              | 40       |
|    policy_objective       | 0.00675  |
|    value_loss             | 9.37e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.05     |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.485    |
|    learning_rate          | 0.000315 |
|    target_kl              | 0.00954  |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 14.6     |
| rollout/                  |          |
|    ep_len_mean            | 500      |
|    ep_rew_mean            | 500      |
| time/                     |          |
|    fps                    | 1275     |
|    iterations             | 42       |
|    time_elapsed           | 67       |
|    total_timesteps        | 86016    |
| train/                    |          |
|    explained_variance     | -0.802   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00515  |
|    learning_rate          | 0.0003   |
|    n_updates              | 41       |
|    policy_objective       | 0.00685  |
|    value_loss             | 7.29e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.03     |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.3      |
|    learning_rate          | 0.000309 |
|    target_kl              | 0.00971  |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 12.7     |
| rollout/                  |          |
|    ep_len_mean            | 500      |
|    ep_rew_mean            | 500      |
| time/                     |          |
|    fps                    | 1276     |
|    iterations             | 43       |
|    time_elapsed           | 68       |
|    total_timesteps        | 88064    |
| train/                    |          |
|    explained_variance     | -0.745   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00451  |
|    learning_rate          | 0.0003   |
|    n_updates              | 42       |
|    policy_objective       | 0.00444  |
|    value_loss             | 4.24e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.0159   |
|    learning_rate          | 0.0003   |
|    target_kl              | 0.00998  |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 9.64     |
| rollout/                  |          |
|    ep_len_mean            | 500      |
|    ep_rew_mean            | 500      |
| time/                     |          |
|    fps                    | 1277     |
|    iterations             | 44       |
|    time_elapsed           | 70       |
|    total_timesteps        | 90112    |
| train/                    |          |
|    explained_variance     | -1.05    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00687  |
|    learning_rate          | 0.0003   |
|    n_updates              | 43       |
|    policy_objective       | 0.00546  |
|    value_loss             | 4.28e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.03     |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.313    |
|    learning_rate          | 0.000309 |
|    target_kl              | 0.0097   |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 6.74     |
| rollout/                  |          |
|    ep_len_mean            | 500      |
|    ep_rew_mean            | 500      |
| time/                     |          |
|    fps                    | 1278     |
|    iterations             | 45       |
|    time_elapsed           | 72       |
|    total_timesteps        | 92160    |
| train/                    |          |
|    explained_variance     | -0.766   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00811  |
|    learning_rate          | 0.0003   |
|    n_updates              | 44       |
|    policy_objective       | 0.0071   |
|    value_loss             | 2.83e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.05     |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.494    |
|    learning_rate          | 0.000315 |
|    target_kl              | 0.00953  |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 4.96     |
| rollout/                  |          |
|    ep_len_mean            | 500      |
|    ep_rew_mean            | 500      |
| time/                     |          |
|    fps                    | 1278     |
|    iterations             | 46       |
|    time_elapsed           | 73       |
|    total_timesteps        | 94208    |
| train/                    |          |
|    explained_variance     | -0.474   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00516  |
|    learning_rate          | 0.0003   |
|    n_updates              | 45       |
|    policy_objective       | 0.00174  |
|    value_loss             | 2.46e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.05     |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.474    |
|    learning_rate          | 0.000314 |
|    target_kl              | 0.00955  |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 5.15     |
| rollout/                  |          |
|    ep_len_mean            | 500      |
|    ep_rew_mean            | 500      |
| time/                     |          |
|    fps                    | 1278     |
|    iterations             | 47       |
|    time_elapsed           | 75       |
|    total_timesteps        | 96256    |
| train/                    |          |
|    explained_variance     | -1.99    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00797  |
|    learning_rate          | 0.0003   |
|    n_updates              | 46       |
|    policy_objective       | 0.00549  |
|    value_loss             | 1.8e-05  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.03     |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.26     |
|    learning_rate          | 0.000308 |
|    target_kl              | 0.00975  |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 7.25     |
| rollout/                  |          |
|    ep_len_mean            | 500      |
|    ep_rew_mean            | 500      |
| time/                     |          |
|    fps                    | 1279     |
|    iterations             | 48       |
|    time_elapsed           | 76       |
|    total_timesteps        | 98304    |
| train/                    |          |
|    explained_variance     | -1.38    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00684  |
|    learning_rate          | 0.0003   |
|    n_updates              | 47       |
|    policy_objective       | 0.00207  |
|    value_loss             | 4.14e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0.0479   |
|    learning_rate          | 0.000301 |
|    target_kl              | 0.00995  |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 10.3     |
| rollout/                  |          |
|    ep_len_mean            | 500      |
|    ep_rew_mean            | 500      |
| time/                     |          |
|    fps                    | 1278     |
|    iterations             | 49       |
|    time_elapsed           | 78       |
|    total_timesteps        | 100352   |
| train/                    |          |
|    explained_variance     | -1.66    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0075   |
|    learning_rate          | 0.0003   |
|    n_updates              | 48       |
|    policy_objective       | 0.00504  |
|    value_loss             | 1.6e-05  |
----------------------------------------
wandb: WARNING Symlinked 1 file into the W&B run directory; call wandb.save again to sync new files.
wandb: updating run metadata
wandb: uploading model.zip; uploading output.log; uploading wandb-summary.json
wandb: uploading config.yaml; uploading logs/CartPole_gravity_sine_Adaptive_20251217_125255_0/events.out.tfevents.1765951059.hungchan-Precision-7560.40748.0
wandb: uploading logs/CartPole_gravity_sine_Adaptive_20251217_125255_0/events.out.tfevents.1765951059.hungchan-Precision-7560.40748.0
wandb: uploading history steps 725-826, summary, console lines 1342-1433
wandb: 
wandb: Run history:
wandb: adaptive/adaptation_factor â–…â–ˆâ–ˆâ–…â–â–ˆâ–‡â–„â–‚â–†â–‡â–„â–‚â–ˆâ–‡â–ƒâ–‡â–ˆâ–†â–ƒâ–‡â–ˆâ–†â–‚â–„â–ˆâ–†â–‚â–„â–‡â–…â–â–…â–ˆâ–ˆâ–â–…â–ˆâ–‡â–
wandb:           adaptive/base_lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    adaptive/base_target_kl â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:   adaptive/drift_magnitude â–…â–ˆâ–ˆâ–…â–â–ˆâ–‡â–„â–‚â–†â–‡â–„â–‚â–†â–ˆâ–ƒâ–ƒâ–‡â–ˆâ–†â–‡â–ˆâ–†â–‚â–„â–ˆâ–†â–‚â–„â–‡â–…â–â–…â–ˆâ–ˆâ–â–…â–ˆâ–‡â–
wandb:     adaptive/learning_rate â–…â–ˆâ–ˆâ–…â–â–ˆâ–‡â–„â–‚â–†â–‡â–„â–‚â–†â–ˆâ–ƒâ–ƒâ–‡â–ˆâ–†â–ƒâ–‡â–†â–‚â–„â–ˆâ–†â–‚â–„â–‡â–…â–â–…â–ˆâ–ˆâ–â–…â–ˆâ–‡â–
wandb:         adaptive/target_kl â–„â–â–â–„â–ˆâ–â–‚â–…â–‡â–ƒâ–‚â–…â–‡â–ƒâ–â–†â–‚â–â–‚â–†â–‚â–â–ƒâ–‡â–…â–â–ƒâ–‡â–…â–‚â–„â–ˆâ–„â–â–â–ˆâ–„â–â–â–ˆ
wandb:             env/base_value â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                env/gravity â–‡â–ˆâ–ˆâ–‡â–„â–â–â–ƒâ–…â–‡â–ˆâ–†â–„â–‚â–â–ƒâ–†â–‡â–‡â–†â–‚â–â–‚â–„â–†â–ˆâ–‡â–…â–ƒâ–â–‚â–„â–†â–ˆâ–ˆâ–„â–‚â–â–â–…
wandb:                global_step â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–„â–…â–…â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:        rollout/ep_len_mean â–â–â–â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                         +8 ...
wandb: 
wandb: Run summary:
wandb: adaptive/adaptation_factor 1.00479
wandb:           adaptive/base_lr 0.0003
wandb:    adaptive/base_target_kl 0.01
wandb:   adaptive/drift_magnitude 0.04785
wandb:     adaptive/learning_rate 0.0003
wandb:         adaptive/target_kl 0.00995
wandb:             env/base_value 9.8
wandb:                env/gravity 10.26898
wandb:                global_step 100352
wandb:        rollout/ep_len_mean 500
wandb:                         +8 ...
wandb: 
wandb: ðŸš€ View run CartPole_gravity_sine_Adaptive_20251217_125255 at: https://wandb.ai/hungtrab-hanoi-university-of-science-and-technology/CartPole_Drift_Research_TRPO/runs/dos688zr
wandb: â­ï¸ View project at: https://wandb.ai/hungtrab-hanoi-university-of-science-and-technology/CartPole_Drift_Research_TRPO
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)
wandb: Find logs at: logs/CartPole_gravity_sine_Adaptive_20251217_125255/wandb/run-20251217_125737-dos688zr/logs
>>> [DriftAdaptiveCallback] Training Ended
    Final LR: 0.000302
    Last Drift Magnitude: 0.0561
    Final Target KL: 0.0099
Model saved locally to: models/CartPole_gravity_sine_Adaptive_20251217_125255.zip
