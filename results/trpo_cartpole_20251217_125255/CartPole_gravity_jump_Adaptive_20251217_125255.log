wandb: Currently logged in as: hungtrab (hungtrab-hanoi-university-of-science-and-technology) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: setting up run 7f6ucnwt
wandb: Tracking run with wandb version 0.23.1
wandb: Run data is saved locally in logs/CartPole_gravity_jump_Adaptive_20251217_125255/wandb/run-20251217_125426-7f6ucnwt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run CartPole_gravity_jump_Adaptive_20251217_125255
wandb: â­ï¸ View project at https://wandb.ai/hungtrab-hanoi-university-of-science-and-technology/CartPole_Drift_Research_TRPO
wandb: ðŸš€ View run at https://wandb.ai/hungtrab-hanoi-university-of-science-and-technology/CartPole_Drift_Research_TRPO/runs/7f6ucnwt
/home/hungchan/miniconda3/envs/rl_hf_course/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run TRPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.
  warnings.warn(
--- Training Start: CartPole_gravity_jump_Adaptive_20251217_125255 ---
>>> [Wrapper] Initialized Non-Stationary CartPole
    - gravity: jump (magnitude=10.0, period=50000)
>>> Initializing TRPO with kwargs: ['policy', 'env', 'learning_rate', 'gamma', 'verbose', 'tensorboard_log', 'n_steps', 'batch_size']
Using cuda device
Wrapping the env in a DummyVecEnv.
Logging to logs/CartPole_gravity_jump_Adaptive_20251217_125255_0
>>> [DriftAdaptiveCallback] Training Started
    Algorithm: TRPO
    Target Param: gravity (base=9.8)
    Scale Factor: 0.1
    
    Adaptive Hyperparameters:
      - Learning Rate: 0.000300
      - Target KL: 0.0100 (adapt=True)
-----------------------------------
| adaptive/            |          |
|    adaptation_factor | 1        |
|    algorithm         | TRPO     |
|    base_lr           | 0.0003   |
|    base_target_kl    | 0.01     |
|    drift_magnitude   | 0        |
|    learning_rate     | 0.0003   |
|    target_kl         | 0.01     |
| env/                 |          |
|    base_value        | 9.8      |
|    gravity           | 9.8      |
| rollout/             |          |
|    ep_len_mean       | 22.6     |
|    ep_rew_mean       | 22.6     |
| time/                |          |
|    fps               | 1328     |
|    iterations        | 1        |
|    time_elapsed      | 1        |
|    total_timesteps   | 2048     |
-----------------------------------
-----------------------------------------
| adaptive/                 |           |
|    adaptation_factor      | 1         |
|    algorithm              | TRPO      |
|    base_lr                | 0.0003    |
|    base_target_kl         | 0.01      |
|    drift_magnitude        | 0         |
|    learning_rate          | 0.0003    |
|    target_kl              | 0.01      |
| env/                      |           |
|    base_value             | 9.8       |
|    gravity                | 9.8       |
| rollout/                  |           |
|    ep_len_mean            | 26.6      |
|    ep_rew_mean            | 26.6      |
| time/                     |           |
|    fps                    | 1225      |
|    iterations             | 2         |
|    time_elapsed           | 3         |
|    total_timesteps        | 4096      |
| train/                    |           |
|    explained_variance     | -0.000437 |
|    is_line_search_success | 1         |
|    kl_divergence_loss     | 0.0084    |
|    learning_rate          | 0.0003    |
|    n_updates              | 1         |
|    policy_objective       | 0.0227    |
|    value_loss             | 52.2      |
-----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.0003   |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 34.8     |
|    ep_rew_mean            | 34.8     |
| time/                     |          |
|    fps                    | 1216     |
|    iterations             | 3        |
|    time_elapsed           | 5        |
|    total_timesteps        | 6144     |
| train/                    |          |
|    explained_variance     | 0.0191   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00816  |
|    learning_rate          | 0.0003   |
|    n_updates              | 2        |
|    policy_objective       | 0.0215   |
|    value_loss             | 40.3     |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.0003   |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 46.9     |
|    ep_rew_mean            | 46.9     |
| time/                     |          |
|    fps                    | 1229     |
|    iterations             | 4        |
|    time_elapsed           | 6        |
|    total_timesteps        | 8192     |
| train/                    |          |
|    explained_variance     | 0.101    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00708  |
|    learning_rate          | 0.0003   |
|    n_updates              | 3        |
|    policy_objective       | 0.0193   |
|    value_loss             | 58       |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.0003   |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 61.8     |
|    ep_rew_mean            | 61.8     |
| time/                     |          |
|    fps                    | 1243     |
|    iterations             | 5        |
|    time_elapsed           | 8        |
|    total_timesteps        | 10240    |
| train/                    |          |
|    explained_variance     | 0.254    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00718  |
|    learning_rate          | 0.0003   |
|    n_updates              | 4        |
|    policy_objective       | 0.0192   |
|    value_loss             | 65.1     |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.0003   |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 76.3     |
|    ep_rew_mean            | 76.3     |
| time/                     |          |
|    fps                    | 1254     |
|    iterations             | 6        |
|    time_elapsed           | 9        |
|    total_timesteps        | 12288    |
| train/                    |          |
|    explained_variance     | 0.287    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00729  |
|    learning_rate          | 0.0003   |
|    n_updates              | 5        |
|    policy_objective       | 0.0167   |
|    value_loss             | 71.4     |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.0003   |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 92.8     |
|    ep_rew_mean            | 92.8     |
| time/                     |          |
|    fps                    | 1263     |
|    iterations             | 7        |
|    time_elapsed           | 11       |
|    total_timesteps        | 14336    |
| train/                    |          |
|    explained_variance     | 0.635    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00743  |
|    learning_rate          | 0.0003   |
|    n_updates              | 6        |
|    policy_objective       | 0.0181   |
|    value_loss             | 47.1     |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.0003   |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 110      |
|    ep_rew_mean            | 110      |
| time/                     |          |
|    fps                    | 1258     |
|    iterations             | 8        |
|    time_elapsed           | 13       |
|    total_timesteps        | 16384    |
| train/                    |          |
|    explained_variance     | 0.809    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00783  |
|    learning_rate          | 0.0003   |
|    n_updates              | 7        |
|    policy_objective       | 0.0139   |
|    value_loss             | 34.4     |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.0003   |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 128      |
|    ep_rew_mean            | 128      |
| time/                     |          |
|    fps                    | 1253     |
|    iterations             | 9        |
|    time_elapsed           | 14       |
|    total_timesteps        | 18432    |
| train/                    |          |
|    explained_variance     | 0.313    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00756  |
|    learning_rate          | 0.0003   |
|    n_updates              | 8        |
|    policy_objective       | 0.017    |
|    value_loss             | 65.9     |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.0003   |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 145      |
|    ep_rew_mean            | 145      |
| time/                     |          |
|    fps                    | 1249     |
|    iterations             | 10       |
|    time_elapsed           | 16       |
|    total_timesteps        | 20480    |
| train/                    |          |
|    explained_variance     | 0.397    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00523  |
|    learning_rate          | 0.0003   |
|    n_updates              | 9        |
|    policy_objective       | 0.0163   |
|    value_loss             | 56.8     |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.0003   |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 163      |
|    ep_rew_mean            | 163      |
| time/                     |          |
|    fps                    | 1251     |
|    iterations             | 11       |
|    time_elapsed           | 18       |
|    total_timesteps        | 22528    |
| train/                    |          |
|    explained_variance     | 0.829    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00385  |
|    learning_rate          | 0.0003   |
|    n_updates              | 10       |
|    policy_objective       | 0.00981  |
|    value_loss             | 17       |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.0003   |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 183      |
|    ep_rew_mean            | 183      |
| time/                     |          |
|    fps                    | 1254     |
|    iterations             | 12       |
|    time_elapsed           | 19       |
|    total_timesteps        | 24576    |
| train/                    |          |
|    explained_variance     | 0.944    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0091   |
|    learning_rate          | 0.0003   |
|    n_updates              | 11       |
|    policy_objective       | 0.0139   |
|    value_loss             | 10.3     |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.0003   |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 202      |
|    ep_rew_mean            | 202      |
| time/                     |          |
|    fps                    | 1260     |
|    iterations             | 13       |
|    time_elapsed           | 21       |
|    total_timesteps        | 26624    |
| train/                    |          |
|    explained_variance     | 0.662    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00712  |
|    learning_rate          | 0.0003   |
|    n_updates              | 12       |
|    policy_objective       | 0.00854  |
|    value_loss             | 27.5     |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.0003   |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 219      |
|    ep_rew_mean            | 219      |
| time/                     |          |
|    fps                    | 1263     |
|    iterations             | 14       |
|    time_elapsed           | 22       |
|    total_timesteps        | 28672    |
| train/                    |          |
|    explained_variance     | 0.795    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00946  |
|    learning_rate          | 0.0003   |
|    n_updates              | 13       |
|    policy_objective       | 0.0145   |
|    value_loss             | 5.17     |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.0003   |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 235      |
|    ep_rew_mean            | 235      |
| time/                     |          |
|    fps                    | 1263     |
|    iterations             | 15       |
|    time_elapsed           | 24       |
|    total_timesteps        | 30720    |
| train/                    |          |
|    explained_variance     | 0.205    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00635  |
|    learning_rate          | 0.0003   |
|    n_updates              | 14       |
|    policy_objective       | 0.00661  |
|    value_loss             | 30.9     |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.0003   |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 253      |
|    ep_rew_mean            | 253      |
| time/                     |          |
|    fps                    | 1263     |
|    iterations             | 16       |
|    time_elapsed           | 25       |
|    total_timesteps        | 32768    |
| train/                    |          |
|    explained_variance     | 0.652    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00919  |
|    learning_rate          | 0.0003   |
|    n_updates              | 15       |
|    policy_objective       | 0.00585  |
|    value_loss             | 29.3     |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.0003   |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 268      |
|    ep_rew_mean            | 268      |
| time/                     |          |
|    fps                    | 1254     |
|    iterations             | 17       |
|    time_elapsed           | 27       |
|    total_timesteps        | 34816    |
| train/                    |          |
|    explained_variance     | 0.333    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00485  |
|    learning_rate          | 0.0003   |
|    n_updates              | 16       |
|    policy_objective       | 0.00926  |
|    value_loss             | 18.2     |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.0003   |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 287      |
|    ep_rew_mean            | 287      |
| time/                     |          |
|    fps                    | 1246     |
|    iterations             | 18       |
|    time_elapsed           | 29       |
|    total_timesteps        | 36864    |
| train/                    |          |
|    explained_variance     | 0.709    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00657  |
|    learning_rate          | 0.0003   |
|    n_updates              | 17       |
|    policy_objective       | 0.00301  |
|    value_loss             | 13.8     |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.0003   |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 301      |
|    ep_rew_mean            | 301      |
| time/                     |          |
|    fps                    | 1239     |
|    iterations             | 19       |
|    time_elapsed           | 31       |
|    total_timesteps        | 38912    |
| train/                    |          |
|    explained_variance     | 0.486    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00699  |
|    learning_rate          | 0.0003   |
|    n_updates              | 18       |
|    policy_objective       | 0.018    |
|    value_loss             | 37.6     |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.0003   |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 321      |
|    ep_rew_mean            | 321      |
| time/                     |          |
|    fps                    | 1238     |
|    iterations             | 20       |
|    time_elapsed           | 33       |
|    total_timesteps        | 40960    |
| train/                    |          |
|    explained_variance     | 0.845    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00548  |
|    learning_rate          | 0.0003   |
|    n_updates              | 19       |
|    policy_objective       | 0.00863  |
|    value_loss             | 17.9     |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.0003   |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 337      |
|    ep_rew_mean            | 337      |
| time/                     |          |
|    fps                    | 1235     |
|    iterations             | 21       |
|    time_elapsed           | 34       |
|    total_timesteps        | 43008    |
| train/                    |          |
|    explained_variance     | 0.919    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00958  |
|    learning_rate          | 0.0003   |
|    n_updates              | 20       |
|    policy_objective       | 0.0151   |
|    value_loss             | 1.57     |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.0003   |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 353      |
|    ep_rew_mean            | 353      |
| time/                     |          |
|    fps                    | 1236     |
|    iterations             | 22       |
|    time_elapsed           | 36       |
|    total_timesteps        | 45056    |
| train/                    |          |
|    explained_variance     | 0.522    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00995  |
|    learning_rate          | 0.0003   |
|    n_updates              | 21       |
|    policy_objective       | 0.0237   |
|    value_loss             | 0.563    |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.0003   |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 369      |
|    ep_rew_mean            | 369      |
| time/                     |          |
|    fps                    | 1236     |
|    iterations             | 23       |
|    time_elapsed           | 38       |
|    total_timesteps        | 47104    |
| train/                    |          |
|    explained_variance     | 0.325    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00865  |
|    learning_rate          | 0.0003   |
|    n_updates              | 22       |
|    policy_objective       | 0.00794  |
|    value_loss             | 0.222    |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.0003   |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 383      |
|    ep_rew_mean            | 383      |
| time/                     |          |
|    fps                    | 1234     |
|    iterations             | 24       |
|    time_elapsed           | 39       |
|    total_timesteps        | 49152    |
| train/                    |          |
|    explained_variance     | 0.0101   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00632  |
|    learning_rate          | 0.0003   |
|    n_updates              | 23       |
|    policy_objective       | 0.00369  |
|    value_loss             | 0.111    |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.1      |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 1.02     |
|    learning_rate          | 0.000331 |
|    target_kl              | 0.00907  |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 19.8     |
| rollout/                  |          |
|    ep_len_mean            | 396      |
|    ep_rew_mean            | 396      |
| time/                     |          |
|    fps                    | 1235     |
|    iterations             | 25       |
|    time_elapsed           | 41       |
|    total_timesteps        | 51200    |
| train/                    |          |
|    explained_variance     | -0.0428  |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00649  |
|    learning_rate          | 0.0003   |
|    n_updates              | 24       |
|    policy_objective       | 0.00409  |
|    value_loss             | 0.0716   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.1      |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 1.02     |
|    learning_rate          | 0.000331 |
|    target_kl              | 0.00907  |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 19.8     |
| rollout/                  |          |
|    ep_len_mean            | 411      |
|    ep_rew_mean            | 411      |
| time/                     |          |
|    fps                    | 1233     |
|    iterations             | 26       |
|    time_elapsed           | 43       |
|    total_timesteps        | 53248    |
| train/                    |          |
|    explained_variance     | 0.853    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00261  |
|    learning_rate          | 0.0003   |
|    n_updates              | 25       |
|    policy_objective       | 0.00415  |
|    value_loss             | 13.3     |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.1      |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 1.02     |
|    learning_rate          | 0.000331 |
|    target_kl              | 0.00907  |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 19.8     |
| rollout/                  |          |
|    ep_len_mean            | 422      |
|    ep_rew_mean            | 422      |
| time/                     |          |
|    fps                    | 1234     |
|    iterations             | 27       |
|    time_elapsed           | 44       |
|    total_timesteps        | 55296    |
| train/                    |          |
|    explained_variance     | 0.958    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00859  |
|    learning_rate          | 0.0003   |
|    n_updates              | 26       |
|    policy_objective       | 0.0195   |
|    value_loss             | 2.51     |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.1      |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 1.02     |
|    learning_rate          | 0.000331 |
|    target_kl              | 0.00907  |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 19.8     |
| rollout/                  |          |
|    ep_len_mean            | 436      |
|    ep_rew_mean            | 436      |
| time/                     |          |
|    fps                    | 1235     |
|    iterations             | 28       |
|    time_elapsed           | 46       |
|    total_timesteps        | 57344    |
| train/                    |          |
|    explained_variance     | 0.542    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00895  |
|    learning_rate          | 0.0003   |
|    n_updates              | 27       |
|    policy_objective       | 0.0193   |
|    value_loss             | 0.038    |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.1      |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 1.02     |
|    learning_rate          | 0.000331 |
|    target_kl              | 0.00907  |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 19.8     |
| rollout/                  |          |
|    ep_len_mean            | 440      |
|    ep_rew_mean            | 440      |
| time/                     |          |
|    fps                    | 1236     |
|    iterations             | 29       |
|    time_elapsed           | 48       |
|    total_timesteps        | 59392    |
| train/                    |          |
|    explained_variance     | 0.0877   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00796  |
|    learning_rate          | 0.0003   |
|    n_updates              | 28       |
|    policy_objective       | 0.00792  |
|    value_loss             | 0.0149   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.1      |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 1.02     |
|    learning_rate          | 0.000331 |
|    target_kl              | 0.00907  |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 19.8     |
| rollout/                  |          |
|    ep_len_mean            | 451      |
|    ep_rew_mean            | 451      |
| time/                     |          |
|    fps                    | 1238     |
|    iterations             | 30       |
|    time_elapsed           | 49       |
|    total_timesteps        | 61440    |
| train/                    |          |
|    explained_variance     | -0.00389 |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00733  |
|    learning_rate          | 0.0003   |
|    n_updates              | 29       |
|    policy_objective       | 0.0119   |
|    value_loss             | 0.0104   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.1      |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 1.02     |
|    learning_rate          | 0.000331 |
|    target_kl              | 0.00907  |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 19.8     |
| rollout/                  |          |
|    ep_len_mean            | 459      |
|    ep_rew_mean            | 459      |
| time/                     |          |
|    fps                    | 1240     |
|    iterations             | 31       |
|    time_elapsed           | 51       |
|    total_timesteps        | 63488    |
| train/                    |          |
|    explained_variance     | -0.133   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00579  |
|    learning_rate          | 0.0003   |
|    n_updates              | 30       |
|    policy_objective       | 0.00568  |
|    value_loss             | 0.00618  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.1      |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 1.02     |
|    learning_rate          | 0.000331 |
|    target_kl              | 0.00907  |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 19.8     |
| rollout/                  |          |
|    ep_len_mean            | 465      |
|    ep_rew_mean            | 465      |
| time/                     |          |
|    fps                    | 1241     |
|    iterations             | 32       |
|    time_elapsed           | 52       |
|    total_timesteps        | 65536    |
| train/                    |          |
|    explained_variance     | -0.149   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00712  |
|    learning_rate          | 0.0003   |
|    n_updates              | 31       |
|    policy_objective       | 0.00417  |
|    value_loss             | 0.00406  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.1      |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 1.02     |
|    learning_rate          | 0.000331 |
|    target_kl              | 0.00907  |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 19.8     |
| rollout/                  |          |
|    ep_len_mean            | 470      |
|    ep_rew_mean            | 470      |
| time/                     |          |
|    fps                    | 1242     |
|    iterations             | 33       |
|    time_elapsed           | 54       |
|    total_timesteps        | 67584    |
| train/                    |          |
|    explained_variance     | -0.0878  |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00878  |
|    learning_rate          | 0.0003   |
|    n_updates              | 32       |
|    policy_objective       | 0.00745  |
|    value_loss             | 0.00272  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.1      |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 1.02     |
|    learning_rate          | 0.000331 |
|    target_kl              | 0.00907  |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 19.8     |
| rollout/                  |          |
|    ep_len_mean            | 476      |
|    ep_rew_mean            | 476      |
| time/                     |          |
|    fps                    | 1242     |
|    iterations             | 34       |
|    time_elapsed           | 56       |
|    total_timesteps        | 69632    |
| train/                    |          |
|    explained_variance     | -0.256   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00797  |
|    learning_rate          | 0.0003   |
|    n_updates              | 33       |
|    policy_objective       | 0.0117   |
|    value_loss             | 0.00315  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.1      |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 1.02     |
|    learning_rate          | 0.000331 |
|    target_kl              | 0.00907  |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 19.8     |
| rollout/                  |          |
|    ep_len_mean            | 478      |
|    ep_rew_mean            | 478      |
| time/                     |          |
|    fps                    | 1242     |
|    iterations             | 35       |
|    time_elapsed           | 57       |
|    total_timesteps        | 71680    |
| train/                    |          |
|    explained_variance     | 0.114    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00656  |
|    learning_rate          | 0.0003   |
|    n_updates              | 34       |
|    policy_objective       | 0.008    |
|    value_loss             | 0.00134  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.1      |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 1.02     |
|    learning_rate          | 0.000331 |
|    target_kl              | 0.00907  |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 19.8     |
| rollout/                  |          |
|    ep_len_mean            | 479      |
|    ep_rew_mean            | 479      |
| time/                     |          |
|    fps                    | 1242     |
|    iterations             | 36       |
|    time_elapsed           | 59       |
|    total_timesteps        | 73728    |
| train/                    |          |
|    explained_variance     | -0.0772  |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00839  |
|    learning_rate          | 0.0003   |
|    n_updates              | 35       |
|    policy_objective       | 0.0031   |
|    value_loss             | 0.000856 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.1      |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 1.02     |
|    learning_rate          | 0.000331 |
|    target_kl              | 0.00907  |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 19.8     |
| rollout/                  |          |
|    ep_len_mean            | 480      |
|    ep_rew_mean            | 480      |
| time/                     |          |
|    fps                    | 1241     |
|    iterations             | 37       |
|    time_elapsed           | 61       |
|    total_timesteps        | 75776    |
| train/                    |          |
|    explained_variance     | -0.0173  |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00808  |
|    learning_rate          | 0.0003   |
|    n_updates              | 36       |
|    policy_objective       | 0.00454  |
|    value_loss             | 0.000654 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.1      |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 1.02     |
|    learning_rate          | 0.000331 |
|    target_kl              | 0.00907  |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 19.8     |
| rollout/                  |          |
|    ep_len_mean            | 485      |
|    ep_rew_mean            | 485      |
| time/                     |          |
|    fps                    | 1241     |
|    iterations             | 38       |
|    time_elapsed           | 62       |
|    total_timesteps        | 77824    |
| train/                    |          |
|    explained_variance     | -0.05    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00693  |
|    learning_rate          | 0.0003   |
|    n_updates              | 37       |
|    policy_objective       | 0.00704  |
|    value_loss             | 0.000418 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.1      |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 1.02     |
|    learning_rate          | 0.000331 |
|    target_kl              | 0.00907  |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 19.8     |
| rollout/                  |          |
|    ep_len_mean            | 490      |
|    ep_rew_mean            | 490      |
| time/                     |          |
|    fps                    | 1240     |
|    iterations             | 39       |
|    time_elapsed           | 64       |
|    total_timesteps        | 79872    |
| train/                    |          |
|    explained_variance     | -0.109   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00672  |
|    learning_rate          | 0.0003   |
|    n_updates              | 38       |
|    policy_objective       | 0.00412  |
|    value_loss             | 0.000286 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.1      |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 1.02     |
|    learning_rate          | 0.000331 |
|    target_kl              | 0.00907  |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 19.8     |
| rollout/                  |          |
|    ep_len_mean            | 490      |
|    ep_rew_mean            | 490      |
| time/                     |          |
|    fps                    | 1240     |
|    iterations             | 40       |
|    time_elapsed           | 66       |
|    total_timesteps        | 81920    |
| train/                    |          |
|    explained_variance     | 0.534    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00798  |
|    learning_rate          | 0.0003   |
|    n_updates              | 39       |
|    policy_objective       | 0.0127   |
|    value_loss             | 0.000341 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.1      |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 1.02     |
|    learning_rate          | 0.000331 |
|    target_kl              | 0.00907  |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 19.8     |
| rollout/                  |          |
|    ep_len_mean            | 492      |
|    ep_rew_mean            | 492      |
| time/                     |          |
|    fps                    | 1240     |
|    iterations             | 41       |
|    time_elapsed           | 67       |
|    total_timesteps        | 83968    |
| train/                    |          |
|    explained_variance     | -0.747   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00679  |
|    learning_rate          | 0.0003   |
|    n_updates              | 40       |
|    policy_objective       | 0.0059   |
|    value_loss             | 0.000159 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.1      |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 1.02     |
|    learning_rate          | 0.000331 |
|    target_kl              | 0.00907  |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 19.8     |
| rollout/                  |          |
|    ep_len_mean            | 495      |
|    ep_rew_mean            | 495      |
| time/                     |          |
|    fps                    | 1240     |
|    iterations             | 42       |
|    time_elapsed           | 69       |
|    total_timesteps        | 86016    |
| train/                    |          |
|    explained_variance     | -0.602   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00518  |
|    learning_rate          | 0.0003   |
|    n_updates              | 41       |
|    policy_objective       | 0.0039   |
|    value_loss             | 0.000116 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.1      |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 1.02     |
|    learning_rate          | 0.000331 |
|    target_kl              | 0.00907  |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 19.8     |
| rollout/                  |          |
|    ep_len_mean            | 498      |
|    ep_rew_mean            | 498      |
| time/                     |          |
|    fps                    | 1240     |
|    iterations             | 43       |
|    time_elapsed           | 70       |
|    total_timesteps        | 88064    |
| train/                    |          |
|    explained_variance     | -0.695   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00667  |
|    learning_rate          | 0.0003   |
|    n_updates              | 42       |
|    policy_objective       | 0.00404  |
|    value_loss             | 7.66e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.1      |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 1.02     |
|    learning_rate          | 0.000331 |
|    target_kl              | 0.00907  |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 19.8     |
| rollout/                  |          |
|    ep_len_mean            | 498      |
|    ep_rew_mean            | 498      |
| time/                     |          |
|    fps                    | 1239     |
|    iterations             | 44       |
|    time_elapsed           | 72       |
|    total_timesteps        | 90112    |
| train/                    |          |
|    explained_variance     | -0.952   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0077   |
|    learning_rate          | 0.0003   |
|    n_updates              | 43       |
|    policy_objective       | 0.004    |
|    value_loss             | 7.19e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.1      |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 1.02     |
|    learning_rate          | 0.000331 |
|    target_kl              | 0.00907  |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 19.8     |
| rollout/                  |          |
|    ep_len_mean            | 498      |
|    ep_rew_mean            | 498      |
| time/                     |          |
|    fps                    | 1239     |
|    iterations             | 45       |
|    time_elapsed           | 74       |
|    total_timesteps        | 92160    |
| train/                    |          |
|    explained_variance     | -1.17    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00734  |
|    learning_rate          | 0.0003   |
|    n_updates              | 44       |
|    policy_objective       | 0.00644  |
|    value_loss             | 5.08e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.1      |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 1.02     |
|    learning_rate          | 0.000331 |
|    target_kl              | 0.00907  |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 19.8     |
| rollout/                  |          |
|    ep_len_mean            | 498      |
|    ep_rew_mean            | 498      |
| time/                     |          |
|    fps                    | 1240     |
|    iterations             | 46       |
|    time_elapsed           | 75       |
|    total_timesteps        | 94208    |
| train/                    |          |
|    explained_variance     | -1.45    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00542  |
|    learning_rate          | 0.0003   |
|    n_updates              | 45       |
|    policy_objective       | 0.00187  |
|    value_loss             | 3.58e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.1      |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 1.02     |
|    learning_rate          | 0.000331 |
|    target_kl              | 0.00907  |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 19.8     |
| rollout/                  |          |
|    ep_len_mean            | 498      |
|    ep_rew_mean            | 498      |
| time/                     |          |
|    fps                    | 1240     |
|    iterations             | 47       |
|    time_elapsed           | 77       |
|    total_timesteps        | 96256    |
| train/                    |          |
|    explained_variance     | -1.6     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00588  |
|    learning_rate          | 0.0003   |
|    n_updates              | 46       |
|    policy_objective       | 0.00403  |
|    value_loss             | 3.13e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1.1      |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 1.02     |
|    learning_rate          | 0.000331 |
|    target_kl              | 0.00907  |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 19.8     |
| rollout/                  |          |
|    ep_len_mean            | 498      |
|    ep_rew_mean            | 498      |
| time/                     |          |
|    fps                    | 1240     |
|    iterations             | 48       |
|    time_elapsed           | 79       |
|    total_timesteps        | 98304    |
| train/                    |          |
|    explained_variance     | -1.08    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00321  |
|    learning_rate          | 0.0003   |
|    n_updates              | 47       |
|    policy_objective       | 0.00427  |
|    value_loss             | 3.74e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.0003   |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 9.8      |
|    gravity                | 9.8      |
| rollout/                  |          |
|    ep_len_mean            | 500      |
|    ep_rew_mean            | 500      |
| time/                     |          |
|    fps                    | 1240     |
|    iterations             | 49       |
|    time_elapsed           | 80       |
|    total_timesteps        | 100352   |
| train/                    |          |
|    explained_variance     | -0.664   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00554  |
|    learning_rate          | 0.0003   |
|    n_updates              | 48       |
|    policy_objective       | 0.00565  |
|    value_loss             | 2.05e-05 |
----------------------------------------
wandb: WARNING Symlinked 1 file into the W&B run directory; call wandb.save again to sync new files.
wandb: updating run metadata
wandb: uploading output.log; uploading wandb-summary.json; uploading model.zip
wandb: uploading output.log; uploading wandb-summary.json; uploading model.zip; uploading config.yaml; uploading logs/CartPole_gravity_jump_Adaptive_20251217_125255_0/events.out.tfevents.1765950869.hungchan-Precision-7560.38376.0
wandb: uploading model.zip; uploading logs/CartPole_gravity_jump_Adaptive_20251217_125255_0/events.out.tfevents.1765950869.hungchan-Precision-7560.38376.0
wandb: uploading logs/CartPole_gravity_jump_Adaptive_20251217_125255_0/events.out.tfevents.1765950869.hungchan-Precision-7560.38376.0
wandb: uploading history steps 708-826, summary, console lines 1284-1433
wandb: 
wandb: Run history:
wandb: adaptive/adaptation_factor â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–
wandb:           adaptive/base_lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    adaptive/base_target_kl â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:   adaptive/drift_magnitude â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–
wandb:     adaptive/learning_rate â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–
wandb:         adaptive/target_kl â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆ
wandb:             env/base_value â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                env/gravity â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–
wandb:                global_step â–â–â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆ
wandb:        rollout/ep_len_mean â–â–â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                         +8 ...
wandb: 
wandb: Run summary:
wandb: adaptive/adaptation_factor 1
wandb:           adaptive/base_lr 0.0003
wandb:    adaptive/base_target_kl 0.01
wandb:   adaptive/drift_magnitude 0
wandb:     adaptive/learning_rate 0.0003
wandb:         adaptive/target_kl 0.01
wandb:             env/base_value 9.8
wandb:                env/gravity 9.8
wandb:                global_step 100352
wandb:        rollout/ep_len_mean 500
wandb:                         +8 ...
wandb: 
wandb: ðŸš€ View run CartPole_gravity_jump_Adaptive_20251217_125255 at: https://wandb.ai/hungtrab-hanoi-university-of-science-and-technology/CartPole_Drift_Research_TRPO/runs/7f6ucnwt
wandb: â­ï¸ View project at: https://wandb.ai/hungtrab-hanoi-university-of-science-and-technology/CartPole_Drift_Research_TRPO
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)
wandb: Find logs at: logs/CartPole_gravity_jump_Adaptive_20251217_125255/wandb/run-20251217_125426-7f6ucnwt/logs
>>> [DriftAdaptiveCallback] Training Ended
    Final LR: 0.000300
    Last Drift Magnitude: 0.0000
    Final Target KL: 0.0100
Model saved locally to: models/CartPole_gravity_jump_Adaptive_20251217_125255.zip
