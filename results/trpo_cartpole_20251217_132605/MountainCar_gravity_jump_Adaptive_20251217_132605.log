wandb: Currently logged in as: hungtrab (hungtrab-hanoi-university-of-science-and-technology) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: setting up run sd0okufg
wandb: Tracking run with wandb version 0.23.1
wandb: Run data is saved locally in logs/MountainCar_gravity_jump_Adaptive_20251217_132605/wandb/run-20251217_133945-sd0okufg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run MountainCar_gravity_jump_Adaptive_20251217_132605
wandb: â­ï¸ View project at https://wandb.ai/hungtrab-hanoi-university-of-science-and-technology/MountainCar_Drift_Research_TRPO
wandb: ðŸš€ View run at https://wandb.ai/hungtrab-hanoi-university-of-science-and-technology/MountainCar_Drift_Research_TRPO/runs/sd0okufg
/home/hungchan/miniconda3/envs/rl_hf_course/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run TRPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.
  warnings.warn(
--- Training Start: MountainCar_gravity_jump_Adaptive_20251217_132605 ---
>>> [Wrapper] Initialized Non-Stationary MountainCar
    - gravity: jump (magnitude=10.0)
>>> Initializing TRPO with kwargs: ['policy', 'env', 'learning_rate', 'gamma', 'verbose', 'tensorboard_log', 'n_steps', 'batch_size']
Using cuda device
Wrapping the env in a DummyVecEnv.
Logging to logs/MountainCar_gravity_jump_Adaptive_20251217_132605_0
>>> [DriftAdaptiveCallback] Training Started
    Algorithm: TRPO
    Target Param: gravity (base=0.0025)
    Scale Factor: 0.1
    
    Adaptive Hyperparameters:
      - Learning Rate: 0.000300
      - Target KL: 0.0100 (adapt=True)
-----------------------------------
| adaptive/            |          |
|    adaptation_factor | 1        |
|    algorithm         | TRPO     |
|    base_lr           | 0.0003   |
|    base_target_kl    | 0.01     |
|    drift_magnitude   | 0        |
|    learning_rate     | 0.0003   |
|    target_kl         | 0.01     |
| env/                 |          |
|    base_value        | 0.0025   |
|    gravity           | 0.0025   |
| rollout/             |          |
|    ep_len_mean       | 200      |
|    ep_rew_mean       | -200     |
| time/                |          |
|    fps               | 1294     |
|    iterations        | 1        |
|    time_elapsed      | 1        |
|    total_timesteps   | 2048     |
-----------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.0003   |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 0.0025   |
|    gravity                | 0.0025   |
| rollout/                  |          |
|    ep_len_mean            | 200      |
|    ep_rew_mean            | -200     |
| time/                     |          |
|    fps                    | 1220     |
|    iterations             | 2        |
|    time_elapsed           | 3        |
|    total_timesteps        | 4096     |
| train/                    |          |
|    explained_variance     | 1.32e-05 |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.000792 |
|    learning_rate          | 0.0003   |
|    n_updates              | 1        |
|    policy_objective       | 0.000855 |
|    value_loss             | 125      |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.0003   |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 0.0025   |
|    gravity                | 0.0025   |
| rollout/                  |          |
|    ep_len_mean            | 200      |
|    ep_rew_mean            | -200     |
| time/                     |          |
|    fps                    | 1205     |
|    iterations             | 3        |
|    time_elapsed           | 5        |
|    total_timesteps        | 6144     |
| train/                    |          |
|    explained_variance     | -0.044   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00835  |
|    learning_rate          | 0.0003   |
|    n_updates              | 2        |
|    policy_objective       | 0.00445  |
|    value_loss             | 77.9     |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.0003   |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 0.0025   |
|    gravity                | 0.0025   |
| rollout/                  |          |
|    ep_len_mean            | 200      |
|    ep_rew_mean            | -200     |
| time/                     |          |
|    fps                    | 1216     |
|    iterations             | 4        |
|    time_elapsed           | 6        |
|    total_timesteps        | 8192     |
| train/                    |          |
|    explained_variance     | 0.000521 |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00768  |
|    learning_rate          | 0.0003   |
|    n_updates              | 3        |
|    policy_objective       | 0.00323  |
|    value_loss             | 77.3     |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.0003   |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 0.0025   |
|    gravity                | 0.0025   |
| rollout/                  |          |
|    ep_len_mean            | 200      |
|    ep_rew_mean            | -200     |
| time/                     |          |
|    fps                    | 1221     |
|    iterations             | 5        |
|    time_elapsed           | 8        |
|    total_timesteps        | 10240    |
| train/                    |          |
|    explained_variance     | 0.00321  |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00845  |
|    learning_rate          | 0.0003   |
|    n_updates              | 4        |
|    policy_objective       | 0.00604  |
|    value_loss             | 66.7     |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.0003   |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 0.0025   |
|    gravity                | 0.0025   |
| rollout/                  |          |
|    ep_len_mean            | 200      |
|    ep_rew_mean            | -200     |
| time/                     |          |
|    fps                    | 1214     |
|    iterations             | 6        |
|    time_elapsed           | 10       |
|    total_timesteps        | 12288    |
| train/                    |          |
|    explained_variance     | -0.00119 |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00784  |
|    learning_rate          | 0.0003   |
|    n_updates              | 5        |
|    policy_objective       | 0.00308  |
|    value_loss             | 55.5     |
----------------------------------------
-----------------------------------------
| adaptive/                 |           |
|    adaptation_factor      | 1         |
|    algorithm              | TRPO      |
|    base_lr                | 0.0003    |
|    base_target_kl         | 0.01      |
|    drift_magnitude        | 0         |
|    learning_rate          | 0.0003    |
|    target_kl              | 0.01      |
| env/                      |           |
|    base_value             | 0.0025    |
|    gravity                | 0.0025    |
| rollout/                  |           |
|    ep_len_mean            | 200       |
|    ep_rew_mean            | -200      |
| time/                     |           |
|    fps                    | 1214      |
|    iterations             | 7         |
|    time_elapsed           | 11        |
|    total_timesteps        | 14336     |
| train/                    |           |
|    explained_variance     | -0.000141 |
|    is_line_search_success | 1         |
|    kl_divergence_loss     | 0.00834   |
|    learning_rate          | 0.0003    |
|    n_updates              | 6         |
|    policy_objective       | 0.00655   |
|    value_loss             | 45.5      |
-----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.0003   |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 0.0025   |
|    gravity                | 0.0025   |
| rollout/                  |          |
|    ep_len_mean            | 200      |
|    ep_rew_mean            | -200     |
| time/                     |          |
|    fps                    | 1208     |
|    iterations             | 8        |
|    time_elapsed           | 13       |
|    total_timesteps        | 16384    |
| train/                    |          |
|    explained_variance     | 0.000829 |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00994  |
|    learning_rate          | 0.0003   |
|    n_updates              | 7        |
|    policy_objective       | 0.00261  |
|    value_loss             | 36.8     |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.0003   |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 0.0025   |
|    gravity                | 0.0025   |
| rollout/                  |          |
|    ep_len_mean            | 200      |
|    ep_rew_mean            | -200     |
| time/                     |          |
|    fps                    | 1208     |
|    iterations             | 9        |
|    time_elapsed           | 15       |
|    total_timesteps        | 18432    |
| train/                    |          |
|    explained_variance     | 0.000984 |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00907  |
|    learning_rate          | 0.0003   |
|    n_updates              | 8        |
|    policy_objective       | 0.00476  |
|    value_loss             | 29.3     |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.0003   |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 0.0025   |
|    gravity                | 0.0025   |
| rollout/                  |          |
|    ep_len_mean            | 200      |
|    ep_rew_mean            | -200     |
| time/                     |          |
|    fps                    | 1204     |
|    iterations             | 10       |
|    time_elapsed           | 17       |
|    total_timesteps        | 20480    |
| train/                    |          |
|    explained_variance     | 0.000774 |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00904  |
|    learning_rate          | 0.0003   |
|    n_updates              | 9        |
|    policy_objective       | 0.00737  |
|    value_loss             | 22.9     |
----------------------------------------
-----------------------------------------
| adaptive/                 |           |
|    adaptation_factor      | 1         |
|    algorithm              | TRPO      |
|    base_lr                | 0.0003    |
|    base_target_kl         | 0.01      |
|    drift_magnitude        | 0         |
|    learning_rate          | 0.0003    |
|    target_kl              | 0.01      |
| env/                      |           |
|    base_value             | 0.0025    |
|    gravity                | 0.0025    |
| rollout/                  |           |
|    ep_len_mean            | 200       |
|    ep_rew_mean            | -200      |
| time/                     |           |
|    fps                    | 1198      |
|    iterations             | 11        |
|    time_elapsed           | 18        |
|    total_timesteps        | 22528     |
| train/                    |           |
|    explained_variance     | -0.000594 |
|    is_line_search_success | 1         |
|    kl_divergence_loss     | 0.00751   |
|    learning_rate          | 0.0003    |
|    n_updates              | 10        |
|    policy_objective       | 0.00202   |
|    value_loss             | 17.8      |
-----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.0003   |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 0.0025   |
|    gravity                | 0.0025   |
| rollout/                  |          |
|    ep_len_mean            | 200      |
|    ep_rew_mean            | -200     |
| time/                     |          |
|    fps                    | 1198     |
|    iterations             | 12       |
|    time_elapsed           | 20       |
|    total_timesteps        | 24576    |
| train/                    |          |
|    explained_variance     | 0.000543 |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00849  |
|    learning_rate          | 0.0003   |
|    n_updates              | 11       |
|    policy_objective       | 0.00476  |
|    value_loss             | 13.5     |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.0003   |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 0.0025   |
|    gravity                | 0.0025   |
| rollout/                  |          |
|    ep_len_mean            | 200      |
|    ep_rew_mean            | -200     |
| time/                     |          |
|    fps                    | 1195     |
|    iterations             | 13       |
|    time_elapsed           | 22       |
|    total_timesteps        | 26624    |
| train/                    |          |
|    explained_variance     | 0.000576 |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00822  |
|    learning_rate          | 0.0003   |
|    n_updates              | 12       |
|    policy_objective       | 0.00554  |
|    value_loss             | 10       |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.0003   |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 0.0025   |
|    gravity                | 0.0025   |
| rollout/                  |          |
|    ep_len_mean            | 200      |
|    ep_rew_mean            | -200     |
| time/                     |          |
|    fps                    | 1195     |
|    iterations             | 14       |
|    time_elapsed           | 23       |
|    total_timesteps        | 28672    |
| train/                    |          |
|    explained_variance     | -0.00018 |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00722  |
|    learning_rate          | 0.0003   |
|    n_updates              | 13       |
|    policy_objective       | 0.00142  |
|    value_loss             | 7.34     |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.0003   |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 0.0025   |
|    gravity                | 0.0025   |
| rollout/                  |          |
|    ep_len_mean            | 200      |
|    ep_rew_mean            | -200     |
| time/                     |          |
|    fps                    | 1201     |
|    iterations             | 15       |
|    time_elapsed           | 25       |
|    total_timesteps        | 30720    |
| train/                    |          |
|    explained_variance     | 0.00143  |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00737  |
|    learning_rate          | 0.0003   |
|    n_updates              | 14       |
|    policy_objective       | 0.00367  |
|    value_loss             | 5.27     |
----------------------------------------
-----------------------------------------
| adaptive/                 |           |
|    adaptation_factor      | 1         |
|    algorithm              | TRPO      |
|    base_lr                | 0.0003    |
|    base_target_kl         | 0.01      |
|    drift_magnitude        | 0         |
|    learning_rate          | 0.0003    |
|    target_kl              | 0.01      |
| env/                      |           |
|    base_value             | 0.0025    |
|    gravity                | 0.0025    |
| rollout/                  |           |
|    ep_len_mean            | 200       |
|    ep_rew_mean            | -200      |
| time/                     |           |
|    fps                    | 1204      |
|    iterations             | 16        |
|    time_elapsed           | 27        |
|    total_timesteps        | 32768     |
| train/                    |           |
|    explained_variance     | -0.000498 |
|    is_line_search_success | 1         |
|    kl_divergence_loss     | 0.00699   |
|    learning_rate          | 0.0003    |
|    n_updates              | 15        |
|    policy_objective       | 0.00297   |
|    value_loss             | 3.71      |
-----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.0003   |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 0.0025   |
|    gravity                | 0.0025   |
| rollout/                  |          |
|    ep_len_mean            | 200      |
|    ep_rew_mean            | -200     |
| time/                     |          |
|    fps                    | 1200     |
|    iterations             | 17       |
|    time_elapsed           | 28       |
|    total_timesteps        | 34816    |
| train/                    |          |
|    explained_variance     | 0.000609 |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00684  |
|    learning_rate          | 0.0003   |
|    n_updates              | 16       |
|    policy_objective       | 0.00291  |
|    value_loss             | 2.56     |
----------------------------------------
-----------------------------------------
| adaptive/                 |           |
|    adaptation_factor      | 1         |
|    algorithm              | TRPO      |
|    base_lr                | 0.0003    |
|    base_target_kl         | 0.01      |
|    drift_magnitude        | 0         |
|    learning_rate          | 0.0003    |
|    target_kl              | 0.01      |
| env/                      |           |
|    base_value             | 0.0025    |
|    gravity                | 0.0025    |
| rollout/                  |           |
|    ep_len_mean            | 200       |
|    ep_rew_mean            | -200      |
| time/                     |           |
|    fps                    | 1198      |
|    iterations             | 18        |
|    time_elapsed           | 30        |
|    total_timesteps        | 36864     |
| train/                    |           |
|    explained_variance     | -0.000339 |
|    is_line_search_success | 1         |
|    kl_divergence_loss     | 0.00839   |
|    learning_rate          | 0.0003    |
|    n_updates              | 17        |
|    policy_objective       | 0.00585   |
|    value_loss             | 1.75      |
-----------------------------------------
-----------------------------------------
| adaptive/                 |           |
|    adaptation_factor      | 1         |
|    algorithm              | TRPO      |
|    base_lr                | 0.0003    |
|    base_target_kl         | 0.01      |
|    drift_magnitude        | 0         |
|    learning_rate          | 0.0003    |
|    target_kl              | 0.01      |
| env/                      |           |
|    base_value             | 0.0025    |
|    gravity                | 0.0025    |
| rollout/                  |           |
|    ep_len_mean            | 200       |
|    ep_rew_mean            | -200      |
| time/                     |           |
|    fps                    | 1201      |
|    iterations             | 19        |
|    time_elapsed           | 32        |
|    total_timesteps        | 38912     |
| train/                    |           |
|    explained_variance     | -7.19e-05 |
|    is_line_search_success | 1         |
|    kl_divergence_loss     | 0.00667   |
|    learning_rate          | 0.0003    |
|    n_updates              | 18        |
|    policy_objective       | 0.00359   |
|    value_loss             | 1.17      |
-----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.0003   |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 0.0025   |
|    gravity                | 0.0025   |
| rollout/                  |          |
|    ep_len_mean            | 200      |
|    ep_rew_mean            | -200     |
| time/                     |          |
|    fps                    | 1204     |
|    iterations             | 20       |
|    time_elapsed           | 34       |
|    total_timesteps        | 40960    |
| train/                    |          |
|    explained_variance     | 0.000619 |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00672  |
|    learning_rate          | 0.0003   |
|    n_updates              | 19       |
|    policy_objective       | 0.0061   |
|    value_loss             | 0.776    |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.0003   |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 0.0025   |
|    gravity                | 0.0025   |
| rollout/                  |          |
|    ep_len_mean            | 200      |
|    ep_rew_mean            | -200     |
| time/                     |          |
|    fps                    | 1202     |
|    iterations             | 21       |
|    time_elapsed           | 35       |
|    total_timesteps        | 43008    |
| train/                    |          |
|    explained_variance     | 0.000953 |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00821  |
|    learning_rate          | 0.0003   |
|    n_updates              | 20       |
|    policy_objective       | 0.00503  |
|    value_loss             | 0.51     |
----------------------------------------
-----------------------------------------
| adaptive/                 |           |
|    adaptation_factor      | 1         |
|    algorithm              | TRPO      |
|    base_lr                | 0.0003    |
|    base_target_kl         | 0.01      |
|    drift_magnitude        | 0         |
|    learning_rate          | 0.0003    |
|    target_kl              | 0.01      |
| env/                      |           |
|    base_value             | 0.0025    |
|    gravity                | 0.0025    |
| rollout/                  |           |
|    ep_len_mean            | 200       |
|    ep_rew_mean            | -200      |
| time/                     |           |
|    fps                    | 1204      |
|    iterations             | 22        |
|    time_elapsed           | 37        |
|    total_timesteps        | 45056     |
| train/                    |           |
|    explained_variance     | -0.000454 |
|    is_line_search_success | 1         |
|    kl_divergence_loss     | 0.00808   |
|    learning_rate          | 0.0003    |
|    n_updates              | 21        |
|    policy_objective       | 0.00601   |
|    value_loss             | 0.337     |
-----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.0003   |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 0.0025   |
|    gravity                | 0.0025   |
| rollout/                  |          |
|    ep_len_mean            | 200      |
|    ep_rew_mean            | -200     |
| time/                     |          |
|    fps                    | 1207     |
|    iterations             | 23       |
|    time_elapsed           | 38       |
|    total_timesteps        | 47104    |
| train/                    |          |
|    explained_variance     | -0.00088 |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00724  |
|    learning_rate          | 0.0003   |
|    n_updates              | 22       |
|    policy_objective       | 0.00297  |
|    value_loss             | 0.218    |
----------------------------------------
-----------------------------------------
| adaptive/                 |           |
|    adaptation_factor      | 1         |
|    algorithm              | TRPO      |
|    base_lr                | 0.0003    |
|    base_target_kl         | 0.01      |
|    drift_magnitude        | 0         |
|    learning_rate          | 0.0003    |
|    target_kl              | 0.01      |
| env/                      |           |
|    base_value             | 0.0025    |
|    gravity                | 0.0025    |
| rollout/                  |           |
|    ep_len_mean            | 200       |
|    ep_rew_mean            | -200      |
| time/                     |           |
|    fps                    | 1207      |
|    iterations             | 24        |
|    time_elapsed           | 40        |
|    total_timesteps        | 49152     |
| train/                    |           |
|    explained_variance     | -8.88e-05 |
|    is_line_search_success | 1         |
|    kl_divergence_loss     | 0.00785   |
|    learning_rate          | 0.0003    |
|    n_updates              | 23        |
|    policy_objective       | 0.00594   |
|    value_loss             | 0.142     |
-----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 3        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 4e+03    |
|    learning_rate          | 0.0009   |
|    target_kl              | 0.00333  |
| env/                      |          |
|    base_value             | 0.0025   |
|    gravity                | 10       |
| rollout/                  |          |
|    ep_len_mean            | 200      |
|    ep_rew_mean            | -200     |
| time/                     |          |
|    fps                    | 1205     |
|    iterations             | 25       |
|    time_elapsed           | 42       |
|    total_timesteps        | 51200    |
| train/                    |          |
|    explained_variance     | 0.00269  |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0069   |
|    learning_rate          | 0.0003   |
|    n_updates              | 24       |
|    policy_objective       | 0.00318  |
|    value_loss             | 0.0933   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 3        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 4e+03    |
|    learning_rate          | 0.0009   |
|    target_kl              | 0.00333  |
| env/                      |          |
|    base_value             | 0.0025   |
|    gravity                | 10       |
| rollout/                  |          |
|    ep_len_mean            | 200      |
|    ep_rew_mean            | -200     |
| time/                     |          |
|    fps                    | 1207     |
|    iterations             | 26       |
|    time_elapsed           | 44       |
|    total_timesteps        | 53248    |
| train/                    |          |
|    explained_variance     | -0.00213 |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.000233 |
|    learning_rate          | 0.0003   |
|    n_updates              | 25       |
|    policy_objective       | 0.000465 |
|    value_loss             | 0.0614   |
----------------------------------------
-----------------------------------------
| adaptive/                 |           |
|    adaptation_factor      | 3         |
|    algorithm              | TRPO      |
|    base_lr                | 0.0003    |
|    base_target_kl         | 0.01      |
|    drift_magnitude        | 4e+03     |
|    learning_rate          | 0.0009    |
|    target_kl              | 0.00333   |
| env/                      |           |
|    base_value             | 0.0025    |
|    gravity                | 10        |
| rollout/                  |           |
|    ep_len_mean            | 200       |
|    ep_rew_mean            | -200      |
| time/                     |           |
|    fps                    | 1210      |
|    iterations             | 27        |
|    time_elapsed           | 45        |
|    total_timesteps        | 55296     |
| train/                    |           |
|    explained_variance     | -0.000348 |
|    is_line_search_success | 1         |
|    kl_divergence_loss     | 0.00289   |
|    learning_rate          | 0.0003    |
|    n_updates              | 26        |
|    policy_objective       | 0.00299   |
|    value_loss             | 0.0405    |
-----------------------------------------
-----------------------------------------
| adaptive/                 |           |
|    adaptation_factor      | 3         |
|    algorithm              | TRPO      |
|    base_lr                | 0.0003    |
|    base_target_kl         | 0.01      |
|    drift_magnitude        | 4e+03     |
|    learning_rate          | 0.0009    |
|    target_kl              | 0.00333   |
| env/                      |           |
|    base_value             | 0.0025    |
|    gravity                | 10        |
| rollout/                  |           |
|    ep_len_mean            | 200       |
|    ep_rew_mean            | -200      |
| time/                     |           |
|    fps                    | 1214      |
|    iterations             | 28        |
|    time_elapsed           | 47        |
|    total_timesteps        | 57344     |
| train/                    |           |
|    explained_variance     | -0.000451 |
|    is_line_search_success | 1         |
|    kl_divergence_loss     | 0.00258   |
|    learning_rate          | 0.0003    |
|    n_updates              | 27        |
|    policy_objective       | 0.00247   |
|    value_loss             | 0.0268    |
-----------------------------------------
-----------------------------------------
| adaptive/                 |           |
|    adaptation_factor      | 3         |
|    algorithm              | TRPO      |
|    base_lr                | 0.0003    |
|    base_target_kl         | 0.01      |
|    drift_magnitude        | 4e+03     |
|    learning_rate          | 0.0009    |
|    target_kl              | 0.00333   |
| env/                      |           |
|    base_value             | 0.0025    |
|    gravity                | 10        |
| rollout/                  |           |
|    ep_len_mean            | 200       |
|    ep_rew_mean            | -200      |
| time/                     |           |
|    fps                    | 1215      |
|    iterations             | 29        |
|    time_elapsed           | 48        |
|    total_timesteps        | 59392     |
| train/                    |           |
|    explained_variance     | -0.000523 |
|    is_line_search_success | 1         |
|    kl_divergence_loss     | 0.00219   |
|    learning_rate          | 0.0003    |
|    n_updates              | 28        |
|    policy_objective       | 0.000425  |
|    value_loss             | 0.0179    |
-----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 3        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 4e+03    |
|    learning_rate          | 0.0009   |
|    target_kl              | 0.00333  |
| env/                      |          |
|    base_value             | 0.0025   |
|    gravity                | 10       |
| rollout/                  |          |
|    ep_len_mean            | 200      |
|    ep_rew_mean            | -200     |
| time/                     |          |
|    fps                    | 1214     |
|    iterations             | 30       |
|    time_elapsed           | 50       |
|    total_timesteps        | 61440    |
| train/                    |          |
|    explained_variance     | 0.000165 |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00261  |
|    learning_rate          | 0.0003   |
|    n_updates              | 29       |
|    policy_objective       | 0.0036   |
|    value_loss             | 0.012    |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 3        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 4e+03    |
|    learning_rate          | 0.0009   |
|    target_kl              | 0.00333  |
| env/                      |          |
|    base_value             | 0.0025   |
|    gravity                | 10       |
| rollout/                  |          |
|    ep_len_mean            | 200      |
|    ep_rew_mean            | -200     |
| time/                     |          |
|    fps                    | 1214     |
|    iterations             | 31       |
|    time_elapsed           | 52       |
|    total_timesteps        | 63488    |
| train/                    |          |
|    explained_variance     | 0.00014  |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00292  |
|    learning_rate          | 0.0003   |
|    n_updates              | 30       |
|    policy_objective       | 0.0035   |
|    value_loss             | 0.00828  |
----------------------------------------
-----------------------------------------
| adaptive/                 |           |
|    adaptation_factor      | 3         |
|    algorithm              | TRPO      |
|    base_lr                | 0.0003    |
|    base_target_kl         | 0.01      |
|    drift_magnitude        | 4e+03     |
|    learning_rate          | 0.0009    |
|    target_kl              | 0.00333   |
| env/                      |           |
|    base_value             | 0.0025    |
|    gravity                | 10        |
| rollout/                  |           |
|    ep_len_mean            | 200       |
|    ep_rew_mean            | -200      |
| time/                     |           |
|    fps                    | 1215      |
|    iterations             | 32        |
|    time_elapsed           | 53        |
|    total_timesteps        | 65536     |
| train/                    |           |
|    explained_variance     | -0.000671 |
|    is_line_search_success | 1         |
|    kl_divergence_loss     | 0.00247   |
|    learning_rate          | 0.0003    |
|    n_updates              | 31        |
|    policy_objective       | 0.00295   |
|    value_loss             | 0.00548   |
-----------------------------------------
-----------------------------------------
| adaptive/                 |           |
|    adaptation_factor      | 3         |
|    algorithm              | TRPO      |
|    base_lr                | 0.0003    |
|    base_target_kl         | 0.01      |
|    drift_magnitude        | 4e+03     |
|    learning_rate          | 0.0009    |
|    target_kl              | 0.00333   |
| env/                      |           |
|    base_value             | 0.0025    |
|    gravity                | 10        |
| rollout/                  |           |
|    ep_len_mean            | 200       |
|    ep_rew_mean            | -200      |
| time/                     |           |
|    fps                    | 1216      |
|    iterations             | 33        |
|    time_elapsed           | 55        |
|    total_timesteps        | 67584     |
| train/                    |           |
|    explained_variance     | -0.000697 |
|    is_line_search_success | 1         |
|    kl_divergence_loss     | 0.00167   |
|    learning_rate          | 0.0003    |
|    n_updates              | 32        |
|    policy_objective       | 0.00119   |
|    value_loss             | 0.00372   |
-----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 3        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 4e+03    |
|    learning_rate          | 0.0009   |
|    target_kl              | 0.00333  |
| env/                      |          |
|    base_value             | 0.0025   |
|    gravity                | 10       |
| rollout/                  |          |
|    ep_len_mean            | 200      |
|    ep_rew_mean            | -200     |
| time/                     |          |
|    fps                    | 1217     |
|    iterations             | 34       |
|    time_elapsed           | 57       |
|    total_timesteps        | 69632    |
| train/                    |          |
|    explained_variance     | 2.67e-05 |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00302  |
|    learning_rate          | 0.0003   |
|    n_updates              | 33       |
|    policy_objective       | 0.00282  |
|    value_loss             | 0.00255  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 3        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 4e+03    |
|    learning_rate          | 0.0009   |
|    target_kl              | 0.00333  |
| env/                      |          |
|    base_value             | 0.0025   |
|    gravity                | 10       |
| rollout/                  |          |
|    ep_len_mean            | 200      |
|    ep_rew_mean            | -200     |
| time/                     |          |
|    fps                    | 1217     |
|    iterations             | 35       |
|    time_elapsed           | 58       |
|    total_timesteps        | 71680    |
| train/                    |          |
|    explained_variance     | 0.000155 |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00223  |
|    learning_rate          | 0.0003   |
|    n_updates              | 34       |
|    policy_objective       | 0.00323  |
|    value_loss             | 0.00183  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 3        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 4e+03    |
|    learning_rate          | 0.0009   |
|    target_kl              | 0.00333  |
| env/                      |          |
|    base_value             | 0.0025   |
|    gravity                | 10       |
| rollout/                  |          |
|    ep_len_mean            | 200      |
|    ep_rew_mean            | -200     |
| time/                     |          |
|    fps                    | 1218     |
|    iterations             | 36       |
|    time_elapsed           | 60       |
|    total_timesteps        | 73728    |
| train/                    |          |
|    explained_variance     | -0.00106 |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00219  |
|    learning_rate          | 0.0003   |
|    n_updates              | 35       |
|    policy_objective       | 0.00165  |
|    value_loss             | 0.00122  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 3        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 4e+03    |
|    learning_rate          | 0.0009   |
|    target_kl              | 0.00333  |
| env/                      |          |
|    base_value             | 0.0025   |
|    gravity                | 10       |
| rollout/                  |          |
|    ep_len_mean            | 200      |
|    ep_rew_mean            | -200     |
| time/                     |          |
|    fps                    | 1220     |
|    iterations             | 37       |
|    time_elapsed           | 62       |
|    total_timesteps        | 75776    |
| train/                    |          |
|    explained_variance     | -0.00017 |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.000478 |
|    learning_rate          | 0.0003   |
|    n_updates              | 36       |
|    policy_objective       | 0.000396 |
|    value_loss             | 0.000841 |
----------------------------------------
-----------------------------------------
| adaptive/                 |           |
|    adaptation_factor      | 3         |
|    algorithm              | TRPO      |
|    base_lr                | 0.0003    |
|    base_target_kl         | 0.01      |
|    drift_magnitude        | 4e+03     |
|    learning_rate          | 0.0009    |
|    target_kl              | 0.00333   |
| env/                      |           |
|    base_value             | 0.0025    |
|    gravity                | 10        |
| rollout/                  |           |
|    ep_len_mean            | 200       |
|    ep_rew_mean            | -200      |
| time/                     |           |
|    fps                    | 1221      |
|    iterations             | 38        |
|    time_elapsed           | 63        |
|    total_timesteps        | 77824     |
| train/                    |           |
|    explained_variance     | -0.000149 |
|    is_line_search_success | 1         |
|    kl_divergence_loss     | 0.00137   |
|    learning_rate          | 0.0003    |
|    n_updates              | 37        |
|    policy_objective       | 0.000447  |
|    value_loss             | 0.000585  |
-----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 3        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 4e+03    |
|    learning_rate          | 0.0009   |
|    target_kl              | 0.00333  |
| env/                      |          |
|    base_value             | 0.0025   |
|    gravity                | 10       |
| rollout/                  |          |
|    ep_len_mean            | 200      |
|    ep_rew_mean            | -200     |
| time/                     |          |
|    fps                    | 1221     |
|    iterations             | 39       |
|    time_elapsed           | 65       |
|    total_timesteps        | 79872    |
| train/                    |          |
|    explained_variance     | 0.0018   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00247  |
|    learning_rate          | 0.0003   |
|    n_updates              | 38       |
|    policy_objective       | 0.00147  |
|    value_loss             | 0.000431 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 3        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 4e+03    |
|    learning_rate          | 0.0009   |
|    target_kl              | 0.00333  |
| env/                      |          |
|    base_value             | 0.0025   |
|    gravity                | 10       |
| rollout/                  |          |
|    ep_len_mean            | 200      |
|    ep_rew_mean            | -200     |
| time/                     |          |
|    fps                    | 1221     |
|    iterations             | 40       |
|    time_elapsed           | 67       |
|    total_timesteps        | 81920    |
| train/                    |          |
|    explained_variance     | -0.0056  |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00276  |
|    learning_rate          | 0.0003   |
|    n_updates              | 39       |
|    policy_objective       | 0.00232  |
|    value_loss             | 0.00029  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 3        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 4e+03    |
|    learning_rate          | 0.0009   |
|    target_kl              | 0.00333  |
| env/                      |          |
|    base_value             | 0.0025   |
|    gravity                | 10       |
| rollout/                  |          |
|    ep_len_mean            | 200      |
|    ep_rew_mean            | -200     |
| time/                     |          |
|    fps                    | 1222     |
|    iterations             | 41       |
|    time_elapsed           | 68       |
|    total_timesteps        | 83968    |
| train/                    |          |
|    explained_variance     | -0.00225 |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00284  |
|    learning_rate          | 0.0003   |
|    n_updates              | 40       |
|    policy_objective       | 0.00117  |
|    value_loss             | 0.0002   |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 3        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 4e+03    |
|    learning_rate          | 0.0009   |
|    target_kl              | 0.00333  |
| env/                      |          |
|    base_value             | 0.0025   |
|    gravity                | 10       |
| rollout/                  |          |
|    ep_len_mean            | 200      |
|    ep_rew_mean            | -200     |
| time/                     |          |
|    fps                    | 1221     |
|    iterations             | 42       |
|    time_elapsed           | 70       |
|    total_timesteps        | 86016    |
| train/                    |          |
|    explained_variance     | -0.00611 |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00247  |
|    learning_rate          | 0.0003   |
|    n_updates              | 41       |
|    policy_objective       | 0.00104  |
|    value_loss             | 0.000142 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 3        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 4e+03    |
|    learning_rate          | 0.0009   |
|    target_kl              | 0.00333  |
| env/                      |          |
|    base_value             | 0.0025   |
|    gravity                | 10       |
| rollout/                  |          |
|    ep_len_mean            | 200      |
|    ep_rew_mean            | -200     |
| time/                     |          |
|    fps                    | 1221     |
|    iterations             | 43       |
|    time_elapsed           | 72       |
|    total_timesteps        | 88064    |
| train/                    |          |
|    explained_variance     | -0.0121  |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00257  |
|    learning_rate          | 0.0003   |
|    n_updates              | 42       |
|    policy_objective       | 0.00181  |
|    value_loss             | 0.000106 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 3        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 4e+03    |
|    learning_rate          | 0.0009   |
|    target_kl              | 0.00333  |
| env/                      |          |
|    base_value             | 0.0025   |
|    gravity                | 10       |
| rollout/                  |          |
|    ep_len_mean            | 200      |
|    ep_rew_mean            | -200     |
| time/                     |          |
|    fps                    | 1222     |
|    iterations             | 44       |
|    time_elapsed           | 73       |
|    total_timesteps        | 90112    |
| train/                    |          |
|    explained_variance     | -0.00766 |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00272  |
|    learning_rate          | 0.0003   |
|    n_updates              | 43       |
|    policy_objective       | 0.00156  |
|    value_loss             | 7.13e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 3        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 4e+03    |
|    learning_rate          | 0.0009   |
|    target_kl              | 0.00333  |
| env/                      |          |
|    base_value             | 0.0025   |
|    gravity                | 10       |
| rollout/                  |          |
|    ep_len_mean            | 200      |
|    ep_rew_mean            | -200     |
| time/                     |          |
|    fps                    | 1223     |
|    iterations             | 45       |
|    time_elapsed           | 75       |
|    total_timesteps        | 92160    |
| train/                    |          |
|    explained_variance     | -0.00991 |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00212  |
|    learning_rate          | 0.0003   |
|    n_updates              | 44       |
|    policy_objective       | 0.00133  |
|    value_loss             | 5.05e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 3        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 4e+03    |
|    learning_rate          | 0.0009   |
|    target_kl              | 0.00333  |
| env/                      |          |
|    base_value             | 0.0025   |
|    gravity                | 10       |
| rollout/                  |          |
|    ep_len_mean            | 200      |
|    ep_rew_mean            | -200     |
| time/                     |          |
|    fps                    | 1225     |
|    iterations             | 46       |
|    time_elapsed           | 76       |
|    total_timesteps        | 94208    |
| train/                    |          |
|    explained_variance     | -0.0192  |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00199  |
|    learning_rate          | 0.0003   |
|    n_updates              | 45       |
|    policy_objective       | 0.00272  |
|    value_loss             | 3.61e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 3        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 4e+03    |
|    learning_rate          | 0.0009   |
|    target_kl              | 0.00333  |
| env/                      |          |
|    base_value             | 0.0025   |
|    gravity                | 10       |
| rollout/                  |          |
|    ep_len_mean            | 200      |
|    ep_rew_mean            | -200     |
| time/                     |          |
|    fps                    | 1226     |
|    iterations             | 47       |
|    time_elapsed           | 78       |
|    total_timesteps        | 96256    |
| train/                    |          |
|    explained_variance     | -0.0168  |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00198  |
|    learning_rate          | 0.0003   |
|    n_updates              | 46       |
|    policy_objective       | 0.00143  |
|    value_loss             | 2.66e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 3        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 4e+03    |
|    learning_rate          | 0.0009   |
|    target_kl              | 0.00333  |
| env/                      |          |
|    base_value             | 0.0025   |
|    gravity                | 10       |
| rollout/                  |          |
|    ep_len_mean            | 200      |
|    ep_rew_mean            | -200     |
| time/                     |          |
|    fps                    | 1227     |
|    iterations             | 48       |
|    time_elapsed           | 80       |
|    total_timesteps        | 98304    |
| train/                    |          |
|    explained_variance     | -0.0375  |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00294  |
|    learning_rate          | 0.0003   |
|    n_updates              | 47       |
|    policy_objective       | 0.00081  |
|    value_loss             | 1.84e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.0003   |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 0.0025   |
|    gravity                | 0.0025   |
| rollout/                  |          |
|    ep_len_mean            | 200      |
|    ep_rew_mean            | -200     |
| time/                     |          |
|    fps                    | 1228     |
|    iterations             | 49       |
|    time_elapsed           | 81       |
|    total_timesteps        | 100352   |
| train/                    |          |
|    explained_variance     | -0.0293  |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00197  |
|    learning_rate          | 0.0003   |
|    n_updates              | 48       |
|    policy_objective       | 0.00144  |
|    value_loss             | 1.37e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.0003   |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 0.0025   |
|    gravity                | 0.0025   |
| rollout/                  |          |
|    ep_len_mean            | 200      |
|    ep_rew_mean            | -200     |
| time/                     |          |
|    fps                    | 1229     |
|    iterations             | 50       |
|    time_elapsed           | 83       |
|    total_timesteps        | 102400   |
| train/                    |          |
|    explained_variance     | -0.0403  |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00869  |
|    learning_rate          | 0.0003   |
|    n_updates              | 49       |
|    policy_objective       | 0.00631  |
|    value_loss             | 9.89e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.0003   |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 0.0025   |
|    gravity                | 0.0025   |
| rollout/                  |          |
|    ep_len_mean            | 200      |
|    ep_rew_mean            | -200     |
| time/                     |          |
|    fps                    | 1228     |
|    iterations             | 51       |
|    time_elapsed           | 85       |
|    total_timesteps        | 104448   |
| train/                    |          |
|    explained_variance     | -0.0277  |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00589  |
|    learning_rate          | 0.0003   |
|    n_updates              | 50       |
|    policy_objective       | 0.00362  |
|    value_loss             | 9.23e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.0003   |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 0.0025   |
|    gravity                | 0.0025   |
| rollout/                  |          |
|    ep_len_mean            | 200      |
|    ep_rew_mean            | -200     |
| time/                     |          |
|    fps                    | 1226     |
|    iterations             | 52       |
|    time_elapsed           | 86       |
|    total_timesteps        | 106496   |
| train/                    |          |
|    explained_variance     | -0.306   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00859  |
|    learning_rate          | 0.0003   |
|    n_updates              | 51       |
|    policy_objective       | 0.00631  |
|    value_loss             | 6.58e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.0003   |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 0.0025   |
|    gravity                | 0.0025   |
| rollout/                  |          |
|    ep_len_mean            | 200      |
|    ep_rew_mean            | -200     |
| time/                     |          |
|    fps                    | 1225     |
|    iterations             | 53       |
|    time_elapsed           | 88       |
|    total_timesteps        | 108544   |
| train/                    |          |
|    explained_variance     | -0.329   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00935  |
|    learning_rate          | 0.0003   |
|    n_updates              | 52       |
|    policy_objective       | 0.00812  |
|    value_loss             | 1.04e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.0003   |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 0.0025   |
|    gravity                | 0.0025   |
| rollout/                  |          |
|    ep_len_mean            | 200      |
|    ep_rew_mean            | -200     |
| time/                     |          |
|    fps                    | 1225     |
|    iterations             | 54       |
|    time_elapsed           | 90       |
|    total_timesteps        | 110592   |
| train/                    |          |
|    explained_variance     | -0.734   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00461  |
|    learning_rate          | 0.0003   |
|    n_updates              | 53       |
|    policy_objective       | 0.0033   |
|    value_loss             | 8.44e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.0003   |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 0.0025   |
|    gravity                | 0.0025   |
| rollout/                  |          |
|    ep_len_mean            | 200      |
|    ep_rew_mean            | -200     |
| time/                     |          |
|    fps                    | 1226     |
|    iterations             | 55       |
|    time_elapsed           | 91       |
|    total_timesteps        | 112640   |
| train/                    |          |
|    explained_variance     | -0.155   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0043   |
|    learning_rate          | 0.0003   |
|    n_updates              | 54       |
|    policy_objective       | 0.0035   |
|    value_loss             | 5.95e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.0003   |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 0.0025   |
|    gravity                | 0.0025   |
| rollout/                  |          |
|    ep_len_mean            | 200      |
|    ep_rew_mean            | -200     |
| time/                     |          |
|    fps                    | 1225     |
|    iterations             | 56       |
|    time_elapsed           | 93       |
|    total_timesteps        | 114688   |
| train/                    |          |
|    explained_variance     | -0.11    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00722  |
|    learning_rate          | 0.0003   |
|    n_updates              | 55       |
|    policy_objective       | 0.00536  |
|    value_loss             | 4.05e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.0003   |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 0.0025   |
|    gravity                | 0.0025   |
| rollout/                  |          |
|    ep_len_mean            | 200      |
|    ep_rew_mean            | -200     |
| time/                     |          |
|    fps                    | 1226     |
|    iterations             | 57       |
|    time_elapsed           | 95       |
|    total_timesteps        | 116736   |
| train/                    |          |
|    explained_variance     | -0.445   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00865  |
|    learning_rate          | 0.0003   |
|    n_updates              | 56       |
|    policy_objective       | 0.00644  |
|    value_loss             | 9.4e-06  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.0003   |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 0.0025   |
|    gravity                | 0.0025   |
| rollout/                  |          |
|    ep_len_mean            | 200      |
|    ep_rew_mean            | -200     |
| time/                     |          |
|    fps                    | 1226     |
|    iterations             | 58       |
|    time_elapsed           | 96       |
|    total_timesteps        | 118784   |
| train/                    |          |
|    explained_variance     | -1.07    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00784  |
|    learning_rate          | 0.0003   |
|    n_updates              | 57       |
|    policy_objective       | 0.00171  |
|    value_loss             | 9.94e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.0003   |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 0.0025   |
|    gravity                | 0.0025   |
| rollout/                  |          |
|    ep_len_mean            | 200      |
|    ep_rew_mean            | -200     |
| time/                     |          |
|    fps                    | 1225     |
|    iterations             | 59       |
|    time_elapsed           | 98       |
|    total_timesteps        | 120832   |
| train/                    |          |
|    explained_variance     | -0.382   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0079   |
|    learning_rate          | 0.0003   |
|    n_updates              | 58       |
|    policy_objective       | 0.00561  |
|    value_loss             | 4.72e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.0003   |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 0.0025   |
|    gravity                | 0.0025   |
| rollout/                  |          |
|    ep_len_mean            | 200      |
|    ep_rew_mean            | -200     |
| time/                     |          |
|    fps                    | 1225     |
|    iterations             | 60       |
|    time_elapsed           | 100      |
|    total_timesteps        | 122880   |
| train/                    |          |
|    explained_variance     | 0.157    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00435  |
|    learning_rate          | 0.0003   |
|    n_updates              | 59       |
|    policy_objective       | 0.00448  |
|    value_loss             | 1.85e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.0003   |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 0.0025   |
|    gravity                | 0.0025   |
| rollout/                  |          |
|    ep_len_mean            | 200      |
|    ep_rew_mean            | -200     |
| time/                     |          |
|    fps                    | 1225     |
|    iterations             | 61       |
|    time_elapsed           | 101      |
|    total_timesteps        | 124928   |
| train/                    |          |
|    explained_variance     | -0.485   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0069   |
|    learning_rate          | 0.0003   |
|    n_updates              | 60       |
|    policy_objective       | 0.00661  |
|    value_loss             | 2.26e-05 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.0003   |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 0.0025   |
|    gravity                | 0.0025   |
| rollout/                  |          |
|    ep_len_mean            | 200      |
|    ep_rew_mean            | -200     |
| time/                     |          |
|    fps                    | 1226     |
|    iterations             | 62       |
|    time_elapsed           | 103      |
|    total_timesteps        | 126976   |
| train/                    |          |
|    explained_variance     | -0.535   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00868  |
|    learning_rate          | 0.0003   |
|    n_updates              | 61       |
|    policy_objective       | 0.00325  |
|    value_loss             | 3.59e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.0003   |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 0.0025   |
|    gravity                | 0.0025   |
| rollout/                  |          |
|    ep_len_mean            | 200      |
|    ep_rew_mean            | -200     |
| time/                     |          |
|    fps                    | 1226     |
|    iterations             | 63       |
|    time_elapsed           | 105      |
|    total_timesteps        | 129024   |
| train/                    |          |
|    explained_variance     | -1.15    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00769  |
|    learning_rate          | 0.0003   |
|    n_updates              | 62       |
|    policy_objective       | 0.0131   |
|    value_loss             | 1.1e-05  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.0003   |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 0.0025   |
|    gravity                | 0.0025   |
| rollout/                  |          |
|    ep_len_mean            | 200      |
|    ep_rew_mean            | -200     |
| time/                     |          |
|    fps                    | 1226     |
|    iterations             | 64       |
|    time_elapsed           | 106      |
|    total_timesteps        | 131072   |
| train/                    |          |
|    explained_variance     | -0.366   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00477  |
|    learning_rate          | 0.0003   |
|    n_updates              | 63       |
|    policy_objective       | 0.00279  |
|    value_loss             | 7.97e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.0003   |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 0.0025   |
|    gravity                | 0.0025   |
| rollout/                  |          |
|    ep_len_mean            | 200      |
|    ep_rew_mean            | -200     |
| time/                     |          |
|    fps                    | 1225     |
|    iterations             | 65       |
|    time_elapsed           | 108      |
|    total_timesteps        | 133120   |
| train/                    |          |
|    explained_variance     | -0.807   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00141  |
|    learning_rate          | 0.0003   |
|    n_updates              | 64       |
|    policy_objective       | 0.00158  |
|    value_loss             | 3.07e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.0003   |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 0.0025   |
|    gravity                | 0.0025   |
| rollout/                  |          |
|    ep_len_mean            | 200      |
|    ep_rew_mean            | -200     |
| time/                     |          |
|    fps                    | 1226     |
|    iterations             | 66       |
|    time_elapsed           | 110      |
|    total_timesteps        | 135168   |
| train/                    |          |
|    explained_variance     | -0.354   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00604  |
|    learning_rate          | 0.0003   |
|    n_updates              | 65       |
|    policy_objective       | 0.0046   |
|    value_loss             | 2.13e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.0003   |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 0.0025   |
|    gravity                | 0.0025   |
| rollout/                  |          |
|    ep_len_mean            | 200      |
|    ep_rew_mean            | -200     |
| time/                     |          |
|    fps                    | 1227     |
|    iterations             | 67       |
|    time_elapsed           | 111      |
|    total_timesteps        | 137216   |
| train/                    |          |
|    explained_variance     | 0.337    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00589  |
|    learning_rate          | 0.0003   |
|    n_updates              | 66       |
|    policy_objective       | 0.00306  |
|    value_loss             | 8.04e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.0003   |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 0.0025   |
|    gravity                | 0.0025   |
| rollout/                  |          |
|    ep_len_mean            | 200      |
|    ep_rew_mean            | -200     |
| time/                     |          |
|    fps                    | 1228     |
|    iterations             | 68       |
|    time_elapsed           | 113      |
|    total_timesteps        | 139264   |
| train/                    |          |
|    explained_variance     | -0.0475  |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00699  |
|    learning_rate          | 0.0003   |
|    n_updates              | 67       |
|    policy_objective       | 0.00377  |
|    value_loss             | 5.98e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.0003   |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 0.0025   |
|    gravity                | 0.0025   |
| rollout/                  |          |
|    ep_len_mean            | 200      |
|    ep_rew_mean            | -200     |
| time/                     |          |
|    fps                    | 1229     |
|    iterations             | 69       |
|    time_elapsed           | 114      |
|    total_timesteps        | 141312   |
| train/                    |          |
|    explained_variance     | -0.328   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00308  |
|    learning_rate          | 0.0003   |
|    n_updates              | 68       |
|    policy_objective       | 0.00336  |
|    value_loss             | 3.99e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.0003   |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 0.0025   |
|    gravity                | 0.0025   |
| rollout/                  |          |
|    ep_len_mean            | 200      |
|    ep_rew_mean            | -200     |
| time/                     |          |
|    fps                    | 1230     |
|    iterations             | 70       |
|    time_elapsed           | 116      |
|    total_timesteps        | 143360   |
| train/                    |          |
|    explained_variance     | -0.115   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00383  |
|    learning_rate          | 0.0003   |
|    n_updates              | 69       |
|    policy_objective       | 0.00107  |
|    value_loss             | 3.85e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.0003   |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 0.0025   |
|    gravity                | 0.0025   |
| rollout/                  |          |
|    ep_len_mean            | 200      |
|    ep_rew_mean            | -200     |
| time/                     |          |
|    fps                    | 1230     |
|    iterations             | 71       |
|    time_elapsed           | 118      |
|    total_timesteps        | 145408   |
| train/                    |          |
|    explained_variance     | -0.569   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00616  |
|    learning_rate          | 0.0003   |
|    n_updates              | 70       |
|    policy_objective       | 0.00233  |
|    value_loss             | 5.2e-06  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.0003   |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 0.0025   |
|    gravity                | 0.0025   |
| rollout/                  |          |
|    ep_len_mean            | 200      |
|    ep_rew_mean            | -200     |
| time/                     |          |
|    fps                    | 1230     |
|    iterations             | 72       |
|    time_elapsed           | 119      |
|    total_timesteps        | 147456   |
| train/                    |          |
|    explained_variance     | -0.0681  |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00689  |
|    learning_rate          | 0.0003   |
|    n_updates              | 71       |
|    policy_objective       | 0.00224  |
|    value_loss             | 2.15e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 1        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 0        |
|    learning_rate          | 0.0003   |
|    target_kl              | 0.01     |
| env/                      |          |
|    base_value             | 0.0025   |
|    gravity                | 0.0025   |
| rollout/                  |          |
|    ep_len_mean            | 200      |
|    ep_rew_mean            | -200     |
| time/                     |          |
|    fps                    | 1231     |
|    iterations             | 73       |
|    time_elapsed           | 121      |
|    total_timesteps        | 149504   |
| train/                    |          |
|    explained_variance     | -0.853   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00572  |
|    learning_rate          | 0.0003   |
|    n_updates              | 72       |
|    policy_objective       | 0.00277  |
|    value_loss             | 1.3e-06  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 3        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 4e+03    |
|    learning_rate          | 0.0009   |
|    target_kl              | 0.00333  |
| env/                      |          |
|    base_value             | 0.0025   |
|    gravity                | 10       |
| rollout/                  |          |
|    ep_len_mean            | 200      |
|    ep_rew_mean            | -200     |
| time/                     |          |
|    fps                    | 1230     |
|    iterations             | 74       |
|    time_elapsed           | 123      |
|    total_timesteps        | 151552   |
| train/                    |          |
|    explained_variance     | 0.305    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0066   |
|    learning_rate          | 0.0003   |
|    n_updates              | 73       |
|    policy_objective       | 0.00751  |
|    value_loss             | 3.52e-06 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 3        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 4e+03    |
|    learning_rate          | 0.0009   |
|    target_kl              | 0.00333  |
| env/                      |          |
|    base_value             | 0.0025   |
|    gravity                | 10       |
| rollout/                  |          |
|    ep_len_mean            | 200      |
|    ep_rew_mean            | -200     |
| time/                     |          |
|    fps                    | 1230     |
|    iterations             | 75       |
|    time_elapsed           | 124      |
|    total_timesteps        | 153600   |
| train/                    |          |
|    explained_variance     | 0.253    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00233  |
|    learning_rate          | 0.0003   |
|    n_updates              | 74       |
|    policy_objective       | 0.000764 |
|    value_loss             | 8.12e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 3        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 4e+03    |
|    learning_rate          | 0.0009   |
|    target_kl              | 0.00333  |
| env/                      |          |
|    base_value             | 0.0025   |
|    gravity                | 10       |
| rollout/                  |          |
|    ep_len_mean            | 200      |
|    ep_rew_mean            | -200     |
| time/                     |          |
|    fps                    | 1230     |
|    iterations             | 76       |
|    time_elapsed           | 126      |
|    total_timesteps        | 155648   |
| train/                    |          |
|    explained_variance     | -3.05    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00228  |
|    learning_rate          | 0.0003   |
|    n_updates              | 75       |
|    policy_objective       | 0.0014   |
|    value_loss             | 2.68e-08 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 3        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 4e+03    |
|    learning_rate          | 0.0009   |
|    target_kl              | 0.00333  |
| env/                      |          |
|    base_value             | 0.0025   |
|    gravity                | 10       |
| rollout/                  |          |
|    ep_len_mean            | 200      |
|    ep_rew_mean            | -200     |
| time/                     |          |
|    fps                    | 1229     |
|    iterations             | 77       |
|    time_elapsed           | 128      |
|    total_timesteps        | 157696   |
| train/                    |          |
|    explained_variance     | -1.83    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00231  |
|    learning_rate          | 0.0003   |
|    n_updates              | 76       |
|    policy_objective       | 0.00245  |
|    value_loss             | 1.95e-08 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 3        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 4e+03    |
|    learning_rate          | 0.0009   |
|    target_kl              | 0.00333  |
| env/                      |          |
|    base_value             | 0.0025   |
|    gravity                | 10       |
| rollout/                  |          |
|    ep_len_mean            | 200      |
|    ep_rew_mean            | -200     |
| time/                     |          |
|    fps                    | 1228     |
|    iterations             | 78       |
|    time_elapsed           | 129      |
|    total_timesteps        | 159744   |
| train/                    |          |
|    explained_variance     | -5.11    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00247  |
|    learning_rate          | 0.0003   |
|    n_updates              | 77       |
|    policy_objective       | 0.000708 |
|    value_loss             | 2.56e-08 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 3        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 4e+03    |
|    learning_rate          | 0.0009   |
|    target_kl              | 0.00333  |
| env/                      |          |
|    base_value             | 0.0025   |
|    gravity                | 10       |
| rollout/                  |          |
|    ep_len_mean            | 200      |
|    ep_rew_mean            | -200     |
| time/                     |          |
|    fps                    | 1227     |
|    iterations             | 79       |
|    time_elapsed           | 131      |
|    total_timesteps        | 161792   |
| train/                    |          |
|    explained_variance     | -1.77    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.000725 |
|    learning_rate          | 0.0003   |
|    n_updates              | 78       |
|    policy_objective       | 0.000153 |
|    value_loss             | 1.56e-07 |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 3        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 4e+03    |
|    learning_rate          | 0.0009   |
|    target_kl              | 0.00333  |
| env/                      |          |
|    base_value             | 0.0025   |
|    gravity                | 10       |
| rollout/                  |          |
|    ep_len_mean            | 200      |
|    ep_rew_mean            | -200     |
| time/                     |          |
|    fps                    | 1227     |
|    iterations             | 80       |
|    time_elapsed           | 133      |
|    total_timesteps        | 163840   |
| train/                    |          |
|    explained_variance     | -1.59    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00221  |
|    learning_rate          | 0.0003   |
|    n_updates              | 79       |
|    policy_objective       | 0.001    |
|    value_loss             | 2.9e-07  |
----------------------------------------
----------------------------------------
| adaptive/                 |          |
|    adaptation_factor      | 3        |
|    algorithm              | TRPO     |
|    base_lr                | 0.0003   |
|    base_target_kl         | 0.01     |
|    drift_magnitude        | 4e+03    |
|    learning_rate          | 0.0009   |
|    target_kl              | 0.00333  |
| env/                      |          |
|    base_value             | 0.0025   |
|    gravity                | 10       |
| rollout/                  |          |
|    ep_len_mean            | 200      |
|    ep_rew_mean            | -200     |
| time/                     |          |
|    fps                    | 1228     |
|    iterations             | 81       |
|    time_elapsed           | 135      |
|    total_timesteps        | 165888   |
| train/                    |          |
|    explained_variance     | -2.28    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00219  |
|    learning_rate          | 0.0003   |
|    n_updates              | 80       |
|    policy_objective       | 0.00118  |
|    value_loss             | 3.2e-07  |
----------------------------------------
